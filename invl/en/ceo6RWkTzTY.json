{
  "video_id": "ceo6RWkTzTY",
  "title": "Reynold Xin | Spark Summit 2017",
  "es": 0,
  "json": [
    {
      "index": 1,
      "start_time": 1236.0,
      "end_time": 3666.0,
      "text": ">> Narrator: Live from San Francisco,"
    },
    {
      "index": 2,
      "start_time": 3666.0,
      "end_time": 5106.0,
      "text": "it's theCUBE,"
    },
    {
      "index": 3,
      "start_time": 5106.0,
      "end_time": 7597.0,
      "text": "covering Spark Summit 2017."
    },
    {
      "index": 4,
      "start_time": 7597.0,
      "end_time": 10014.0,
      "text": "Brought to you by Databricks."
    },
    {
      "index": 5,
      "start_time": 15330.0,
      "end_time": 19497.0,
      "text": ">> Welcome back we're here at\ntheCube at Spark Summit 2017."
    },
    {
      "index": 6,
      "start_time": 20340.0,
      "end_time": 22871.0,
      "text": "I'm David Goad here with\nGeorge Gilbert, George."
    },
    {
      "index": 7,
      "start_time": 22871.0,
      "end_time": 23896.0,
      "text": ">> Good to be here."
    },
    {
      "index": 8,
      "start_time": 23896.0,
      "end_time": 24769.0,
      "text": ">> Thanks for hanging with us."
    },
    {
      "index": 9,
      "start_time": 24769.0,
      "end_time": 26103.0,
      "text": "Well here's the other\nman of the hour here."
    },
    {
      "index": 10,
      "start_time": 26103.0,
      "end_time": 28430.0,
      "text": "We just talked with Ali,\nthe CEO at Databricks"
    },
    {
      "index": 11,
      "start_time": 28430.0,
      "end_time": 30439.0,
      "text": "and now we have the Chief Architect"
    },
    {
      "index": 12,
      "start_time": 30439.0,
      "end_time": 34102.0,
      "text": "and co-founder at Databricks, Reynold Xin."
    },
    {
      "index": 13,
      "start_time": 34102.0,
      "end_time": 35019.0,
      "text": "Reynold, how are you?"
    },
    {
      "index": 14,
      "start_time": 35019.0,
      "end_time": 36648.0,
      "text": ">> I'm good. How are you doing?"
    },
    {
      "index": 15,
      "start_time": 36648.0,
      "end_time": 37656.0,
      "text": ">> David: Awesome."
    },
    {
      "index": 16,
      "start_time": 37656.0,
      "end_time": 38751.0,
      "text": "Enjoying yourself here at the show?"
    },
    {
      "index": 17,
      "start_time": 38751.0,
      "end_time": 40319.0,
      "text": ">> Absolutely, it's fantastic."
    },
    {
      "index": 18,
      "start_time": 40319.0,
      "end_time": 41433.0,
      "text": "It's the largest Summit."
    },
    {
      "index": 19,
      "start_time": 41433.0,
      "end_time": 42794.0,
      "text": "It's a lot interesting things,"
    },
    {
      "index": 20,
      "start_time": 42794.0,
      "end_time": 44404.0,
      "text": "a lot of interesting\npeople with who I meet."
    },
    {
      "index": 21,
      "start_time": 44404.0,
      "end_time": 46042.0,
      "text": ">> Well I know you're a really humble guy"
    },
    {
      "index": 22,
      "start_time": 46042.0,
      "end_time": 48982.0,
      "text": "but I had to ask Ali\nwhat should I ask Reynold"
    },
    {
      "index": 23,
      "start_time": 48982.0,
      "end_time": 49815.0,
      "text": "when he gets up here."
    },
    {
      "index": 24,
      "start_time": 49815.0,
      "end_time": 51943.0,
      "text": "Reynold is one of the biggest\ncontributors to Spark."
    },
    {
      "index": 25,
      "start_time": 51943.0,
      "end_time": 54553.0,
      "text": "And you've been with us\nfor a long time right?"
    },
    {
      "index": 26,
      "start_time": 54553.0,
      "end_time": 57481.0,
      "text": ">> Yes, I've been contributing for Spark"
    },
    {
      "index": 27,
      "start_time": 57481.0,
      "end_time": 59404.0,
      "text": "for about five or six years"
    },
    {
      "index": 28,
      "start_time": 59404.0,
      "end_time": 62740.0,
      "text": "and that's probably the most number"
    },
    {
      "index": 29,
      "start_time": 62740.0,
      "end_time": 64702.0,
      "text": "of commits to the project"
    },
    {
      "index": 30,
      "start_time": 64702.0,
      "end_time": 67277.0,
      "text": "and lately more I'm\nworking with other people"
    },
    {
      "index": 31,
      "start_time": 67277.0,
      "end_time": 68924.0,
      "text": "to help design the roadmap"
    },
    {
      "index": 32,
      "start_time": 68924.0,
      "end_time": 71542.0,
      "text": "for both Spark and Databricks with them."
    },
    {
      "index": 33,
      "start_time": 71542.0,
      "end_time": 72954.0,
      "text": ">> Well let's get started\ntalking about some"
    },
    {
      "index": 34,
      "start_time": 72954.0,
      "end_time": 74292.0,
      "text": "of the new developments that you want"
    },
    {
      "index": 35,
      "start_time": 74292.0,
      "end_time": 76420.0,
      "text": "maybe our audience at theCUBE hasn't heard"
    },
    {
      "index": 36,
      "start_time": 76420.0,
      "end_time": 78158.0,
      "text": "here in the keynote this morning."
    },
    {
      "index": 37,
      "start_time": 78158.0,
      "end_time": 80631.0,
      "text": "What are some of the most\nexciting new developments?"
    },
    {
      "index": 38,
      "start_time": 80631.0,
      "end_time": 82431.0,
      "text": ">> So, I think in general\nif we look at Spark,"
    },
    {
      "index": 39,
      "start_time": 82431.0,
      "end_time": 85462.0,
      "text": "there are three directions I\nwould say we doubling down."
    },
    {
      "index": 40,
      "start_time": 85462.0,
      "end_time": 88421.0,
      "text": "One the first direction\nis the deep learning."
    },
    {
      "index": 41,
      "start_time": 88421.0,
      "end_time": 92105.0,
      "text": "Deep learning is extremely\nhot and it's very capable"
    },
    {
      "index": 42,
      "start_time": 92105.0,
      "end_time": 95675.0,
      "text": "but as we alluded to\nearlier in a blog post,"
    },
    {
      "index": 43,
      "start_time": 95675.0,
      "end_time": 98700.0,
      "text": "deep learning has reached\nsort of a mass produced point"
    },
    {
      "index": 44,
      "start_time": 98700.0,
      "end_time": 101507.0,
      "text": "in which it shows tremendous\npotential but the tools"
    },
    {
      "index": 45,
      "start_time": 101507.0,
      "end_time": 103126.0,
      "text": "are very difficult to use."
    },
    {
      "index": 46,
      "start_time": 103126.0,
      "end_time": 105582.0,
      "text": "And we are hoping to\ndemocratize deep learning"
    },
    {
      "index": 47,
      "start_time": 105582.0,
      "end_time": 108967.0,
      "text": "and do what Spark did to\nbig data, to deep learning"
    },
    {
      "index": 48,
      "start_time": 108967.0,
      "end_time": 111711.0,
      "text": "with this new library called\ndeep learning pipelines."
    },
    {
      "index": 49,
      "start_time": 111711.0,
      "end_time": 114059.0,
      "text": "What it does, it integrates different"
    },
    {
      "index": 50,
      "start_time": 114059.0,
      "end_time": 116703.0,
      "text": "deep learning libraries directly in Spark"
    },
    {
      "index": 51,
      "start_time": 116703.0,
      "end_time": 119719.0,
      "text": "and can actually expose models in sequel."
    },
    {
      "index": 52,
      "start_time": 119719.0,
      "end_time": 121301.0,
      "text": "So, even the business analysts"
    },
    {
      "index": 53,
      "start_time": 121301.0,
      "end_time": 122968.0,
      "text": "are capable of leveraging that."
    },
    {
      "index": 54,
      "start_time": 122968.0,
      "end_time": 124524.0,
      "text": "So, that one area, deep learning."
    },
    {
      "index": 55,
      "start_time": 124524.0,
      "end_time": 126287.0,
      "text": "The second area is streaming."
    },
    {
      "index": 56,
      "start_time": 126287.0,
      "end_time": 129870.0,
      "text": "Streaming, again, I think\nthat a lot of customers"
    },
    {
      "index": 57,
      "start_time": 129870.0,
      "end_time": 133387.0,
      "text": "have aspirations to\nactually shorten the latency"
    },
    {
      "index": 58,
      "start_time": 133387.0,
      "end_time": 136553.0,
      "text": "and increase the throughput in streaming."
    },
    {
      "index": 59,
      "start_time": 136553.0,
      "end_time": 140703.0,
      "text": "So, the structured streaming\neffort is going to be"
    },
    {
      "index": 60,
      "start_time": 140703.0,
      "end_time": 143298.0,
      "text": "generally available and last month alone"
    },
    {
      "index": 61,
      "start_time": 143298.0,
      "end_time": 144817.0,
      "text": "on Databricks platform,"
    },
    {
      "index": 62,
      "start_time": 144817.0,
      "end_time": 148398.0,
      "text": "I think out customers processed\nthree trillion records,"
    },
    {
      "index": 63,
      "start_time": 148398.0,
      "end_time": 150684.0,
      "text": "last month alone using\nstructured streaming."
    },
    {
      "index": 64,
      "start_time": 150684.0,
      "end_time": 153220.0,
      "text": "And we also have a new\neffort to actually push down"
    },
    {
      "index": 65,
      "start_time": 153220.0,
      "end_time": 156711.0,
      "text": "the latency all the way\nto some millisecond range."
    },
    {
      "index": 66,
      "start_time": 156711.0,
      "end_time": 161300.0,
      "text": "So, you can really do blazingly\nfast streaming analytics."
    },
    {
      "index": 67,
      "start_time": 161300.0,
      "end_time": 164260.0,
      "text": "And last but not least is the\nSEQUEL Data Warehousing area,"
    },
    {
      "index": 68,
      "start_time": 164260.0,
      "end_time": 168427.0,
      "text": "Data warehousing I think\nthat it's a very mature area"
    },
    {
      "index": 69,
      "start_time": 169498.0,
      "end_time": 172262.0,
      "text": "from the outset of big data point of view,"
    },
    {
      "index": 70,
      "start_time": 172262.0,
      "end_time": 174457.0,
      "text": "but from a big data one\nit's still pretty new"
    },
    {
      "index": 71,
      "start_time": 174457.0,
      "end_time": 178498.0,
      "text": "and there's a lot of use\ncases that's popping up there."
    },
    {
      "index": 72,
      "start_time": 178498.0,
      "end_time": 181788.0,
      "text": "And Spark with approaches like\nthe CBO and also impact here"
    },
    {
      "index": 73,
      "start_time": 181788.0,
      "end_time": 184040.0,
      "text": "in the database runtime with DBIO,"
    },
    {
      "index": 74,
      "start_time": 184040.0,
      "end_time": 186101.0,
      "text": "we're actually substantially\nimproving the performance"
    },
    {
      "index": 75,
      "start_time": 186101.0,
      "end_time": 188971.0,
      "text": "and the capabilities of\ndata warehousing futures."
    },
    {
      "index": 76,
      "start_time": 188971.0,
      "end_time": 190869.0,
      "text": ">> We're going to dig in to\nsome of those technologies here"
    },
    {
      "index": 77,
      "start_time": 190869.0,
      "end_time": 192183.0,
      "text": "in just a second with George."
    },
    {
      "index": 78,
      "start_time": 192183.0,
      "end_time": 194261.0,
      "text": "But have you heard anything\nhere so far from anyone"
    },
    {
      "index": 79,
      "start_time": 194261.0,
      "end_time": 198428.0,
      "text": "that's changed your mind maybe\nabout what to focus on next?"
    },
    {
      "index": 80,
      "start_time": 199357.0,
      "end_time": 203865.0,
      "text": "So, one thing I've heard\nfrom a few customers"
    },
    {
      "index": 81,
      "start_time": 203865.0,
      "end_time": 206106.0,
      "text": "is actually visibility and debugability"
    },
    {
      "index": 82,
      "start_time": 206106.0,
      "end_time": 208424.0,
      "text": "of the big data jobs."
    },
    {
      "index": 83,
      "start_time": 208424.0,
      "end_time": 210342.0,
      "text": "So many of them are\nfairly technical engineers"
    },
    {
      "index": 84,
      "start_time": 210342.0,
      "end_time": 212464.0,
      "text": "and some of them are less\nsophisticated engineers"
    },
    {
      "index": 85,
      "start_time": 212464.0,
      "end_time": 215487.0,
      "text": "and they have written jobs and\nsometimes the job runs slow."
    },
    {
      "index": 86,
      "start_time": 215487.0,
      "end_time": 219159.0,
      "text": "And so the performance\nengineer in me would think"
    },
    {
      "index": 87,
      "start_time": 219159.0,
      "end_time": 221139.0,
      "text": "so how do I make the job run fast?"
    },
    {
      "index": 88,
      "start_time": 221139.0,
      "end_time": 223617.0,
      "text": "The different way to\nactually solve that problem"
    },
    {
      "index": 89,
      "start_time": 223617.0,
      "end_time": 225198.0,
      "text": "is how can we expose the right information"
    },
    {
      "index": 90,
      "start_time": 225198.0,
      "end_time": 226711.0,
      "text": "so the customer can actually understand"
    },
    {
      "index": 91,
      "start_time": 226711.0,
      "end_time": 228231.0,
      "text": "and figure it out themselves."
    },
    {
      "index": 92,
      "start_time": 228231.0,
      "end_time": 230912.0,
      "text": "This is why my job is slow\nand this how I can tweak it"
    },
    {
      "index": 93,
      "start_time": 230912.0,
      "end_time": 232170.0,
      "text": "to make it faster."
    },
    {
      "index": 94,
      "start_time": 232170.0,
      "end_time": 234411.0,
      "text": "Rather than giving people the fish,"
    },
    {
      "index": 95,
      "start_time": 234411.0,
      "end_time": 236769.0,
      "text": "you actually give them the tools to fish."
    },
    {
      "index": 96,
      "start_time": 236769.0,
      "end_time": 238031.0,
      "text": ">> If you can call that bugability."
    },
    {
      "index": 97,
      "start_time": 238031.0,
      "end_time": 238956.0,
      "text": ">> Reynold: Yeah, Debugability."
    },
    {
      "index": 98,
      "start_time": 238956.0,
      "end_time": 239792.0,
      "text": ">> Debugability."
    },
    {
      "index": 99,
      "start_time": 239792.0,
      "end_time": 241116.0,
      "text": ">> Reynold: And visibility, yeah."
    },
    {
      "index": 100,
      "start_time": 241116.0,
      "end_time": 242177.0,
      "text": ">> Alright, awesome, George."
    },
    {
      "index": 101,
      "start_time": 242177.0,
      "end_time": 245857.0,
      "text": ">> So, let's go back\nand unpack some of those"
    },
    {
      "index": 102,
      "start_time": 245857.0,
      "end_time": 248376.0,
      "text": "kind of juicy areas that you identified,"
    },
    {
      "index": 103,
      "start_time": 248376.0,
      "end_time": 252126.0,
      "text": "on deep learning you\nwere able to distribute,"
    },
    {
      "index": 104,
      "start_time": 254973.0,
      "end_time": 257896.0,
      "text": "if I understand things\nright, the predictions."
    },
    {
      "index": 105,
      "start_time": 257896.00000000003,
      "end_time": 260805.00000000003,
      "text": "You could put models out on a cluster"
    },
    {
      "index": 106,
      "start_time": 260805.0,
      "end_time": 264628.0,
      "text": "but the really hard part,\nthe compute intensive stuff,"
    },
    {
      "index": 107,
      "start_time": 264628.0,
      "end_time": 267653.0,
      "text": "was training across a cluster."
    },
    {
      "index": 108,
      "start_time": 267653.0,
      "end_time": 271820.0,
      "text": "And so Deep Learning, 4J\nand I think Intel's BigDL,"
    },
    {
      "index": 109,
      "start_time": 273291.0,
      "end_time": 277008.0,
      "text": "they were written for Spark to do that."
    },
    {
      "index": 110,
      "start_time": 277008.0,
      "end_time": 280363.0,
      "text": "But with all the excitement\nover some of the new frameworks,"
    },
    {
      "index": 111,
      "start_time": 280363.0,
      "end_time": 284702.0,
      "text": "are they now at the point\nwhere they are as good citizens"
    },
    {
      "index": 112,
      "start_time": 284702.0,
      "end_time": 288894.0,
      "text": "on Spark as they are on\ntheir native environments?"
    },
    {
      "index": 113,
      "start_time": 288894.0,
      "end_time": 290450.0,
      "text": ">> Yeah so, this is a\nvery interesting question,"
    },
    {
      "index": 114,
      "start_time": 290450.0,
      "end_time": 292293.0,
      "text": "obviously a lot of other frameworks"
    },
    {
      "index": 115,
      "start_time": 292293.0,
      "end_time": 293645.0,
      "text": "are becoming more and more popular,"
    },
    {
      "index": 116,
      "start_time": 293645.0,
      "end_time": 298479.0,
      "text": "such as TensorFlow, MXNet,\nTheano, Keras and Office."
    },
    {
      "index": 117,
      "start_time": 298479.0,
      "end_time": 301573.0,
      "text": "What the Deep Learning\nPipeline library does,"
    },
    {
      "index": 118,
      "start_time": 301573.0,
      "end_time": 304481.0,
      "text": "is actually exposes all these single note"
    },
    {
      "index": 119,
      "start_time": 304481.0,
      "end_time": 306333.0,
      "text": "Deep Learning tools as highly optimized"
    },
    {
      "index": 120,
      "start_time": 306333.0,
      "end_time": 310500.0,
      "text": "for say even GPUs or CPUs, to\nbe available as a estimator"
    },
    {
      "index": 121,
      "start_time": 311731.0,
      "end_time": 314359.0,
      "text": "or like a module in a pipeline\nof the machine learning"
    },
    {
      "index": 122,
      "start_time": 314359.0,
      "end_time": 316247.0,
      "text": "pipeline library in spark."
    },
    {
      "index": 123,
      "start_time": 316247.0,
      "end_time": 319533.0,
      "text": "So, now users can actually\nleverage Spark's capability to,"
    },
    {
      "index": 124,
      "start_time": 319533.0,
      "end_time": 321999.0,
      "text": "for example, do hyper parameter churning."
    },
    {
      "index": 125,
      "start_time": 321999.0,
      "end_time": 323808.0,
      "text": "So, when you're building\na machine learning model,"
    },
    {
      "index": 126,
      "start_time": 323808.0,
      "end_time": 326506.0,
      "text": "it's fairly rare that you\njust run something once"
    },
    {
      "index": 127,
      "start_time": 326506.0,
      "end_time": 327621.0,
      "text": "and you're good with it."
    },
    {
      "index": 128,
      "start_time": 327621.0,
      "end_time": 330412.0,
      "text": "Usually have to fiddle with\na lot of the parameters."
    },
    {
      "index": 129,
      "start_time": 330412.0,
      "end_time": 333390.0,
      "text": "For example, you might run\nover a hundred experiments"
    },
    {
      "index": 130,
      "start_time": 333390.0,
      "end_time": 336495.0,
      "text": "to actually figure out what\nis the best model I can get."
    },
    {
      "index": 131,
      "start_time": 336495.0,
      "end_time": 338655.0,
      "text": "This is where actually\nSpark really shines."
    },
    {
      "index": 132,
      "start_time": 338655.0,
      "end_time": 341300.0,
      "text": "When you combine Spark with\nsome deep learning library"
    },
    {
      "index": 133,
      "start_time": 341300.0,
      "end_time": 344889.0,
      "text": "be it BigDL or be it\nMXNet, be it TensorFlow,"
    },
    {
      "index": 134,
      "start_time": 344889.0,
      "end_time": 347380.0,
      "text": "you could be using Spark\nto distribute that training"
    },
    {
      "index": 135,
      "start_time": 347380.0,
      "end_time": 349317.0,
      "text": "and then do cross validation on it."
    },
    {
      "index": 136,
      "start_time": 349317.0,
      "end_time": 351827.0,
      "text": "So you can actually find\nthe best model very quickly."
    },
    {
      "index": 137,
      "start_time": 351827.0,
      "end_time": 353644.0,
      "text": "And Spark takes care of\nall the job scheduling,"
    },
    {
      "index": 138,
      "start_time": 353644.0,
      "end_time": 356112.0,
      "text": "all the tolerance properties\nand how do you read data"
    },
    {
      "index": 139,
      "start_time": 356112.0,
      "end_time": 358225.0,
      "text": "in from different data sources."
    },
    {
      "index": 140,
      "start_time": 358225.0,
      "end_time": 362225.0,
      "text": ">> And without my dropping\ntoo much in the weeds,"
    },
    {
      "index": 141,
      "start_time": 363281.0,
      "end_time": 366871.0,
      "text": "there was a version of that\nwhere Spark wouldn't take care"
    },
    {
      "index": 142,
      "start_time": 366871.0,
      "end_time": 368842.0,
      "text": "of all the communications."
    },
    {
      "index": 143,
      "start_time": 368842.0,
      "end_time": 373009.0,
      "text": "It would maybe distribute\nthe models and then do some"
    },
    {
      "index": 144,
      "start_time": 374520.0,
      "end_time": 377903.0,
      "text": "of the averaging of what\nwas done out on the cluster."
    },
    {
      "index": 145,
      "start_time": 377903.0,
      "end_time": 381420.0,
      "text": "Are you saying that all that\nnow can be managed by Spark?"
    },
    {
      "index": 146,
      "start_time": 381420.0,
      "end_time": 384491.0,
      "text": ">> In that library, Spark\nwill be able to actually"
    },
    {
      "index": 147,
      "start_time": 384491.0,
      "end_time": 386884.0,
      "text": "take care of picking the\nbest model out of it."
    },
    {
      "index": 148,
      "start_time": 386884.0,
      "end_time": 388423.0,
      "text": "And there are different ways you an design"
    },
    {
      "index": 149,
      "start_time": 388423.0,
      "end_time": 390656.0,
      "text": "how do you define the best."
    },
    {
      "index": 150,
      "start_time": 390656.0,
      "end_time": 393948.0,
      "text": "The best could be some average\nof some different models."
    },
    {
      "index": 151,
      "start_time": 393948.0,
      "end_time": 396674.0,
      "text": "The best could be just\npick one out of this."
    },
    {
      "index": 152,
      "start_time": 396674.0,
      "end_time": 399553.0,
      "text": "The best could be maybe\nthere's a tree of models"
    },
    {
      "index": 153,
      "start_time": 399553.0,
      "end_time": 400679.0,
      "text": "that you classify it on."
    },
    {
      "index": 154,
      "start_time": 400679.0,
      "end_time": 404404.0,
      "text": ">> George: And that's a hyper parameter"
    },
    {
      "index": 155,
      "start_time": 404404.0,
      "end_time": 405989.0,
      "text": "configuration choice?"
    },
    {
      "index": 156,
      "start_time": 405989.0,
      "end_time": 409965.0,
      "text": ">> So that is actually\nbuilding functionality"
    },
    {
      "index": 157,
      "start_time": 409965.0,
      "end_time": 412097.0,
      "text": "in Sparks machine learning pipeline."
    },
    {
      "index": 158,
      "start_time": 412097.0,
      "end_time": 414071.0,
      "text": "And now what we're doing\nis now you can actually"
    },
    {
      "index": 159,
      "start_time": 414071.0,
      "end_time": 416525.0,
      "text": "plug all those deep learning\nlibraries directly into that"
    },
    {
      "index": 160,
      "start_time": 416525.0,
      "end_time": 419442.0,
      "text": "as part of the pipeline to be used."
    },
    {
      "index": 161,
      "start_time": 420383.0,
      "end_time": 421888.0,
      "text": "Another maybe just to add,"
    },
    {
      "index": 162,
      "start_time": 421888.0,
      "end_time": 422805.0,
      "text": ">> Yeah, yeah,"
    },
    {
      "index": 163,
      "start_time": 422805.0,
      "end_time": 424658.0,
      "text": ">> Another really cool functionality"
    },
    {
      "index": 164,
      "start_time": 424658.0,
      "end_time": 426826.0,
      "text": "of the deep learning pipeline\nis transfer learning."
    },
    {
      "index": 165,
      "start_time": 426826.0,
      "end_time": 428932.0,
      "text": "So as you said, deep learning\ntakes a very long time,"
    },
    {
      "index": 166,
      "start_time": 428932.0,
      "end_time": 431002.0,
      "text": "it's very computationally demanding."
    },
    {
      "index": 167,
      "start_time": 431002.0,
      "end_time": 434159.0,
      "text": "And it takes a lot of\nresources, expertise to train."
    },
    {
      "index": 168,
      "start_time": 434159.0,
      "end_time": 436869.0,
      "text": "But with transfer learning what\nwe allow the customers to do"
    },
    {
      "index": 169,
      "start_time": 436869.0,
      "end_time": 439497.0,
      "text": "is they can take an\nexisting deep learning model"
    },
    {
      "index": 170,
      "start_time": 439497.0,
      "end_time": 442835.0,
      "text": "as well train in a different\ndomain and they we'd retrain it"
    },
    {
      "index": 171,
      "start_time": 442835.0,
      "end_time": 445517.0,
      "text": "on a very small amount\nof data very quickly"
    },
    {
      "index": 172,
      "start_time": 445517.0,
      "end_time": 447694.0,
      "text": "and they can adapt it\nto a different domain."
    },
    {
      "index": 173,
      "start_time": 447694.0,
      "end_time": 451168.0,
      "text": "That's how sort of the\ndemo on the James Bond car."
    },
    {
      "index": 174,
      "start_time": 451168.0,
      "end_time": 454490.0,
      "text": "So there is a general image\nclassifier that we train it on"
    },
    {
      "index": 175,
      "start_time": 454490.0,
      "end_time": 456810.0,
      "text": "probably just a few thousand images."
    },
    {
      "index": 176,
      "start_time": 456810.0,
      "end_time": 458789.0,
      "text": "And now we can actually\ndetect whether a car"
    },
    {
      "index": 177,
      "start_time": 458789.0,
      "end_time": 460507.0,
      "text": "is James Bond's car or not."
    },
    {
      "index": 178,
      "start_time": 460507.0,
      "end_time": 461884.0,
      "text": ">> Oh, and the implications\nthere are huge,"
    },
    {
      "index": 179,
      "start_time": 461884.0,
      "end_time": 465025.0,
      "text": "which is you don't have to\nhave huge training data sets"
    },
    {
      "index": 180,
      "start_time": 465025.0,
      "end_time": 468775.0,
      "text": "for modifying a model\nof a similar situation."
    },
    {
      "index": 181,
      "start_time": 470666.0,
      "end_time": 473249.0,
      "text": "I want to, in the time we have,"
    },
    {
      "index": 182,
      "start_time": 474472.0,
      "end_time": 476630.0,
      "text": "there's always been this debate"
    },
    {
      "index": 183,
      "start_time": 476630.0,
      "end_time": 480047.0,
      "text": "about whether Sparks should manage state,"
    },
    {
      "index": 184,
      "start_time": 481789.0,
      "end_time": 485496.0,
      "text": "whether it's database, key value store."
    },
    {
      "index": 185,
      "start_time": 485496.0,
      "end_time": 488277.0,
      "text": "Tell us how the thinking\nabout that has evolved"
    },
    {
      "index": 186,
      "start_time": 488277.0,
      "end_time": 491527.0,
      "text": "and then how the integration interfaces"
    },
    {
      "index": 187,
      "start_time": 493226.0,
      "end_time": 496392.0,
      "text": "for achieving that have evolved."
    },
    {
      "index": 188,
      "start_time": 496392.0,
      "end_time": 500651.0,
      "text": ">> One of the, I would say,\nadvantages of Spark is that"
    },
    {
      "index": 189,
      "start_time": 500651.0,
      "end_time": 504634.0,
      "text": "it's unbiased and works with\na variety of storage systems,"
    },
    {
      "index": 190,
      "start_time": 504634.0,
      "end_time": 508801.0,
      "text": "be it Cassandra, be it\nEdgebase, be it HDFS, be is S3."
    },
    {
      "index": 191,
      "start_time": 511304.0,
      "end_time": 516126.0,
      "text": "There is a metadata management\nfunctionality in Spark"
    },
    {
      "index": 192,
      "start_time": 516126.0,
      "end_time": 519213.0,
      "text": "which is the catalog of tables\nthat customers can define."
    },
    {
      "index": 193,
      "start_time": 519212.99999999994,
      "end_time": 523010.99999999994,
      "text": "But the actual storage\nsits somewhere else."
    },
    {
      "index": 194,
      "start_time": 523010.99999999994,
      "end_time": 526178.0,
      "text": "And I don't think that will\nchange in the near future"
    },
    {
      "index": 195,
      "start_time": 526178.0,
      "end_time": 529292.0,
      "text": "because we do see that the storage systems"
    },
    {
      "index": 196,
      "start_time": 529292.0,
      "end_time": 531828.0,
      "text": "have matured significantly\nin the last few years"
    },
    {
      "index": 197,
      "start_time": 531828.0,
      "end_time": 536039.0,
      "text": "and I just wrote blog post\nlast week about the advantage"
    },
    {
      "index": 198,
      "start_time": 536039.0,
      "end_time": 538505.0,
      "text": "of S3 over HDFS for example."
    },
    {
      "index": 199,
      "start_time": 538505.0,
      "end_time": 540197.0,
      "text": "The storage price is being driven down"
    },
    {
      "index": 200,
      "start_time": 540197.0,
      "end_time": 543587.0,
      "text": "by almost a factor of 10X\nwhen you go to the cloud."
    },
    {
      "index": 201,
      "start_time": 543587.0,
      "end_time": 546621.0,
      "text": "I just don't think it\nmakes sense at this point"
    },
    {
      "index": 202,
      "start_time": 546621.0,
      "end_time": 551030.0,
      "text": "to be building storage\nsystems for analytics."
    },
    {
      "index": 203,
      "start_time": 551030.0,
      "end_time": 553298.0,
      "text": "That said, I think\nthere's a lot of building"
    },
    {
      "index": 204,
      "start_time": 553298.0,
      "end_time": 555357.0,
      "text": "on top of existing storage system."
    },
    {
      "index": 205,
      "start_time": 555357.0,
      "end_time": 558454.0,
      "text": "There's actually a lot of\nopportunities for optimization"
    },
    {
      "index": 206,
      "start_time": 558454.0,
      "end_time": 560685.0,
      "text": "on how you can leverage\nthe specific properties"
    },
    {
      "index": 207,
      "start_time": 560685.0,
      "end_time": 562468.0,
      "text": "of the underlying storage system"
    },
    {
      "index": 208,
      "start_time": 562468.0,
      "end_time": 564220.0,
      "text": "to get to maximum performance."
    },
    {
      "index": 209,
      "start_time": 564220.0,
      "end_time": 566508.0,
      "text": "For example, how are you\ndoing intelligent caching,"
    },
    {
      "index": 210,
      "start_time": 566508.0,
      "end_time": 569539.0,
      "text": "how do you start thinking\nabout building indexes"
    },
    {
      "index": 211,
      "start_time": 569539.0,
      "end_time": 571187.0,
      "text": "actually against the data"
    },
    {
      "index": 212,
      "start_time": 571187.0,
      "end_time": 573938.0,
      "text": "that's stored for scanned workloads."
    },
    {
      "index": 213,
      "start_time": 573938.0,
      "end_time": 577872.0,
      "text": ">> With Tungsten's, you take\nadvantage of the latest hardware"
    },
    {
      "index": 214,
      "start_time": 577872.0,
      "end_time": 581004.0,
      "text": "and where we get more\nmemory intensive systems"
    },
    {
      "index": 215,
      "start_time": 581004.0,
      "end_time": 583802.0,
      "text": "and now that the Catalyst Optimizer"
    },
    {
      "index": 216,
      "start_time": 583802.0,
      "end_time": 587969.0,
      "text": "has a cost based optimizer\nor will be, and large memory."
    },
    {
      "index": 217,
      "start_time": 591244.0,
      "end_time": 595194.0,
      "text": "Can you change how you go about knowing"
    },
    {
      "index": 218,
      "start_time": 595194.0,
      "end_time": 598514.0,
      "text": "what data you're managing\nin the underlying system"
    },
    {
      "index": 219,
      "start_time": 598514.0,
      "end_time": 599604.0,
      "text": "and therefore,"
    },
    {
      "index": 220,
      "start_time": 599604.0,
      "end_time": 603868.0,
      "text": "achieve a tremendous\nacceleration in performance?"
    },
    {
      "index": 221,
      "start_time": 603868.0,
      "end_time": 607978.0,
      "text": ">> This is actually one area\nwe invested in the DBIO module"
    },
    {
      "index": 222,
      "start_time": 607978.0,
      "end_time": 609582.0,
      "text": "as part of Databricks Runtime,"
    },
    {
      "index": 223,
      "start_time": 609582.0,
      "end_time": 612939.0,
      "text": "and what DBIO does, a lot of\nthis are still in progress,"
    },
    {
      "index": 224,
      "start_time": 612939.0,
      "end_time": 615109.0,
      "text": "but for example, we're adding some form"
    },
    {
      "index": 225,
      "start_time": 615109.0,
      "end_time": 617517.0,
      "text": "of indexing capability\nto add to the system"
    },
    {
      "index": 226,
      "start_time": 617517.0,
      "end_time": 621072.0,
      "text": "so we can quickly skip and prune\nout all the irrelevant data"
    },
    {
      "index": 227,
      "start_time": 621072.0,
      "end_time": 623340.0,
      "text": "when the user is doing\nsimple point look-ups."
    },
    {
      "index": 228,
      "start_time": 623340.0,
      "end_time": 625185.0,
      "text": "Or if the user is doing\na scan heavy workload"
    },
    {
      "index": 229,
      "start_time": 625185.0,
      "end_time": 626823.0,
      "text": "with some predicates."
    },
    {
      "index": 230,
      "start_time": 626823.0,
      "end_time": 628792.0,
      "text": "That actually has to do with how we think"
    },
    {
      "index": 231,
      "start_time": 628792.0,
      "end_time": 630595.0,
      "text": "about the underlying data structure."
    },
    {
      "index": 232,
      "start_time": 630595.0,
      "end_time": 632580.0,
      "text": "The storage system is still\nthe same storage system,"
    },
    {
      "index": 233,
      "start_time": 632580.0,
      "end_time": 634993.0,
      "text": "like S3, but were adding actually"
    },
    {
      "index": 234,
      "start_time": 634993.0,
      "end_time": 639457.0,
      "text": "indexing functionalities on\ntop of it as part of DBIO."
    },
    {
      "index": 235,
      "start_time": 639457.0,
      "end_time": 642434.0,
      "text": ">> And so what would be\nthe application profiles?"
    },
    {
      "index": 236,
      "start_time": 642434.0,
      "end_time": 645341.0,
      "text": "Is it just for the analytic queries"
    },
    {
      "index": 237,
      "start_time": 645341.0,
      "end_time": 649058.0,
      "text": "or can you do the point\nlook-ups and updates"
    },
    {
      "index": 238,
      "start_time": 649058.0,
      "end_time": 651029.0,
      "text": "in that sort of scenario too?"
    },
    {
      "index": 239,
      "start_time": 651029.0,
      "end_time": 653060.0,
      "text": ">> So it's interesting\nyou're talking about updates."
    },
    {
      "index": 240,
      "start_time": 653060.0,
      "end_time": 655068.0,
      "text": "Updates is another thing\nthat we've got a lot"
    },
    {
      "index": 241,
      "start_time": 655068.0,
      "end_time": 656337.0,
      "text": "of future requests on."
    },
    {
      "index": 242,
      "start_time": 656337.0,
      "end_time": 657732.0,
      "text": "We're actively thinking about how"
    },
    {
      "index": 243,
      "start_time": 657732.0,
      "end_time": 659414.0,
      "text": "we will support update workload."
    },
    {
      "index": 244,
      "start_time": 659414.0,
      "end_time": 663481.0,
      "text": "Now, that said, I just want\nto emphasize for both use case"
    },
    {
      "index": 245,
      "start_time": 663481.0,
      "end_time": 665316.0,
      "text": "of doing point look-ups and updates,"
    },
    {
      "index": 246,
      "start_time": 665316.0,
      "end_time": 666649.0,
      "text": "we're still talking about in the context"
    },
    {
      "index": 247,
      "start_time": 666649.0,
      "end_time": 668241.0,
      "text": "of analytic environment."
    },
    {
      "index": 248,
      "start_time": 668241.0,
      "end_time": 670465.0,
      "text": "So we would be talking about\nfor example maybe bulk updates"
    },
    {
      "index": 249,
      "start_time": 670465.0,
      "end_time": 671742.0,
      "text": "or low throughput updates"
    },
    {
      "index": 250,
      "start_time": 671742.0,
      "end_time": 673982.0,
      "text": "rather than doing transactional updates"
    },
    {
      "index": 251,
      "start_time": 673982.0,
      "end_time": 675542.0,
      "text": "in which every time you\nswipe a credit card,"
    },
    {
      "index": 252,
      "start_time": 675542.0,
      "end_time": 677230.0,
      "text": "some record gets updated."
    },
    {
      "index": 253,
      "start_time": 677230.0,
      "end_time": 680390.0,
      "text": "That's probably more belongs\non the transactional databases"
    },
    {
      "index": 254,
      "start_time": 680390.0,
      "end_time": 682890.0,
      "text": "like Oracle or my SEQUEL even."
    },
    {
      "index": 255,
      "start_time": 686943.0,
      "end_time": 691678.0,
      "text": ">> What about when you think\nabout people who are going to run,"
    },
    {
      "index": 256,
      "start_time": 691678.0,
      "end_time": 694323.0,
      "text": "they started out with Spark on prem,"
    },
    {
      "index": 257,
      "start_time": 694323.0,
      "end_time": 696296.0,
      "text": "they realize they're\ngoing to put much more"
    },
    {
      "index": 258,
      "start_time": 696296.0,
      "end_time": 698030.0,
      "text": "of their resources in the cloud,"
    },
    {
      "index": 259,
      "start_time": 698030.0,
      "end_time": 701946.0,
      "text": "but with IIOT, industrial\nIOT type applications"
    },
    {
      "index": 260,
      "start_time": 701946.0,
      "end_time": 703946.0,
      "text": "they're going to have Spark"
    },
    {
      "index": 261,
      "start_time": 705977.0,
      "end_time": 708497.0,
      "text": "maybe in a gateway server on the edge?"
    },
    {
      "index": 262,
      "start_time": 708497.0,
      "end_time": 711392.0,
      "text": "What do you think that\nconfiguration looks like?"
    },
    {
      "index": 263,
      "start_time": 711392.0,
      "end_time": 714426.0,
      "text": ">> Really interesting, it's\nkind of two questions maybe."
    },
    {
      "index": 264,
      "start_time": 714426.0,
      "end_time": 717837.0,
      "text": "The first is the hybrid\non prem, cloud solution."
    },
    {
      "index": 265,
      "start_time": 717837.0,
      "end_time": 721050.0,
      "text": "Again, so one of the\nnice advantage of Spark"
    },
    {
      "index": 266,
      "start_time": 721050.0,
      "end_time": 723039.0,
      "text": "is the couple of storage and compute."
    },
    {
      "index": 267,
      "start_time": 723039.0,
      "end_time": 724856.0,
      "text": "So when you want to move for example,"
    },
    {
      "index": 268,
      "start_time": 724856.0,
      "end_time": 726718.0,
      "text": "workloads from one prem to the cloud,"
    },
    {
      "index": 269,
      "start_time": 726718.0,
      "end_time": 728147.0,
      "text": "the one you care the most about"
    },
    {
      "index": 270,
      "start_time": 728147.0,
      "end_time": 729400.0,
      "text": "is probably actually the data"
    },
    {
      "index": 271,
      "start_time": 729400.0,
      "end_time": 730768.0,
      "text": "'cause the compute,"
    },
    {
      "index": 272,
      "start_time": 730768.0,
      "end_time": 732675.0,
      "text": "it doesn't really matter\nthat much where you run it"
    },
    {
      "index": 273,
      "start_time": 732675.0,
      "end_time": 734934.0,
      "text": "but data's the one that's hard to move."
    },
    {
      "index": 274,
      "start_time": 734934.0,
      "end_time": 737399.0,
      "text": "We do have customers that's\nleveraging Databricks"
    },
    {
      "index": 275,
      "start_time": 737399.0,
      "end_time": 739296.0,
      "text": "in the cloud but actually\nreading data directly"
    },
    {
      "index": 276,
      "start_time": 739296.0,
      "end_time": 742007.0,
      "text": "from on prem the reliance\nof the caching solution"
    },
    {
      "index": 277,
      "start_time": 742007.0,
      "end_time": 744882.0,
      "text": "we have that minimize the\ndata transfer over time."
    },
    {
      "index": 278,
      "start_time": 744882.0,
      "end_time": 748381.0,
      "text": "And is one route I would\nsay it's pretty popular."
    },
    {
      "index": 279,
      "start_time": 748381.0,
      "end_time": 752270.0,
      "text": "Another on is, with Amazon\nyou can literally give them"
    },
    {
      "index": 280,
      "start_time": 752270.0,
      "end_time": 754708.0,
      "text": "just a show ball of functionality."
    },
    {
      "index": 281,
      "start_time": 754708.0,
      "end_time": 756562.0,
      "text": "You give them hard drive with trucks,"
    },
    {
      "index": 282,
      "start_time": 756562.0,
      "end_time": 760439.0,
      "text": "the trucks will ship your\ndata directly put in a three."
    },
    {
      "index": 283,
      "start_time": 760439.0,
      "end_time": 763874.0,
      "text": "With IOT, a common pattern we see"
    },
    {
      "index": 284,
      "start_time": 763874.0,
      "end_time": 765902.0,
      "text": "is a lot of the edge devices,"
    },
    {
      "index": 285,
      "start_time": 765902.0,
      "end_time": 769023.0,
      "text": "would be actually\npushing the data directly"
    },
    {
      "index": 286,
      "start_time": 769023.0,
      "end_time": 773029.0,
      "text": "into some some fire hose\nlike Kinesis or Kafka"
    },
    {
      "index": 287,
      "start_time": 773029.0,
      "end_time": 775043.0,
      "text": "or, I'm sure Google and Microsoft"
    },
    {
      "index": 288,
      "start_time": 775043.0,
      "end_time": 777580.0,
      "text": "both have their own variance of that."
    },
    {
      "index": 289,
      "start_time": 777580.0,
      "end_time": 779948.0,
      "text": "And then you use Spark to\ndirectly subscribe to those topics"
    },
    {
      "index": 290,
      "start_time": 779948.0,
      "end_time": 782630.0,
      "text": "and process them in real time\nwith structured streaming."
    },
    {
      "index": 291,
      "start_time": 782630.0,
      "end_time": 784627.0,
      "text": ">> And so would Spark be down,"
    },
    {
      "index": 292,
      "start_time": 784627.0,
      "end_time": 787315.0,
      "text": "let's say at the site level."
    },
    {
      "index": 293,
      "start_time": 787315.0,
      "end_time": 790065.0,
      "text": "if it's not on the device itself?"
    },
    {
      "index": 294,
      "start_time": 791416.0,
      "end_time": 793829.0,
      "text": ">> It's a interesting\nthought and maybe one thing"
    },
    {
      "index": 295,
      "start_time": 793829.0,
      "end_time": 795577.0,
      "text": "we should actually\nconsider more in the future"
    },
    {
      "index": 296,
      "start_time": 795577.0,
      "end_time": 797547.0,
      "text": "is how do we push Spark to the edges."
    },
    {
      "index": 297,
      "start_time": 797547.0,
      "end_time": 799589.0,
      "text": "Right now it's more of a centralized model"
    },
    {
      "index": 298,
      "start_time": 799589.0,
      "end_time": 802802.0,
      "text": "in which the devices push data into Spark"
    },
    {
      "index": 299,
      "start_time": 802802.0,
      "end_time": 804606.0,
      "text": "which is centralized somewhere."
    },
    {
      "index": 300,
      "start_time": 804606.0,
      "end_time": 806439.0,
      "text": "I've seen for example,"
    },
    {
      "index": 301,
      "start_time": 808502.0,
      "end_time": 809697.0,
      "text": "I don't remember exact the use case"
    },
    {
      "index": 302,
      "start_time": 809697.0,
      "end_time": 813871.0,
      "text": "but it has to do with\nsome scientific experiment"
    },
    {
      "index": 303,
      "start_time": 813871.0,
      "end_time": 815554.0,
      "text": "in the North Pole."
    },
    {
      "index": 304,
      "start_time": 815554.0,
      "end_time": 818785.0,
      "text": "And of course there you\ndon't have a great uplink"
    },
    {
      "index": 305,
      "start_time": 818785.0,
      "end_time": 820809.0,
      "text": "of all the data connecting\ntransferring back"
    },
    {
      "index": 306,
      "start_time": 820809.0,
      "end_time": 822626.0,
      "text": "to some national lab"
    },
    {
      "index": 307,
      "start_time": 822626.0,
      "end_time": 824741.0,
      "text": "and rather they would\ndo a smart parsing there"
    },
    {
      "index": 308,
      "start_time": 824741.0,
      "end_time": 827297.0,
      "text": "and then ship the aggregated result back."
    },
    {
      "index": 309,
      "start_time": 827297.0,
      "end_time": 830366.0,
      "text": "There's another one but it's less common."
    },
    {
      "index": 310,
      "start_time": 830366.0,
      "end_time": 832310.0,
      "text": ">> Alright well just one\nminute now before the break"
    },
    {
      "index": 311,
      "start_time": 832310.0,
      "end_time": 833857.0,
      "text": "so I'm going to give you a chance"
    },
    {
      "index": 312,
      "start_time": 833857.0,
      "end_time": 835324.0,
      "text": "to address the Spark community."
    },
    {
      "index": 313,
      "start_time": 835324.0,
      "end_time": 837076.0,
      "text": "What's the next big technical challenge"
    },
    {
      "index": 314,
      "start_time": 837076.0,
      "end_time": 841243.0,
      "text": "you hope people will work on\nfor the benefit of everybody?"
    },
    {
      "index": 315,
      "start_time": 842605.0,
      "end_time": 846522.0,
      "text": ">> In general Spark came\nalong with two focuses."
    },
    {
      "index": 316,
      "start_time": 848053.0,
      "end_time": 850591.0,
      "text": "One is performance, the\nother one's ease of use."
    },
    {
      "index": 317,
      "start_time": 850591.0,
      "end_time": 854126.0,
      "text": "And I still think big data\ntools are too difficult to use."
    },
    {
      "index": 318,
      "start_time": 854126.0,
      "end_time": 856240.0,
      "text": "Deep learning tools, even harder."
    },
    {
      "index": 319,
      "start_time": 856240.0,
      "end_time": 860605.0,
      "text": "The barrier to entry is\nvery high for office tools."
    },
    {
      "index": 320,
      "start_time": 860605.0,
      "end_time": 863539.0,
      "text": "I would say, we might\nhave already addressed"
    },
    {
      "index": 321,
      "start_time": 863539.0,
      "end_time": 865040.0,
      "text": "performance to a degree that"
    },
    {
      "index": 322,
      "start_time": 865040.0,
      "end_time": 867065.0,
      "text": "I think it's actually pretty usable."
    },
    {
      "index": 323,
      "start_time": 867065.0,
      "end_time": 868595.0,
      "text": "The systems are fast enough."
    },
    {
      "index": 324,
      "start_time": 868595.0,
      "end_time": 870566.0,
      "text": "Now, we should work on actually make"
    },
    {
      "index": 325,
      "start_time": 870566.0,
      "end_time": 872127.0,
      "text": "(mumbles) even easier to use."
    },
    {
      "index": 326,
      "start_time": 872127.0,
      "end_time": 875303.0,
      "text": "It's what also we focus a\nlot on at Databricks here."
    },
    {
      "index": 327,
      "start_time": 875303.0,
      "end_time": 876465.0,
      "text": ">> David: Democratizing access right?"
    },
    {
      "index": 328,
      "start_time": 876465.0,
      "end_time": 877372.0,
      "text": ">> Absolutely."
    },
    {
      "index": 329,
      "start_time": 877372.0,
      "end_time": 879234.0,
      "text": ">> Alright well Reynold, I wish\nwe could talk to you all day."
    },
    {
      "index": 330,
      "start_time": 879234.0,
      "end_time": 880081.0,
      "text": "This is great."
    },
    {
      "index": 331,
      "start_time": 880081.0,
      "end_time": 881186.0,
      "text": "We are out of time now."
    },
    {
      "index": 332,
      "start_time": 881186.0,
      "end_time": 882924.0,
      "text": "Want to appreciate you coming by theCUBE"
    },
    {
      "index": 333,
      "start_time": 882924.0,
      "end_time": 883922.0,
      "text": "and sharing your insights"
    },
    {
      "index": 334,
      "start_time": 883922.0,
      "end_time": 885064.0,
      "text": "and good luck with the rest of the show."
    },
    {
      "index": 335,
      "start_time": 885064.0,
      "end_time": 886830.0,
      "text": ">> Thank you very much David and George."
    },
    {
      "index": 336,
      "start_time": 886830.0,
      "end_time": 888559.0,
      "text": ">> Thank you all for\nwatching here were at theCUBE"
    },
    {
      "index": 337,
      "start_time": 888559.0,
      "end_time": 890609.0,
      "text": "at Sparks Summit 2017."
    },
    {
      "index": 338,
      "start_time": 890609.0,
      "end_time": 893390.0,
      "text": "Stay tuned, lots of other\ngreat guests coming up today."
    },
    {
      "index": 339,
      "start_time": 893390.0,
      "end_time": 895973.0,
      "text": "We'll see you in a few minutes."
    }
  ]
}