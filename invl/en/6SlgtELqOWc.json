{
  "video_id": "6SlgtELqOWc",
  "title": "Lecture 8 | Deep Learning Software",
  "es": 0,
  "json": [
    {
      "index": 1,
      "start_time": 9739.0,
      "end_time": 10898.0,
      "text": "- Hello?"
    },
    {
      "index": 2,
      "start_time": 10898.0,
      "end_time": 13891.0,
      "text": "Okay, it&#39;s after 12, so I want to get started."
    },
    {
      "index": 3,
      "start_time": 13891.0,
      "end_time": 16151.0,
      "text": "So today, lecture eight, we&#39;re going to talk about"
    },
    {
      "index": 4,
      "start_time": 16151.0,
      "end_time": 17822.0,
      "text": "deep learning software."
    },
    {
      "index": 5,
      "start_time": 17822.0,
      "end_time": 19593.0,
      "text": "This is a super exciting topic because it changes"
    },
    {
      "index": 6,
      "start_time": 19593.0,
      "end_time": 21283.0,
      "text": "a lot every year."
    },
    {
      "index": 7,
      "start_time": 21283.0,
      "end_time": 23156.0,
      "text": "But also means it&#39;s a lot of work to give this lecture"
    },
    {
      "index": 8,
      "start_time": 23156.0,
      "end_time": 25621.0,
      "text": "&#39;cause it changes a lot every year."
    },
    {
      "index": 9,
      "start_time": 25621.0,
      "end_time": 28302.0,
      "text": "But as usual, a couple administrative notes"
    },
    {
      "index": 10,
      "start_time": 28302.0,
      "end_time": 30240.0,
      "text": "before we dive into the material."
    },
    {
      "index": 11,
      "start_time": 30240.0,
      "end_time": 32323.0,
      "text": "So as a reminder the project proposals for your"
    },
    {
      "index": 12,
      "start_time": 32323.0,
      "end_time": 34563.0,
      "text": "course projects were due on Tuesday."
    },
    {
      "index": 13,
      "start_time": 34563.0,
      "end_time": 37405.0,
      "text": "So hopefully you all turned that in,"
    },
    {
      "index": 14,
      "start_time": 37405.0,
      "end_time": 39704.0,
      "text": "and hopefully you all have a somewhat good idea"
    },
    {
      "index": 15,
      "start_time": 39704.0,
      "end_time": 41566.0,
      "text": "of what kind of projects you want to work on"
    },
    {
      "index": 16,
      "start_time": 41566.0,
      "end_time": 42766.0,
      "text": "for the class."
    },
    {
      "index": 17,
      "start_time": 42766.0,
      "end_time": 45852.0,
      "text": "So we&#39;re in the process of assigning TA&#39;s to projects"
    },
    {
      "index": 18,
      "start_time": 45852.0,
      "end_time": 47979.0,
      "text": "based on what the project area is"
    },
    {
      "index": 19,
      "start_time": 47979.0,
      "end_time": 50217.0,
      "text": "and the expertise of the TA&#39;s."
    },
    {
      "index": 20,
      "start_time": 50217.0,
      "end_time": 52546.0,
      "text": "So we&#39;ll have some more information about that"
    },
    {
      "index": 21,
      "start_time": 52546.0,
      "end_time": 54263.0,
      "text": "in the next couple days I think."
    },
    {
      "index": 22,
      "start_time": 54264.0,
      "end_time": 56563.0,
      "text": "We&#39;re also in the process of grading assignment one,"
    },
    {
      "index": 23,
      "start_time": 56563.0,
      "end_time": 59724.0,
      "text": "so stay tuned and we&#39;ll get those grades back to you"
    },
    {
      "index": 24,
      "start_time": 59724.0,
      "end_time": 60941.0,
      "text": "as soon as we can."
    },
    {
      "index": 25,
      "start_time": 60942.0,
      "end_time": 63464.0,
      "text": "Another reminder is that assignment two has been out"
    },
    {
      "index": 26,
      "start_time": 63464.0,
      "end_time": 64449.0,
      "text": "for a while."
    },
    {
      "index": 27,
      "start_time": 64449.0,
      "end_time": 68679.0,
      "text": "That&#39;s going to be due next week, a week from today, Thursday."
    },
    {
      "index": 28,
      "start_time": 68680.0,
      "end_time": 70848.0,
      "text": "And again, when working on assignment two,"
    },
    {
      "index": 29,
      "start_time": 70848.0,
      "end_time": 72846.0,
      "text": "remember to stop your Google Cloud instances"
    },
    {
      "index": 30,
      "start_time": 72846.0,
      "end_time": 76231.0,
      "text": "when you&#39;re not working to try to preserve your credits."
    },
    {
      "index": 31,
      "start_time": 76231.0,
      "end_time": 78264.0,
      "text": "And another bit of confusion, I just wanted to"
    },
    {
      "index": 32,
      "start_time": 78264.0,
      "end_time": 81326.0,
      "text": "re-emphasize is that for assignment two you really"
    },
    {
      "index": 33,
      "start_time": 81326.0,
      "end_time": 84812.0,
      "text": "only need to use GPU instances for the last notebook."
    },
    {
      "index": 34,
      "start_time": 84812.0,
      "end_time": 89210.0,
      "text": "For all of the several notebooks it&#39;s just in Python"
    },
    {
      "index": 35,
      "start_time": 89210.0,
      "end_time": 92250.0,
      "text": "and Numpy so you don&#39;t need any GPUs for those questions."
    },
    {
      "index": 36,
      "start_time": 92250.0,
      "end_time": 94414.0,
      "text": "So again, conserve your credits,"
    },
    {
      "index": 37,
      "start_time": 94414.0,
      "end_time": 96701.0,
      "text": "only use GPUs when you need them."
    },
    {
      "index": 38,
      "start_time": 96701.0,
      "end_time": 99973.0,
      "text": "And the final reminder is that the midterm is coming up."
    },
    {
      "index": 39,
      "start_time": 99973.0,
      "end_time": 101516.0,
      "text": "It&#39;s kind of hard to believe we&#39;re there already,"
    },
    {
      "index": 40,
      "start_time": 101516.0,
      "end_time": 105683.0,
      "text": "but the midterm will be in class on Tuesday, five nine."
    },
    {
      "index": 41,
      "start_time": 105683.0,
      "end_time": 107901.0,
      "text": "So the midterm will be more theoretical."
    },
    {
      "index": 42,
      "start_time": 107901.0,
      "end_time": 111180.0,
      "text": "It&#39;ll be sort of pen and paper working through different"
    },
    {
      "index": 43,
      "start_time": 111180.0,
      "end_time": 114137.0,
      "text": "kinds of, slightly more theoretical questions"
    },
    {
      "index": 44,
      "start_time": 114137.0,
      "end_time": 115450.0,
      "text": "to check your understanding of the material that we&#39;ve"
    },
    {
      "index": 45,
      "start_time": 115450.0,
      "end_time": 117710.0,
      "text": "covered so far."
    },
    {
      "index": 46,
      "start_time": 117710.0,
      "end_time": 119652.0,
      "text": "And I think we&#39;ll probably post at least a short sort of"
    },
    {
      "index": 47,
      "start_time": 119652.0,
      "end_time": 122506.0,
      "text": "sample of the types of questions to expect."
    },
    {
      "index": 48,
      "start_time": 122506.0,
      "end_time": 123695.0,
      "text": "Question?"
    },
    {
      "index": 49,
      "start_time": 123695.0,
      "end_time": 125309.0,
      "text": "[student&#39;s words obscured due to lack of microphone]"
    },
    {
      "index": 50,
      "start_time": 125310.0,
      "end_time": 128233.0,
      "text": "Oh yeah, question is whether it&#39;s open-book,"
    },
    {
      "index": 51,
      "start_time": 128233.0,
      "end_time": 130676.0,
      "text": "so we&#39;re going to say closed note, closed book."
    },
    {
      "index": 52,
      "start_time": 130675.00000000001,
      "end_time": 132360.0,
      "text": "So just,"
    },
    {
      "index": 53,
      "start_time": 132370.0,
      "end_time": 133757.0,
      "text": "Yeah, yeah, so that&#39;s what we&#39;ve done in the past"
    },
    {
      "index": 54,
      "start_time": 133757.0,
      "end_time": 135671.0,
      "text": "is just closed note, closed book, relatively"
    },
    {
      "index": 55,
      "start_time": 135671.0,
      "end_time": 137567.0,
      "text": "just like want to check that you understand"
    },
    {
      "index": 56,
      "start_time": 137568.0,
      "end_time": 141735.0,
      "text": "the intuition behind most of the stuff we&#39;ve presented."
    },
    {
      "index": 57,
      "start_time": 143618.0,
      "end_time": 146150.0,
      "text": "So, a quick recap as a reminder of what we were talking"
    },
    {
      "index": 58,
      "start_time": 146150.0,
      "end_time": 147577.0,
      "text": "about last time."
    },
    {
      "index": 59,
      "start_time": 147577.0,
      "end_time": 149737.0,
      "text": "Last time we talked about fancier optimization algorithms"
    },
    {
      "index": 60,
      "start_time": 149737.0,
      "end_time": 153162.0,
      "text": "for deep learning models including SGD Momentum,"
    },
    {
      "index": 61,
      "start_time": 153162.0,
      "end_time": 154975.0,
      "text": "Nesterov, RMSProp and Adam."
    },
    {
      "index": 62,
      "start_time": 154975.0,
      "end_time": 157257.0,
      "text": "And we saw that these relatively small tweaks"
    },
    {
      "index": 63,
      "start_time": 157257.0,
      "end_time": 162139.0,
      "text": "on top of vanilla SGD, are relatively easy to implement"
    },
    {
      "index": 64,
      "start_time": 162139.0,
      "end_time": 165492.0,
      "text": "but can make your networks converge a bit faster."
    },
    {
      "index": 65,
      "start_time": 165492.0,
      "end_time": 166954.0,
      "text": "We also talked about regularization,"
    },
    {
      "index": 66,
      "start_time": 166955.0,
      "end_time": 168529.0,
      "text": "especially dropout."
    },
    {
      "index": 67,
      "start_time": 168529.0,
      "end_time": 170666.0,
      "text": "So remember dropout, you&#39;re kind of randomly setting"
    },
    {
      "index": 68,
      "start_time": 170666.0,
      "end_time": 172585.0,
      "text": "parts of the network to zero during the forward pass,"
    },
    {
      "index": 69,
      "start_time": 172586.0,
      "end_time": 174959.0,
      "text": "and then you kind of marginalize out over that noise"
    },
    {
      "index": 70,
      "start_time": 174959.0,
      "end_time": 176975.0,
      "text": "in the back at test time."
    },
    {
      "index": 71,
      "start_time": 176975.0,
      "end_time": 178575.0,
      "text": "And we saw that this was kind of a general pattern"
    },
    {
      "index": 72,
      "start_time": 178575.0,
      "end_time": 180676.0,
      "text": "across many different types of regularization"
    },
    {
      "index": 73,
      "start_time": 180676.0,
      "end_time": 182804.0,
      "text": "in deep learning, where you might add some kind"
    },
    {
      "index": 74,
      "start_time": 182805.0,
      "end_time": 185132.0,
      "text": "of noise during training, but then marginalize out"
    },
    {
      "index": 75,
      "start_time": 185132.0,
      "end_time": 187370.0,
      "text": "that noise at test time so it&#39;s not stochastic"
    },
    {
      "index": 76,
      "start_time": 187370.0,
      "end_time": 188415.0,
      "text": "at test time."
    },
    {
      "index": 77,
      "start_time": 188415.0,
      "end_time": 190156.0,
      "text": "We also talked about transfer learning where you"
    },
    {
      "index": 78,
      "start_time": 190156.0,
      "end_time": 192533.0,
      "text": "can maybe download big networks that were pre-trained"
    },
    {
      "index": 79,
      "start_time": 192533.0,
      "end_time": 194353.0,
      "text": "on some dataset and then fine tune them for your"
    },
    {
      "index": 80,
      "start_time": 194354.0,
      "end_time": 195376.0,
      "text": "own problem."
    },
    {
      "index": 81,
      "start_time": 195376.0,
      "end_time": 197577.0,
      "text": "And this is one way that you can attack a lot of problems"
    },
    {
      "index": 82,
      "start_time": 197577.0,
      "end_time": 199647.0,
      "text": "in deep learning, even if you don&#39;t have a huge"
    },
    {
      "index": 83,
      "start_time": 199647.0,
      "end_time": 201314.0,
      "text": "dataset of your own."
    },
    {
      "index": 84,
      "start_time": 202781.0,
      "end_time": 204239.0,
      "text": "So today we&#39;re going to shift gears a little bit"
    },
    {
      "index": 85,
      "start_time": 204239.0,
      "end_time": 205947.0,
      "text": "and talk about some of the nuts and bolts"
    },
    {
      "index": 86,
      "start_time": 205947.0,
      "end_time": 209615.0,
      "text": "about writing software and how the hardware works."
    },
    {
      "index": 87,
      "start_time": 209615.0,
      "end_time": 211956.0,
      "text": "And a little bit, diving into a lot of details"
    },
    {
      "index": 88,
      "start_time": 211956.0,
      "end_time": 213972.0,
      "text": "about what the software looks like that you actually"
    },
    {
      "index": 89,
      "start_time": 213973.0,
      "end_time": 216276.0,
      "text": "use to train these things in practice."
    },
    {
      "index": 90,
      "start_time": 216276.0,
      "end_time": 219203.0,
      "text": "So we&#39;ll talk a little bit about CPUs and GPUs"
    },
    {
      "index": 91,
      "start_time": 219203.0,
      "end_time": 221476.0,
      "text": "and then we&#39;ll talk about several of the major"
    },
    {
      "index": 92,
      "start_time": 221476.0,
      "end_time": 223500.0,
      "text": "deep learning frameworks that are out there in use"
    },
    {
      "index": 93,
      "start_time": 223500.0,
      "end_time": 223967.0,
      "text": "these days."
    },
    {
      "index": 94,
      "start_time": 225471.0,
      "end_time": 228174.0,
      "text": "So first, we&#39;ve sort of mentioned this off hand"
    },
    {
      "index": 95,
      "start_time": 228174.0,
      "end_time": 229890.0,
      "text": "a bunch of different times,"
    },
    {
      "index": 96,
      "start_time": 229890.0,
      "end_time": 232960.0,
      "text": "that computers have CPUs, computers have GPUs."
    },
    {
      "index": 97,
      "start_time": 232961.0,
      "end_time": 235257.0,
      "text": "Deep learning uses GPUs, but we weren&#39;t really"
    },
    {
      "index": 98,
      "start_time": 235257.0,
      "end_time": 237455.0,
      "text": "too explicit up to this point about what exactly"
    },
    {
      "index": 99,
      "start_time": 237455.0,
      "end_time": 239726.0,
      "text": "these things are and why one might be better"
    },
    {
      "index": 100,
      "start_time": 239726.0,
      "end_time": 242655.0,
      "text": "than another for different tasks."
    },
    {
      "index": 101,
      "start_time": 242655.0,
      "end_time": 244655.0,
      "text": "So, who&#39;s built a computer before?"
    },
    {
      "index": 102,
      "start_time": 244655.0,
      "end_time": 246472.0,
      "text": "Just kind of show of hands."
    },
    {
      "index": 103,
      "start_time": 246472.0,
      "end_time": 249390.0,
      "text": "So, maybe about a third of you, half of you,"
    },
    {
      "index": 104,
      "start_time": 249390.0,
      "end_time": 250964.0,
      "text": "somewhere around that ballpark."
    },
    {
      "index": 105,
      "start_time": 250965.0,
      "end_time": 254119.0,
      "text": "So this is a shot of my computer at home"
    },
    {
      "index": 106,
      "start_time": 254119.0,
      "end_time": 255174.0,
      "text": "that I built."
    },
    {
      "index": 107,
      "start_time": 255174.0,
      "end_time": 257839.0,
      "text": "And you can see that there&#39;s a lot of stuff going on"
    },
    {
      "index": 108,
      "start_time": 257839.0,
      "end_time": 260940.0,
      "text": "inside the computer, maybe, hopefully you know"
    },
    {
      "index": 109,
      "start_time": 260950.0,
      "end_time": 262261.0,
      "text": "what most of these parts are."
    },
    {
      "index": 110,
      "start_time": 262261.0,
      "end_time": 265594.0,
      "text": "And the CPU is the Central Processing Unit."
    },
    {
      "index": 111,
      "start_time": 265594.0,
      "end_time": 268419.0,
      "text": "That&#39;s this little chip hidden under this cooling fan"
    },
    {
      "index": 112,
      "start_time": 268419.0,
      "end_time": 271390.0,
      "text": "right here near the top of the case."
    },
    {
      "index": 113,
      "start_time": 271391.0,
      "end_time": 274217.0,
      "text": "And the CPU is actually relatively small piece."
    },
    {
      "index": 114,
      "start_time": 274217.0,
      "end_time": 276616.0,
      "text": "It&#39;s a relatively small thing inside the case."
    },
    {
      "index": 115,
      "start_time": 276617.0,
      "end_time": 279555.0,
      "text": "It&#39;s not taking up a lot of space."
    },
    {
      "index": 116,
      "start_time": 279555.0,
      "end_time": 282204.0,
      "text": "And the GPUs are these two big monster things"
    },
    {
      "index": 117,
      "start_time": 282204.0,
      "end_time": 284845.0,
      "text": "that are taking up a gigantic amount of space"
    },
    {
      "index": 118,
      "start_time": 284845.0,
      "end_time": 286221.0,
      "text": "in the case."
    },
    {
      "index": 119,
      "start_time": 286221.0,
      "end_time": 287411.0,
      "text": "They have their own cooling,"
    },
    {
      "index": 120,
      "start_time": 287411.0,
      "end_time": 288760.0,
      "text": "they&#39;re taking a lot of power."
    },
    {
      "index": 121,
      "start_time": 288760.0,
      "end_time": 290296.0,
      "text": "They&#39;re quite large."
    },
    {
      "index": 122,
      "start_time": 290296.0,
      "end_time": 293539.0,
      "text": "So, just in terms of how much power they&#39;re using,"
    },
    {
      "index": 123,
      "start_time": 293539.0,
      "end_time": 295906.0,
      "text": "in terms of how big they are, the GPUs are kind of"
    },
    {
      "index": 124,
      "start_time": 295906.0,
      "end_time": 297455.0,
      "text": "physically imposing and taking up a lot of space"
    },
    {
      "index": 125,
      "start_time": 297455.0,
      "end_time": 299139.0,
      "text": "in the case."
    },
    {
      "index": 126,
      "start_time": 299139.0,
      "end_time": 300927.0,
      "text": "So the question is what are these things"
    },
    {
      "index": 127,
      "start_time": 300927.0,
      "end_time": 304516.0,
      "text": "and why are they so important for deep learning?"
    },
    {
      "index": 128,
      "start_time": 304516.0,
      "end_time": 307402.0,
      "text": "Well, the GPU is called a graphics card,"
    },
    {
      "index": 129,
      "start_time": 307402.0,
      "end_time": 308937.0,
      "text": "or Graphics Processing Unit."
    },
    {
      "index": 130,
      "start_time": 308937.0,
      "end_time": 312430.0,
      "text": "And these were really developed, originally for rendering"
    },
    {
      "index": 131,
      "start_time": 312430.0,
      "end_time": 314457.0,
      "text": "computer graphics, and especially around games"
    },
    {
      "index": 132,
      "start_time": 314457.0,
      "end_time": 316166.0,
      "text": "and that sort of thing."
    },
    {
      "index": 133,
      "start_time": 316166.0,
      "end_time": 320225.0,
      "text": "So another show of hands, who plays video games at home"
    },
    {
      "index": 134,
      "start_time": 320225.0,
      "end_time": 323247.0,
      "text": "sometimes, from time to time on their computer?"
    },
    {
      "index": 135,
      "start_time": 323247.0,
      "end_time": 325693.0,
      "text": "Yeah, so again, maybe about half, good fraction."
    },
    {
      "index": 136,
      "start_time": 325693.0,
      "end_time": 328159.0,
      "text": "So for those of you who&#39;ve played video games before"
    },
    {
      "index": 137,
      "start_time": 328159.0,
      "end_time": 329717.0,
      "text": "and who&#39;ve built your own computers,"
    },
    {
      "index": 138,
      "start_time": 329717.0,
      "end_time": 332195.0,
      "text": "you probably have your own opinions on this debate."
    },
    {
      "index": 139,
      "start_time": 332196.0,
      "end_time": 334950.0,
      "text": "[laughs]"
    },
    {
      "index": 140,
      "start_time": 334950.0,
      "end_time": 337666.0,
      "text": "So this is one of those big debates in computer science."
    },
    {
      "index": 141,
      "start_time": 337666.0,
      "end_time": 340349.0,
      "text": "You know, there&#39;s like Intel versus AMD,"
    },
    {
      "index": 142,
      "start_time": 340349.0,
      "end_time": 342620.0,
      "text": "NVIDIA versus AMD for graphics cards."
    },
    {
      "index": 143,
      "start_time": 342620.0,
      "end_time": 345394.0,
      "text": "It&#39;s up there with Vim versus Emacs for text editor."
    },
    {
      "index": 144,
      "start_time": 345394.0,
      "end_time": 347660.0,
      "text": "And pretty much any gamer has their own opinions"
    },
    {
      "index": 145,
      "start_time": 347660.0,
      "end_time": 350768.0,
      "text": "on which of these two sides they prefer"
    },
    {
      "index": 146,
      "start_time": 350768.0,
      "end_time": 351945.0,
      "text": "for their own cards."
    },
    {
      "index": 147,
      "start_time": 351945.0,
      "end_time": 354895.0,
      "text": "And in deep learning we kind of have mostly picked"
    },
    {
      "index": 148,
      "start_time": 354895.0,
      "end_time": 359116.0,
      "text": "one side of this fight, and that&#39;s NVIDIA."
    },
    {
      "index": 149,
      "start_time": 359116.0,
      "end_time": 360816.0,
      "text": "So if you guys have AMD cards,"
    },
    {
      "index": 150,
      "start_time": 360816.0,
      "end_time": 363250.0,
      "text": "you might be in a little bit more trouble if you want"
    },
    {
      "index": 151,
      "start_time": 363260.0,
      "end_time": 365117.0,
      "text": "to use those for deep learning."
    },
    {
      "index": 152,
      "start_time": 365117.0,
      "end_time": 367729.0,
      "text": "And really, NVIDIA&#39;s been pushing a lot for deep learning"
    },
    {
      "index": 153,
      "start_time": 367729.0,
      "end_time": 368812.0,
      "text": "in the last several years."
    },
    {
      "index": 154,
      "start_time": 368812.0,
      "end_time": 371997.0,
      "text": "It&#39;s been kind of a large focus of some of their strategy."
    },
    {
      "index": 155,
      "start_time": 371997.0,
      "end_time": 374170.0,
      "text": "And they put in a lot effort into engineering"
    },
    {
      "index": 156,
      "start_time": 374170.0,
      "end_time": 377647.0,
      "text": "sort of good solutions to make their hardware"
    },
    {
      "index": 157,
      "start_time": 377647.0,
      "end_time": 379354.0,
      "text": "better suited for deep learning."
    },
    {
      "index": 158,
      "start_time": 379354.0,
      "end_time": 383854.0,
      "text": "So most people in deep learning when we talk about GPUs,"
    },
    {
      "index": 159,
      "start_time": 383855.0,
      "end_time": 387718.0,
      "text": "we&#39;re pretty much exclusively talking about NVIDIA GPUs."
    },
    {
      "index": 160,
      "start_time": 387718.0,
      "end_time": 389607.0,
      "text": "Maybe in the future this&#39;ll change a little bit,"
    },
    {
      "index": 161,
      "start_time": 389607.0,
      "end_time": 391465.0,
      "text": "and there might be new players coming up,"
    },
    {
      "index": 162,
      "start_time": 391465.0,
      "end_time": 395268.0,
      "text": "but at least for now NVIDIA is pretty dominant."
    },
    {
      "index": 163,
      "start_time": 395268.0,
      "end_time": 397224.0,
      "text": "So to give you an idea of like what is the difference"
    },
    {
      "index": 164,
      "start_time": 397225.0,
      "end_time": 400163.0,
      "text": "between a CPU and a GPU, I&#39;ve kind of made a little"
    },
    {
      "index": 165,
      "start_time": 400163.0,
      "end_time": 401705.0,
      "text": "spread sheet here."
    },
    {
      "index": 166,
      "start_time": 401705.0,
      "end_time": 404758.0,
      "text": "On the top we have two of the kind of top end Intel"
    },
    {
      "index": 167,
      "start_time": 404759.0,
      "end_time": 407364.0,
      "text": "consumer CPUs, and on the bottom we have two of"
    },
    {
      "index": 168,
      "start_time": 407364.0,
      "end_time": 412780.0,
      "text": "NVIDIA&#39;s sort of current top end consumer GPUs."
    },
    {
      "index": 169,
      "start_time": 412790.0,
      "end_time": 415975.0,
      "text": "And there&#39;s a couple general trends to notice here."
    },
    {
      "index": 170,
      "start_time": 415975.0,
      "end_time": 418445.0,
      "text": "Both GPUs and CPUs are kind of a general purpose"
    },
    {
      "index": 171,
      "start_time": 418445.0,
      "end_time": 421359.0,
      "text": "computing machine where they can execute programs"
    },
    {
      "index": 172,
      "start_time": 421359.0,
      "end_time": 423284.0,
      "text": "and do sort of arbitrary instructions,"
    },
    {
      "index": 173,
      "start_time": 423284.0,
      "end_time": 425986.0,
      "text": "but they&#39;re qualitatively pretty different."
    },
    {
      "index": 174,
      "start_time": 425987.0,
      "end_time": 429298.0,
      "text": "So CPUs tend to have just a few cores,"
    },
    {
      "index": 175,
      "start_time": 429298.0,
      "end_time": 432700.0,
      "text": "for consumer desktop CPUs these days,"
    },
    {
      "index": 176,
      "start_time": 432700.0,
      "end_time": 434941.0,
      "text": "they might have something like four or six"
    },
    {
      "index": 177,
      "start_time": 434941.0,
      "end_time": 436714.0,
      "text": "or maybe up to 10 cores."
    },
    {
      "index": 178,
      "start_time": 436714.0,
      "end_time": 440393.0,
      "text": "With hyperthreading technology that means they can run,"
    },
    {
      "index": 179,
      "start_time": 440393.0,
      "end_time": 442726.0,
      "text": "the hardware can physically run, like maybe eight"
    },
    {
      "index": 180,
      "start_time": 442726.0,
      "end_time": 444893.0,
      "text": "or up to 20 threads concurrently."
    },
    {
      "index": 181,
      "start_time": 444893.0,
      "end_time": 449700.0,
      "text": "So the CPU can maybe do 20 things in parallel at once."
    },
    {
      "index": 182,
      "start_time": 449700.0,
      "end_time": 451691.0,
      "text": "So that&#39;s just not a gigantic number,"
    },
    {
      "index": 183,
      "start_time": 451691.0,
      "end_time": 454527.0,
      "text": "but those threads for a CPU are pretty powerful."
    },
    {
      "index": 184,
      "start_time": 454527.0,
      "end_time": 456840.0,
      "text": "They can actually do a lot of things,"
    },
    {
      "index": 185,
      "start_time": 456840.0,
      "end_time": 457223.0,
      "text": "they&#39;re very fast."
    },
    {
      "index": 186,
      "start_time": 457223.0,
      "end_time": 459660.0,
      "text": "Every CPU instruction can actually do quite a lot"
    },
    {
      "index": 187,
      "start_time": 459660.0,
      "end_time": 459899.0,
      "text": "of stuff."
    },
    {
      "index": 188,
      "start_time": 459899.0,
      "end_time": 463110.0,
      "text": "And they can all work pretty independently."
    },
    {
      "index": 189,
      "start_time": 463110.0,
      "end_time": 465303.0,
      "text": "For GPUs it&#39;s a little bit different."
    },
    {
      "index": 190,
      "start_time": 465303.0,
      "end_time": 468672.0,
      "text": "So for GPUs we see that these sort of common top end"
    },
    {
      "index": 191,
      "start_time": 468672.0,
      "end_time": 471909.0,
      "text": "consumer GPUs have thousands of cores."
    },
    {
      "index": 192,
      "start_time": 471909.0,
      "end_time": 475340.0,
      "text": "So the NVIDIA Titan XP which is the current"
    },
    {
      "index": 193,
      "start_time": 475340.0,
      "end_time": 479600.0,
      "text": "top of the line consumer GPU has 3840 cores."
    },
    {
      "index": 194,
      "start_time": 480818.0,
      "end_time": 482222.0,
      "text": "So that&#39;s a crazy number."
    },
    {
      "index": 195,
      "start_time": 482223.0,
      "end_time": 484615.0,
      "text": "That&#39;s like way more than the 10 cores that you&#39;ll get"
    },
    {
      "index": 196,
      "start_time": 484615.0,
      "end_time": 486357.0,
      "text": "for a similarly priced CPU."
    },
    {
      "index": 197,
      "start_time": 486357.0,
      "end_time": 489574.0,
      "text": "The downside of a GPU is that each of those cores,"
    },
    {
      "index": 198,
      "start_time": 489574.0,
      "end_time": 492207.0,
      "text": "one, it runs at a much slower clock speed."
    },
    {
      "index": 199,
      "start_time": 492207.0,
      "end_time": 494439.0,
      "text": "And two they really can&#39;t do quite as much."
    },
    {
      "index": 200,
      "start_time": 494439.0,
      "end_time": 497441.0,
      "text": "You can&#39;t really compare CPU cores and GPU cores"
    },
    {
      "index": 201,
      "start_time": 497441.0,
      "end_time": 499679.0,
      "text": "apples to apples."
    },
    {
      "index": 202,
      "start_time": 499680.0,
      "end_time": 502510.0,
      "text": "The GPU cores can&#39;t really operate very independently."
    },
    {
      "index": 203,
      "start_time": 502510.0,
      "end_time": 504460.0,
      "text": "They all kind of need to work together"
    },
    {
      "index": 204,
      "start_time": 504460.0,
      "end_time": 506589.0,
      "text": "and sort of paralyze one task across many cores"
    },
    {
      "index": 205,
      "start_time": 506589.0,
      "end_time": 509297.0,
      "text": "rather than each core totally doing its own thing."
    },
    {
      "index": 206,
      "start_time": 509297.0,
      "end_time": 512406.0,
      "text": "So you can&#39;t really compare these numbers directly."
    },
    {
      "index": 207,
      "start_time": 512405.0,
      "end_time": 514708.0,
      "text": "But it should give you the sense that due"
    },
    {
      "index": 208,
      "start_time": 514707.99999999994,
      "end_time": 517179.99999999994,
      "text": "to the large number of cores GPUs can sort of,"
    },
    {
      "index": 209,
      "start_time": 517190.00000000006,
      "end_time": 519440.00000000006,
      "text": "are really good for parallel things where you"
    },
    {
      "index": 210,
      "start_time": 519440.00000000006,
      "end_time": 521370.00000000006,
      "text": "need to do a lot of things all at the same time,"
    },
    {
      "index": 211,
      "start_time": 521370.0,
      "end_time": 524742.0,
      "text": "but those things are all pretty much the same flavor."
    },
    {
      "index": 212,
      "start_time": 524742.0,
      "end_time": 528140.0,
      "text": "Another thing to point out between CPUs and GPUs"
    },
    {
      "index": 213,
      "start_time": 528140.0,
      "end_time": 529387.0,
      "text": "is this idea of memory."
    },
    {
      "index": 214,
      "start_time": 529387.0,
      "end_time": 532887.0,
      "text": "Right, so CPUs have some cache on the CPU,"
    },
    {
      "index": 215,
      "start_time": 533770.0,
      "end_time": 536151.0,
      "text": "but that&#39;s relatively small and the majority"
    },
    {
      "index": 216,
      "start_time": 536151.0,
      "end_time": 538522.0,
      "text": "of the memory for your CPU is pulling from your"
    },
    {
      "index": 217,
      "start_time": 538523.0,
      "end_time": 540969.0,
      "text": "system memory, the RAM, which will maybe be like"
    },
    {
      "index": 218,
      "start_time": 540969.0,
      "end_time": 544538.0,
      "text": "eight, 12, 16, 32 gigabytes of RAM on a typical"
    },
    {
      "index": 219,
      "start_time": 544538.0,
      "end_time": 546589.0,
      "text": "consumer desktop these days."
    },
    {
      "index": 220,
      "start_time": 546589.0,
      "end_time": 549479.0,
      "text": "Whereas GPUs actually have their own RAM built"
    },
    {
      "index": 221,
      "start_time": 549479.0,
      "end_time": 550646.0,
      "text": "into the chip."
    },
    {
      "index": 222,
      "start_time": 552550.0,
      "end_time": 553627.0,
      "text": "There&#39;s a pretty large bottleneck communicating"
    },
    {
      "index": 223,
      "start_time": 553627.0,
      "end_time": 556434.0,
      "text": "between the RAM in your system and the GPU,"
    },
    {
      "index": 224,
      "start_time": 556434.0,
      "end_time": 558507.0,
      "text": "so the GPUs typically have their own"
    },
    {
      "index": 225,
      "start_time": 558508.0,
      "end_time": 562675.0,
      "text": "relatively large block of memory within the card itself."
    },
    {
      "index": 226,
      "start_time": 563955.0,
      "end_time": 567172.0,
      "text": "And for the Titan XP, which again is maybe the current"
    },
    {
      "index": 227,
      "start_time": 567172.0,
      "end_time": 569920.0,
      "text": "top of the line consumer card,"
    },
    {
      "index": 228,
      "start_time": 569920.0,
      "end_time": 573481.0,
      "text": "this thing has 12 gigabytes of memory local to the GPU."
    },
    {
      "index": 229,
      "start_time": 573481.0,
      "end_time": 575462.0,
      "text": "GPUs also have their own caching system"
    },
    {
      "index": 230,
      "start_time": 575462.0,
      "end_time": 577755.0,
      "text": "where there are sort of multiple hierarchies of caching"
    },
    {
      "index": 231,
      "start_time": 577755.0,
      "end_time": 580670.0,
      "text": "between the 12 gigabytes of GPU memory"
    },
    {
      "index": 232,
      "start_time": 580670.0,
      "end_time": 581790.0,
      "text": "and the actual GPU cores."
    },
    {
      "index": 233,
      "start_time": 581790.0,
      "end_time": 584574.0,
      "text": "And that&#39;s somewhat similar to the caching hierarchy"
    },
    {
      "index": 234,
      "start_time": 584575.0,
      "end_time": 586908.0,
      "text": "that you might see in a CPU."
    },
    {
      "index": 235,
      "start_time": 587985.0,
      "end_time": 590652.0,
      "text": "So, CPUs are kind of good for general purpose processing."
    },
    {
      "index": 236,
      "start_time": 590652.0,
      "end_time": 592583.0,
      "text": "They can do a lot of different things."
    },
    {
      "index": 237,
      "start_time": 592583.0,
      "end_time": 594572.0,
      "text": "And GPUs are maybe more specialized for these highly"
    },
    {
      "index": 238,
      "start_time": 594572.0,
      "end_time": 597890.0,
      "text": "paralyzable algorithms."
    },
    {
      "index": 239,
      "start_time": 597890.0,
      "end_time": 599167.0,
      "text": "So the prototypical algorithm of something that works"
    },
    {
      "index": 240,
      "start_time": 599167.0,
      "end_time": 601969.0,
      "text": "really really well and is like perfectly suited"
    },
    {
      "index": 241,
      "start_time": 601969.0,
      "end_time": 604106.0,
      "text": "to a GPU is matrix multiplication."
    },
    {
      "index": 242,
      "start_time": 604106.0,
      "end_time": 606733.0,
      "text": "So remember in matrix multiplication on the left"
    },
    {
      "index": 243,
      "start_time": 606733.0,
      "end_time": 609686.0,
      "text": "we&#39;ve got like a matrix composed of a bunch of rows."
    },
    {
      "index": 244,
      "start_time": 609687.0,
      "end_time": 612482.0,
      "text": "We multiply that on the right by another matrix composed"
    },
    {
      "index": 245,
      "start_time": 612482.0,
      "end_time": 614348.0,
      "text": "of a bunch of columns and then this produces"
    },
    {
      "index": 246,
      "start_time": 614348.0,
      "end_time": 617497.0,
      "text": "another, a final matrix where each element in the"
    },
    {
      "index": 247,
      "start_time": 617498.0,
      "end_time": 620718.0,
      "text": "output matrix is a dot product between one of the rows"
    },
    {
      "index": 248,
      "start_time": 620718.0,
      "end_time": 622780.0,
      "text": "and one of the columns of the two input matrices."
    },
    {
      "index": 249,
      "start_time": 622780.0,
      "end_time": 625900.0,
      "text": "And these dot products are all independent."
    },
    {
      "index": 250,
      "start_time": 625900.0,
      "end_time": 627548.0,
      "text": "Like you could imagine, for this output matrix"
    },
    {
      "index": 251,
      "start_time": 627548.0,
      "end_time": 629202.0,
      "text": "you could split it up completely"
    },
    {
      "index": 252,
      "start_time": 629202.0,
      "end_time": 631110.0,
      "text": "and have each of those different elements"
    },
    {
      "index": 253,
      "start_time": 631110.0,
      "end_time": 633653.0,
      "text": "of the output matrix all being computed in parallel"
    },
    {
      "index": 254,
      "start_time": 633653.0,
      "end_time": 635646.0,
      "text": "and they all sort of are running the same computation"
    },
    {
      "index": 255,
      "start_time": 635646.0,
      "end_time": 638289.0,
      "text": "which is taking a dot product of these two vectors."
    },
    {
      "index": 256,
      "start_time": 638289.0,
      "end_time": 640754.0,
      "text": "But exactly where they&#39;re reading that data from"
    },
    {
      "index": 257,
      "start_time": 640754.0,
      "end_time": 644177.0,
      "text": "is from different places in the two input matrices."
    },
    {
      "index": 258,
      "start_time": 644177.0,
      "end_time": 646920.0,
      "text": "So you could imagine that for a GPU you can just"
    },
    {
      "index": 259,
      "start_time": 646920.0,
      "end_time": 648797.0,
      "text": "like blast this out and have all of this elements"
    },
    {
      "index": 260,
      "start_time": 648797.0,
      "end_time": 650390.0,
      "text": "of the output matrix all computed in parallel"
    },
    {
      "index": 261,
      "start_time": 650390.0,
      "end_time": 653909.0,
      "text": "and that could make this thing computer super super fast"
    },
    {
      "index": 262,
      "start_time": 653909.0,
      "end_time": 655165.0,
      "text": "on GPU."
    },
    {
      "index": 263,
      "start_time": 655166.0,
      "end_time": 657985.0,
      "text": "So that&#39;s kind of the prototypical type of problem"
    },
    {
      "index": 264,
      "start_time": 657985.0,
      "end_time": 660431.0,
      "text": "that like where a GPU is really well suited,"
    },
    {
      "index": 265,
      "start_time": 660431.0,
      "end_time": 662293.0,
      "text": "where a CPU might have to go in and step through"
    },
    {
      "index": 266,
      "start_time": 662293.0,
      "end_time": 664230.0,
      "text": "sequentially and compute each of these elements"
    },
    {
      "index": 267,
      "start_time": 664230.0,
      "end_time": 664940.0,
      "text": "one by one."
    },
    {
      "index": 268,
      "start_time": 666337.0,
      "end_time": 669473.0,
      "text": "That picture is a little bit of a caricature because"
    },
    {
      "index": 269,
      "start_time": 669473.0,
      "end_time": 671647.0,
      "text": "CPUs these days have multiple cores,"
    },
    {
      "index": 270,
      "start_time": 671648.0,
      "end_time": 673829.0,
      "text": "they can do vectorized instructions as well,"
    },
    {
      "index": 271,
      "start_time": 673829.0,
      "end_time": 676651.0,
      "text": "but still, for these like massively parallel problems"
    },
    {
      "index": 272,
      "start_time": 676652.0,
      "end_time": 679568.0,
      "text": "GPUs tend to have much better throughput."
    },
    {
      "index": 273,
      "start_time": 679568.0,
      "end_time": 681350.0,
      "text": "Especially when these matrices get really really big."
    },
    {
      "index": 274,
      "start_time": 681350.0,
      "end_time": 684265.0,
      "text": "And by the way, convolution is kind of the same"
    },
    {
      "index": 275,
      "start_time": 684265.0,
      "end_time": 685404.0,
      "text": "kind of story."
    },
    {
      "index": 276,
      "start_time": 685404.0,
      "end_time": 687827.0,
      "text": "Where you know in convolution we have this input tensor,"
    },
    {
      "index": 277,
      "start_time": 687827.0,
      "end_time": 690128.0,
      "text": "we have this weight tensor and then every point in the"
    },
    {
      "index": 278,
      "start_time": 690128.0,
      "end_time": 693260.0,
      "text": "output tensor after a convolution is again some inner"
    },
    {
      "index": 279,
      "start_time": 693260.0,
      "end_time": 695800.0,
      "text": "product between some part of the weights"
    },
    {
      "index": 280,
      "start_time": 695810.0,
      "end_time": 696359.0,
      "text": "and some part of the input."
    },
    {
      "index": 281,
      "start_time": 696359.0,
      "end_time": 698326.0,
      "text": "And you can imagine that a GPU could really paralyze"
    },
    {
      "index": 282,
      "start_time": 698326.0,
      "end_time": 701693.0,
      "text": "this computation, split it all up across the many cores"
    },
    {
      "index": 283,
      "start_time": 701693.0,
      "end_time": 703353.0,
      "text": "and compute it very quickly."
    },
    {
      "index": 284,
      "start_time": 703354.0,
      "end_time": 705746.0,
      "text": "So that&#39;s kind of the general flavor of the types"
    },
    {
      "index": 285,
      "start_time": 705746.0,
      "end_time": 708677.0,
      "text": "of problems where GPUs give you a huge speed advantage"
    },
    {
      "index": 286,
      "start_time": 708677.0,
      "end_time": 709510.0,
      "text": "over CPUs."
    },
    {
      "index": 287,
      "start_time": 711695.0,
      "end_time": 714230.0,
      "text": "So you can actually write programs that run directly"
    },
    {
      "index": 288,
      "start_time": 714230.0,
      "end_time": 715498.0,
      "text": "on GPUs."
    },
    {
      "index": 289,
      "start_time": 715498.0,
      "end_time": 718136.0,
      "text": "So NVIDIA has this CUDA abstraction that lets you write"
    },
    {
      "index": 290,
      "start_time": 718136.0,
      "end_time": 720377.0,
      "text": "code that kind of looks like C,"
    },
    {
      "index": 291,
      "start_time": 720378.0,
      "end_time": 723614.0,
      "text": "but executes directly on the GPUs."
    },
    {
      "index": 292,
      "start_time": 723614.0,
      "end_time": 725484.0,
      "text": "But CUDA code is really really tricky."
    },
    {
      "index": 293,
      "start_time": 725484.0,
      "end_time": 728230.0,
      "text": "It&#39;s actually really tough to write CUDA code that&#39;s"
    },
    {
      "index": 294,
      "start_time": 728230.0,
      "end_time": 730560.0,
      "text": "performant and actually squeezes all the juice out"
    },
    {
      "index": 295,
      "start_time": 730560.0,
      "end_time": 732200.0,
      "text": "of these GPUs."
    },
    {
      "index": 296,
      "start_time": 732200.0,
      "end_time": 733842.0,
      "text": "You have to be very careful managing the memory hierarchy"
    },
    {
      "index": 297,
      "start_time": 733842.0,
      "end_time": 736140.0,
      "text": "and making sure you don&#39;t have cache misses"
    },
    {
      "index": 298,
      "start_time": 736140.0,
      "end_time": 739163.0,
      "text": "and branch mispredictions and all that sort of stuff."
    },
    {
      "index": 299,
      "start_time": 739163.0,
      "end_time": 741373.0,
      "text": "So it&#39;s actually really really hard to write performant"
    },
    {
      "index": 300,
      "start_time": 741373.0,
      "end_time": 742930.0,
      "text": "CUDA code on your own."
    },
    {
      "index": 301,
      "start_time": 742930.0,
      "end_time": 745885.0,
      "text": "So as a result NVIDIA has released a lot of libraries"
    },
    {
      "index": 302,
      "start_time": 745885.0,
      "end_time": 749152.0,
      "text": "that implement common computational primitives"
    },
    {
      "index": 303,
      "start_time": 749152.0,
      "end_time": 752537.0,
      "text": "that are very very highly optimized for GPUs."
    },
    {
      "index": 304,
      "start_time": 752537.0,
      "end_time": 755938.0,
      "text": "So for example NVIDIA has a cuBLAS library that implements"
    },
    {
      "index": 305,
      "start_time": 755938.0,
      "end_time": 758152.0,
      "text": "different kinds of matrix multiplications"
    },
    {
      "index": 306,
      "start_time": 758152.0,
      "end_time": 760610.0,
      "text": "and different matrix operations that are super optimized,"
    },
    {
      "index": 307,
      "start_time": 760610.0,
      "end_time": 763517.0,
      "text": "run really well on GPU, get very close to sort of"
    },
    {
      "index": 308,
      "start_time": 763517.0,
      "end_time": 766438.0,
      "text": "theoretical peak hardware utilization."
    },
    {
      "index": 309,
      "start_time": 766438.0,
      "end_time": 768817.0,
      "text": "Similarly they have a cuDNN library which implements"
    },
    {
      "index": 310,
      "start_time": 768817.0,
      "end_time": 771964.0,
      "text": "things like convolution, forward and backward passes,"
    },
    {
      "index": 311,
      "start_time": 771964.0,
      "end_time": 774499.0,
      "text": "batch normalization, recurrent networks,"
    },
    {
      "index": 312,
      "start_time": 774499.0,
      "end_time": 776116.0,
      "text": "all these kinds of computational primitives"
    },
    {
      "index": 313,
      "start_time": 776116.0,
      "end_time": 777454.0,
      "text": "that we need in deep learning."
    },
    {
      "index": 314,
      "start_time": 777454.0,
      "end_time": 780530.0,
      "text": "NVIDIA has gone in there and released their own binaries"
    },
    {
      "index": 315,
      "start_time": 780530.0,
      "end_time": 782600.0,
      "text": "that compute these primitives very efficiently"
    },
    {
      "index": 316,
      "start_time": 782600.0,
      "end_time": 783842.0,
      "text": "on NVIDIA hardware."
    },
    {
      "index": 317,
      "start_time": 783842.0,
      "end_time": 787776.0,
      "text": "So in practice, you tend not to end up writing your own"
    },
    {
      "index": 318,
      "start_time": 787777.0,
      "end_time": 789624.0,
      "text": "CUDA code for deep learning."
    },
    {
      "index": 319,
      "start_time": 789624.0,
      "end_time": 792642.0,
      "text": "You typically are just mostly calling into existing"
    },
    {
      "index": 320,
      "start_time": 792642.0,
      "end_time": 794173.0,
      "text": "code that other people have written."
    },
    {
      "index": 321,
      "start_time": 794173.0,
      "end_time": 796493.0,
      "text": "Much of which is the stuff which has been heavily"
    },
    {
      "index": 322,
      "start_time": 796493.0,
      "end_time": 799573.0,
      "text": "optimized by NVIDIA already."
    },
    {
      "index": 323,
      "start_time": 799573.0,
      "end_time": 802457.0,
      "text": "There&#39;s another sort of language called OpenCL"
    },
    {
      "index": 324,
      "start_time": 802457.0,
      "end_time": 803693.0,
      "text": "which is a bit more general."
    },
    {
      "index": 325,
      "start_time": 803693.0,
      "end_time": 805850.0,
      "text": "Runs on more than just NVIDIA GPUs,"
    },
    {
      "index": 326,
      "start_time": 805850.0,
      "end_time": 809185.0,
      "text": "can run on AMD hardware, can run on CPUs,"
    },
    {
      "index": 327,
      "start_time": 809185.0,
      "end_time": 813524.0,
      "text": "but OpenCL, nobody&#39;s really spent a really large amount"
    },
    {
      "index": 328,
      "start_time": 813524.0,
      "end_time": 816742.0,
      "text": "of effort and energy trying to get optimized deep learning"
    },
    {
      "index": 329,
      "start_time": 816742.0,
      "end_time": 819934.0,
      "text": "primitives for OpenCL, so it tends to be a lot less"
    },
    {
      "index": 330,
      "start_time": 819934.0,
      "end_time": 823938.0,
      "text": "performant the super optimized versions in CUDA."
    },
    {
      "index": 331,
      "start_time": 823938.0,
      "end_time": 826262.0,
      "text": "So maybe in the future we might see a bit of a more open"
    },
    {
      "index": 332,
      "start_time": 826262.0,
      "end_time": 829700.0,
      "text": "standard and we might see this across many different"
    },
    {
      "index": 333,
      "start_time": 829800.0,
      "end_time": 831839.0,
      "text": "more types of platforms, but at least for now,"
    },
    {
      "index": 334,
      "start_time": 831839.0,
      "end_time": 835488.0,
      "text": "NVIDIA&#39;s kind of the main game in town for deep learning."
    },
    {
      "index": 335,
      "start_time": 835488.0,
      "end_time": 838159.0,
      "text": "So you can check, there&#39;s a lot of different resources"
    },
    {
      "index": 336,
      "start_time": 838159.0,
      "end_time": 840853.0,
      "text": "for learning about how you can do GPU programming yourself."
    },
    {
      "index": 337,
      "start_time": 840853.0,
      "end_time": 841685.0,
      "text": "It&#39;s kind of fun."
    },
    {
      "index": 338,
      "start_time": 841686.0,
      "end_time": 843919.0,
      "text": "It&#39;s sort of a different paradigm of writing code"
    },
    {
      "index": 339,
      "start_time": 843919.0,
      "end_time": 845900.0,
      "text": "because it&#39;s this massively parallel architecture,"
    },
    {
      "index": 340,
      "start_time": 845900.0,
      "end_time": 848230.0,
      "text": "but that&#39;s a bit beyond the scope of this course."
    },
    {
      "index": 341,
      "start_time": 848230.0,
      "end_time": 850424.0,
      "text": "And again, you don&#39;t really need to write your own"
    },
    {
      "index": 342,
      "start_time": 850424.0,
      "end_time": 852263.0,
      "text": "CUDA code much in practice for deep learning."
    },
    {
      "index": 343,
      "start_time": 852263.0,
      "end_time": 854872.0,
      "text": "And in fact, I&#39;ve never written my own CUDA code"
    },
    {
      "index": 344,
      "start_time": 854872.0,
      "end_time": 856599.0,
      "text": "for any research project, so,"
    },
    {
      "index": 345,
      "start_time": 856600.0,
      "end_time": 858856.0,
      "text": "but it is kind of useful to know like how it works"
    },
    {
      "index": 346,
      "start_time": 858856.0,
      "end_time": 860552.0,
      "text": "and what are the basic ideas even if you&#39;re not"
    },
    {
      "index": 347,
      "start_time": 860552.0,
      "end_time": 862219.0,
      "text": "writing it yourself."
    },
    {
      "index": 348,
      "start_time": 863488.0,
      "end_time": 866600.0,
      "text": "So if you want to look at kind of CPU GPU performance"
    },
    {
      "index": 349,
      "start_time": 866600.0,
      "end_time": 869167.0,
      "text": "in practice, I did some benchmarks last summer"
    },
    {
      "index": 350,
      "start_time": 869168.0,
      "end_time": 871501.0,
      "text": "comparing a decent Intel CPU"
    },
    {
      "index": 351,
      "start_time": 874183.0,
      "end_time": 876766.0,
      "text": "against a bunch of different GPUs that were sort"
    },
    {
      "index": 352,
      "start_time": 876766.0,
      "end_time": 878747.0,
      "text": "of near top of the line at that time."
    },
    {
      "index": 353,
      "start_time": 878747.0,
      "end_time": 881980.0,
      "text": "And these were my own benchmarks that you can find"
    },
    {
      "index": 354,
      "start_time": 881980.0,
      "end_time": 884786.0,
      "text": "more details on GitHub, but my findings were that"
    },
    {
      "index": 355,
      "start_time": 884787.0,
      "end_time": 888954.0,
      "text": "for things like VGG 16 and 19, ResNets, various ResNets,"
    },
    {
      "index": 356,
      "start_time": 889830.0,
      "end_time": 893186.0,
      "text": "then you typically see something like a 65 to 75 times"
    },
    {
      "index": 357,
      "start_time": 893186.0,
      "end_time": 897114.0,
      "text": "speed up when running the exact same computation"
    },
    {
      "index": 358,
      "start_time": 897114.0,
      "end_time": 900984.0,
      "text": "on a top of the line GPU, in this case a Pascal Titan X,"
    },
    {
      "index": 359,
      "start_time": 900984.0,
      "end_time": 904183.0,
      "text": "versus a top of the line, well, not quite top of the line"
    },
    {
      "index": 360,
      "start_time": 904183.0,
      "end_time": 908604.0,
      "text": "CPU, which in this case was an Intel E5 processor."
    },
    {
      "index": 361,
      "start_time": 908604.0,
      "end_time": 912388.0,
      "text": "Although, I&#39;d like to make one sort of caveat here"
    },
    {
      "index": 362,
      "start_time": 912388.0,
      "end_time": 914194.0,
      "text": "is that you always need to be super careful"
    },
    {
      "index": 363,
      "start_time": 914194.0,
      "end_time": 915550.0,
      "text": "whenever you&#39;re reading any kind of benchmarks"
    },
    {
      "index": 364,
      "start_time": 915550.0,
      "end_time": 918400.0,
      "text": "about deep learning, because it&#39;s super easy to be"
    },
    {
      "index": 365,
      "start_time": 918400.0,
      "end_time": 920103.0,
      "text": "unfair between different things."
    },
    {
      "index": 366,
      "start_time": 920103.0,
      "end_time": 922103.0,
      "text": "And you kind of need to know a lot of the details about"
    },
    {
      "index": 367,
      "start_time": 922103.0,
      "end_time": 924373.0,
      "text": "what exactly is being benchmarked in order to know"
    },
    {
      "index": 368,
      "start_time": 924374.0,
      "end_time": 926339.0,
      "text": "whether or not the comparison is fair."
    },
    {
      "index": 369,
      "start_time": 926339.0,
      "end_time": 929680.0,
      "text": "So in this case I&#39;ll come right out and tell you"
    },
    {
      "index": 370,
      "start_time": 929680.0,
      "end_time": 931473.0,
      "text": "that probably this comparison is a little bit unfair"
    },
    {
      "index": 371,
      "start_time": 931473.0,
      "end_time": 935854.0,
      "text": "to CPU because I didn&#39;t spend a lot of effort"
    },
    {
      "index": 372,
      "start_time": 935855.0,
      "end_time": 937638.0,
      "text": "trying to squeeze the maximal performance"
    },
    {
      "index": 373,
      "start_time": 937638.0,
      "end_time": 938721.0,
      "text": "out of CPUs."
    },
    {
      "index": 374,
      "start_time": 938721.0,
      "end_time": 941650.0,
      "text": "I probably could have tuned the blast libraries better"
    },
    {
      "index": 375,
      "start_time": 941650.0,
      "end_time": 942483.0,
      "text": "for the CPU performance."
    },
    {
      "index": 376,
      "start_time": 942483.0,
      "end_time": 943707.0,
      "text": "And I probably could have gotten these numbers"
    },
    {
      "index": 377,
      "start_time": 943707.0,
      "end_time": 944540.0,
      "text": "a bit better."
    },
    {
      "index": 378,
      "start_time": 944540.0,
      "end_time": 946540.0,
      "text": "This was sort of out of the box performance"
    },
    {
      "index": 379,
      "start_time": 946540.0,
      "end_time": 949180.0,
      "text": "between just installing Torch, running it on a CPU,"
    },
    {
      "index": 380,
      "start_time": 949180.0,
      "end_time": 951964.0,
      "text": "just installing Torch running it on a GPU."
    },
    {
      "index": 381,
      "start_time": 951964.0,
      "end_time": 953884.0,
      "text": "So this is kind of out of the box performance,"
    },
    {
      "index": 382,
      "start_time": 953884.0,
      "end_time": 956277.0,
      "text": "but it&#39;s not really like peak, possible, theoretical"
    },
    {
      "index": 383,
      "start_time": 956277.0,
      "end_time": 957872.0,
      "text": "throughput on the CPU."
    },
    {
      "index": 384,
      "start_time": 957872.0,
      "end_time": 960262.0,
      "text": "But that being said, I think there are still pretty"
    },
    {
      "index": 385,
      "start_time": 960263.0,
      "end_time": 962422.0,
      "text": "substantial speed ups to be had here."
    },
    {
      "index": 386,
      "start_time": 962422.0,
      "end_time": 965660.0,
      "text": "Another kind of interesting outcome from this benchmarking"
    },
    {
      "index": 387,
      "start_time": 965660.0,
      "end_time": 969602.0,
      "text": "was comparing these optimized cuDNN libraries"
    },
    {
      "index": 388,
      "start_time": 969602.0,
      "end_time": 972478.0,
      "text": "from NVIDIA for convolution and whatnot versus"
    },
    {
      "index": 389,
      "start_time": 972478.0,
      "end_time": 975543.0,
      "text": "sort of more naive CUDA that had been hand written"
    },
    {
      "index": 390,
      "start_time": 975543.0,
      "end_time": 977623.0,
      "text": "out in the open source community."
    },
    {
      "index": 391,
      "start_time": 977623.0,
      "end_time": 979815.0,
      "text": "And you can see that if you compare the same networks"
    },
    {
      "index": 392,
      "start_time": 979815.0,
      "end_time": 982278.0,
      "text": "on the same hardware with the same deep learning"
    },
    {
      "index": 393,
      "start_time": 982278.0,
      "end_time": 984653.0,
      "text": "framework and the only difference is swapping out"
    },
    {
      "index": 394,
      "start_time": 984653.0,
      "end_time": 987340.0,
      "text": "these cuDNN versus sort of hand written, less optimized"
    },
    {
      "index": 395,
      "start_time": 987340.0,
      "end_time": 990312.0,
      "text": "CUDA you can see something like nearly a three X speed up"
    },
    {
      "index": 396,
      "start_time": 990312.0,
      "end_time": 993714.0,
      "text": "across the board when you switch from the relatively"
    },
    {
      "index": 397,
      "start_time": 993714.0,
      "end_time": 995777.0,
      "text": "simple CUDA to these like super optimized cuDNN"
    },
    {
      "index": 398,
      "start_time": 995777.0,
      "end_time": 997442.0,
      "text": "implementations."
    },
    {
      "index": 399,
      "start_time": 997442.0,
      "end_time": 1000440.0,
      "text": "So in general, whenever you&#39;re writing code on GPU,"
    },
    {
      "index": 400,
      "start_time": 1000440.0,
      "end_time": 1003143.0,
      "text": "you should probably almost always like just make sure"
    },
    {
      "index": 401,
      "start_time": 1003140.0,
      "end_time": 1005199.0,
      "text": "you&#39;re using cuDNN because you&#39;re leaving probably"
    },
    {
      "index": 402,
      "start_time": 1005200.0,
      "end_time": 1007701.0,
      "text": "a three X performance boost on the table if you&#39;re"
    },
    {
      "index": 403,
      "start_time": 1007700.0,
      "end_time": 1011599.0,
      "text": "not calling into cuDNN for your stuff."
    },
    {
      "index": 404,
      "start_time": 1011600.0,
      "end_time": 1013360.0,
      "text": "So another problem that comes up in practice,"
    },
    {
      "index": 405,
      "start_time": 1013360.0,
      "end_time": 1015380.0,
      "text": "when you&#39;re training these things is that"
    },
    {
      "index": 406,
      "start_time": 1015380.0,
      "end_time": 1017561.0,
      "text": "you know, your model is maybe sitting on the GPU,"
    },
    {
      "index": 407,
      "start_time": 1017560.0,
      "end_time": 1019917.0,
      "text": "the weights of the model are in that 12 gigabytes"
    },
    {
      "index": 408,
      "start_time": 1019920.0,
      "end_time": 1022880.0,
      "text": "of local storage on the GPU, but your big dataset"
    },
    {
      "index": 409,
      "start_time": 1022880.0,
      "end_time": 1025200.0,
      "text": "is sitting over on the right on a hard drive"
    },
    {
      "index": 410,
      "start_time": 1025200.0,
      "end_time": 1027241.0,
      "text": "or an SSD or something like that."
    },
    {
      "index": 411,
      "start_time": 1027240.0,
      "end_time": 1030201.0,
      "text": "So if you&#39;re not careful you can actually bottleneck"
    },
    {
      "index": 412,
      "start_time": 1030200.0,
      "end_time": 1032117.0,
      "text": "your training by just trying to read the data"
    },
    {
      "index": 413,
      "start_time": 1032119.9999999999,
      "end_time": 1033202.9999999999,
      "text": "off the disk."
    },
    {
      "index": 414,
      "start_time": 1034319.9999999999,
      "end_time": 1036111.9999999999,
      "text": "&#39;Cause the GPU is super fast, it can compute"
    },
    {
      "index": 415,
      "start_time": 1036109.9999999999,
      "end_time": 1038637.9999999999,
      "text": "forward and backward quite fast, but if you&#39;re reading"
    },
    {
      "index": 416,
      "start_time": 1038640.0000000001,
      "end_time": 1040972.0000000001,
      "text": "sequentially off a spinning disk, you can actually"
    },
    {
      "index": 417,
      "start_time": 1040970.0,
      "end_time": 1043197.0,
      "text": "bottleneck your training quite,"
    },
    {
      "index": 418,
      "start_time": 1043200.0,
      "end_time": 1045699.0,
      "text": "and that can be really bad and slow you down."
    },
    {
      "index": 419,
      "start_time": 1045700.0,
      "end_time": 1047180.0,
      "text": "So some solutions here are that like you know"
    },
    {
      "index": 420,
      "start_time": 1047180.0000000001,
      "end_time": 1049848.0,
      "text": "if your dataset&#39;s really small, sometimes you might just"
    },
    {
      "index": 421,
      "start_time": 1049850.0,
      "end_time": 1051461.0,
      "text": "read the whole dataset into RAM."
    },
    {
      "index": 422,
      "start_time": 1051460.0,
      "end_time": 1053485.0,
      "text": "Or even if your dataset isn&#39;t so small,"
    },
    {
      "index": 423,
      "start_time": 1053480.0,
      "end_time": 1055396.0,
      "text": "but you have a giant server with a ton of RAM,"
    },
    {
      "index": 424,
      "start_time": 1055500.0,
      "end_time": 1056479.0,
      "text": "you might do that anyway."
    },
    {
      "index": 425,
      "start_time": 1056480.0,
      "end_time": 1058664.0,
      "text": "You can also make sure you&#39;re using an SSD instead"
    },
    {
      "index": 426,
      "start_time": 1058660.0,
      "end_time": 1062914.0,
      "text": "of a hard drive, that can help a lot with read throughput."
    },
    {
      "index": 427,
      "start_time": 1062920.0,
      "end_time": 1065498.0,
      "text": "Another common strategy is to use multiple threads"
    },
    {
      "index": 428,
      "start_time": 1065490.0,
      "end_time": 1069156.0,
      "text": "on the CPU that are pre-fetching data off RAM"
    },
    {
      "index": 429,
      "start_time": 1069160.0,
      "end_time": 1072150.0,
      "text": "or off disk, buffering it in memory, in RAM so that"
    },
    {
      "index": 430,
      "start_time": 1072150.0,
      "end_time": 1074703.0,
      "text": "then you can continue feeding that buffer data down"
    },
    {
      "index": 431,
      "start_time": 1074700.0,
      "end_time": 1077719.0,
      "text": "to the GPU with good performance."
    },
    {
      "index": 432,
      "start_time": 1077720.0,
      "end_time": 1079103.0,
      "text": "This is a little bit painful to set up,"
    },
    {
      "index": 433,
      "start_time": 1079110.0,
      "end_time": 1081829.0,
      "text": "but again like, these GPU&#39;s are so fast that"
    },
    {
      "index": 434,
      "start_time": 1081830.0,
      "end_time": 1083686.0,
      "text": "if you&#39;re not really careful with trying to feed"
    },
    {
      "index": 435,
      "start_time": 1083680.0,
      "end_time": 1085541.0,
      "text": "them data as quickly as possible,"
    },
    {
      "index": 436,
      "start_time": 1085540.0,
      "end_time": 1087161.0,
      "text": "just reading the data can sometimes bottleneck"
    },
    {
      "index": 437,
      "start_time": 1087160.0,
      "end_time": 1088800.0,
      "text": "the whole training process."
    },
    {
      "index": 438,
      "start_time": 1088800.0,
      "end_time": 1091653.0,
      "text": "So that&#39;s something to be aware of."
    },
    {
      "index": 439,
      "start_time": 1091660.0,
      "end_time": 1093531.0,
      "text": "So that&#39;s kind of the brief introduction to like"
    },
    {
      "index": 440,
      "start_time": 1093530.0,
      "end_time": 1095902.0,
      "text": "sort of GPU CPU hardware in practice when it comes"
    },
    {
      "index": 441,
      "start_time": 1095900.0,
      "end_time": 1097432.0,
      "text": "to deep learning."
    },
    {
      "index": 442,
      "start_time": 1097430.0,
      "end_time": 1099213.0,
      "text": "And then I wanted to switch gears a little bit"
    },
    {
      "index": 443,
      "start_time": 1099210.0,
      "end_time": 1101611.0,
      "text": "and talk about the software side of things."
    },
    {
      "index": 444,
      "start_time": 1101620.0,
      "end_time": 1103927.0,
      "text": "The various deep learning frameworks that people are using"
    },
    {
      "index": 445,
      "start_time": 1103920.0,
      "end_time": 1105597.0,
      "text": "in practice."
    },
    {
      "index": 446,
      "start_time": 1105600.0,
      "end_time": 1106190.0,
      "text": "But I guess before I move on,"
    },
    {
      "index": 447,
      "start_time": 1106190.0,
      "end_time": 1108819.0,
      "text": "is there any sort of questions about CPU GPU?"
    },
    {
      "index": 448,
      "start_time": 1108820.0,
      "end_time": 1110520.0,
      "text": "Yeah, question?"
    },
    {
      "index": 449,
      "start_time": 1110520.0,
      "end_time": 1114687.0,
      "text": "[student&#39;s words obscured due to lack of microphone]"
    },
    {
      "index": 450,
      "start_time": 1120960.0,
      "end_time": 1122688.0,
      "text": "Yeah, so the question is what can you sort of,"
    },
    {
      "index": 451,
      "start_time": 1122690.0,
      "end_time": 1124290.0,
      "text": "what can you do mechanically when you&#39;re coding"
    },
    {
      "index": 452,
      "start_time": 1124290.0,
      "end_time": 1125855.0,
      "text": "to avoid these problems?"
    },
    {
      "index": 453,
      "start_time": 1125850.0,
      "end_time": 1127868.0,
      "text": "Probably the biggest thing you can do in software"
    },
    {
      "index": 454,
      "start_time": 1127870.0,
      "end_time": 1130831.0,
      "text": "is set up sort of pre-fetching on the CPU."
    },
    {
      "index": 455,
      "start_time": 1130830.0,
      "end_time": 1133967.0,
      "text": "Like you couldn&#39;t like, sort of a naive thing"
    },
    {
      "index": 456,
      "start_time": 1133970.0,
      "end_time": 1135540.0,
      "text": "would be you have this sequential process where you"
    },
    {
      "index": 457,
      "start_time": 1135540.0,
      "end_time": 1137441.0,
      "text": "first read data off disk, wait for the data,"
    },
    {
      "index": 458,
      "start_time": 1137440.0,
      "end_time": 1138790.0,
      "text": "wait for the minibatch to be read,"
    },
    {
      "index": 459,
      "start_time": 1138790.0,
      "end_time": 1140696.0,
      "text": "then feed the minibatch to the GPU,"
    },
    {
      "index": 460,
      "start_time": 1140700.0,
      "end_time": 1142460.0,
      "text": "then go forward and backward on the GPU,"
    },
    {
      "index": 461,
      "start_time": 1142460.0,
      "end_time": 1144444.0,
      "text": "then read another minibatch and sort of do this all"
    },
    {
      "index": 462,
      "start_time": 1144440.0,
      "end_time": 1145440.0,
      "text": "in sequence."
    },
    {
      "index": 463,
      "start_time": 1146710.0,
      "end_time": 1148212.0,
      "text": "And if you actually have multiple,"
    },
    {
      "index": 464,
      "start_time": 1148220.0,
      "end_time": 1150536.0,
      "text": "like instead you might have CPU threads running in the"
    },
    {
      "index": 465,
      "start_time": 1150530.0,
      "end_time": 1153273.0,
      "text": "background that are fetching data off the disk"
    },
    {
      "index": 466,
      "start_time": 1153280.0,
      "end_time": 1155472.0,
      "text": "such that while the,"
    },
    {
      "index": 467,
      "start_time": 1155470.0,
      "end_time": 1157761.0,
      "text": "you can sort of interleave all of these things."
    },
    {
      "index": 468,
      "start_time": 1157760.0,
      "end_time": 1158794.0,
      "text": "Like the GPU is computing,"
    },
    {
      "index": 469,
      "start_time": 1158790.0,
      "end_time": 1161502.0,
      "text": "the CPU background threads are feeding data off disk"
    },
    {
      "index": 470,
      "start_time": 1161510.0,
      "end_time": 1163503.0,
      "text": "and your main thread is kind of waiting for these things to,"
    },
    {
      "index": 471,
      "start_time": 1163500.0,
      "end_time": 1165793.0,
      "text": "just doing a bit of synchronization between these things"
    },
    {
      "index": 472,
      "start_time": 1165790.0,
      "end_time": 1168531.0,
      "text": "so they&#39;re all happening in parallel."
    },
    {
      "index": 473,
      "start_time": 1168530.0,
      "end_time": 1170933.0,
      "text": "And thankfully if you&#39;re using some of these deep learning"
    },
    {
      "index": 474,
      "start_time": 1170940.0,
      "end_time": 1172854.0,
      "text": "frameworks that we&#39;re about to talk about,"
    },
    {
      "index": 475,
      "start_time": 1172850.0,
      "end_time": 1174708.0,
      "text": "then some of this work has already been done for you"
    },
    {
      "index": 476,
      "start_time": 1174710.0,
      "end_time": 1178161.0,
      "text": "&#39;cause it&#39;s a little bit painful."
    },
    {
      "index": 477,
      "start_time": 1178160.0,
      "end_time": 1180110.0,
      "text": "So the landscape of deep learning frameworks"
    },
    {
      "index": 478,
      "start_time": 1180110.0,
      "end_time": 1181737.0,
      "text": "is super fast moving."
    },
    {
      "index": 479,
      "start_time": 1181740.0,
      "end_time": 1184791.0,
      "text": "So last year when I gave this lecture I talked mostly"
    },
    {
      "index": 480,
      "start_time": 1184790.0,
      "end_time": 1187916.0,
      "text": "about Caffe, Torch, Theano and TensorFlow."
    },
    {
      "index": 481,
      "start_time": 1187920.0,
      "end_time": 1191454.0,
      "text": "And when I last gave this talk, again more than a year ago,"
    },
    {
      "index": 482,
      "start_time": 1191450.0,
      "end_time": 1193754.0,
      "text": "TensorFlow was relatively new."
    },
    {
      "index": 483,
      "start_time": 1193750.0,
      "end_time": 1197810.0,
      "text": "It had not seen super widespread adoption yet at that time."
    },
    {
      "index": 484,
      "start_time": 1197810.0,
      "end_time": 1200228.0,
      "text": "But now I think in the last year TensorFlow"
    },
    {
      "index": 485,
      "start_time": 1200230.0,
      "end_time": 1201901.0,
      "text": "has gotten much more popular."
    },
    {
      "index": 486,
      "start_time": 1201900.0,
      "end_time": 1204390.0,
      "text": "It&#39;s probably the main framework of choice for many people."
    },
    {
      "index": 487,
      "start_time": 1204390.0,
      "end_time": 1206307.0,
      "text": "So that&#39;s a big change."
    },
    {
      "index": 488,
      "start_time": 1207340.0,
      "end_time": 1209831.0,
      "text": "We&#39;ve also seen a ton of new frameworks"
    },
    {
      "index": 489,
      "start_time": 1209830.0,
      "end_time": 1212279.0,
      "text": "sort of popping up like mushrooms in the last year."
    },
    {
      "index": 490,
      "start_time": 1212280.0,
      "end_time": 1215730.0,
      "text": "So in particular Caffe2 and PyTorch are new frameworks"
    },
    {
      "index": 491,
      "start_time": 1215730.0,
      "end_time": 1218518.0,
      "text": "from Facebook that I think are pretty interesting."
    },
    {
      "index": 492,
      "start_time": 1218520.0,
      "end_time": 1220408.0,
      "text": "There&#39;s also a ton of other frameworks."
    },
    {
      "index": 493,
      "start_time": 1220410.0,
      "end_time": 1224891.0,
      "text": "Paddle, Baidu has Paddle, Microsoft has CNTK,"
    },
    {
      "index": 494,
      "start_time": 1224890.0,
      "end_time": 1228591.0,
      "text": "Amazon is mostly using MXNet and there&#39;s a ton"
    },
    {
      "index": 495,
      "start_time": 1228590.0,
      "end_time": 1230335.0,
      "text": "of other frameworks as well, but I&#39;m less familiar with,"
    },
    {
      "index": 496,
      "start_time": 1230340.0,
      "end_time": 1233452.0,
      "text": "and really don&#39;t have time to get into."
    },
    {
      "index": 497,
      "start_time": 1233450.0,
      "end_time": 1237111.0,
      "text": "But one interesting thing to point out from this picture"
    },
    {
      "index": 498,
      "start_time": 1237110.0,
      "end_time": 1239756.0,
      "text": "is that kind of the first generation of deep learning"
    },
    {
      "index": 499,
      "start_time": 1239760.0,
      "end_time": 1241842.0,
      "text": "frameworks that really saw wide adoption"
    },
    {
      "index": 500,
      "start_time": 1241840.0,
      "end_time": 1243573.0,
      "text": "were built in academia."
    },
    {
      "index": 501,
      "start_time": 1243570.0,
      "end_time": 1245570.0,
      "text": "So Caffe was from Berkeley, Torch was developed"
    },
    {
      "index": 502,
      "start_time": 1245570.0,
      "end_time": 1249386.0,
      "text": "originally NYU and also in collaboration with Facebook."
    },
    {
      "index": 503,
      "start_time": 1249390.0,
      "end_time": 1252772.0,
      "text": "And Theana was mostly build at the University of Montreal."
    },
    {
      "index": 504,
      "start_time": 1252770.0,
      "end_time": 1254491.0,
      "text": "But these kind of next generation deep learning"
    },
    {
      "index": 505,
      "start_time": 1254490.0,
      "end_time": 1256490.0,
      "text": "frameworks all originated in industry."
    },
    {
      "index": 506,
      "start_time": 1256490.0,
      "end_time": 1258988.0,
      "text": "So Caffe2 is from Facebook, PyTorch is from Facebook."
    },
    {
      "index": 507,
      "start_time": 1258990.0,
      "end_time": 1260660.0,
      "text": "TensorFlow is from Google."
    },
    {
      "index": 508,
      "start_time": 1260660.0,
      "end_time": 1262558.0,
      "text": "So it&#39;s kind of an interesting shift that we&#39;ve seen"
    },
    {
      "index": 509,
      "start_time": 1262560.0,
      "end_time": 1264730.0,
      "text": "in the landscape over the last couple of years"
    },
    {
      "index": 510,
      "start_time": 1264730.0,
      "end_time": 1266869.0,
      "text": "is that these ideas have really moved a lot"
    },
    {
      "index": 511,
      "start_time": 1266870.0,
      "end_time": 1268929.0,
      "text": "from academia into industry."
    },
    {
      "index": 512,
      "start_time": 1268930.0,
      "end_time": 1270775.0,
      "text": "And now industry is kind of giving us these big powerful"
    },
    {
      "index": 513,
      "start_time": 1270770.0,
      "end_time": 1273187.0,
      "text": "nice frameworks to work with."
    },
    {
      "index": 514,
      "start_time": 1274150.0,
      "end_time": 1277913.0,
      "text": "So today I wanted to mostly talk about PyTorch"
    },
    {
      "index": 515,
      "start_time": 1277920.0,
      "end_time": 1279988.0,
      "text": "and TensorFlow &#39;cause I personally think that those"
    },
    {
      "index": 516,
      "start_time": 1279990.0,
      "end_time": 1282603.0,
      "text": "are probably the ones you should be focusing on for"
    },
    {
      "index": 517,
      "start_time": 1282600.0,
      "end_time": 1284849.0,
      "text": "a lot of research type problems these days."
    },
    {
      "index": 518,
      "start_time": 1284850.0,
      "end_time": 1288469.0,
      "text": "I&#39;ll also talk a bit about Caffe and Caffe2."
    },
    {
      "index": 519,
      "start_time": 1288470.0,
      "end_time": 1292192.0,
      "text": "But probably a little bit less emphasis on those."
    },
    {
      "index": 520,
      "start_time": 1292190.0,
      "end_time": 1294339.0,
      "text": "And before we move any farther, I thought I should make"
    },
    {
      "index": 521,
      "start_time": 1294340.0,
      "end_time": 1296704.0,
      "text": "my own biases a little bit more explicit."
    },
    {
      "index": 522,
      "start_time": 1296700.0,
      "end_time": 1299575.0,
      "text": "So I have mostly, I&#39;ve worked with Torch mostly"
    },
    {
      "index": 523,
      "start_time": 1299580.0,
      "end_time": 1300315.0,
      "text": "for the last several years."
    },
    {
      "index": 524,
      "start_time": 1300310.0,
      "end_time": 1303496.0,
      "text": "And I&#39;ve used it quite a lot, I like it a lot."
    },
    {
      "index": 525,
      "start_time": 1303500.0,
      "end_time": 1306305.0,
      "text": "And then in the last year I&#39;ve mostly switched to PyTorch"
    },
    {
      "index": 526,
      "start_time": 1306310.0,
      "end_time": 1308572.0,
      "text": "as my main research framework."
    },
    {
      "index": 527,
      "start_time": 1308570.0,
      "end_time": 1310489.0,
      "text": "So I have a little bit less experience with some"
    },
    {
      "index": 528,
      "start_time": 1310490.0,
      "end_time": 1312309.0,
      "text": "of these others, especially TensorFlow,"
    },
    {
      "index": 529,
      "start_time": 1312310.0,
      "end_time": 1314874.0,
      "text": "but I&#39;ll still try to do my best to give you a fair"
    },
    {
      "index": 530,
      "start_time": 1314870.0,
      "end_time": 1318382.0,
      "text": "picture and a decent overview of these things."
    },
    {
      "index": 531,
      "start_time": 1318380.0,
      "end_time": 1322505.0,
      "text": "So, remember that in the last several lectures"
    },
    {
      "index": 532,
      "start_time": 1322510.0,
      "end_time": 1324728.0,
      "text": "we&#39;ve hammered this idea of computational graphs in"
    },
    {
      "index": 533,
      "start_time": 1324720.0,
      "end_time": 1326802.0,
      "text": "sort of over and over."
    },
    {
      "index": 534,
      "start_time": 1326810.0,
      "end_time": 1328220.0,
      "text": "That whenever you&#39;re doing deep learning,"
    },
    {
      "index": 535,
      "start_time": 1328220.0,
      "end_time": 1329973.0,
      "text": "you want to think about building some computational graph"
    },
    {
      "index": 536,
      "start_time": 1329970.0,
      "end_time": 1333176.0,
      "text": "that computes whatever function that you want to compute."
    },
    {
      "index": 537,
      "start_time": 1333180.0,
      "end_time": 1335904.0,
      "text": "So in the case of a linear classifier you&#39;ll combine"
    },
    {
      "index": 538,
      "start_time": 1335900.0,
      "end_time": 1338778.0,
      "text": "your data X and your weights W with a matrix multiply."
    },
    {
      "index": 539,
      "start_time": 1338780.0,
      "end_time": 1341556.0,
      "text": "You&#39;ll do some kind of hinge loss to maybe have,"
    },
    {
      "index": 540,
      "start_time": 1341550.0,
      "end_time": 1342828.0,
      "text": "compute your loss."
    },
    {
      "index": 541,
      "start_time": 1342830.0,
      "end_time": 1344384.0,
      "text": "You&#39;ll have some regularization term"
    },
    {
      "index": 542,
      "start_time": 1344390.0,
      "end_time": 1346401.0,
      "text": "and you imagine stitching together all these different"
    },
    {
      "index": 543,
      "start_time": 1346400.0,
      "end_time": 1348911.0,
      "text": "operations into some graph structure."
    },
    {
      "index": 544,
      "start_time": 1348910.0,
      "end_time": 1351691.0,
      "text": "Remember that these graph structures can get pretty"
    },
    {
      "index": 545,
      "start_time": 1351690.0,
      "end_time": 1353191.0,
      "text": "complex in the case of a big neural net,"
    },
    {
      "index": 546,
      "start_time": 1353190.0,
      "end_time": 1354679.0,
      "text": "now there&#39;s many different layers,"
    },
    {
      "index": 547,
      "start_time": 1354680.0,
      "end_time": 1356167.0,
      "text": "many different activations."
    },
    {
      "index": 548,
      "start_time": 1356170.0,
      "end_time": 1358873.0,
      "text": "Many different weights spread all around in a pretty"
    },
    {
      "index": 549,
      "start_time": 1358870.0,
      "end_time": 1359687.0,
      "text": "complex graph."
    },
    {
      "index": 550,
      "start_time": 1359690.0,
      "end_time": 1361493.0,
      "text": "And as you move to things like neural turing machines"
    },
    {
      "index": 551,
      "start_time": 1361490.0,
      "end_time": 1364130.0,
      "text": "then you can get these really crazy computational graphs"
    },
    {
      "index": 552,
      "start_time": 1364130.0,
      "end_time": 1365911.0,
      "text": "that you can&#39;t even really draw because they&#39;re"
    },
    {
      "index": 553,
      "start_time": 1365910.0,
      "end_time": 1367327.0,
      "text": "so big and messy."
    },
    {
      "index": 554,
      "start_time": 1368350.0,
      "end_time": 1372128.0,
      "text": "So the point of deep learning frameworks is really,"
    },
    {
      "index": 555,
      "start_time": 1372130.0,
      "end_time": 1374395.0,
      "text": "there&#39;s really kind of three main reasons why you might"
    },
    {
      "index": 556,
      "start_time": 1374390.0,
      "end_time": 1376423.0,
      "text": "want to use one of these deep learning frameworks"
    },
    {
      "index": 557,
      "start_time": 1376430.0,
      "end_time": 1378731.0,
      "text": "rather than just writing your own code."
    },
    {
      "index": 558,
      "start_time": 1378730.0,
      "end_time": 1381417.0,
      "text": "So the first would be that these frameworks enable"
    },
    {
      "index": 559,
      "start_time": 1381410.0,
      "end_time": 1383250.0,
      "text": "you to easily build and work with these big hairy"
    },
    {
      "index": 560,
      "start_time": 1383260.0,
      "end_time": 1385955.0,
      "text": "computational graphs without kind of worrying"
    },
    {
      "index": 561,
      "start_time": 1385950.0,
      "end_time": 1388610.0,
      "text": "about a lot of those bookkeeping details yourself."
    },
    {
      "index": 562,
      "start_time": 1388610.0,
      "end_time": 1390860.0,
      "text": "Another major idea is that,"
    },
    {
      "index": 563,
      "start_time": 1391720.0,
      "end_time": 1393482.0,
      "text": "whenever we&#39;re working in deep learning"
    },
    {
      "index": 564,
      "start_time": 1393480.0,
      "end_time": 1394813.0,
      "text": "we always need to compute gradients."
    },
    {
      "index": 565,
      "start_time": 1394810.0,
      "end_time": 1396208.0,
      "text": "We&#39;re always computing some loss,"
    },
    {
      "index": 566,
      "start_time": 1396210.0,
      "end_time": 1397628.0,
      "text": "we&#39;re always computer gradient of our weight"
    },
    {
      "index": 567,
      "start_time": 1397630.0,
      "end_time": 1398900.0,
      "text": "with respect to the loss."
    },
    {
      "index": 568,
      "start_time": 1398900.0,
      "end_time": 1402973.0,
      "text": "And we&#39;d like to make this automatically computing gradient,"
    },
    {
      "index": 569,
      "start_time": 1402970.0,
      "end_time": 1406112.0,
      "text": "you don&#39;t want to have to write that code yourself."
    },
    {
      "index": 570,
      "start_time": 1406110.0,
      "end_time": 1408282.0,
      "text": "You want that framework to handle all these back propagation"
    },
    {
      "index": 571,
      "start_time": 1408290.0,
      "end_time": 1410488.0,
      "text": "details for you so you can just think about"
    },
    {
      "index": 572,
      "start_time": 1410480.0,
      "end_time": 1412520.0,
      "text": "writing down the forward pass of your network"
    },
    {
      "index": 573,
      "start_time": 1412530.0,
      "end_time": 1414729.0,
      "text": "and have the backward pass sort of come out for free"
    },
    {
      "index": 574,
      "start_time": 1414720.0,
      "end_time": 1416534.0,
      "text": "without any additional work."
    },
    {
      "index": 575,
      "start_time": 1416540.0,
      "end_time": 1418906.0,
      "text": "And finally you want all this stuff to run efficiently"
    },
    {
      "index": 576,
      "start_time": 1418910.0,
      "end_time": 1422005.0,
      "text": "on GPUs so you don&#39;t have to worry too much about these"
    },
    {
      "index": 577,
      "start_time": 1422000.0,
      "end_time": 1424973.0,
      "text": "low level hardware details about cuBLAS and cuDNN"
    },
    {
      "index": 578,
      "start_time": 1424970.0,
      "end_time": 1428386.0,
      "text": "and CUDA and moving data between the CPU and GPU memory."
    },
    {
      "index": 579,
      "start_time": 1428390.0,
      "end_time": 1431301.0,
      "text": "You kind of want all those messy details to be taken care of"
    },
    {
      "index": 580,
      "start_time": 1431300.0,
      "end_time": 1432439.0,
      "text": "for you."
    },
    {
      "index": 581,
      "start_time": 1432440.0,
      "end_time": 1434484.0,
      "text": "So those are kind of some of the major reasons"
    },
    {
      "index": 582,
      "start_time": 1434480.0,
      "end_time": 1436926.0,
      "text": "why you might choose to use frameworks rather than"
    },
    {
      "index": 583,
      "start_time": 1436930.0,
      "end_time": 1439450.0,
      "text": "writing your own stuff from scratch."
    },
    {
      "index": 584,
      "start_time": 1439450.0,
      "end_time": 1442969.0,
      "text": "So as kind of a concrete example of a computational graph"
    },
    {
      "index": 585,
      "start_time": 1442970.0,
      "end_time": 1445232.0,
      "text": "we can maybe write down this super simple thing."
    },
    {
      "index": 586,
      "start_time": 1445230.0,
      "end_time": 1448366.0,
      "text": "Where we have three inputs, X, Y, and Z."
    },
    {
      "index": 587,
      "start_time": 1448370.0,
      "end_time": 1449911.0,
      "text": "We&#39;re going to combine X and Y to produce A."
    },
    {
      "index": 588,
      "start_time": 1449910.0,
      "end_time": 1453712.0,
      "text": "Then we&#39;re going to combine A and Z to produce B"
    },
    {
      "index": 589,
      "start_time": 1453710.0,
      "end_time": 1455406.0,
      "text": "and then finally we&#39;re going to do some maybe summing out"
    },
    {
      "index": 590,
      "start_time": 1455410.0,
      "end_time": 1458633.0,
      "text": "operation on B to give some scaler final result C."
    },
    {
      "index": 591,
      "start_time": 1458630.0,
      "end_time": 1461638.0,
      "text": "So you&#39;ve probably written enough Numpy code at this point"
    },
    {
      "index": 592,
      "start_time": 1461640.0,
      "end_time": 1464312.0,
      "text": "to realize that it&#39;s super easy to write down,"
    },
    {
      "index": 593,
      "start_time": 1464310.0,
      "end_time": 1467216.0,
      "text": "to implement this computational graph,"
    },
    {
      "index": 594,
      "start_time": 1467220.0,
      "end_time": 1470802.0,
      "text": "or rather to implement this bit of computation in Numpy,"
    },
    {
      "index": 595,
      "start_time": 1470800.0,
      "end_time": 1471633.0,
      "text": "right?"
    },
    {
      "index": 596,
      "start_time": 1471630.0,
      "end_time": 1473723.0,
      "text": "You can just kind of write down in Numpy that you want to"
    },
    {
      "index": 597,
      "start_time": 1473720.0,
      "end_time": 1476504.0,
      "text": "generate some random data, you want to multiply two things,"
    },
    {
      "index": 598,
      "start_time": 1476510.0,
      "end_time": 1478549.0,
      "text": "you want to add two things, you want to sum out a couple things."
    },
    {
      "index": 599,
      "start_time": 1478550.0,
      "end_time": 1481926.0,
      "text": "And it&#39;s really easy to do this in Numpy."
    },
    {
      "index": 600,
      "start_time": 1481920.0,
      "end_time": 1484357.0,
      "text": "But then the question is like suppose that we want"
    },
    {
      "index": 601,
      "start_time": 1484360.0,
      "end_time": 1488354.0,
      "text": "to compute the gradient of C with respect to X, Y, and Z."
    },
    {
      "index": 602,
      "start_time": 1488350.0,
      "end_time": 1491144.0,
      "text": "So, if you&#39;re working in Numpy, you kind of need to write out"
    },
    {
      "index": 603,
      "start_time": 1491150.0,
      "end_time": 1492726.0,
      "text": "this backward pass yourself."
    },
    {
      "index": 604,
      "start_time": 1492720.0,
      "end_time": 1494960.0,
      "text": "And you&#39;ve gotten a lot of practice with this on the"
    },
    {
      "index": 605,
      "start_time": 1494960.0,
      "end_time": 1498122.0,
      "text": "homeworks, but it can be kind of a pain"
    },
    {
      "index": 606,
      "start_time": 1498130.0,
      "end_time": 1500309.0,
      "text": "and a little bit annoying and messy once you get to"
    },
    {
      "index": 607,
      "start_time": 1500310.0,
      "end_time": 1502863.0,
      "text": "really big complicated things."
    },
    {
      "index": 608,
      "start_time": 1502860.0,
      "end_time": 1504487.0,
      "text": "The other problem with Numpy is that it doesn&#39;t run"
    },
    {
      "index": 609,
      "start_time": 1504490.0,
      "end_time": 1505678.0,
      "text": "on the GPU."
    },
    {
      "index": 610,
      "start_time": 1505680.0,
      "end_time": 1508193.0,
      "text": "So Numpy is definitely CPU only."
    },
    {
      "index": 611,
      "start_time": 1508190.0,
      "end_time": 1510515.0,
      "text": "And you&#39;re never going to be able to experience"
    },
    {
      "index": 612,
      "start_time": 1510510.0,
      "end_time": 1513107.0,
      "text": "or take advantage of these GPU accelerated speedups"
    },
    {
      "index": 613,
      "start_time": 1513110.0,
      "end_time": 1514918.0,
      "text": "if you&#39;re stuck working in Numpy."
    },
    {
      "index": 614,
      "start_time": 1514920.0,
      "end_time": 1517110.0,
      "text": "And it&#39;s, again, it&#39;s a pain to have to compute"
    },
    {
      "index": 615,
      "start_time": 1517110.0,
      "end_time": 1519527.0,
      "text": "your own gradients in all these situations."
    },
    {
      "index": 616,
      "start_time": 1519530.0,
      "end_time": 1522810.0,
      "text": "So, kind of the goal of most deep learning frameworks"
    },
    {
      "index": 617,
      "start_time": 1522810.0,
      "end_time": 1526832.0,
      "text": "these days is to let you write code in the forward pass"
    },
    {
      "index": 618,
      "start_time": 1526830.0,
      "end_time": 1529471.0,
      "text": "that looks very similar to Numpy,"
    },
    {
      "index": 619,
      "start_time": 1529470.0,
      "end_time": 1531170.0,
      "text": "but lets you run it on the GPU"
    },
    {
      "index": 620,
      "start_time": 1531170.0,
      "end_time": 1533690.0,
      "text": "and lets you automatically compute gradients."
    },
    {
      "index": 621,
      "start_time": 1533690.0,
      "end_time": 1534966.0,
      "text": "And that&#39;s kind of the big picture goal of most of these"
    },
    {
      "index": 622,
      "start_time": 1534970.0,
      "end_time": 1536400.0,
      "text": "frameworks."
    },
    {
      "index": 623,
      "start_time": 1536400.0,
      "end_time": 1538536.0,
      "text": "So if you imagine looking at, if we look at an example"
    },
    {
      "index": 624,
      "start_time": 1538530.0,
      "end_time": 1542223.0,
      "text": "in TensorFlow of the exact same computational graph,"
    },
    {
      "index": 625,
      "start_time": 1542230.0,
      "end_time": 1544318.0,
      "text": "we now see that in this forward pass,"
    },
    {
      "index": 626,
      "start_time": 1544310.0,
      "end_time": 1547237.0,
      "text": "you write this code that ends up looking very very similar"
    },
    {
      "index": 627,
      "start_time": 1547240.0,
      "end_time": 1549333.0,
      "text": "to the Numpy forward pass where you&#39;re kind of doing"
    },
    {
      "index": 628,
      "start_time": 1549330.0,
      "end_time": 1552683.0,
      "text": "these multiplication and these addition operations."
    },
    {
      "index": 629,
      "start_time": 1552690.0,
      "end_time": 1555671.0,
      "text": "But now TensorFlow has this magic line that just"
    },
    {
      "index": 630,
      "start_time": 1555670.0,
      "end_time": 1557624.0,
      "text": "computes all the gradients for you."
    },
    {
      "index": 631,
      "start_time": 1557620.0,
      "end_time": 1559683.0,
      "text": "So now you don&#39;t have go in and write your own backward pass"
    },
    {
      "index": 632,
      "start_time": 1559690.0,
      "end_time": 1562239.0,
      "text": "and that&#39;s much more convenient."
    },
    {
      "index": 633,
      "start_time": 1562230.0,
      "end_time": 1564935.0,
      "text": "The other nice thing about TensorFlow is you can really"
    },
    {
      "index": 634,
      "start_time": 1564950.0,
      "end_time": 1566841.0,
      "text": "just, like with one line you can switch all this computation"
    },
    {
      "index": 635,
      "start_time": 1566840.0,
      "end_time": 1568925.0,
      "text": "between CPU and GPU."
    },
    {
      "index": 636,
      "start_time": 1568930.0,
      "end_time": 1571154.0,
      "text": "So here, if you just add this with statement"
    },
    {
      "index": 637,
      "start_time": 1571160.0,
      "end_time": 1573370.0,
      "text": "before you&#39;re doing this forward pass,"
    },
    {
      "index": 638,
      "start_time": 1573370.0,
      "end_time": 1574866.0,
      "text": "you just can explicitly tell the framework,"
    },
    {
      "index": 639,
      "start_time": 1574870.0,
      "end_time": 1576672.0,
      "text": "hey I want to run this code on the CPU."
    },
    {
      "index": 640,
      "start_time": 1576670.0,
      "end_time": 1579538.0,
      "text": "But now if we just change that with statement a little bit"
    },
    {
      "index": 641,
      "start_time": 1579540.0,
      "end_time": 1581530.0,
      "text": "with just with a one character change in this case,"
    },
    {
      "index": 642,
      "start_time": 1581530.0,
      "end_time": 1584869.0,
      "text": "changing that C to a G, now the code runs on GPU."
    },
    {
      "index": 643,
      "start_time": 1584870.0,
      "end_time": 1587872.0,
      "text": "And now in this little code snippet,"
    },
    {
      "index": 644,
      "start_time": 1587870.0,
      "end_time": 1589541.0,
      "text": "we&#39;ve solved these two problems."
    },
    {
      "index": 645,
      "start_time": 1589540.0,
      "end_time": 1591389.0,
      "text": "We&#39;re running our code on the GPU"
    },
    {
      "index": 646,
      "start_time": 1591390.0,
      "end_time": 1593129.0,
      "text": "and we&#39;re having the framework compute all the gradients"
    },
    {
      "index": 647,
      "start_time": 1593130.0,
      "end_time": 1595688.0,
      "text": "for us, so that&#39;s really nice."
    },
    {
      "index": 648,
      "start_time": 1595690.0,
      "end_time": 1598463.0,
      "text": "And PyTorch kind looks almost exactly the same."
    },
    {
      "index": 649,
      "start_time": 1598460.0,
      "end_time": 1600350.0,
      "text": "So again, in PyTorch you kind of write down,"
    },
    {
      "index": 650,
      "start_time": 1600350.0,
      "end_time": 1602510.0,
      "text": "you define some variables,"
    },
    {
      "index": 651,
      "start_time": 1602510.0,
      "end_time": 1605150.0,
      "text": "you have some forward pass and the forward pass again"
    },
    {
      "index": 652,
      "start_time": 1605150.0,
      "end_time": 1607640.0,
      "text": "looks very similar to like, in this case identical"
    },
    {
      "index": 653,
      "start_time": 1607640.0,
      "end_time": 1609262.0,
      "text": "to the Numpy code."
    },
    {
      "index": 654,
      "start_time": 1609260.0,
      "end_time": 1612144.0,
      "text": "And then again, you can just use PyTorch to compute"
    },
    {
      "index": 655,
      "start_time": 1612150.0,
      "end_time": 1616255.0,
      "text": "gradients, all your gradients with just one line."
    },
    {
      "index": 656,
      "start_time": 1616250.0,
      "end_time": 1618839.0,
      "text": "And now in PyTorch again, it&#39;s really easy to switch"
    },
    {
      "index": 657,
      "start_time": 1618840.0,
      "end_time": 1620263.0,
      "text": "to GPU, you just need to cast all your stuff to the"
    },
    {
      "index": 658,
      "start_time": 1620260.0,
      "end_time": 1623206.0,
      "text": "CUDA data type before you rung your computation"
    },
    {
      "index": 659,
      "start_time": 1623210.0,
      "end_time": 1626781.0,
      "text": "and now everything runs transparently on the GPU for you."
    },
    {
      "index": 660,
      "start_time": 1626780.0,
      "end_time": 1629909.0,
      "text": "So if you kind of just look at these three examples,"
    },
    {
      "index": 661,
      "start_time": 1629910.0,
      "end_time": 1631321.0,
      "text": "these three snippets of code side by side,"
    },
    {
      "index": 662,
      "start_time": 1631320.0,
      "end_time": 1633877.0,
      "text": "the Numpy, the TensorFlow and the PyTorch"
    },
    {
      "index": 663,
      "start_time": 1633880.0,
      "end_time": 1637581.0,
      "text": "you see that the TensorFlow and the PyTorch code"
    },
    {
      "index": 664,
      "start_time": 1637580.0,
      "end_time": 1640564.0,
      "text": "in the forward pass looks almost exactly like Numpy"
    },
    {
      "index": 665,
      "start_time": 1640560.0,
      "end_time": 1643476.0,
      "text": "which is great &#39;cause Numpy has a beautiful API,"
    },
    {
      "index": 666,
      "start_time": 1643480.0,
      "end_time": 1644349.0,
      "text": "it&#39;s really easy to work with."
    },
    {
      "index": 667,
      "start_time": 1644350.0,
      "end_time": 1646110.0,
      "text": "But we can compute gradients automatically"
    },
    {
      "index": 668,
      "start_time": 1646110.0,
      "end_time": 1649193.0,
      "text": "and we can run the GPU automatically."
    },
    {
      "index": 669,
      "start_time": 1650190.0,
      "end_time": 1651876.0,
      "text": "So after that kind of introduction,"
    },
    {
      "index": 670,
      "start_time": 1651870.0,
      "end_time": 1653651.0,
      "text": "I wanted to dive in and talk in a little bit more"
    },
    {
      "index": 671,
      "start_time": 1653650.0,
      "end_time": 1655754.0,
      "text": "detail about kind of what&#39;s going on inside this"
    },
    {
      "index": 672,
      "start_time": 1655760.0,
      "end_time": 1657504.0,
      "text": "TensorFlow example."
    },
    {
      "index": 673,
      "start_time": 1657500.0,
      "end_time": 1660382.0,
      "text": "So as a running example throughout the rest of the lecture,"
    },
    {
      "index": 674,
      "start_time": 1660380.0,
      "end_time": 1664276.0,
      "text": "I&#39;m going to use the training a two-layer fully connected"
    },
    {
      "index": 675,
      "start_time": 1664280.0,
      "end_time": 1668377.0,
      "text": "ReLU network on random data as kind of a running example"
    },
    {
      "index": 676,
      "start_time": 1668380.0,
      "end_time": 1670665.0,
      "text": "throughout the rest of the examples here."
    },
    {
      "index": 677,
      "start_time": 1670660.0,
      "end_time": 1673351.0,
      "text": "And we&#39;re going to train this thing with an L2 Euclidean"
    },
    {
      "index": 678,
      "start_time": 1673350.0,
      "end_time": 1675286.0,
      "text": "loss on random data."
    },
    {
      "index": 679,
      "start_time": 1675290.0,
      "end_time": 1677634.0,
      "text": "So this is kind of a silly network, it&#39;s not really doing"
    },
    {
      "index": 680,
      "start_time": 1677630.0,
      "end_time": 1679833.0,
      "text": "anything useful, but it does give you the,"
    },
    {
      "index": 681,
      "start_time": 1679840.0,
      "end_time": 1681727.0,
      "text": "it&#39;s relatively small, self contained,"
    },
    {
      "index": 682,
      "start_time": 1681720.0,
      "end_time": 1684441.0,
      "text": "the code fits on the slide without being too small,"
    },
    {
      "index": 683,
      "start_time": 1684440.0,
      "end_time": 1686424.0,
      "text": "and it lets you demonstrate kind of a lot of the useful"
    },
    {
      "index": 684,
      "start_time": 1686430.0,
      "end_time": 1688968.0,
      "text": "ideas inside these frameworks."
    },
    {
      "index": 685,
      "start_time": 1688970.0,
      "end_time": 1690817.0,
      "text": "So here on the right, oh, and then another note,"
    },
    {
      "index": 686,
      "start_time": 1690810.0,
      "end_time": 1693393.0,
      "text": "I&#39;m kind of assuming that Numpy and TensorFlow"
    },
    {
      "index": 687,
      "start_time": 1693400.0,
      "end_time": 1695902.0,
      "text": "have already been imported in all these code snippets."
    },
    {
      "index": 688,
      "start_time": 1695900.0,
      "end_time": 1699308.0,
      "text": "So in TensorFlow you would typically divide your computation"
    },
    {
      "index": 689,
      "start_time": 1699310.0,
      "end_time": 1701165.0,
      "text": "into two major stages."
    },
    {
      "index": 690,
      "start_time": 1701160.0,
      "end_time": 1703993.0,
      "text": "First, we&#39;re going to write some code that defines"
    },
    {
      "index": 691,
      "start_time": 1704000.0,
      "end_time": 1706856.0,
      "text": "our computational graph, and that&#39;s this red code"
    },
    {
      "index": 692,
      "start_time": 1706850.0,
      "end_time": 1708361.0,
      "text": "up in the top half."
    },
    {
      "index": 693,
      "start_time": 1708360.0,
      "end_time": 1710344.0,
      "text": "And then after you define your graph,"
    },
    {
      "index": 694,
      "start_time": 1710350.0,
      "end_time": 1712363.0,
      "text": "you&#39;re going to run the graph over and over again"
    },
    {
      "index": 695,
      "start_time": 1712360.0,
      "end_time": 1714112.0,
      "text": "and actually feed data into the graph"
    },
    {
      "index": 696,
      "start_time": 1714110.0,
      "end_time": 1716848.0,
      "text": "to perform whatever computation you want it to perform."
    },
    {
      "index": 697,
      "start_time": 1716850.0,
      "end_time": 1718771.0,
      "text": "So this is the really, this is kind of the big"
    },
    {
      "index": 698,
      "start_time": 1718770.0,
      "end_time": 1720959.0,
      "text": "common pattern in TensorFlow."
    },
    {
      "index": 699,
      "start_time": 1720960.0,
      "end_time": 1722906.0,
      "text": "You&#39;ll first have a bunch of code that builds the graph"
    },
    {
      "index": 700,
      "start_time": 1722910.0,
      "end_time": 1725285.0,
      "text": "and then you&#39;ll go and run the graph and reuse it"
    },
    {
      "index": 701,
      "start_time": 1725280.0,
      "end_time": 1726613.0,
      "text": "many many times."
    },
    {
      "index": 702,
      "start_time": 1728990.0,
      "end_time": 1730827.0,
      "text": "So if you kind of dive into the code of building"
    },
    {
      "index": 703,
      "start_time": 1730830.0,
      "end_time": 1732766.0,
      "text": "the graph in this case."
    },
    {
      "index": 704,
      "start_time": 1732760.0,
      "end_time": 1736539.0,
      "text": "Up at the top you see that we&#39;re defining this X, Y,"
    },
    {
      "index": 705,
      "start_time": 1736540.0,
      "end_time": 1740706.0,
      "text": "w1 and w2, and we&#39;re creating these tf.placeholder objects."
    },
    {
      "index": 706,
      "start_time": 1741640.0,
      "end_time": 1745196.0,
      "text": "So these are going to be input nodes to the graph."
    },
    {
      "index": 707,
      "start_time": 1745190.0,
      "end_time": 1748357.0,
      "text": "These are going to be sort of entry points to the graph"
    },
    {
      "index": 708,
      "start_time": 1748360.0,
      "end_time": 1751101.0,
      "text": "where when we run the graph, we&#39;re going to feed in data"
    },
    {
      "index": 709,
      "start_time": 1751100.0,
      "end_time": 1753378.0,
      "text": "and put them in through these input slots in our"
    },
    {
      "index": 710,
      "start_time": 1753380.0,
      "end_time": 1755380.0,
      "text": "computational graph."
    },
    {
      "index": 711,
      "start_time": 1755380.0,
      "end_time": 1757218.0,
      "text": "So this is not actually like allocating any memory"
    },
    {
      "index": 712,
      "start_time": 1757220.0,
      "end_time": 1758512.0,
      "text": "right now."
    },
    {
      "index": 713,
      "start_time": 1759440.0,
      "end_time": 1760861.0,
      "text": "We&#39;re just sort of setting up these input slots"
    },
    {
      "index": 714,
      "start_time": 1760860.0,
      "end_time": 1761943.0,
      "text": "to the graph."
    },
    {
      "index": 715,
      "start_time": 1763270.0,
      "end_time": 1765558.0,
      "text": "Then we&#39;re going to use those input slots which are now"
    },
    {
      "index": 716,
      "start_time": 1765560.0,
      "end_time": 1768665.0,
      "text": "kind of like these symbolic variables"
    },
    {
      "index": 717,
      "start_time": 1768670.0,
      "end_time": 1771215.0,
      "text": "and we&#39;re going to perform different TensorFlow operations"
    },
    {
      "index": 718,
      "start_time": 1771210.0,
      "end_time": 1773917.0,
      "text": "on these symbolic variables in order to set up"
    },
    {
      "index": 719,
      "start_time": 1773920.0,
      "end_time": 1777138.0,
      "text": "what computation we want to run on those variables."
    },
    {
      "index": 720,
      "start_time": 1777140.0,
      "end_time": 1779384.0,
      "text": "So in this case we&#39;re doing a matrix multiplication"
    },
    {
      "index": 721,
      "start_time": 1779380.0,
      "end_time": 1783905.0,
      "text": "between X and w1, we&#39;re doing some tf.maximum to do a"
    },
    {
      "index": 722,
      "start_time": 1783900.0,
      "end_time": 1786105.0,
      "text": "ReLU nonlinearity and then we&#39;re doing another"
    },
    {
      "index": 723,
      "start_time": 1786110.0,
      "end_time": 1789241.0,
      "text": "matrix multiplication to compute our output predictions."
    },
    {
      "index": 724,
      "start_time": 1789240.0,
      "end_time": 1790955.0,
      "text": "And then we&#39;re again using a sort of basic Tensor"
    },
    {
      "index": 725,
      "start_time": 1790950.0,
      "end_time": 1793351.0,
      "text": "operations to compute our Euclidean distance,"
    },
    {
      "index": 726,
      "start_time": 1793360.0,
      "end_time": 1798179.0,
      "text": "our L2 loss between our prediction and the target Y."
    },
    {
      "index": 727,
      "start_time": 1798180.0,
      "end_time": 1800995.0,
      "text": "Another thing to point out here is that"
    },
    {
      "index": 728,
      "start_time": 1800990.0,
      "end_time": 1803647.0,
      "text": "these lines of code are not actually computing anything."
    },
    {
      "index": 729,
      "start_time": 1803650.0,
      "end_time": 1805826.0,
      "text": "There&#39;s no data in the system right now."
    },
    {
      "index": 730,
      "start_time": 1805820.0,
      "end_time": 1807567.0,
      "text": "We&#39;re just building up this computational graph data"
    },
    {
      "index": 731,
      "start_time": 1807570.0,
      "end_time": 1810798.0,
      "text": "structure telling TensorFlow which operations"
    },
    {
      "index": 732,
      "start_time": 1810800.0,
      "end_time": 1815101.0,
      "text": "we want to eventually run once we put in real data."
    },
    {
      "index": 733,
      "start_time": 1815100.0,
      "end_time": 1816393.0,
      "text": "So this is just building the graph,"
    },
    {
      "index": 734,
      "start_time": 1816390.0,
      "end_time": 1818645.0,
      "text": "this is not actually doing anything."
    },
    {
      "index": 735,
      "start_time": 1818650.0,
      "end_time": 1821660.0,
      "text": "Then we have this magical line where after we&#39;ve computed"
    },
    {
      "index": 736,
      "start_time": 1821660.0,
      "end_time": 1824740.0,
      "text": "our loss with these symbolic operations,"
    },
    {
      "index": 737,
      "start_time": 1824740.0,
      "end_time": 1827182.0,
      "text": "then we can just ask TensorFlow to compute"
    },
    {
      "index": 738,
      "start_time": 1827180.0,
      "end_time": 1831185.0,
      "text": "the gradient of the loss with respect to w1 and w2"
    },
    {
      "index": 739,
      "start_time": 1831190.0,
      "end_time": 1833139.0,
      "text": "in this one magical, beautiful line."
    },
    {
      "index": 740,
      "start_time": 1833140.0,
      "end_time": 1835624.0,
      "text": "And this avoids you writing all your own backprop code"
    },
    {
      "index": 741,
      "start_time": 1835620.0,
      "end_time": 1837982.0,
      "text": "that you had to do in the assignments."
    },
    {
      "index": 742,
      "start_time": 1837980.0,
      "end_time": 1840438.0,
      "text": "But again there&#39;s no actual computation happening here."
    },
    {
      "index": 743,
      "start_time": 1840440.0,
      "end_time": 1842522.0,
      "text": "This is just sort of adding extra operations"
    },
    {
      "index": 744,
      "start_time": 1842520.0,
      "end_time": 1846899.0,
      "text": "to the computational graph where now the computational"
    },
    {
      "index": 745,
      "start_time": 1846900.0,
      "end_time": 1847950.0,
      "text": "graph has these additional operations which will end up"
    },
    {
      "index": 746,
      "start_time": 1847950.0,
      "end_time": 1851108.0,
      "text": "computing these gradients for you."
    },
    {
      "index": 747,
      "start_time": 1851110.0,
      "end_time": 1853131.0,
      "text": "So now at this point we&#39;ve computed our computational"
    },
    {
      "index": 748,
      "start_time": 1853130.0,
      "end_time": 1856639.0,
      "text": "graph, we have this big graph in this graph data structure"
    },
    {
      "index": 749,
      "start_time": 1856640.0,
      "end_time": 1859392.0,
      "text": "in memory that knows what operations we want to perform"
    },
    {
      "index": 750,
      "start_time": 1859390.0,
      "end_time": 1861421.0,
      "text": "to compute the loss in gradients."
    },
    {
      "index": 751,
      "start_time": 1861420.0,
      "end_time": 1863704.0,
      "text": "And now we enter a TensorFlow session to actually run"
    },
    {
      "index": 752,
      "start_time": 1863700.0,
      "end_time": 1866837.0,
      "text": "this graph and feed it with data."
    },
    {
      "index": 753,
      "start_time": 1866840.0,
      "end_time": 1869157.0,
      "text": "So then, once we&#39;ve entered the session,"
    },
    {
      "index": 754,
      "start_time": 1869160.0,
      "end_time": 1871943.0,
      "text": "then we actually need to construct some concrete values"
    },
    {
      "index": 755,
      "start_time": 1871940.0,
      "end_time": 1873856.0,
      "text": "that will be fed to the graph."
    },
    {
      "index": 756,
      "start_time": 1873860.0,
      "end_time": 1877227.0,
      "text": "So TensorFlow just expects to receive data from"
    },
    {
      "index": 757,
      "start_time": 1877230.0,
      "end_time": 1879462.0,
      "text": "Numpy arrays in most cases."
    },
    {
      "index": 758,
      "start_time": 1879460.0,
      "end_time": 1883702.0,
      "text": "So here we&#39;re just creating concrete actual values"
    },
    {
      "index": 759,
      "start_time": 1883700.0,
      "end_time": 1888659.0,
      "text": "for X, Y, w1 and w2 using Numpy and then storing these"
    },
    {
      "index": 760,
      "start_time": 1888660.0,
      "end_time": 1890226.0,
      "text": "in some dictionary."
    },
    {
      "index": 761,
      "start_time": 1890230.0,
      "end_time": 1892747.0,
      "text": "And now here is where we&#39;re actually running the graph."
    },
    {
      "index": 762,
      "start_time": 1892740.0,
      "end_time": 1896203.0,
      "text": "So you can see that we&#39;re calling a session.run"
    },
    {
      "index": 763,
      "start_time": 1896210.0,
      "end_time": 1898124.0,
      "text": "to actually execute some part of the graph."
    },
    {
      "index": 764,
      "start_time": 1898120.0,
      "end_time": 1901602.0,
      "text": "The first argument loss, tells us which part of the graph"
    },
    {
      "index": 765,
      "start_time": 1901600.0,
      "end_time": 1903896.0,
      "text": "do we actually want as output."
    },
    {
      "index": 766,
      "start_time": 1903900.0,
      "end_time": 1905979.0,
      "text": "And that, so we actually want the graph,"
    },
    {
      "index": 767,
      "start_time": 1905980.0,
      "end_time": 1907598.0,
      "text": "in this case we need to tell it that we actually"
    },
    {
      "index": 768,
      "start_time": 1907600.0,
      "end_time": 1910953.0,
      "text": "want to compute loss and grad1 and grad w2"
    },
    {
      "index": 769,
      "start_time": 1910950.0,
      "end_time": 1913880.0,
      "text": "and we need to pass in with this feed dict parameter"
    },
    {
      "index": 770,
      "start_time": 1913880.0,
      "end_time": 1917140.0,
      "text": "the actual concrete values that will be fed to the graph."
    },
    {
      "index": 771,
      "start_time": 1917140.0,
      "end_time": 1920430.0,
      "text": "And then after, in this one line,"
    },
    {
      "index": 772,
      "start_time": 1920430.0,
      "end_time": 1922888.0,
      "text": "it&#39;s going and running the graph and then computing"
    },
    {
      "index": 773,
      "start_time": 1922890.0,
      "end_time": 1926543.0,
      "text": "those values for loss grad1 to grad w2"
    },
    {
      "index": 774,
      "start_time": 1926540.0,
      "end_time": 1929969.0,
      "text": "and then returning the actual concrete values"
    },
    {
      "index": 775,
      "start_time": 1929970.0,
      "end_time": 1932300.0,
      "text": "for those in Numpy arrays again."
    },
    {
      "index": 776,
      "start_time": 1932300.0,
      "end_time": 1934398.0,
      "text": "So now after you unpack this output in the second line,"
    },
    {
      "index": 777,
      "start_time": 1934400.0,
      "end_time": 1938448.0,
      "text": "you get Numpy arrays, or you get Numpy arrays with the loss"
    },
    {
      "index": 778,
      "start_time": 1938450.0,
      "end_time": 1939863.0,
      "text": "and the gradients."
    },
    {
      "index": 779,
      "start_time": 1939860.0,
      "end_time": 1941721.0,
      "text": "So then you can go and do whatever you want"
    },
    {
      "index": 780,
      "start_time": 1941720.0,
      "end_time": 1943697.0,
      "text": "with these values."
    },
    {
      "index": 781,
      "start_time": 1943700.0,
      "end_time": 1948658.0,
      "text": "So then, this has only run sort of one forward and backward"
    },
    {
      "index": 782,
      "start_time": 1948660.0,
      "end_time": 1949604.0,
      "text": "pass through our graph,"
    },
    {
      "index": 783,
      "start_time": 1949600.0,
      "end_time": 1951468.0,
      "text": "and it only takes a couple extra lines if we actually"
    },
    {
      "index": 784,
      "start_time": 1951470.0,
      "end_time": 1953169.0,
      "text": "want to train the network."
    },
    {
      "index": 785,
      "start_time": 1953170.0,
      "end_time": 1956228.0,
      "text": "So here we&#39;re, now we&#39;re running the graph many times"
    },
    {
      "index": 786,
      "start_time": 1956220.0,
      "end_time": 1958572.0,
      "text": "in a loop so we&#39;re doing a four loop"
    },
    {
      "index": 787,
      "start_time": 1958580.0,
      "end_time": 1960742.0,
      "text": "and in each iteration of the loop,"
    },
    {
      "index": 788,
      "start_time": 1960740.0,
      "end_time": 1963636.0,
      "text": "we&#39;re calling session.run asking it to compute"
    },
    {
      "index": 789,
      "start_time": 1963640.0,
      "end_time": 1965516.0,
      "text": "the loss and the gradients."
    },
    {
      "index": 790,
      "start_time": 1965510.0,
      "end_time": 1968359.0,
      "text": "And now we&#39;re doing a manual gradient discent step"
    },
    {
      "index": 791,
      "start_time": 1968360.0,
      "end_time": 1970851.0,
      "text": "using those computed gradients to now update our current"
    },
    {
      "index": 792,
      "start_time": 1970850.0,
      "end_time": 1972289.0,
      "text": "values of the weights."
    },
    {
      "index": 793,
      "start_time": 1972290.0,
      "end_time": 1976157.0,
      "text": "So if you actually run this code and plot the losses,"
    },
    {
      "index": 794,
      "start_time": 1976160.0,
      "end_time": 1977771.0,
      "text": "then you&#39;ll see that the loss goes down"
    },
    {
      "index": 795,
      "start_time": 1977770.0,
      "end_time": 1980749.0,
      "text": "and the network is training and this is working pretty well."
    },
    {
      "index": 796,
      "start_time": 1980750.0,
      "end_time": 1983450.0,
      "text": "So this is kind of like a super bare bones example"
    },
    {
      "index": 797,
      "start_time": 1983450.0,
      "end_time": 1986114.0,
      "text": "of training a fully connected network in TensorFlow."
    },
    {
      "index": 798,
      "start_time": 1986110.0,
      "end_time": 1988457.0,
      "text": "But there&#39;s a problem here."
    },
    {
      "index": 799,
      "start_time": 1988460.0,
      "end_time": 1991437.0,
      "text": "So here, remember that on the forward pass,"
    },
    {
      "index": 800,
      "start_time": 1991440.0,
      "end_time": 1993258.0,
      "text": "every time we execute this graph,"
    },
    {
      "index": 801,
      "start_time": 1993260.0,
      "end_time": 1995864.0,
      "text": "we&#39;re actually feeding in the weights."
    },
    {
      "index": 802,
      "start_time": 1995860.0,
      "end_time": 1996659.0,
      "text": "We have the weights as Numpy arrays"
    },
    {
      "index": 803,
      "start_time": 1996660.0,
      "end_time": 1998836.0,
      "text": "and we&#39;re explicitly feeding them into the graph."
    },
    {
      "index": 804,
      "start_time": 1998830.0,
      "end_time": 2001390.0,
      "text": "And now when the graph finishes executing"
    },
    {
      "index": 805,
      "start_time": 2001400.0,
      "end_time": 2003235.0,
      "text": "it&#39;s going to give us these gradients."
    },
    {
      "index": 806,
      "start_time": 2003230.0,
      "end_time": 2004979.0,
      "text": "And remember the gradients are the same size"
    },
    {
      "index": 807,
      "start_time": 2004980.0,
      "end_time": 2006340.0,
      "text": "as the weights."
    },
    {
      "index": 808,
      "start_time": 2006340.0,
      "end_time": 2008193.0,
      "text": "So this means that every time we&#39;re running the graph here,"
    },
    {
      "index": 809,
      "start_time": 2008190.0,
      "end_time": 2010673.0,
      "text": "we&#39;re copying the weights from Numpy arrays into"
    },
    {
      "index": 810,
      "start_time": 2010680.0,
      "end_time": 2012670.0,
      "text": "TensorFlow then getting the gradients"
    },
    {
      "index": 811,
      "start_time": 2012670.0,
      "end_time": 2014587.0,
      "text": "and then copying the gradients from TensorFlow"
    },
    {
      "index": 812,
      "start_time": 2014580.0,
      "end_time": 2016416.0,
      "text": "back out to Numpy arrays."
    },
    {
      "index": 813,
      "start_time": 2016420.0,
      "end_time": 2017887.0,
      "text": "So if you&#39;re just running on CPU,"
    },
    {
      "index": 814,
      "start_time": 2017890.0,
      "end_time": 2019853.0,
      "text": "this is maybe not a huge deal,"
    },
    {
      "index": 815,
      "start_time": 2019850.0,
      "end_time": 2022677.0,
      "text": "but remember we talked about CPU GPU bottleneck"
    },
    {
      "index": 816,
      "start_time": 2022680.0,
      "end_time": 2024871.0,
      "text": "and how it&#39;s very expensive actually to copy data"
    },
    {
      "index": 817,
      "start_time": 2024870.0,
      "end_time": 2027238.0,
      "text": "between CPU memory and GPU memory."
    },
    {
      "index": 818,
      "start_time": 2027230.0,
      "end_time": 2029835.0,
      "text": "So if your network is very large and your weights"
    },
    {
      "index": 819,
      "start_time": 2029840.0,
      "end_time": 2031960.0,
      "text": "and gradients were very big,"
    },
    {
      "index": 820,
      "start_time": 2031960.0,
      "end_time": 2032975.0,
      "text": "then doing something like this would be super expensive"
    },
    {
      "index": 821,
      "start_time": 2032970.0,
      "end_time": 2035894.0,
      "text": "and super slow because we&#39;d be copying all kinds of data"
    },
    {
      "index": 822,
      "start_time": 2035900.0,
      "end_time": 2038423.0,
      "text": "back and forth between the CPU and the GPU at every"
    },
    {
      "index": 823,
      "start_time": 2038420.0,
      "end_time": 2039253.0,
      "text": "time step."
    },
    {
      "index": 824,
      "start_time": 2039260.0,
      "end_time": 2040445.0,
      "text": "So that&#39;s bad, we don&#39;t want to do that."
    },
    {
      "index": 825,
      "start_time": 2040440.0,
      "end_time": 2041688.0,
      "text": "We need to fix that."
    },
    {
      "index": 826,
      "start_time": 2041690.0,
      "end_time": 2046271.0,
      "text": "So, obviously TensorFlow has some solution to this."
    },
    {
      "index": 827,
      "start_time": 2046270.0,
      "end_time": 2048342.0,
      "text": "And the idea is that now we want our weights,"
    },
    {
      "index": 828,
      "start_time": 2048340.0000000002,
      "end_time": 2051435.0000000002,
      "text": "w1 and w2, rather than being placeholders where we&#39;re"
    },
    {
      "index": 829,
      "start_time": 2051440.0,
      "end_time": 2054458.0,
      "text": "going to, where we expect to feed them in to the network"
    },
    {
      "index": 830,
      "start_time": 2054460.0,
      "end_time": 2057973.0,
      "text": "on every forward pass, instead we define them as variables."
    },
    {
      "index": 831,
      "start_time": 2057969.9999999998,
      "end_time": 2060476.9999999998,
      "text": "So a variable is something is a value that lives inside"
    },
    {
      "index": 832,
      "start_time": 2060480.0,
      "end_time": 2063180.0,
      "text": "the computational graph and it&#39;s going to persist"
    },
    {
      "index": 833,
      "start_time": 2063179.9999999998,
      "end_time": 2065604.9999999998,
      "text": "inside the computational graph across different times"
    },
    {
      "index": 834,
      "start_time": 2065600.0,
      "end_time": 2067346.0,
      "text": "when you run the same graph."
    },
    {
      "index": 835,
      "start_time": 2067350.0,
      "end_time": 2071303.0,
      "text": "So now instead of declaring these w1 and w2 as placeholders,"
    },
    {
      "index": 836,
      "start_time": 2071300.0000000002,
      "end_time": 2073940.0000000002,
      "text": "instead we just construct them as variables."
    },
    {
      "index": 837,
      "start_time": 2073940.0,
      "end_time": 2075514.0,
      "text": "But now since they live inside the graph,"
    },
    {
      "index": 838,
      "start_time": 2075510.0000000002,
      "end_time": 2078406.0000000002,
      "text": "we also need to tell TensorFlow how they should be"
    },
    {
      "index": 839,
      "start_time": 2078409.9999999998,
      "end_time": 2079218.9999999998,
      "text": "initialized, right?"
    },
    {
      "index": 840,
      "start_time": 2079219.9999999998,
      "end_time": 2080815.9999999998,
      "text": "Because in the previous case we were feeding in"
    },
    {
      "index": 841,
      "start_time": 2080810.0,
      "end_time": 2082692.0,
      "text": "their values from outside the graph,"
    },
    {
      "index": 842,
      "start_time": 2082699.9999999998,
      "end_time": 2084608.9999999998,
      "text": "so we initialized them in Numpy,"
    },
    {
      "index": 843,
      "start_time": 2084610.0000000002,
      "end_time": 2087441.0000000002,
      "text": "but now because these things live inside the graph,"
    },
    {
      "index": 844,
      "start_time": 2087440.0,
      "end_time": 2090572.0,
      "text": "TensorFlow is responsible for initializing them."
    },
    {
      "index": 845,
      "start_time": 2090570.0000000002,
      "end_time": 2093150.0000000002,
      "text": "So we need to pass in a tf.randomnormal operation,"
    },
    {
      "index": 846,
      "start_time": 2093150.0,
      "end_time": 2095689.0,
      "text": "which again is not actually initializing them"
    },
    {
      "index": 847,
      "start_time": 2095690.0,
      "end_time": 2098222.0,
      "text": "when we run this line, this is just telling TensorFlow"
    },
    {
      "index": 848,
      "start_time": 2098220.0,
      "end_time": 2100627.0,
      "text": "how we want them to be initialized."
    },
    {
      "index": 849,
      "start_time": 2100630.0,
      "end_time": 2102483.0,
      "text": "So it&#39;s a little bit of confusing misdirection"
    },
    {
      "index": 850,
      "start_time": 2102480.0,
      "end_time": 2103214.0,
      "text": "going on here."
    },
    {
      "index": 851,
      "start_time": 2104870.0,
      "end_time": 2107479.0,
      "text": "And now, remember in the previous example"
    },
    {
      "index": 852,
      "start_time": 2107480.0,
      "end_time": 2110209.0,
      "text": "we were actually updating the weights outside"
    },
    {
      "index": 853,
      "start_time": 2110210.0,
      "end_time": 2111865.0,
      "text": "of the computational graph."
    },
    {
      "index": 854,
      "start_time": 2111860.0,
      "end_time": 2114552.0,
      "text": "We, in the previous example, we were computing the gradients"
    },
    {
      "index": 855,
      "start_time": 2114550.0,
      "end_time": 2117215.0,
      "text": "and then using them to update the weights as Numpy arrays"
    },
    {
      "index": 856,
      "start_time": 2117220.0,
      "end_time": 2119432.0,
      "text": "and then feeding in the updated weights at the next"
    },
    {
      "index": 857,
      "start_time": 2119430.0,
      "end_time": 2120263.0,
      "text": "time step."
    },
    {
      "index": 858,
      "start_time": 2120260.0,
      "end_time": 2122738.0,
      "text": "But now because we want these weights to live inside"
    },
    {
      "index": 859,
      "start_time": 2122740.0,
      "end_time": 2125816.0,
      "text": "the graph, this operation of updating the weights"
    },
    {
      "index": 860,
      "start_time": 2125820.0,
      "end_time": 2128402.0,
      "text": "needs to also be an operation inside"
    },
    {
      "index": 861,
      "start_time": 2128400.0,
      "end_time": 2129402.0,
      "text": "the computational graph."
    },
    {
      "index": 862,
      "start_time": 2129400.0,
      "end_time": 2134240.0,
      "text": "So now we used this assign function which mutates"
    },
    {
      "index": 863,
      "start_time": 2134240.0,
      "end_time": 2137198.0,
      "text": "these variables inside the computational graph"
    },
    {
      "index": 864,
      "start_time": 2137200.0,
      "end_time": 2139407.0,
      "text": "and now the mutated value will persist across multiple runs"
    },
    {
      "index": 865,
      "start_time": 2139410.0,
      "end_time": 2141490.0,
      "text": "of the same graph."
    },
    {
      "index": 866,
      "start_time": 2141490.0,
      "end_time": 2144198.0,
      "text": "So now when we run this graph"
    },
    {
      "index": 867,
      "start_time": 2144200.0,
      "end_time": 2145981.0,
      "text": "and when we train the network,"
    },
    {
      "index": 868,
      "start_time": 2145980.0,
      "end_time": 2148424.0,
      "text": "now we need to run the graph once with a little bit of"
    },
    {
      "index": 869,
      "start_time": 2148420.0,
      "end_time": 2150830.0,
      "text": "special incantation to tell TensorFlow to set up these"
    },
    {
      "index": 870,
      "start_time": 2150830.0,
      "end_time": 2153825.0,
      "text": "variables that are going to live inside the graph."
    },
    {
      "index": 871,
      "start_time": 2153820.0,
      "end_time": 2155774.0,
      "text": "And then once we&#39;ve done that initialization,"
    },
    {
      "index": 872,
      "start_time": 2155780.0,
      "end_time": 2158575.0,
      "text": "now we can run the graph over and over again."
    },
    {
      "index": 873,
      "start_time": 2158570.0,
      "end_time": 2162145.0,
      "text": "And here, we&#39;re now only feeding in the data and labels"
    },
    {
      "index": 874,
      "start_time": 2162150.0,
      "end_time": 2165911.0,
      "text": "X and Y and the weights are living inside the graph."
    },
    {
      "index": 875,
      "start_time": 2165910.0,
      "end_time": 2167350.0,
      "text": "And here we&#39;ve asked the network to,"
    },
    {
      "index": 876,
      "start_time": 2167350.0,
      "end_time": 2169517.0,
      "text": "we&#39;ve asked TensorFlow to compute the loss for us."
    },
    {
      "index": 877,
      "start_time": 2169520.0,
      "end_time": 2173003.0,
      "text": "And then you might think that this would train the network,"
    },
    {
      "index": 878,
      "start_time": 2173100.0,
      "end_time": 2175627.0,
      "text": "but there&#39;s actually a bug here."
    },
    {
      "index": 879,
      "start_time": 2175630.0,
      "end_time": 2177577.0,
      "text": "So, if you actually run this code,"
    },
    {
      "index": 880,
      "start_time": 2177570.0,
      "end_time": 2179960.0,
      "text": "and you plot the loss, it doesn&#39;t train."
    },
    {
      "index": 881,
      "start_time": 2179960.0,
      "end_time": 2183397.0,
      "text": "So that&#39;s bad, it&#39;s confusing, like what&#39;s going on?"
    },
    {
      "index": 882,
      "start_time": 2183400.0,
      "end_time": 2185383.0,
      "text": "We wrote this assign code, we ran the thing,"
    },
    {
      "index": 883,
      "start_time": 2185390.0,
      "end_time": 2186907.0,
      "text": "like we computed the loss and the gradients"
    },
    {
      "index": 884,
      "start_time": 2186900.0,
      "end_time": 2189955.0,
      "text": "and our loss is flat, what&#39;s going on?"
    },
    {
      "index": 885,
      "start_time": 2189960.0,
      "end_time": 2191463.0,
      "text": "Any ideas?"
    },
    {
      "index": 886,
      "start_time": 2191460.0,
      "end_time": 2194595.0,
      "text": "[student&#39;s words obscured due to lack of microphone]"
    },
    {
      "index": 887,
      "start_time": 2194590.0,
      "end_time": 2198649.0,
      "text": "Yeah so one hypothesis is that maybe we&#39;re accidentally"
    },
    {
      "index": 888,
      "start_time": 2198650.0,
      "end_time": 2201745.0,
      "text": "re-initializing the w&#39;s every time we call the graph."
    },
    {
      "index": 889,
      "start_time": 2201750.0,
      "end_time": 2203855.0,
      "text": "That&#39;s a good hypothesis, that&#39;s actually not the problem"
    },
    {
      "index": 890,
      "start_time": 2203850.0,
      "end_time": 2204975.0,
      "text": "in this case."
    },
    {
      "index": 891,
      "start_time": 2204980.0,
      "end_time": 2208571.0,
      "text": "[student&#39;s words obscured due to lack of microphone]"
    },
    {
      "index": 892,
      "start_time": 2208570.0,
      "end_time": 2211776.0,
      "text": "Yeah, so the answer is that we actually need to explicitly"
    },
    {
      "index": 893,
      "start_time": 2211780.0,
      "end_time": 2214342.0,
      "text": "tell TensorFlow that we want to run these new w1"
    },
    {
      "index": 894,
      "start_time": 2214340.0,
      "end_time": 2216318.0,
      "text": "and new w2 operations."
    },
    {
      "index": 895,
      "start_time": 2216320.0,
      "end_time": 2218837.0,
      "text": "So we&#39;ve built up this big computational graph data"
    },
    {
      "index": 896,
      "start_time": 2218830.0,
      "end_time": 2221694.0,
      "text": "structure in memory and now when we call run,"
    },
    {
      "index": 897,
      "start_time": 2221700.0,
      "end_time": 2224895.0,
      "text": "we only told TensorFlow that we wanted to compute loss."
    },
    {
      "index": 898,
      "start_time": 2224890.0,
      "end_time": 2227357.0,
      "text": "And if you look at the dependencies among these different"
    },
    {
      "index": 899,
      "start_time": 2227360.0,
      "end_time": 2229153.0,
      "text": "operations inside the graph,"
    },
    {
      "index": 900,
      "start_time": 2229160.0,
      "end_time": 2231282.0,
      "text": "you see that in order to compute loss"
    },
    {
      "index": 901,
      "start_time": 2231280.0,
      "end_time": 2233718.0,
      "text": "we don&#39;t actually need to perform this update operation."
    },
    {
      "index": 902,
      "start_time": 2233720.0,
      "end_time": 2236371.0,
      "text": "So TensorFlow is smart and it only computes the parts"
    },
    {
      "index": 903,
      "start_time": 2236370.0,
      "end_time": 2239420.0,
      "text": "of the graph that are necessary for computing the output"
    },
    {
      "index": 904,
      "start_time": 2239420.0,
      "end_time": 2241500.0,
      "text": "that you asked it to compute."
    },
    {
      "index": 905,
      "start_time": 2241500.0,
      "end_time": 2244503.0,
      "text": "So that&#39;s kind of a nice thing because it means it&#39;s only"
    },
    {
      "index": 906,
      "start_time": 2244500.0,
      "end_time": 2246657.0,
      "text": "doing as much work as it needs to,"
    },
    {
      "index": 907,
      "start_time": 2246660.0,
      "end_time": 2249733.0,
      "text": "but in situations like this it can be a little bit confusing"
    },
    {
      "index": 908,
      "start_time": 2249730.0,
      "end_time": 2252740.0,
      "text": "and lead to behavior that you didn&#39;t expect."
    },
    {
      "index": 909,
      "start_time": 2252740.0,
      "end_time": 2254937.0,
      "text": "So the solution in this case is that we actually need to"
    },
    {
      "index": 910,
      "start_time": 2254940.0,
      "end_time": 2257660.0,
      "text": "explicitly tell TensorFlow to perform those"
    },
    {
      "index": 911,
      "start_time": 2257660.0,
      "end_time": 2259145.0,
      "text": "update operations."
    },
    {
      "index": 912,
      "start_time": 2259140.0,
      "end_time": 2261474.0,
      "text": "So one thing we could do, which is what was suggested"
    },
    {
      "index": 913,
      "start_time": 2261480.0,
      "end_time": 2265608.0,
      "text": "is we could add new w1 and new w2 as outputs"
    },
    {
      "index": 914,
      "start_time": 2265600.0,
      "end_time": 2267758.0,
      "text": "and just tell TensorFlow that we want to produce"
    },
    {
      "index": 915,
      "start_time": 2267760.0,
      "end_time": 2269530.0,
      "text": "these values as outputs."
    },
    {
      "index": 916,
      "start_time": 2269530.0,
      "end_time": 2273198.0,
      "text": "But that&#39;s a problem too because the values,"
    },
    {
      "index": 917,
      "start_time": 2273200.0,
      "end_time": 2277367.0,
      "text": "those new w1, new w2 values are again these big tensors."
    },
    {
      "index": 918,
      "start_time": 2278890.0,
      "end_time": 2281122.0,
      "text": "So now if we tell TensorFlow we want those as output,"
    },
    {
      "index": 919,
      "start_time": 2281120.0,
      "end_time": 2283677.0,
      "text": "we&#39;re going to again get this copying behavior"
    },
    {
      "index": 920,
      "start_time": 2283680.0,
      "end_time": 2285138.0,
      "text": "between CPU and GPU at ever iteration."
    },
    {
      "index": 921,
      "start_time": 2285140.0,
      "end_time": 2287318.0,
      "text": "So that&#39;s bad, we don&#39;t want that."
    },
    {
      "index": 922,
      "start_time": 2287320.0,
      "end_time": 2289220.0,
      "text": "So there&#39;s a little trick you can do instead."
    },
    {
      "index": 923,
      "start_time": 2289220.0,
      "end_time": 2291745.0,
      "text": "Which is that we add kind of a dummy node to the graph."
    },
    {
      "index": 924,
      "start_time": 2291740.0,
      "end_time": 2294253.0,
      "text": "With these fake data dependencies"
    },
    {
      "index": 925,
      "start_time": 2294250.0,
      "end_time": 2296981.0,
      "text": "and we just say that this dummy node updates,"
    },
    {
      "index": 926,
      "start_time": 2296990.0,
      "end_time": 2300311.0,
      "text": "has these data dependencies of new w1 and new w2."
    },
    {
      "index": 927,
      "start_time": 2300310.0,
      "end_time": 2302413.0,
      "text": "And now when we actually run the graph,"
    },
    {
      "index": 928,
      "start_time": 2302410.0,
      "end_time": 2305803.0,
      "text": "we tell it to compute both the loss and this dummy node."
    },
    {
      "index": 929,
      "start_time": 2305800.0,
      "end_time": 2307836.0,
      "text": "And this dummy node doesn&#39;t actually return"
    },
    {
      "index": 930,
      "start_time": 2307840.0,
      "end_time": 2311169.0,
      "text": "any value it just returns none, but because of this"
    },
    {
      "index": 931,
      "start_time": 2311170.0,
      "end_time": 2313953.0,
      "text": "dependency that we&#39;ve put into the node it ensures"
    },
    {
      "index": 932,
      "start_time": 2313950.0,
      "end_time": 2315978.0,
      "text": "that when we run the updates value,"
    },
    {
      "index": 933,
      "start_time": 2315980.0,
      "end_time": 2318468.0,
      "text": "we actually also run these update operations."
    },
    {
      "index": 934,
      "start_time": 2318470.0,
      "end_time": 2319553.0,
      "text": "So, question?"
    },
    {
      "index": 935,
      "start_time": 2320790.0,
      "end_time": 2324957.0,
      "text": "[student&#39;s words obscured due to lack of microphone]"
    },
    {
      "index": 936,
      "start_time": 2325850.0,
      "end_time": 2328544.0,
      "text": "Is there a reason why we didn&#39;t put X and Y into the graph?"
    },
    {
      "index": 937,
      "start_time": 2328550.0,
      "end_time": 2331372.0,
      "text": "And that it stayed as Numpy."
    },
    {
      "index": 938,
      "start_time": 2331370.0,
      "end_time": 2334725.0,
      "text": "So in this example we&#39;re reusing X and Y on every,"
    },
    {
      "index": 939,
      "start_time": 2334730.0,
      "end_time": 2337156.0,
      "text": "we&#39;re reusing the same X and Y on every iteration."
    },
    {
      "index": 940,
      "start_time": 2337150.0,
      "end_time": 2339155.0,
      "text": "So you&#39;re right, we could have just also stuck those"
    },
    {
      "index": 941,
      "start_time": 2339160.0,
      "end_time": 2342215.0,
      "text": "in the graph, but in a more realistic scenario,"
    },
    {
      "index": 942,
      "start_time": 2342210.0,
      "end_time": 2345300.0,
      "text": "X and Y will be minibatches of data so those will actually"
    },
    {
      "index": 943,
      "start_time": 2345300.0,
      "end_time": 2347525.0,
      "text": "change at every iteration and we will want to feed"
    },
    {
      "index": 944,
      "start_time": 2347530.0,
      "end_time": 2350126.0,
      "text": "different values for those at every iteration."
    },
    {
      "index": 945,
      "start_time": 2350120.0,
      "end_time": 2352188.0,
      "text": "So in this case, they could have stayed in the graph,"
    },
    {
      "index": 946,
      "start_time": 2352190.0,
      "end_time": 2354330.0,
      "text": "but in most cases they will change,"
    },
    {
      "index": 947,
      "start_time": 2354330.0,
      "end_time": 2357913.0,
      "text": "so we don&#39;t want them to live in the graph."
    },
    {
      "index": 948,
      "start_time": 2359390.0,
      "end_time": 2361292.0,
      "text": "Oh, another question?"
    },
    {
      "index": 949,
      "start_time": 2361290.0,
      "end_time": 2365457.0,
      "text": "[student&#39;s words obscured due to lack of microphone]"
    },
    {
      "index": 950,
      "start_time": 2377460.0,
      "end_time": 2380926.0,
      "text": "Yeah, so we&#39;ve told it, we had put into TensorFlow"
    },
    {
      "index": 951,
      "start_time": 2380930.0,
      "end_time": 2384308.0,
      "text": "that the outputs we want are loss and updates."
    },
    {
      "index": 952,
      "start_time": 2384300.0,
      "end_time": 2387383.0,
      "text": "Updates is not actually a real value."
    },
    {
      "index": 953,
      "start_time": 2388670.0,
      "end_time": 2391805.0,
      "text": "So when updates evaluates it just returns none."
    },
    {
      "index": 954,
      "start_time": 2391800.0,
      "end_time": 2394568.0,
      "text": "But because of this dependency we&#39;ve told it that updates"
    },
    {
      "index": 955,
      "start_time": 2394570.0,
      "end_time": 2397416.0,
      "text": "depends on these assign operations."
    },
    {
      "index": 956,
      "start_time": 2397420.0,
      "end_time": 2399360.0,
      "text": "But these assign operations live inside"
    },
    {
      "index": 957,
      "start_time": 2399360.0,
      "end_time": 2402362.0,
      "text": "the computational graph and all live inside GPU memory."
    },
    {
      "index": 958,
      "start_time": 2402360.0,
      "end_time": 2404428.0,
      "text": "So then we&#39;re doing these update operations"
    },
    {
      "index": 959,
      "start_time": 2404430.0,
      "end_time": 2407111.0,
      "text": "entirely on the GPU and we&#39;re no longer copying the"
    },
    {
      "index": 960,
      "start_time": 2407110.0,
      "end_time": 2410193.0,
      "text": "updated values back out of the graph."
    },
    {
      "index": 961,
      "start_time": 2411720.0,
      "end_time": 2415109.0,
      "text": "[student&#39;s words obscured due to lack of microphone]"
    },
    {
      "index": 962,
      "start_time": 2415110.0,
      "end_time": 2418193.0,
      "text": "So the question is does tf.group return none?"
    },
    {
      "index": 963,
      "start_time": 2418200.0,
      "end_time": 2421829.0,
      "text": "So this gets into the trickiness of TensorFlow."
    },
    {
      "index": 964,
      "start_time": 2421820.0,
      "end_time": 2425919.0,
      "text": "So tf.group returns some crazy TensorFlow value."
    },
    {
      "index": 965,
      "start_time": 2425920.0,
      "end_time": 2429367.0,
      "text": "It sort of returns some like internal TensorFlow node"
    },
    {
      "index": 966,
      "start_time": 2429370.0,
      "end_time": 2432657.0,
      "text": "operation that we need to continue building the graph."
    },
    {
      "index": 967,
      "start_time": 2432660.0,
      "end_time": 2434268.0,
      "text": "But when you execute the graph,"
    },
    {
      "index": 968,
      "start_time": 2434270.0,
      "end_time": 2437421.0,
      "text": "and when you tell, inside the session.run,"
    },
    {
      "index": 969,
      "start_time": 2437420.0,
      "end_time": 2440253.0,
      "text": "when we told it we want it to compute the concrete value"
    },
    {
      "index": 970,
      "start_time": 2440250.0,
      "end_time": 2443333.0,
      "text": "from updates, then that returns none."
    },
    {
      "index": 971,
      "start_time": 2443330.0,
      "end_time": 2445479.0,
      "text": "So whenever you&#39;re working with TensorFlow"
    },
    {
      "index": 972,
      "start_time": 2445480.0,
      "end_time": 2447905.0,
      "text": "you have this funny indirection between building the graph"
    },
    {
      "index": 973,
      "start_time": 2447910.0,
      "end_time": 2450784.0,
      "text": "and the actual output values during building the graph"
    },
    {
      "index": 974,
      "start_time": 2450780.0,
      "end_time": 2453486.0,
      "text": "is some funny weird object, and then you actually get"
    },
    {
      "index": 975,
      "start_time": 2453490.0,
      "end_time": 2455469.0,
      "text": "a concrete value when you run the graph."
    },
    {
      "index": 976,
      "start_time": 2455470.0,
      "end_time": 2458662.0,
      "text": "So here after you run updates, then the output is none."
    },
    {
      "index": 977,
      "start_time": 2458660.0,
      "end_time": 2459969.0,
      "text": "Does that clear it up a little bit?"
    },
    {
      "index": 978,
      "start_time": 2459970.0,
      "end_time": 2464137.0,
      "text": "[student&#39;s words obscured due to lack of microphone]"
    },
    {
      "index": 979,
      "start_time": 2478800.0,
      "end_time": 2480796.0,
      "text": "So the question is why is loss a value"
    },
    {
      "index": 980,
      "start_time": 2480790.0,
      "end_time": 2482332.0,
      "text": "and why is updates none?"
    },
    {
      "index": 981,
      "start_time": 2482330.0,
      "end_time": 2484666.0,
      "text": "That&#39;s just the way that updates works."
    },
    {
      "index": 982,
      "start_time": 2484680.0,
      "end_time": 2485988.0,
      "text": "So loss is a value when we compute,"
    },
    {
      "index": 983,
      "start_time": 2485990.0,
      "end_time": 2488598.0,
      "text": "when we tell TensorFlow we want to run a tensor,"
    },
    {
      "index": 984,
      "start_time": 2488600.0,
      "end_time": 2490179.0,
      "text": "then we get the concrete value."
    },
    {
      "index": 985,
      "start_time": 2490180.0,
      "end_time": 2493151.0,
      "text": "Updates is this kind of special other data type"
    },
    {
      "index": 986,
      "start_time": 2493150.0,
      "end_time": 2495756.0,
      "text": "that does not return a value, it instead returns none."
    },
    {
      "index": 987,
      "start_time": 2495750.0,
      "end_time": 2498700.0,
      "text": "So it&#39;s kind of some TensorFlow magic that&#39;s going on there."
    },
    {
      "index": 988,
      "start_time": 2498700.0,
      "end_time": 2500599.0,
      "text": "Maybe we can talk offline if you&#39;re still confused."
    },
    {
      "index": 989,
      "start_time": 2500600.0,
      "end_time": 2502676.0,
      "text": "[student&#39;s words obscured due to lack of microphone]"
    },
    {
      "index": 990,
      "start_time": 2502680.0,
      "end_time": 2506187.0,
      "text": "Yeah, yeah, that behavior is coming from the group method."
    },
    {
      "index": 991,
      "start_time": 2506190.0,
      "end_time": 2508392.0,
      "text": "So now, we kind of have this weird pattern where we"
    },
    {
      "index": 992,
      "start_time": 2508390.0,
      "end_time": 2510550.0,
      "text": "wanted to do these different assign operations,"
    },
    {
      "index": 993,
      "start_time": 2510550.0,
      "end_time": 2512493.0,
      "text": "we have to use this funny tf.group thing."
    },
    {
      "index": 994,
      "start_time": 2512490.0,
      "end_time": 2516246.0,
      "text": "That&#39;s kind of a pain, so thankfully TensorFlow gives"
    },
    {
      "index": 995,
      "start_time": 2516250.0,
      "end_time": 2518582.0,
      "text": "you some convenience operations that kind of do that"
    },
    {
      "index": 996,
      "start_time": 2518580.0,
      "end_time": 2520400.0,
      "text": "kind of stuff for you."
    },
    {
      "index": 997,
      "start_time": 2520400.0,
      "end_time": 2521706.0,
      "text": "And that&#39;s called an optimizer."
    },
    {
      "index": 998,
      "start_time": 2521710.0,
      "end_time": 2526474.0,
      "text": "So here we&#39;re using a tf.train.GradientDescentOptimizer"
    },
    {
      "index": 999,
      "start_time": 2526470.0,
      "end_time": 2528458.0,
      "text": "and we&#39;re telling it what learning rate we want to use."
    },
    {
      "index": 1000,
      "start_time": 2528460.0,
      "end_time": 2530966.0,
      "text": "And you can imagine that there&#39;s, there&#39;s RMSprop,"
    },
    {
      "index": 1001,
      "start_time": 2530960.0,
      "end_time": 2532780.0,
      "text": "there&#39;s all kinds of different optimization algorithms here."
    },
    {
      "index": 1002,
      "start_time": 2532780.0,
      "end_time": 2536280.0,
      "text": "And now we call optimizer.minimize of loss"
    },
    {
      "index": 1003,
      "start_time": 2537310.0,
      "end_time": 2539669.0,
      "text": "and now this is a pretty magical,"
    },
    {
      "index": 1004,
      "start_time": 2539670.0,
      "end_time": 2541204.0,
      "text": "this is a pretty magical thing,"
    },
    {
      "index": 1005,
      "start_time": 2541200.0,
      "end_time": 2544523.0,
      "text": "because now this call is aware that these variables"
    },
    {
      "index": 1006,
      "start_time": 2544530.0,
      "end_time": 2548109.0,
      "text": "w1 and w2 are marked as trainable by default,"
    },
    {
      "index": 1007,
      "start_time": 2548110.0,
      "end_time": 2550590.0,
      "text": "so then internally, inside this optimizer.minimize"
    },
    {
      "index": 1008,
      "start_time": 2550590.0,
      "end_time": 2553108.0,
      "text": "it&#39;s going in and adding nodes to the graph"
    },
    {
      "index": 1009,
      "start_time": 2553100.0,
      "end_time": 2555179.0,
      "text": "which will compute gradient of loss with respect"
    },
    {
      "index": 1010,
      "start_time": 2555180.0,
      "end_time": 2558155.0,
      "text": "to w1 and w2 and then it&#39;s also performing that update"
    },
    {
      "index": 1011,
      "start_time": 2558160.0,
      "end_time": 2560288.0,
      "text": "operation for you and it&#39;s doing the grouping operation"
    },
    {
      "index": 1012,
      "start_time": 2560290.0,
      "end_time": 2562221.0,
      "text": "for you and it&#39;s doing the assigns."
    },
    {
      "index": 1013,
      "start_time": 2562220.0,
      "end_time": 2564207.0,
      "text": "It&#39;s like doing a lot of magical stuff inside there."
    },
    {
      "index": 1014,
      "start_time": 2564210.0,
      "end_time": 2566510.0,
      "text": "But then it ends up giving you this magical updates value"
    },
    {
      "index": 1015,
      "start_time": 2566510.0,
      "end_time": 2569546.0,
      "text": "which, if you dig through the code they&#39;re actually using"
    },
    {
      "index": 1016,
      "start_time": 2569540.0,
      "end_time": 2572342.0,
      "text": "tf.group so it looks very similar internally to what"
    },
    {
      "index": 1017,
      "start_time": 2572340.0,
      "end_time": 2573514.0,
      "text": "we saw before."
    },
    {
      "index": 1018,
      "start_time": 2573520.0,
      "end_time": 2575948.0,
      "text": "And now when we run the graph inside our loop"
    },
    {
      "index": 1019,
      "start_time": 2575950.0,
      "end_time": 2578611.0,
      "text": "we do the same pattern of telling it to compute loss"
    },
    {
      "index": 1020,
      "start_time": 2578610.0,
      "end_time": 2580403.0,
      "text": "and updates."
    },
    {
      "index": 1021,
      "start_time": 2580400.0,
      "end_time": 2583444.0,
      "text": "And every time we tell the graph to compute updates,"
    },
    {
      "index": 1022,
      "start_time": 2583440.0,
      "end_time": 2587446.0,
      "text": "then it&#39;ll actually go and update the graph."
    },
    {
      "index": 1023,
      "start_time": 2587450.0,
      "end_time": 2588593.0,
      "text": "Question?"
    },
    {
      "index": 1024,
      "start_time": 2588590.0,
      "end_time": 2590956.0,
      "text": "[student&#39;s words obscured due to lack of microphone]"
    },
    {
      "index": 1025,
      "start_time": 2590960.0,
      "end_time": 2594250.0,
      "text": "Yeah, so what is the tf.GlobalVariablesInitializer?"
    },
    {
      "index": 1026,
      "start_time": 2594250.0,
      "end_time": 2598761.0,
      "text": "So that&#39;s initializing w1 and w2 because these are"
    },
    {
      "index": 1027,
      "start_time": 2598760.0,
      "end_time": 2600502.0,
      "text": "variables which live inside the graph."
    },
    {
      "index": 1028,
      "start_time": 2600500.0,
      "end_time": 2602821.0,
      "text": "So we need to, when we saw this, when we create"
    },
    {
      "index": 1029,
      "start_time": 2602820.0,
      "end_time": 2605240.0,
      "text": "the tf.variable we have this tf.randomnormal"
    },
    {
      "index": 1030,
      "start_time": 2605240.0,
      "end_time": 2608362.0,
      "text": "which is this initialization so the"
    },
    {
      "index": 1031,
      "start_time": 2608370.0,
      "end_time": 2610775.0,
      "text": "tf.GlobalVariablesInitializer is causing the"
    },
    {
      "index": 1032,
      "start_time": 2610770.0,
      "end_time": 2614945.0,
      "text": "tf.randomnormal to actually run and generate concrete values"
    },
    {
      "index": 1033,
      "start_time": 2614950.0,
      "end_time": 2617736.0,
      "text": "to initialize those variables."
    },
    {
      "index": 1034,
      "start_time": 2617730.0,
      "end_time": 2620791.0,
      "text": "[student&#39;s words obscured due to lack of microphone]"
    },
    {
      "index": 1035,
      "start_time": 2620790.0,
      "end_time": 2622266.0,
      "text": "Sorry, what was the question?"
    },
    {
      "index": 1036,
      "start_time": 2622270.0,
      "end_time": 2625232.0,
      "text": "[student&#39;s words obscured due to lack of microphone]"
    },
    {
      "index": 1037,
      "start_time": 2625230.0,
      "end_time": 2627932.0,
      "text": "So it knows that a placeholder is going to be fed"
    },
    {
      "index": 1038,
      "start_time": 2627940.0,
      "end_time": 2629983.0,
      "text": "outside of the graph and a variable is something that"
    },
    {
      "index": 1039,
      "start_time": 2629980.0,
      "end_time": 2631387.0,
      "text": "lives inside the graph."
    },
    {
      "index": 1040,
      "start_time": 2631390.0,
      "end_time": 2633775.0,
      "text": "So I don&#39;t know all the details about how it decides,"
    },
    {
      "index": 1041,
      "start_time": 2633770.0,
      "end_time": 2636371.0,
      "text": "what exactly it decides to run with that call."
    },
    {
      "index": 1042,
      "start_time": 2636370.0,
      "end_time": 2637679.0,
      "text": "I think you&#39;d need to dig through the code to figure"
    },
    {
      "index": 1043,
      "start_time": 2637680.0,
      "end_time": 2640384.0,
      "text": "that out, or maybe it&#39;s documented somewhere."
    },
    {
      "index": 1044,
      "start_time": 2640380.0,
      "end_time": 2641937.0,
      "text": "So but now we&#39;ve kind of got this,"
    },
    {
      "index": 1045,
      "start_time": 2641940.0,
      "end_time": 2644655.0,
      "text": "again we&#39;ve got this full example of training a"
    },
    {
      "index": 1046,
      "start_time": 2644660.0,
      "end_time": 2646134.0,
      "text": "network in TensorFlow and we&#39;re kind of adding"
    },
    {
      "index": 1047,
      "start_time": 2646130.0,
      "end_time": 2649328.0,
      "text": "bells and whistles to make it a little bit more convenient."
    },
    {
      "index": 1048,
      "start_time": 2649330.0,
      "end_time": 2651895.0,
      "text": "So we can also here, in the previous example"
    },
    {
      "index": 1049,
      "start_time": 2651890.0,
      "end_time": 2654267.0,
      "text": "we were computing the loss explicitly using our own"
    },
    {
      "index": 1050,
      "start_time": 2654270.0,
      "end_time": 2656954.0,
      "text": "tensor operations, TensorFlow you can always do that,"
    },
    {
      "index": 1051,
      "start_time": 2656950.0,
      "end_time": 2659144.0,
      "text": "you can use basic tensor operations to compute"
    },
    {
      "index": 1052,
      "start_time": 2659150.0,
      "end_time": 2660741.0,
      "text": "just about anything you want."
    },
    {
      "index": 1053,
      "start_time": 2660740.0,
      "end_time": 2662731.0,
      "text": "But TensorFlow also gives you a bunch of convenience"
    },
    {
      "index": 1054,
      "start_time": 2662730.0,
      "end_time": 2665901.0,
      "text": "functions that compute these common neural network things"
    },
    {
      "index": 1055,
      "start_time": 2665900.0,
      "end_time": 2666733.0,
      "text": "for you."
    },
    {
      "index": 1056,
      "start_time": 2666730.0,
      "end_time": 2670396.0,
      "text": "So in this case we can use tf.losses.mean_squared_error"
    },
    {
      "index": 1057,
      "start_time": 2670400.0,
      "end_time": 2672531.0,
      "text": "and it just does the L2 loss for us so we don&#39;t have"
    },
    {
      "index": 1058,
      "start_time": 2672530.0,
      "end_time": 2676272.0,
      "text": "to compute it ourself in terms of basic tensor operations."
    },
    {
      "index": 1059,
      "start_time": 2676270.0,
      "end_time": 2679191.0,
      "text": "So another kind of weirdness here is that it was kind of"
    },
    {
      "index": 1060,
      "start_time": 2679190.0,
      "end_time": 2682602.0,
      "text": "annoying that we had to explicitly define our inputs"
    },
    {
      "index": 1061,
      "start_time": 2682610.0,
      "end_time": 2684733.0,
      "text": "and define our weights and then like chain them together"
    },
    {
      "index": 1062,
      "start_time": 2684730.0,
      "end_time": 2686668.0,
      "text": "in the forward pass using a matrix multiply."
    },
    {
      "index": 1063,
      "start_time": 2686670.0,
      "end_time": 2689961.0,
      "text": "And in this example we&#39;ve actually not put biases"
    },
    {
      "index": 1064,
      "start_time": 2689960.0,
      "end_time": 2692822.0,
      "text": "in the layer because that would be kind of an extra,"
    },
    {
      "index": 1065,
      "start_time": 2692820.0,
      "end_time": 2694291.0,
      "text": "then we&#39;d have to initialize biases,"
    },
    {
      "index": 1066,
      "start_time": 2694290.0,
      "end_time": 2696329.0,
      "text": "we&#39;d have to get them in the right shape,"
    },
    {
      "index": 1067,
      "start_time": 2696330.0,
      "end_time": 2698494.0,
      "text": "we&#39;d have to broadcast the biases against the output"
    },
    {
      "index": 1068,
      "start_time": 2698490.0,
      "end_time": 2700564.0,
      "text": "of the matrix multiply and you can see that that"
    },
    {
      "index": 1069,
      "start_time": 2700570.0,
      "end_time": 2701968.0,
      "text": "would kind of be a lot of code."
    },
    {
      "index": 1070,
      "start_time": 2701970.0,
      "end_time": 2703667.0,
      "text": "It would be kind of annoying write."
    },
    {
      "index": 1071,
      "start_time": 2703660.0,
      "end_time": 2705227.0,
      "text": "And once you get to like convolutions"
    },
    {
      "index": 1072,
      "start_time": 2705230.0,
      "end_time": 2707625.0,
      "text": "and batch normalizations and other types of layers"
    },
    {
      "index": 1073,
      "start_time": 2707630.0,
      "end_time": 2709657.0,
      "text": "this kind of basic way of working,"
    },
    {
      "index": 1074,
      "start_time": 2709650.0,
      "end_time": 2712508.0,
      "text": "of having these variables, having these inputs and outputs"
    },
    {
      "index": 1075,
      "start_time": 2712510.0,
      "end_time": 2714624.0,
      "text": "and combining them all together with basic"
    },
    {
      "index": 1076,
      "start_time": 2714630.0,
      "end_time": 2717407.0,
      "text": "computational graph operations could be a little bit"
    },
    {
      "index": 1077,
      "start_time": 2717400.0,
      "end_time": 2719746.0,
      "text": "unwieldy and it could be really annoying to"
    },
    {
      "index": 1078,
      "start_time": 2719750.0,
      "end_time": 2721275.0,
      "text": "make sure you initialize the weights with the right"
    },
    {
      "index": 1079,
      "start_time": 2721270.0,
      "end_time": 2722949.0,
      "text": "shapes and all that sort of stuff."
    },
    {
      "index": 1080,
      "start_time": 2722950.0,
      "end_time": 2725349.0,
      "text": "So as a result, there&#39;s a bunch of sort of higher level"
    },
    {
      "index": 1081,
      "start_time": 2725350.0,
      "end_time": 2727532.0,
      "text": "libraries that wrap around TensorFlow"
    },
    {
      "index": 1082,
      "start_time": 2727530.0,
      "end_time": 2730610.0,
      "text": "and handle some of these details for you."
    },
    {
      "index": 1083,
      "start_time": 2730610.0,
      "end_time": 2733184.0,
      "text": "So one example that ships with TensorFlow,"
    },
    {
      "index": 1084,
      "start_time": 2733190.0,
      "end_time": 2735965.0,
      "text": "is this tf.layers inside."
    },
    {
      "index": 1085,
      "start_time": 2735970.0,
      "end_time": 2738559.0,
      "text": "So now in this code example you can see that our code"
    },
    {
      "index": 1086,
      "start_time": 2738550.0,
      "end_time": 2741451.0,
      "text": "is only explicitly declaring the X and the Y"
    },
    {
      "index": 1087,
      "start_time": 2741460.0,
      "end_time": 2744605.0,
      "text": "which are the placeholders for the data and the labels."
    },
    {
      "index": 1088,
      "start_time": 2744600.0,
      "end_time": 2748474.0,
      "text": "And now we say that H=tf.layers.dense,"
    },
    {
      "index": 1089,
      "start_time": 2748470.0,
      "end_time": 2753356.0,
      "text": "we give it the input X and we tell it units=H."
    },
    {
      "index": 1090,
      "start_time": 2753360.0,
      "end_time": 2755171.0,
      "text": "This is again kind of a magical line"
    },
    {
      "index": 1091,
      "start_time": 2755170.0,
      "end_time": 2757780.0,
      "text": "because inside this line, it&#39;s kind of setting up"
    },
    {
      "index": 1092,
      "start_time": 2757780.0,
      "end_time": 2762478.0,
      "text": "w1 and b1, the bias, it&#39;s setting up variables for those"
    },
    {
      "index": 1093,
      "start_time": 2762480.0,
      "end_time": 2765221.0,
      "text": "with the right shapes that are kind of inside the graph"
    },
    {
      "index": 1094,
      "start_time": 2765220.0,
      "end_time": 2767409.0,
      "text": "but a little bit hidden from us."
    },
    {
      "index": 1095,
      "start_time": 2767410.0,
      "end_time": 2770119.0,
      "text": "And it&#39;s using this xavier initializer object"
    },
    {
      "index": 1096,
      "start_time": 2770120.0,
      "end_time": 2772931.0,
      "text": "to set up an initialization strategy for those."
    },
    {
      "index": 1097,
      "start_time": 2772930.0,
      "end_time": 2774729.0,
      "text": "So before we were doing that explicitly ourselves"
    },
    {
      "index": 1098,
      "start_time": 2774730.0,
      "end_time": 2777200.0,
      "text": "with the tf.randomnormal business,"
    },
    {
      "index": 1099,
      "start_time": 2777200.0,
      "end_time": 2779335.0,
      "text": "but now here it&#39;s kind of handling some of those details"
    },
    {
      "index": 1100,
      "start_time": 2779330.0,
      "end_time": 2782261.0,
      "text": "for us and it&#39;s just spitting out an H,"
    },
    {
      "index": 1101,
      "start_time": 2782270.0,
      "end_time": 2783993.0,
      "text": "which is again the same sort of H that we saw"
    },
    {
      "index": 1102,
      "start_time": 2783990.0,
      "end_time": 2786266.0,
      "text": "in the previous layer, it&#39;s just doing some of those"
    },
    {
      "index": 1103,
      "start_time": 2786260.0,
      "end_time": 2787510.0,
      "text": "details for us."
    },
    {
      "index": 1104,
      "start_time": 2788490.0,
      "end_time": 2790357.0,
      "text": "And you can see here, we&#39;re also passing an"
    },
    {
      "index": 1105,
      "start_time": 2790350.0,
      "end_time": 2793853.0,
      "text": "activation=tf.nn.relu so it&#39;s even doing the activation,"
    },
    {
      "index": 1106,
      "start_time": 2793860.0,
      "end_time": 2796913.0,
      "text": "the relu activation function inside this layer for us."
    },
    {
      "index": 1107,
      "start_time": 2796910.0,
      "end_time": 2799540.0,
      "text": "So it&#39;s taking care of a lot of these architectural"
    },
    {
      "index": 1108,
      "start_time": 2799540.0,
      "end_time": 2801369.0,
      "text": "details for us."
    },
    {
      "index": 1109,
      "start_time": 2801370.0,
      "end_time": 2802784.0,
      "text": "Question?"
    },
    {
      "index": 1110,
      "start_time": 2802780.0,
      "end_time": 2806442.0,
      "text": "[student&#39;s words obscured due to lack of microphone]"
    },
    {
      "index": 1111,
      "start_time": 2806450.0,
      "end_time": 2809314.0,
      "text": "Question is does the xavier initializer default"
    },
    {
      "index": 1112,
      "start_time": 2809320.0,
      "end_time": 2811168.0,
      "text": "to particular distribution?"
    },
    {
      "index": 1113,
      "start_time": 2811170.0,
      "end_time": 2813889.0,
      "text": "I&#39;m sure it has some default, I&#39;m not sure what it is."
    },
    {
      "index": 1114,
      "start_time": 2813890.0,
      "end_time": 2815853.0,
      "text": "I think you&#39;ll have to look at the documentation."
    },
    {
      "index": 1115,
      "start_time": 2815850.0,
      "end_time": 2818900.0,
      "text": "But it seems to be a reasonable strategy, I guess."
    },
    {
      "index": 1116,
      "start_time": 2818100.0,
      "end_time": 2819625.0,
      "text": "And in fact if you run this code,"
    },
    {
      "index": 1117,
      "start_time": 2819620.0,
      "end_time": 2821298.0,
      "text": "it converges much faster than the previous one"
    },
    {
      "index": 1118,
      "start_time": 2821300.0,
      "end_time": 2824108.0,
      "text": "because the initialization is better."
    },
    {
      "index": 1119,
      "start_time": 2824110.0,
      "end_time": 2826469.0,
      "text": "And you can see that we&#39;re using two calls to"
    },
    {
      "index": 1120,
      "start_time": 2826470.0,
      "end_time": 2828370.0,
      "text": "tf.layers and this lets us build our model"
    },
    {
      "index": 1121,
      "start_time": 2828370.0,
      "end_time": 2830464.0,
      "text": "without doing all these explicit bookkeeping details"
    },
    {
      "index": 1122,
      "start_time": 2830470.0,
      "end_time": 2831916.0,
      "text": "ourself."
    },
    {
      "index": 1123,
      "start_time": 2831910.0,
      "end_time": 2834272.0,
      "text": "So this is maybe a little bit more convenient."
    },
    {
      "index": 1124,
      "start_time": 2834270.0,
      "end_time": 2838679.0,
      "text": "But tf.contrib.layer is really not the only game in town."
    },
    {
      "index": 1125,
      "start_time": 2838680.0,
      "end_time": 2841257.0,
      "text": "There&#39;s like a lot of different higher level libraries"
    },
    {
      "index": 1126,
      "start_time": 2841260.0,
      "end_time": 2843349.0,
      "text": "that people build on top of TensorFlow."
    },
    {
      "index": 1127,
      "start_time": 2843350.0,
      "end_time": 2846842.0,
      "text": "And it&#39;s kind of due to this basic impotence mis-match"
    },
    {
      "index": 1128,
      "start_time": 2846840.0,
      "end_time": 2850314.0,
      "text": "where the computational graph is relatively low level thing,"
    },
    {
      "index": 1129,
      "start_time": 2850310.0,
      "end_time": 2852351.0,
      "text": "but when we&#39;re working with neural networks"
    },
    {
      "index": 1130,
      "start_time": 2852360.0,
      "end_time": 2854313.0,
      "text": "we have this concept of layers and weights"
    },
    {
      "index": 1131,
      "start_time": 2854310.0,
      "end_time": 2856427.0,
      "text": "and some layers have weights associated with them,"
    },
    {
      "index": 1132,
      "start_time": 2856430.0,
      "end_time": 2858953.0,
      "text": "and we typically think at a slightly higher level"
    },
    {
      "index": 1133,
      "start_time": 2858950.0,
      "end_time": 2861867.0,
      "text": "of abstraction than this raw computational graph."
    },
    {
      "index": 1134,
      "start_time": 2861870.0,
      "end_time": 2864903.0,
      "text": "So that&#39;s what these various packages are trying to"
    },
    {
      "index": 1135,
      "start_time": 2864900.0,
      "end_time": 2866564.0,
      "text": "help you out and let you work at this higher layer"
    },
    {
      "index": 1136,
      "start_time": 2866560.0,
      "end_time": 2868500.0,
      "text": "of abstraction."
    },
    {
      "index": 1137,
      "start_time": 2868500.0,
      "end_time": 2870778.0,
      "text": "So another very popular package that you may have"
    },
    {
      "index": 1138,
      "start_time": 2870780.0,
      "end_time": 2872459.0,
      "text": "seen before is Keras."
    },
    {
      "index": 1139,
      "start_time": 2872460.0,
      "end_time": 2876275.0,
      "text": "Keras is a very beautiful, nice API that sits on top of"
    },
    {
      "index": 1140,
      "start_time": 2876270.0,
      "end_time": 2879505.0,
      "text": "TensorFlow and handles sort of building up these"
    },
    {
      "index": 1141,
      "start_time": 2879510.0,
      "end_time": 2882806.0,
      "text": "computational graph for you up in the back end."
    },
    {
      "index": 1142,
      "start_time": 2882810.0,
      "end_time": 2885294.0,
      "text": "By the way, Keras also supports Theano as a back end,"
    },
    {
      "index": 1143,
      "start_time": 2885290.0,
      "end_time": 2887704.0,
      "text": "so that&#39;s also kind of nice."
    },
    {
      "index": 1144,
      "start_time": 2887700.0,
      "end_time": 2889689.0,
      "text": "And in this example you can see we build the model"
    },
    {
      "index": 1145,
      "start_time": 2889690.0,
      "end_time": 2890955.0,
      "text": "as a sequence of layers."
    },
    {
      "index": 1146,
      "start_time": 2890960.0,
      "end_time": 2892740.0,
      "text": "We build some optimizer object"
    },
    {
      "index": 1147,
      "start_time": 2892740.0,
      "end_time": 2895591.0,
      "text": "and we call model.compile and this does a lot of magic"
    },
    {
      "index": 1148,
      "start_time": 2895590.0,
      "end_time": 2897911.0,
      "text": "in the back end to build the graph."
    },
    {
      "index": 1149,
      "start_time": 2897910.0,
      "end_time": 2900759.0,
      "text": "And now we can call model.fit and that does the whole"
    },
    {
      "index": 1150,
      "start_time": 2900760.0,
      "end_time": 2902798.0,
      "text": "training procedure for us magically."
    },
    {
      "index": 1151,
      "start_time": 2902800.0,
      "end_time": 2904917.0,
      "text": "So I don&#39;t know all the details of how this works,"
    },
    {
      "index": 1152,
      "start_time": 2904910.0,
      "end_time": 2906207.0,
      "text": "but I know Keras is very popular,"
    },
    {
      "index": 1153,
      "start_time": 2906210.0,
      "end_time": 2907605.0,
      "text": "so you might consider using it if you&#39;re talking about"
    },
    {
      "index": 1154,
      "start_time": 2907610.0,
      "end_time": 2908527.0,
      "text": "TensorFlow."
    },
    {
      "index": 1155,
      "start_time": 2909800.0,
      "end_time": 2911273.0,
      "text": "Question?"
    },
    {
      "index": 1156,
      "start_time": 2911270.0,
      "end_time": 2915437.0,
      "text": "[student&#39;s words obscured due to lack of microphone]"
    },
    {
      "index": 1157,
      "start_time": 2921720.0,
      "end_time": 2923902.0,
      "text": "Yeah, so the question is like why there&#39;s no explicit"
    },
    {
      "index": 1158,
      "start_time": 2923900.0,
      "end_time": 2925526.0,
      "text": "CPU, GPU going on here."
    },
    {
      "index": 1159,
      "start_time": 2925520.0,
      "end_time": 2928404.0,
      "text": "So I&#39;ve kind of left that out to keep the code clean."
    },
    {
      "index": 1160,
      "start_time": 2928410.0,
      "end_time": 2930421.0,
      "text": "But you saw at the beginning examples"
    },
    {
      "index": 1161,
      "start_time": 2930420.0,
      "end_time": 2932147.0,
      "text": "it was pretty easy to flop all these things"
    },
    {
      "index": 1162,
      "start_time": 2932150.0,
      "end_time": 2934610.0,
      "text": "between CPU and GPU and there was either some global flag"
    },
    {
      "index": 1163,
      "start_time": 2934610.0,
      "end_time": 2936372.0,
      "text": "or some different data type"
    },
    {
      "index": 1164,
      "start_time": 2936370.0,
      "end_time": 2939450.0,
      "text": "or some with statement and it&#39;s usually relatively simple"
    },
    {
      "index": 1165,
      "start_time": 2939450.0,
      "end_time": 2941636.0,
      "text": "and just about one line to swap in each case."
    },
    {
      "index": 1166,
      "start_time": 2941640.0,
      "end_time": 2943354.0,
      "text": "But exactly what that line looks like"
    },
    {
      "index": 1167,
      "start_time": 2943350.0,
      "end_time": 2946150.0,
      "text": "differs a bit depending on the situation."
    },
    {
      "index": 1168,
      "start_time": 2946150.0,
      "end_time": 2949456.0,
      "text": "So there&#39;s actually like this whole large set"
    },
    {
      "index": 1169,
      "start_time": 2949460.0,
      "end_time": 2952531.0,
      "text": "of higher level TensorFlow wrappers that you might see"
    },
    {
      "index": 1170,
      "start_time": 2952530.0,
      "end_time": 2954189.0,
      "text": "out there in the wild."
    },
    {
      "index": 1171,
      "start_time": 2954190.0,
      "end_time": 2957113.0,
      "text": "And it seems that like even people within Google"
    },
    {
      "index": 1172,
      "start_time": 2957110.0,
      "end_time": 2961277.0,
      "text": "can&#39;t really agree on which one is the right one to use."
    },
    {
      "index": 1173,
      "start_time": 2962230.0,
      "end_time": 2964690.0,
      "text": "So Keras and TFLearn are third party libraries"
    },
    {
      "index": 1174,
      "start_time": 2964690.0,
      "end_time": 2966829.0,
      "text": "that are out there on the internet by other people."
    },
    {
      "index": 1175,
      "start_time": 2966830.0,
      "end_time": 2969769.0,
      "text": "But there&#39;s these three different ones,"
    },
    {
      "index": 1176,
      "start_time": 2969770.0,
      "end_time": 2972565.0,
      "text": "tf.layers, TF-Slim and tf.contrib.learn"
    },
    {
      "index": 1177,
      "start_time": 2972560.0,
      "end_time": 2975352.0,
      "text": "that all ship with TensorFlow, that are all kind of"
    },
    {
      "index": 1178,
      "start_time": 2975350.0,
      "end_time": 2977885.0,
      "text": "doing a slightly different version of this"
    },
    {
      "index": 1179,
      "start_time": 2977890.0,
      "end_time": 2979727.0,
      "text": "higher level wrapper thing."
    },
    {
      "index": 1180,
      "start_time": 2979730.0,
      "end_time": 2981768.0,
      "text": "There&#39;s another framework also from Google,"
    },
    {
      "index": 1181,
      "start_time": 2981760.0,
      "end_time": 2984104.0,
      "text": "but not shipping with TensorFlow called Pretty Tensor"
    },
    {
      "index": 1182,
      "start_time": 2984110.0,
      "end_time": 2986291.0,
      "text": "that does the same sort of thing."
    },
    {
      "index": 1183,
      "start_time": 2986290.0,
      "end_time": 2988598.0,
      "text": "And I guess none of these were good enough for DeepMind,"
    },
    {
      "index": 1184,
      "start_time": 2988600.0,
      "end_time": 2990270.0,
      "text": "because they went ahead a couple weeks ago"
    },
    {
      "index": 1185,
      "start_time": 2990270.0,
      "end_time": 2992489.0,
      "text": "and wrote and released their very own high level"
    },
    {
      "index": 1186,
      "start_time": 2992490.0,
      "end_time": 2994531.0,
      "text": "TensorFlow wrapper called Sonnet."
    },
    {
      "index": 1187,
      "start_time": 2994530.0,
      "end_time": 2997570.0,
      "text": "So I wouldn&#39;t begrudge you if you were kind of confused"
    },
    {
      "index": 1188,
      "start_time": 2997570.0,
      "end_time": 2999506.0,
      "text": "by all these things."
    },
    {
      "index": 1189,
      "start_time": 2999510.0,
      "end_time": 3000718.0,
      "text": "There&#39;s a lot of different choices."
    },
    {
      "index": 1190,
      "start_time": 3000720.0,
      "end_time": 3003118.0,
      "text": "They don&#39;t always play nicely with each other."
    },
    {
      "index": 1191,
      "start_time": 3003110.0,
      "end_time": 3007420.0,
      "text": "But you have a lot of options, so that&#39;s good."
    },
    {
      "index": 1192,
      "start_time": 3007420.0,
      "end_time": 3009119.0,
      "text": "TensorFlow has pretrained models."
    },
    {
      "index": 1193,
      "start_time": 3009120.0,
      "end_time": 3011109.0,
      "text": "There&#39;s some examples in TF-Slim, and in Keras."
    },
    {
      "index": 1194,
      "start_time": 3011110.0,
      "end_time": 3014718.0,
      "text": "&#39;Cause remember retrained models are super important"
    },
    {
      "index": 1195,
      "start_time": 3014720.0,
      "end_time": 3015874.0,
      "text": "when you&#39;re training your own things."
    },
    {
      "index": 1196,
      "start_time": 3015870.0,
      "end_time": 3017926.0,
      "text": "There&#39;s also this idea of Tensorboard"
    },
    {
      "index": 1197,
      "start_time": 3017930.0,
      "end_time": 3019633.0,
      "text": "where you can load up your,"
    },
    {
      "index": 1198,
      "start_time": 3019630.0,
      "end_time": 3021716.0,
      "text": "I don&#39;t want to get into details,"
    },
    {
      "index": 1199,
      "start_time": 3021720.0,
      "end_time": 3022834.0,
      "text": "but Tensorboard you can add sort of instrumentation"
    },
    {
      "index": 1200,
      "start_time": 3022830.0,
      "end_time": 3024728.0,
      "text": "to your code and then plot losses and things"
    },
    {
      "index": 1201,
      "start_time": 3024730.0,
      "end_time": 3027744.0,
      "text": "as you go through the training process."
    },
    {
      "index": 1202,
      "start_time": 3027750.0,
      "end_time": 3029538.0,
      "text": "TensorFlow also let&#39;s you run distributed"
    },
    {
      "index": 1203,
      "start_time": 3029530.0,
      "end_time": 3031367.0,
      "text": "where you can break up a computational graph"
    },
    {
      "index": 1204,
      "start_time": 3031370.0,
      "end_time": 3032757.0,
      "text": "run on different machines."
    },
    {
      "index": 1205,
      "start_time": 3032760.0,
      "end_time": 3035222.0,
      "text": "That&#39;s super cool but I think probably not anyone"
    },
    {
      "index": 1206,
      "start_time": 3035220.0,
      "end_time": 3037611.0,
      "text": "outside of Google is really using that to great success"
    },
    {
      "index": 1207,
      "start_time": 3037610.0,
      "end_time": 3040729.0,
      "text": "these days, but if you do want to run distributed stuff"
    },
    {
      "index": 1208,
      "start_time": 3040730.0,
      "end_time": 3044190.0,
      "text": "probably TensorFlow is the main game in town for that."
    },
    {
      "index": 1209,
      "start_time": 3044190.0,
      "end_time": 3046831.0,
      "text": "A side note is that a lot of the design of TensorFlow"
    },
    {
      "index": 1210,
      "start_time": 3046830.0,
      "end_time": 3049987.0,
      "text": "is kind of spiritually inspired by this earlier framework"
    },
    {
      "index": 1211,
      "start_time": 3049990.0,
      "end_time": 3051531.0,
      "text": "called Theano from Montreal."
    },
    {
      "index": 1212,
      "start_time": 3051530.0,
      "end_time": 3054797.0,
      "text": "I don&#39;t want to go through the details here,"
    },
    {
      "index": 1213,
      "start_time": 3054800.0,
      "end_time": 3055933.0,
      "text": "just if you go through these slides on your own,"
    },
    {
      "index": 1214,
      "start_time": 3055930.0,
      "end_time": 3058124.0,
      "text": "you can see that the code for Theano ends up looking"
    },
    {
      "index": 1215,
      "start_time": 3058130.0,
      "end_time": 3059982.0,
      "text": "very similar to TensorFlow."
    },
    {
      "index": 1216,
      "start_time": 3059980.0,
      "end_time": 3061420.0,
      "text": "Where we define some variables,"
    },
    {
      "index": 1217,
      "start_time": 3061420.0,
      "end_time": 3063512.0,
      "text": "we do some forward pass, we compute some gradients,"
    },
    {
      "index": 1218,
      "start_time": 3063510.0,
      "end_time": 3065976.0,
      "text": "and we compile some function, then we run the function"
    },
    {
      "index": 1219,
      "start_time": 3065980.0,
      "end_time": 3068342.0,
      "text": "over and over to train the network."
    },
    {
      "index": 1220,
      "start_time": 3068340.0,
      "end_time": 3070290.0,
      "text": "So it kind of looks a lot like TensorFlow."
    },
    {
      "index": 1221,
      "start_time": 3070290.0,
      "end_time": 3073900.0,
      "text": "So we still have a lot to get through,"
    },
    {
      "index": 1222,
      "start_time": 3073100.0,
      "end_time": 3074462.0,
      "text": "so I&#39;m going to move on to PyTorch"
    },
    {
      "index": 1223,
      "start_time": 3074460.0,
      "end_time": 3076669.0,
      "text": "and maybe take questions at the end."
    },
    {
      "index": 1224,
      "start_time": 3076670.0,
      "end_time": 3080769.0,
      "text": "So, PyTorch from Facebook is kind of different from"
    },
    {
      "index": 1225,
      "start_time": 3080770.0,
      "end_time": 3082868.0,
      "text": "TensorFlow in that we have sort of three explicit"
    },
    {
      "index": 1226,
      "start_time": 3082870.0,
      "end_time": 3086399.0,
      "text": "different layers of abstraction inside PyTorch."
    },
    {
      "index": 1227,
      "start_time": 3086400.0,
      "end_time": 3089418.0,
      "text": "So PyTorch has this tensor object which is just like a"
    },
    {
      "index": 1228,
      "start_time": 3089420.0,
      "end_time": 3090624.0,
      "text": "Numpy array."
    },
    {
      "index": 1229,
      "start_time": 3090620.0,
      "end_time": 3093604.0,
      "text": "It&#39;s just an imperative array, it doesn&#39;t know anything"
    },
    {
      "index": 1230,
      "start_time": 3093600.0,
      "end_time": 3096767.0,
      "text": "about deep learning, but it can run with GPU."
    },
    {
      "index": 1231,
      "start_time": 3096770.0,
      "end_time": 3098676.0,
      "text": "We have this variable object which is a node in a"
    },
    {
      "index": 1232,
      "start_time": 3098680.0,
      "end_time": 3102278.0,
      "text": "computational graph which builds up computational graphs,"
    },
    {
      "index": 1233,
      "start_time": 3102270.0,
      "end_time": 3104926.0,
      "text": "lets you compute gradients, that sort of thing."
    },
    {
      "index": 1234,
      "start_time": 3104930.0,
      "end_time": 3106312.0,
      "text": "And we have a module object which is a neural network"
    },
    {
      "index": 1235,
      "start_time": 3106310.0,
      "end_time": 3108571.0,
      "text": "layer that you can compose together these modules"
    },
    {
      "index": 1236,
      "start_time": 3108570.0,
      "end_time": 3110763.0,
      "text": "to build big networks."
    },
    {
      "index": 1237,
      "start_time": 3110770.0,
      "end_time": 3112977.0,
      "text": "So if you kind of want to think about rough equivalents"
    },
    {
      "index": 1238,
      "start_time": 3112970.0,
      "end_time": 3115968.0,
      "text": "between PyTorch and TensorFlow you can think of the"
    },
    {
      "index": 1239,
      "start_time": 3115970.0,
      "end_time": 3118758.0,
      "text": "PyTorch tensor as fulfilling the same role"
    },
    {
      "index": 1240,
      "start_time": 3118760.0,
      "end_time": 3121458.0,
      "text": "as the Numpy array in TensorFlow."
    },
    {
      "index": 1241,
      "start_time": 3121460.0,
      "end_time": 3124605.0,
      "text": "The PyTorch variable is similar to the TensorFlow tensor"
    },
    {
      "index": 1242,
      "start_time": 3124600.0,
      "end_time": 3127547.0,
      "text": "or variable or placeholder, which are all sort of nodes"
    },
    {
      "index": 1243,
      "start_time": 3127550.0,
      "end_time": 3128804.0,
      "text": "in a computational graph."
    },
    {
      "index": 1244,
      "start_time": 3128800.0,
      "end_time": 3131967.0,
      "text": "And now the PyTorch module is kind of equivalent"
    },
    {
      "index": 1245,
      "start_time": 3131970.0,
      "end_time": 3136288.0,
      "text": "to these higher level things from tf.slim or tf.layers"
    },
    {
      "index": 1246,
      "start_time": 3136290.0,
      "end_time": 3138450.0,
      "text": "or sonnet or these other higher level frameworks."
    },
    {
      "index": 1247,
      "start_time": 3138450.0,
      "end_time": 3141104.0,
      "text": "So right away one thing to notice about PyTorch"
    },
    {
      "index": 1248,
      "start_time": 3141100.0,
      "end_time": 3144708.0,
      "text": "is that because it ships with this high level abstraction"
    },
    {
      "index": 1249,
      "start_time": 3144720.0,
      "end_time": 3146696.0,
      "text": "and like one really nice higher level abstraction"
    },
    {
      "index": 1250,
      "start_time": 3146700.0,
      "end_time": 3148951.0,
      "text": "called modules on its own, there&#39;s sort of less choice"
    },
    {
      "index": 1251,
      "start_time": 3148950.0,
      "end_time": 3149783.0,
      "text": "involved."
    },
    {
      "index": 1252,
      "start_time": 3149780.0,
      "end_time": 3152534.0,
      "text": "Just stick with nnmodules and you&#39;ll be good to go."
    },
    {
      "index": 1253,
      "start_time": 3152530.0,
      "end_time": 3155805.0,
      "text": "You don&#39;t need to worry about which higher level wrapper"
    },
    {
      "index": 1254,
      "start_time": 3155810.0,
      "end_time": 3156643.0,
      "text": "to use."
    },
    {
      "index": 1255,
      "start_time": 3157780.0,
      "end_time": 3161947.0,
      "text": "So PyTorch tensors, as I said, are just like Numpy arrays"
    },
    {
      "index": 1256,
      "start_time": 3163660.0,
      "end_time": 3166181.0,
      "text": "so here on the right we&#39;ve done an entire two layer network"
    },
    {
      "index": 1257,
      "start_time": 3166180.0,
      "end_time": 3167786.0,
      "text": "using entirely PyTorch tensors."
    },
    {
      "index": 1258,
      "start_time": 3167790.0,
      "end_time": 3170282.0,
      "text": "One thing to note is that we&#39;re not importing Numpy here"
    },
    {
      "index": 1259,
      "start_time": 3170280.0,
      "end_time": 3171380.0,
      "text": "at all anymore."
    },
    {
      "index": 1260,
      "start_time": 3171380.0,
      "end_time": 3173911.0,
      "text": "We&#39;re just doing all these operations using PyTorch tensors."
    },
    {
      "index": 1261,
      "start_time": 3173910.0,
      "end_time": 3178624.0,
      "text": "And this code looks exactly like the two layer net code"
    },
    {
      "index": 1262,
      "start_time": 3178620.0,
      "end_time": 3181241.0,
      "text": "that you wrote in Numpy on the first homework."
    },
    {
      "index": 1263,
      "start_time": 3181250.0,
      "end_time": 3185779.0,
      "text": "So you set up some random data, you use some operations"
    },
    {
      "index": 1264,
      "start_time": 3185770.0,
      "end_time": 3187123.0,
      "text": "to compute the forward pass."
    },
    {
      "index": 1265,
      "start_time": 3187130.0,
      "end_time": 3189335.0,
      "text": "And then we&#39;re explicitly viewing the backward pass"
    },
    {
      "index": 1266,
      "start_time": 3189330.0,
      "end_time": 3190163.0,
      "text": "ourself."
    },
    {
      "index": 1267,
      "start_time": 3190170.0,
      "end_time": 3192799.0,
      "text": "Just sort of backhopping through the network,"
    },
    {
      "index": 1268,
      "start_time": 3192790.0,
      "end_time": 3195976.0,
      "text": "through the operations, just as you did on homework one."
    },
    {
      "index": 1269,
      "start_time": 3195980.0,
      "end_time": 3198241.0,
      "text": "And now we&#39;re doing a manual update of the weights"
    },
    {
      "index": 1270,
      "start_time": 3198240.0,
      "end_time": 3202671.0,
      "text": "using a learning rate and using our computed gradients."
    },
    {
      "index": 1271,
      "start_time": 3202670.0,
      "end_time": 3204679.0,
      "text": "But the major difference between the PyTorch tensor"
    },
    {
      "index": 1272,
      "start_time": 3204680.0,
      "end_time": 3207784.0,
      "text": "and Numpy arrays is that they run on GPU"
    },
    {
      "index": 1273,
      "start_time": 3207780.0,
      "end_time": 3210646.0,
      "text": "so all you have to do to make this code run on"
    },
    {
      "index": 1274,
      "start_time": 3210650.0,
      "end_time": 3213329.0,
      "text": "GPU is use a different data type."
    },
    {
      "index": 1275,
      "start_time": 3213340.0,
      "end_time": 3215920.0,
      "text": "Rather than using torch.FloatTensor,"
    },
    {
      "index": 1276,
      "start_time": 3215920.0,
      "end_time": 3219259.0,
      "text": "you do torch.cuda.FloatTensor, cast all of your tensors"
    },
    {
      "index": 1277,
      "start_time": 3220150.0,
      "end_time": 3222172.0,
      "text": "to this new datatype and everything runs magically"
    },
    {
      "index": 1278,
      "start_time": 3222170.0,
      "end_time": 3223705.0,
      "text": "on the GPU."
    },
    {
      "index": 1279,
      "start_time": 3223710.0,
      "end_time": 3227637.0,
      "text": "You should think of PyTorch tensors as just Numpy plus GPU."
    },
    {
      "index": 1280,
      "start_time": 3227640.0,
      "end_time": 3229404.0,
      "text": "That&#39;s exactly what it is, nothing specific"
    },
    {
      "index": 1281,
      "start_time": 3229400.0,
      "end_time": 3230816.0,
      "text": "to deep learning."
    },
    {
      "index": 1282,
      "start_time": 3232640.0,
      "end_time": 3235280.0,
      "text": "So the next layer of abstraction in PyTorch is the variable."
    },
    {
      "index": 1283,
      "start_time": 3235280.0,
      "end_time": 3238441.0,
      "text": "So this is, once we moved from tensors to variables"
    },
    {
      "index": 1284,
      "start_time": 3238440.0,
      "end_time": 3240702.0,
      "text": "now we&#39;re building computational graphs"
    },
    {
      "index": 1285,
      "start_time": 3240700.0,
      "end_time": 3242192.0,
      "text": "and we&#39;re able to take gradients automatically"
    },
    {
      "index": 1286,
      "start_time": 3242190.0,
      "end_time": 3243456.0,
      "text": "and everything like that."
    },
    {
      "index": 1287,
      "start_time": 3243460.0,
      "end_time": 3247627.0,
      "text": "So here, if X is a variable, then x.data is a tensor"
    },
    {
      "index": 1288,
      "start_time": 3248890.0,
      "end_time": 3252163.0,
      "text": "and x.grad is another variable containing the gradients"
    },
    {
      "index": 1289,
      "start_time": 3252160.0,
      "end_time": 3254696.0,
      "text": "of the loss with respect to that tensor."
    },
    {
      "index": 1290,
      "start_time": 3254700.0,
      "end_time": 3255913.0,
      "text": "So x.grad.data is an actual tensor containing"
    },
    {
      "index": 1291,
      "start_time": 3255910.0,
      "end_time": 3257243.0,
      "text": "those gradients."
    },
    {
      "index": 1292,
      "start_time": 3258970.0,
      "end_time": 3262385.0,
      "text": "And PyTorch tensors and variables have the exact same API."
    },
    {
      "index": 1293,
      "start_time": 3262390.0,
      "end_time": 3265609.0,
      "text": "So any code that worked on PyTorch tensors you can just"
    },
    {
      "index": 1294,
      "start_time": 3265610.0,
      "end_time": 3268461.0,
      "text": "make them variables instead and run the same code,"
    },
    {
      "index": 1295,
      "start_time": 3268460.0,
      "end_time": 3270295.0,
      "text": "except now you&#39;re building up a computational graph"
    },
    {
      "index": 1296,
      "start_time": 3270290.0,
      "end_time": 3274457.0,
      "text": "rather than just doing these imperative operations."
    },
    {
      "index": 1297,
      "start_time": 3275940.0,
      "end_time": 3278550.0,
      "text": "So here when we create these variables"
    },
    {
      "index": 1298,
      "start_time": 3278550.0,
      "end_time": 3281231.0,
      "text": "each call to the variable constructor wraps a PyTorch"
    },
    {
      "index": 1299,
      "start_time": 3281230.0,
      "end_time": 3283648.0,
      "text": "tensor and then also gives a flag whether or not"
    },
    {
      "index": 1300,
      "start_time": 3283650.0,
      "end_time": 3287459.0,
      "text": "we want to compute gradients with respect to this variable."
    },
    {
      "index": 1301,
      "start_time": 3287460.0,
      "end_time": 3289411.0,
      "text": "And now in the forward pass it looks exactly like"
    },
    {
      "index": 1302,
      "start_time": 3289410.0,
      "end_time": 3292108.0,
      "text": "it did before in the variable in the case with tensors"
    },
    {
      "index": 1303,
      "start_time": 3292120.0,
      "end_time": 3294730.0,
      "text": "because they have the same API."
    },
    {
      "index": 1304,
      "start_time": 3294730.0,
      "end_time": 3295667.0,
      "text": "So now we&#39;re computing our predictions,"
    },
    {
      "index": 1305,
      "start_time": 3295670.0,
      "end_time": 3298434.0,
      "text": "we&#39;re computing our loss in kind of this imperative"
    },
    {
      "index": 1306,
      "start_time": 3298430.0,
      "end_time": 3299682.0,
      "text": "kind of way."
    },
    {
      "index": 1307,
      "start_time": 3299680.0,
      "end_time": 3303489.0,
      "text": "And then we call loss.backwards and now all these gradients"
    },
    {
      "index": 1308,
      "start_time": 3303490.0,
      "end_time": 3305249.0,
      "text": "come out for us."
    },
    {
      "index": 1309,
      "start_time": 3305250.0,
      "end_time": 3306789.0,
      "text": "And then we can make a gradient update step"
    },
    {
      "index": 1310,
      "start_time": 3306790.0,
      "end_time": 3309214.0,
      "text": "on our weights using the gradients that are now present"
    },
    {
      "index": 1311,
      "start_time": 3309210.0,
      "end_time": 3311524.0,
      "text": "in the w1.grad.data."
    },
    {
      "index": 1312,
      "start_time": 3311530.0,
      "end_time": 3316229.0,
      "text": "So this ends up looking quite like the Numpy case,"
    },
    {
      "index": 1313,
      "start_time": 3316230.0,
      "end_time": 3318139.0,
      "text": "except all the gradients come for free."
    },
    {
      "index": 1314,
      "start_time": 3318140.0,
      "end_time": 3320599.0,
      "text": "One thing to note that&#39;s kind of different between"
    },
    {
      "index": 1315,
      "start_time": 3320600.0,
      "end_time": 3323357.0,
      "text": "PyTorch and TensorFlow is that in a TensorFlow case"
    },
    {
      "index": 1316,
      "start_time": 3323350.0,
      "end_time": 3325286.0,
      "text": "we were building up this explicit graph,"
    },
    {
      "index": 1317,
      "start_time": 3325290.0,
      "end_time": 3327133.0,
      "text": "then running the graph many times."
    },
    {
      "index": 1318,
      "start_time": 3327130.0,
      "end_time": 3330306.0,
      "text": "Here in PyTorch, instead we&#39;re building up a new graph"
    },
    {
      "index": 1319,
      "start_time": 3330310.0,
      "end_time": 3332154.0,
      "text": "every time we do a forward pass."
    },
    {
      "index": 1320,
      "start_time": 3332150.0,
      "end_time": 3333885.0,
      "text": "And this makes the code look a bit cleaner."
    },
    {
      "index": 1321,
      "start_time": 3333890.0,
      "end_time": 3335287.0,
      "text": "And it has some other implications that we&#39;ll"
    },
    {
      "index": 1322,
      "start_time": 3335280.0,
      "end_time": 3337576.0,
      "text": "get to in a bit."
    },
    {
      "index": 1323,
      "start_time": 3337580.0,
      "end_time": 3340630.0,
      "text": "So in PyTorch you can define your own new autograd functions"
    },
    {
      "index": 1324,
      "start_time": 3340630.0,
      "end_time": 3342933.0,
      "text": "by defining the forward and backward in terms of tensors."
    },
    {
      "index": 1325,
      "start_time": 3342930.0,
      "end_time": 3345951.0,
      "text": "This ends up looking kind of like the module layers"
    },
    {
      "index": 1326,
      "start_time": 3345950.0,
      "end_time": 3348299.0,
      "text": "code that you write for homework two."
    },
    {
      "index": 1327,
      "start_time": 3348300.0,
      "end_time": 3350401.0,
      "text": "Where you can implement forward and backward using"
    },
    {
      "index": 1328,
      "start_time": 3350400.0,
      "end_time": 3352672.0,
      "text": "tensor operations and then stick these things inside"
    },
    {
      "index": 1329,
      "start_time": 3352680.0,
      "end_time": 3354437.0,
      "text": "computational graph."
    },
    {
      "index": 1330,
      "start_time": 3354430.0,
      "end_time": 3356294.0,
      "text": "So here we&#39;re defining our own relu"
    },
    {
      "index": 1331,
      "start_time": 3356300.0,
      "end_time": 3360657.0,
      "text": "and then we can actually go in and use our own relu"
    },
    {
      "index": 1332,
      "start_time": 3360650.0,
      "end_time": 3362750.0,
      "text": "operation and now stick it inside our computational graph"
    },
    {
      "index": 1333,
      "start_time": 3362750.0,
      "end_time": 3365210.0,
      "text": "and define our own operations this way."
    },
    {
      "index": 1334,
      "start_time": 3365210.0,
      "end_time": 3366853.0,
      "text": "But most of the time you will probably not need"
    },
    {
      "index": 1335,
      "start_time": 3366860.0,
      "end_time": 3369963.0,
      "text": "to define your own autograd operations."
    },
    {
      "index": 1336,
      "start_time": 3369970.0,
      "end_time": 3370814.0,
      "text": "Most of the times the operations you need will"
    },
    {
      "index": 1337,
      "start_time": 3370810.0,
      "end_time": 3374241.0,
      "text": "mostly be already implemented for you."
    },
    {
      "index": 1338,
      "start_time": 3374250.0,
      "end_time": 3376297.0,
      "text": "So in TensorFlow we saw,"
    },
    {
      "index": 1339,
      "start_time": 3376290.0,
      "end_time": 3379537.0,
      "text": "if we can move to something like Keras or TF.Learn"
    },
    {
      "index": 1340,
      "start_time": 3379540.0,
      "end_time": 3381253.0,
      "text": "and this gives us a higher level API to work with,"
    },
    {
      "index": 1341,
      "start_time": 3381250.0,
      "end_time": 3383346.0,
      "text": "rather than this raw computational graphs."
    },
    {
      "index": 1342,
      "start_time": 3383350.0,
      "end_time": 3385434.0,
      "text": "The equivalent in PyTorch is the nn package."
    },
    {
      "index": 1343,
      "start_time": 3385430.0,
      "end_time": 3389445.0,
      "text": "Where it provides these high level wrappers for working"
    },
    {
      "index": 1344,
      "start_time": 3389450.0,
      "end_time": 3390950.0,
      "text": "with these things."
    },
    {
      "index": 1345,
      "start_time": 3391880.0,
      "end_time": 3393452.0,
      "text": "But unlike TensorFlow there&#39;s only one of them."
    },
    {
      "index": 1346,
      "start_time": 3393450.0,
      "end_time": 3395833.0,
      "text": "And it works pretty well, so just use that if you&#39;re"
    },
    {
      "index": 1347,
      "start_time": 3395840.0,
      "end_time": 3397775.0,
      "text": "using PyTorch."
    },
    {
      "index": 1348,
      "start_time": 3397770.0,
      "end_time": 3399372.0,
      "text": "So here, this ends up kind of looking like Keras"
    },
    {
      "index": 1349,
      "start_time": 3399370.0,
      "end_time": 3402192.0,
      "text": "where we define our model as some sequence of layers."
    },
    {
      "index": 1350,
      "start_time": 3402200.0,
      "end_time": 3404439.0,
      "text": "Our linear and relu operations."
    },
    {
      "index": 1351,
      "start_time": 3404440.0,
      "end_time": 3407578.0,
      "text": "And we use some loss function defined in the nn package"
    },
    {
      "index": 1352,
      "start_time": 3407570.0,
      "end_time": 3409812.0,
      "text": "that&#39;s our mean squared error loss."
    },
    {
      "index": 1353,
      "start_time": 3409820.0,
      "end_time": 3411597.0,
      "text": "And now inside each iteration of our loop"
    },
    {
      "index": 1354,
      "start_time": 3411590.0,
      "end_time": 3413713.0,
      "text": "we can run data forward through the model to get"
    },
    {
      "index": 1355,
      "start_time": 3413720.0,
      "end_time": 3415218.0,
      "text": "our predictions."
    },
    {
      "index": 1356,
      "start_time": 3415210.0,
      "end_time": 3417507.0,
      "text": "We can run the predictions forward through the loss function"
    },
    {
      "index": 1357,
      "start_time": 3417510.0,
      "end_time": 3419539.0,
      "text": "to get our scale or loss,"
    },
    {
      "index": 1358,
      "start_time": 3419540.0,
      "end_time": 3421177.0,
      "text": "then we can call loss.backward, get all our gradients"
    },
    {
      "index": 1359,
      "start_time": 3421180.0,
      "end_time": 3424213.0,
      "text": "for free and then loop over the parameters of the models"
    },
    {
      "index": 1360,
      "start_time": 3424210.0,
      "end_time": 3426143.0,
      "text": "and do our explicit gradient descent step to update"
    },
    {
      "index": 1361,
      "start_time": 3426140.0,
      "end_time": 3427270.0,
      "text": "the models."
    },
    {
      "index": 1362,
      "start_time": 3427270.0,
      "end_time": 3429537.0,
      "text": "And again we see that we&#39;re sort of building up this"
    },
    {
      "index": 1363,
      "start_time": 3429540.0,
      "end_time": 3432749.0,
      "text": "new computational graph every time we do a forward pass."
    },
    {
      "index": 1364,
      "start_time": 3432750.0,
      "end_time": 3434715.0,
      "text": "And just like we saw in TensorFlow,"
    },
    {
      "index": 1365,
      "start_time": 3434710.0,
      "end_time": 3437166.0,
      "text": "PyTorch provides these optimizer operations"
    },
    {
      "index": 1366,
      "start_time": 3437170.0,
      "end_time": 3439654.0,
      "text": "that kind of abstract away this updating logic"
    },
    {
      "index": 1367,
      "start_time": 3439660.0,
      "end_time": 3441763.0,
      "text": "and implement fancier update rules like Adam"
    },
    {
      "index": 1368,
      "start_time": 3441760.0,
      "end_time": 3443002.0,
      "text": "and whatnot."
    },
    {
      "index": 1369,
      "start_time": 3443000.0,
      "end_time": 3445380.0,
      "text": "So here we&#39;re constructing an optimizer object"
    },
    {
      "index": 1370,
      "start_time": 3445380.0,
      "end_time": 3447340.0,
      "text": "telling it that we want it to optimize over the"
    },
    {
      "index": 1371,
      "start_time": 3447340.0,
      "end_time": 3448771.0,
      "text": "parameters of the model."
    },
    {
      "index": 1372,
      "start_time": 3448770.0,
      "end_time": 3451114.0,
      "text": "Giving it some learning rate under the hyper parameters."
    },
    {
      "index": 1373,
      "start_time": 3451110.0,
      "end_time": 3453432.0,
      "text": "And now after we compute our gradients"
    },
    {
      "index": 1374,
      "start_time": 3453440.0,
      "end_time": 3455358.0,
      "text": "we can just call optimizer.step and it updates"
    },
    {
      "index": 1375,
      "start_time": 3455360.0,
      "end_time": 3459814.0,
      "text": "all the parameters of the model for us right here."
    },
    {
      "index": 1376,
      "start_time": 3459810.0,
      "end_time": 3461951.0,
      "text": "So another common thing you&#39;ll do in PyTorch"
    },
    {
      "index": 1377,
      "start_time": 3461950.0,
      "end_time": 3464713.0,
      "text": "a lot is define your own nn modules."
    },
    {
      "index": 1378,
      "start_time": 3464710.0,
      "end_time": 3467264.0,
      "text": "So typically you&#39;ll write your own class"
    },
    {
      "index": 1379,
      "start_time": 3467270.0,
      "end_time": 3469963.0,
      "text": "which defines you entire model as a single"
    },
    {
      "index": 1380,
      "start_time": 3469960.0,
      "end_time": 3471800.0,
      "text": "new nn module class."
    },
    {
      "index": 1381,
      "start_time": 3471800.0,
      "end_time": 3474978.0,
      "text": "And a module is just kind of a neural network layer"
    },
    {
      "index": 1382,
      "start_time": 3474980.0,
      "end_time": 3477679.0,
      "text": "that can contain either other other modules"
    },
    {
      "index": 1383,
      "start_time": 3477680.0,
      "end_time": 3481422.0,
      "text": "or trainable weights or other other kinds of state."
    },
    {
      "index": 1384,
      "start_time": 3481430.0,
      "end_time": 3484142.0,
      "text": "So in this case we can redo the two layer net example"
    },
    {
      "index": 1385,
      "start_time": 3484140.0,
      "end_time": 3487508.0,
      "text": "by defining our own nn module class."
    },
    {
      "index": 1386,
      "start_time": 3487510.0,
      "end_time": 3489924.0,
      "text": "So now here in the initializer of the class"
    },
    {
      "index": 1387,
      "start_time": 3489930.0,
      "end_time": 3491677.0,
      "text": "we&#39;re assigning this linear1 and linear2."
    },
    {
      "index": 1388,
      "start_time": 3491670.0,
      "end_time": 3493851.0,
      "text": "We&#39;re constructing these new module objects"
    },
    {
      "index": 1389,
      "start_time": 3493850.0,
      "end_time": 3497254.0,
      "text": "and then store them inside of our own class."
    },
    {
      "index": 1390,
      "start_time": 3497260.0,
      "end_time": 3500338.0,
      "text": "And now in the forward pass we can use both our own"
    },
    {
      "index": 1391,
      "start_time": 3500330.0,
      "end_time": 3502827.0,
      "text": "internal modules as well as arbitrary autograd operations"
    },
    {
      "index": 1392,
      "start_time": 3502830.0,
      "end_time": 3506464.0,
      "text": "on variables to compute the output of our network."
    },
    {
      "index": 1393,
      "start_time": 3506470.0,
      "end_time": 3509785.0,
      "text": "So here we receive the, inside this forward method here,"
    },
    {
      "index": 1394,
      "start_time": 3509780.0,
      "end_time": 3511592.0,
      "text": "the input acts as a variable,"
    },
    {
      "index": 1395,
      "start_time": 3511590.0,
      "end_time": 3514209.0,
      "text": "then we pass the variable to our self.linear1"
    },
    {
      "index": 1396,
      "start_time": 3514210.0,
      "end_time": 3515814.0,
      "text": "for the first layer."
    },
    {
      "index": 1397,
      "start_time": 3515820.0,
      "end_time": 3518132.0,
      "text": "We use an autograd op clamp to complete the relu,"
    },
    {
      "index": 1398,
      "start_time": 3518130.0,
      "end_time": 3520233.0,
      "text": "we pass the output of that to the second linear"
    },
    {
      "index": 1399,
      "start_time": 3520230.0,
      "end_time": 3522230.0,
      "text": "and then that gives us our output."
    },
    {
      "index": 1400,
      "start_time": 3522230.0,
      "end_time": 3524729.0,
      "text": "And now the rest of this code for training this thing"
    },
    {
      "index": 1401,
      "start_time": 3524730.0,
      "end_time": 3526631.0,
      "text": "looks pretty much the same."
    },
    {
      "index": 1402,
      "start_time": 3526630.0,
      "end_time": 3528452.0,
      "text": "Where we build an optimizer and loop over"
    },
    {
      "index": 1403,
      "start_time": 3528460.0,
      "end_time": 3530920.0,
      "text": "and on ever iteration feed data to the model,"
    },
    {
      "index": 1404,
      "start_time": 3530920.0,
      "end_time": 3532781.0,
      "text": "compute the gradients with loss.backwards,"
    },
    {
      "index": 1405,
      "start_time": 3532780.0,
      "end_time": 3534679.0,
      "text": "call optimizer.step."
    },
    {
      "index": 1406,
      "start_time": 3534680.0,
      "end_time": 3537928.0,
      "text": "So this is like relatively characteristic"
    },
    {
      "index": 1407,
      "start_time": 3537920.0,
      "end_time": 3540229.0,
      "text": "of what you might see in a lot of PyTorch type"
    },
    {
      "index": 1408,
      "start_time": 3540230.0,
      "end_time": 3541814.0,
      "text": "training scenarios."
    },
    {
      "index": 1409,
      "start_time": 3541820.0,
      "end_time": 3542967.0,
      "text": "Where you define your own class,"
    },
    {
      "index": 1410,
      "start_time": 3542960.0,
      "end_time": 3544928.0,
      "text": "defining your own model that contains other modules"
    },
    {
      "index": 1411,
      "start_time": 3544930.0,
      "end_time": 3547100.0,
      "text": "and whatnot and then you have some explicit training"
    },
    {
      "index": 1412,
      "start_time": 3547100.0,
      "end_time": 3551163.0,
      "text": "loop like this that runs it and updates it."
    },
    {
      "index": 1413,
      "start_time": 3551170.0,
      "end_time": 3553357.0,
      "text": "One kind of nice quality of life thing that you have"
    },
    {
      "index": 1414,
      "start_time": 3553350.0,
      "end_time": 3556567.0,
      "text": "in PyTorch is a dataloader."
    },
    {
      "index": 1415,
      "start_time": 3556570.0,
      "end_time": 3558872.0,
      "text": "So a dataloader can handle building minibatches for you."
    },
    {
      "index": 1416,
      "start_time": 3558870.0,
      "end_time": 3561270.0,
      "text": "It can handle some of the multi-threading that we talked"
    },
    {
      "index": 1417,
      "start_time": 3561270.0,
      "end_time": 3563873.0,
      "text": "about for you, where it can actually use multiple threads"
    },
    {
      "index": 1418,
      "start_time": 3563880.0,
      "end_time": 3565938.0,
      "text": "in the background to build many batches for you"
    },
    {
      "index": 1419,
      "start_time": 3565930.0,
      "end_time": 3567269.0,
      "text": "and stream off disk."
    },
    {
      "index": 1420,
      "start_time": 3567270.0,
      "end_time": 3570774.0,
      "text": "So here a dataloader wraps a dataset and provides"
    },
    {
      "index": 1421,
      "start_time": 3570780.0,
      "end_time": 3573224.0,
      "text": "some of these abstractions for you."
    },
    {
      "index": 1422,
      "start_time": 3573220.0,
      "end_time": 3575561.0,
      "text": "And in practice when you want to run your own data,"
    },
    {
      "index": 1423,
      "start_time": 3575560.0,
      "end_time": 3578136.0,
      "text": "you typically will write your own dataset class"
    },
    {
      "index": 1424,
      "start_time": 3578140.0,
      "end_time": 3580210.0,
      "text": "which knows how to read your particular type of data"
    },
    {
      "index": 1425,
      "start_time": 3580210.0,
      "end_time": 3582253.0,
      "text": "off whatever source you want and then wrap it in"
    },
    {
      "index": 1426,
      "start_time": 3582250.0,
      "end_time": 3584457.0,
      "text": "a data loader and train with that."
    },
    {
      "index": 1427,
      "start_time": 3584460.0,
      "end_time": 3587633.0,
      "text": "So, here we can see that now we&#39;re iterating over"
    },
    {
      "index": 1428,
      "start_time": 3587630.0,
      "end_time": 3590443.0,
      "text": "the dataloader object and at every iteration"
    },
    {
      "index": 1429,
      "start_time": 3590440.0,
      "end_time": 3592229.0,
      "text": "this is yielding minibatches of data."
    },
    {
      "index": 1430,
      "start_time": 3592230.0,
      "end_time": 3595524.0,
      "text": "And it&#39;s internally handling the shuffling of the data"
    },
    {
      "index": 1431,
      "start_time": 3595530.0,
      "end_time": 3597579.0,
      "text": "and multithreaded dataloading and all this sort of stuff"
    },
    {
      "index": 1432,
      "start_time": 3597580.0,
      "end_time": 3598413.0,
      "text": "for you."
    },
    {
      "index": 1433,
      "start_time": 3598410.0,
      "end_time": 3600655.0,
      "text": "So this is kind of a completely PyTorch example"
    },
    {
      "index": 1434,
      "start_time": 3600650.0,
      "end_time": 3602490.0,
      "text": "and a lot of PyTorch training code ends up looking"
    },
    {
      "index": 1435,
      "start_time": 3602490.0,
      "end_time": 3604157.0,
      "text": "something like this."
    },
    {
      "index": 1436,
      "start_time": 3605580.0,
      "end_time": 3607584.0,
      "text": "PyTorch provides pretrained models."
    },
    {
      "index": 1437,
      "start_time": 3607590.0,
      "end_time": 3609472.0,
      "text": "And this is probably the slickest pretrained model"
    },
    {
      "index": 1438,
      "start_time": 3609470.0,
      "end_time": 3611522.0,
      "text": "experience I&#39;ve ever seen."
    },
    {
      "index": 1439,
      "start_time": 3611520.0,
      "end_time": 3614267.0,
      "text": "You just say torchvision.models.alexnet pretained=true."
    },
    {
      "index": 1440,
      "start_time": 3614270.0,
      "end_time": 3616953.0,
      "text": "That&#39;ll go down in the background, download the pretrained"
    },
    {
      "index": 1441,
      "start_time": 3616950.0,
      "end_time": 3618758.0,
      "text": "weights for you if you don&#39;t already have them,"
    },
    {
      "index": 1442,
      "start_time": 3618760.0,
      "end_time": 3621521.0,
      "text": "and then it&#39;s right there, you&#39;re good to go."
    },
    {
      "index": 1443,
      "start_time": 3621520.0,
      "end_time": 3624242.0,
      "text": "So this is super easy to use."
    },
    {
      "index": 1444,
      "start_time": 3624240.0,
      "end_time": 3627938.0,
      "text": "PyTorch also has, there&#39;s also a package called Visdom"
    },
    {
      "index": 1445,
      "start_time": 3627940.0,
      "end_time": 3630253.0,
      "text": "that lets you visualize some of these loss statistics"
    },
    {
      "index": 1446,
      "start_time": 3630250.0,
      "end_time": 3633597.0,
      "text": "somewhat similar to Tensorboard."
    },
    {
      "index": 1447,
      "start_time": 3633600.0,
      "end_time": 3635168.0,
      "text": "So that&#39;s kind of nice, I haven&#39;t actually gotten"
    },
    {
      "index": 1448,
      "start_time": 3635170.0,
      "end_time": 3636936.0,
      "text": "a chance to play around with this myself so I can&#39;t really"
    },
    {
      "index": 1449,
      "start_time": 3636930.0,
      "end_time": 3638565.0,
      "text": "speak to how useful it is,"
    },
    {
      "index": 1450,
      "start_time": 3638570.0,
      "end_time": 3640928.0,
      "text": "but one of the major differences between Tensorboard"
    },
    {
      "index": 1451,
      "start_time": 3640930.0,
      "end_time": 3643772.0,
      "text": "and Visdom is that Tensorboard actually lets you visualize"
    },
    {
      "index": 1452,
      "start_time": 3643770.0,
      "end_time": 3645907.0,
      "text": "the structure of the computational graph."
    },
    {
      "index": 1453,
      "start_time": 3645910.0,
      "end_time": 3647987.0,
      "text": "Which is really cool, a really useful debugging strategy."
    },
    {
      "index": 1454,
      "start_time": 3647980.0,
      "end_time": 3650985.0,
      "text": "And Visdom does not have that functionality yet."
    },
    {
      "index": 1455,
      "start_time": 3650990.0,
      "end_time": 3653111.0,
      "text": "But I&#39;ve never really used this myself so I can&#39;t really"
    },
    {
      "index": 1456,
      "start_time": 3653110.0,
      "end_time": 3654761.0,
      "text": "speak to its utility."
    },
    {
      "index": 1457,
      "start_time": 3656350.0,
      "end_time": 3658627.0,
      "text": "As a bit of an aside, PyTorch is kind of an evolution of,"
    },
    {
      "index": 1458,
      "start_time": 3658630.0,
      "end_time": 3661750.0,
      "text": "kind of a newer updated version of an older framework"
    },
    {
      "index": 1459,
      "start_time": 3661750.0,
      "end_time": 3664863.0,
      "text": "called Torch which I worked with a lot in the last"
    },
    {
      "index": 1460,
      "start_time": 3664860.0,
      "end_time": 3665491.0,
      "text": "couple of years."
    },
    {
      "index": 1461,
      "start_time": 3665490.0,
      "end_time": 3667576.0,
      "text": "And I don&#39;t want to go through the details here,"
    },
    {
      "index": 1462,
      "start_time": 3667580.0,
      "end_time": 3670572.0,
      "text": "but PyTorch is pretty much better in a lot of ways"
    },
    {
      "index": 1463,
      "start_time": 3670570.0,
      "end_time": 3673280.0,
      "text": "than the old Lua Torch, but they actually share a lot"
    },
    {
      "index": 1464,
      "start_time": 3673280.0,
      "end_time": 3675657.0,
      "text": "of the same back end C code for computing with tensors"
    },
    {
      "index": 1465,
      "start_time": 3675660.0,
      "end_time": 3678103.0,
      "text": "and GPU operations on tensors and whatnot."
    },
    {
      "index": 1466,
      "start_time": 3678100.0,
      "end_time": 3679554.0,
      "text": "So if you look through this Torch example,"
    },
    {
      "index": 1467,
      "start_time": 3679550.0,
      "end_time": 3681902.0,
      "text": "some of it ends up looking kind of similar to PyTorch,"
    },
    {
      "index": 1468,
      "start_time": 3681910.0,
      "end_time": 3683373.0,
      "text": "some of it&#39;s a bit different."
    },
    {
      "index": 1469,
      "start_time": 3683370.0,
      "end_time": 3685958.0,
      "text": "Maybe you can step through this offline."
    },
    {
      "index": 1470,
      "start_time": 3685960.0,
      "end_time": 3688364.0,
      "text": "But kind of the high level differences between"
    },
    {
      "index": 1471,
      "start_time": 3688360.0,
      "end_time": 3691228.0,
      "text": "Torch and PyTorch are that Torch is actually in Lua,"
    },
    {
      "index": 1472,
      "start_time": 3691230.0,
      "end_time": 3693111.0,
      "text": "not Python, unlike these other things."
    },
    {
      "index": 1473,
      "start_time": 3693110.0,
      "end_time": 3697748.0,
      "text": "So learning Lua is a bit of a turn off for some people."
    },
    {
      "index": 1474,
      "start_time": 3697750.0,
      "end_time": 3700902.0,
      "text": "Torch doesn&#39;t have autograd."
    },
    {
      "index": 1475,
      "start_time": 3700900.0,
      "end_time": 3701710.0,
      "text": "Torch is also older, so it&#39;s more stable,"
    },
    {
      "index": 1476,
      "start_time": 3701710.0,
      "end_time": 3703491.0,
      "text": "less susceptible to bugs, there&#39;s maybe more example code"
    },
    {
      "index": 1477,
      "start_time": 3703490.0,
      "end_time": 3704323.0,
      "text": "for Torch."
    },
    {
      "index": 1478,
      "start_time": 3705230.0,
      "end_time": 3707214.0,
      "text": "They&#39;re about the same speeds, that&#39;s not really a concern."
    },
    {
      "index": 1479,
      "start_time": 3707210.0,
      "end_time": 3709823.0,
      "text": "But in PyTorch it&#39;s in Python which is great,"
    },
    {
      "index": 1480,
      "start_time": 3709830.0,
      "end_time": 3712273.0,
      "text": "you&#39;ve got autograd which makes it a lot simpler"
    },
    {
      "index": 1481,
      "start_time": 3712270.0,
      "end_time": 3714531.0,
      "text": "to write complex models."
    },
    {
      "index": 1482,
      "start_time": 3714530.0,
      "end_time": 3716421.0,
      "text": "In Lua Torch you end up writing a lot of your own"
    },
    {
      "index": 1483,
      "start_time": 3716420.0,
      "end_time": 3719668.0,
      "text": "back prop code sometimes, so that&#39;s a little bit annoying."
    },
    {
      "index": 1484,
      "start_time": 3719670.0,
      "end_time": 3721650.0,
      "text": "But PyTorch is newer, there&#39;s less existing code,"
    },
    {
      "index": 1485,
      "start_time": 3721650.0,
      "end_time": 3723689.0,
      "text": "it&#39;s still subject to change."
    },
    {
      "index": 1486,
      "start_time": 3723690.0,
      "end_time": 3726511.0,
      "text": "So it&#39;s a little bit more of an adventure."
    },
    {
      "index": 1487,
      "start_time": 3726510.0,
      "end_time": 3728145.0,
      "text": "But at least for me, I kind of prefer,"
    },
    {
      "index": 1488,
      "start_time": 3728150.0,
      "end_time": 3730167.0,
      "text": "I don&#39;t really see much reason for myself"
    },
    {
      "index": 1489,
      "start_time": 3730160.0,
      "end_time": 3733225.0,
      "text": "to use Torch over PyTorch anymore at this time."
    },
    {
      "index": 1490,
      "start_time": 3733230.0,
      "end_time": 3735850.0,
      "text": "So I&#39;m pretty much using PyTorch exclusively for"
    },
    {
      "index": 1491,
      "start_time": 3735850.0,
      "end_time": 3737767.0,
      "text": "all my work these days."
    },
    {
      "index": 1492,
      "start_time": 3738610.0,
      "end_time": 3740561.0,
      "text": "We talked about this a little bit about this idea"
    },
    {
      "index": 1493,
      "start_time": 3740560.0,
      "end_time": 3742534.0,
      "text": "of static versus dynamic graphs."
    },
    {
      "index": 1494,
      "start_time": 3742530.0,
      "end_time": 3744349.0,
      "text": "And this is one of the main distinguishing features"
    },
    {
      "index": 1495,
      "start_time": 3744350.0,
      "end_time": 3746290.0,
      "text": "between PyTorch and TensorFlow."
    },
    {
      "index": 1496,
      "start_time": 3746290.0,
      "end_time": 3749415.0,
      "text": "So we saw in TensorFlow you have these two stages"
    },
    {
      "index": 1497,
      "start_time": 3749420.0,
      "end_time": 3751671.0,
      "text": "of operation where first you build up this"
    },
    {
      "index": 1498,
      "start_time": 3751670.0,
      "end_time": 3754374.0,
      "text": "computational graph, then you run the computational graph"
    },
    {
      "index": 1499,
      "start_time": 3754370.0,
      "end_time": 3757245.0,
      "text": "over and over again many many times reusing that same"
    },
    {
      "index": 1500,
      "start_time": 3757250.0,
      "end_time": 3758149.0,
      "text": "graph."
    },
    {
      "index": 1501,
      "start_time": 3758150.0,
      "end_time": 3760214.0,
      "text": "That&#39;s called a static computational graph &#39;cause there&#39;s"
    },
    {
      "index": 1502,
      "start_time": 3760210.0,
      "end_time": 3762404.0,
      "text": "only one of them."
    },
    {
      "index": 1503,
      "start_time": 3762400.0,
      "end_time": 3764936.0,
      "text": "And we saw PyTorch is quite different where we&#39;re actually"
    },
    {
      "index": 1504,
      "start_time": 3764940.0,
      "end_time": 3766829.0,
      "text": "building up this new computational graph,"
    },
    {
      "index": 1505,
      "start_time": 3766830.0,
      "end_time": 3768772.0,
      "text": "this new fresh thing on every forward pass."
    },
    {
      "index": 1506,
      "start_time": 3768770.0,
      "end_time": 3772258.0,
      "text": "That&#39;s called a dynamic computational graph."
    },
    {
      "index": 1507,
      "start_time": 3772260.0,
      "end_time": 3774751.0,
      "text": "For kind of simple cases, with kind of feed forward"
    },
    {
      "index": 1508,
      "start_time": 3774750.0,
      "end_time": 3777530.0,
      "text": "neural networks, it doesn&#39;t really make a huge difference,"
    },
    {
      "index": 1509,
      "start_time": 3777530.0,
      "end_time": 3778467.0,
      "text": "the code ends up kind of similarly"
    },
    {
      "index": 1510,
      "start_time": 3778470.0,
      "end_time": 3780228.0,
      "text": "and they work kind of similarly,"
    },
    {
      "index": 1511,
      "start_time": 3780230.0,
      "end_time": 3782785.0,
      "text": "but I do want to talk a bit about some of the implications"
    },
    {
      "index": 1512,
      "start_time": 3782790.0,
      "end_time": 3784227.0,
      "text": "of static versus dynamic."
    },
    {
      "index": 1513,
      "start_time": 3784230.0,
      "end_time": 3787105.0,
      "text": "And what are the tradeoffs of those two."
    },
    {
      "index": 1514,
      "start_time": 3787100.0,
      "end_time": 3788944.0,
      "text": "So one kind of nice idea with static graphs"
    },
    {
      "index": 1515,
      "start_time": 3788950.0,
      "end_time": 3791334.0,
      "text": "is that because we&#39;re kind of building up one"
    },
    {
      "index": 1516,
      "start_time": 3791330.0,
      "end_time": 3795285.0,
      "text": "computational graph once, and then reusing it many times,"
    },
    {
      "index": 1517,
      "start_time": 3795290.0,
      "end_time": 3797359.0,
      "text": "the framework might have the opportunity to go in"
    },
    {
      "index": 1518,
      "start_time": 3797350.0,
      "end_time": 3799566.0,
      "text": "and do optimizations on that graph."
    },
    {
      "index": 1519,
      "start_time": 3799570.0,
      "end_time": 3802820.0,
      "text": "And kind of fuse some operations, reorder some operations,"
    },
    {
      "index": 1520,
      "start_time": 3802820.0,
      "end_time": 3804519.0,
      "text": "figure out the most efficient way to operate"
    },
    {
      "index": 1521,
      "start_time": 3804520.0,
      "end_time": 3806809.0,
      "text": "that graph so it can be really efficient."
    },
    {
      "index": 1522,
      "start_time": 3806810.0,
      "end_time": 3808726.0,
      "text": "And because we&#39;re going to reuse that graph"
    },
    {
      "index": 1523,
      "start_time": 3808730.0,
      "end_time": 3811795.0,
      "text": "many times, maybe that optimization process"
    },
    {
      "index": 1524,
      "start_time": 3811790.0,
      "end_time": 3813380.0,
      "text": "is expensive up front,"
    },
    {
      "index": 1525,
      "start_time": 3813390.0,
      "end_time": 3814947.0,
      "text": "but we can amortize that cost with the speedups"
    },
    {
      "index": 1526,
      "start_time": 3814950.0,
      "end_time": 3817233.0,
      "text": "that we&#39;ve gotten when we run the graph many many times."
    },
    {
      "index": 1527,
      "start_time": 3817230.0,
      "end_time": 3820162.0,
      "text": "So as kind of a concrete example,"
    },
    {
      "index": 1528,
      "start_time": 3820160.0,
      "end_time": 3821812.0,
      "text": "maybe if you write some graph which has convolution"
    },
    {
      "index": 1529,
      "start_time": 3821810.0,
      "end_time": 3824846.0,
      "text": "and relu operations kind of one after another,"
    },
    {
      "index": 1530,
      "start_time": 3824850.0,
      "end_time": 3828250.0,
      "text": "you might imagine that some fancy graph optimizer"
    },
    {
      "index": 1531,
      "start_time": 3828250.0,
      "end_time": 3831865.0,
      "text": "could go in and actually output, like emit custom code"
    },
    {
      "index": 1532,
      "start_time": 3831860.0,
      "end_time": 3834524.0,
      "text": "which has fused operations, fusing the convolution"
    },
    {
      "index": 1533,
      "start_time": 3834530.0,
      "end_time": 3836371.0,
      "text": "and the relu so now it&#39;s computing the same thing"
    },
    {
      "index": 1534,
      "start_time": 3836370.0,
      "end_time": 3840524.0,
      "text": "as the code you wrote, but now might be able to be"
    },
    {
      "index": 1535,
      "start_time": 3840520.0,
      "end_time": 3843440.0,
      "text": "executed more efficiently."
    },
    {
      "index": 1536,
      "start_time": 3843450.0,
      "end_time": 3847914.0,
      "text": "So I&#39;m not too sure on exactly what the state in practice"
    },
    {
      "index": 1537,
      "start_time": 3847910.0,
      "end_time": 3850420.0,
      "text": "of TensorFlow graph optimization is right now,"
    },
    {
      "index": 1538,
      "start_time": 3850420.0,
      "end_time": 3854470.0,
      "text": "but at least in principle, this is one place where"
    },
    {
      "index": 1539,
      "start_time": 3854470.0,
      "end_time": 3857748.0,
      "text": "static graph really, you can have the potential for"
    },
    {
      "index": 1540,
      "start_time": 3857750.0,
      "end_time": 3860134.0,
      "text": "doing this optimization in static graphs"
    },
    {
      "index": 1541,
      "start_time": 3860130.0,
      "end_time": 3864297.0,
      "text": "where maybe it would be not so tractable for dynamic graphs."
    },
    {
      "index": 1542,
      "start_time": 3865500.0,
      "end_time": 3866933.0,
      "text": "Another kind of subtle point about static versus dynamic"
    },
    {
      "index": 1543,
      "start_time": 3866940.0,
      "end_time": 3868934.0,
      "text": "is this idea of serialization."
    },
    {
      "index": 1544,
      "start_time": 3868930.0,
      "end_time": 3872346.0,
      "text": "So with a static graph you can imagine that you write"
    },
    {
      "index": 1545,
      "start_time": 3872350.0,
      "end_time": 3874263.0,
      "text": "this code that builds up the graph"
    },
    {
      "index": 1546,
      "start_time": 3874260.0,
      "end_time": 3875640.0,
      "text": "and then once you&#39;ve built the graph,"
    },
    {
      "index": 1547,
      "start_time": 3875640.0,
      "end_time": 3877666.0,
      "text": "you have this data structure in memory that represents"
    },
    {
      "index": 1548,
      "start_time": 3877670.0,
      "end_time": 3879574.0,
      "text": "the entire structure of your network."
    },
    {
      "index": 1549,
      "start_time": 3879570.0,
      "end_time": 3881225.0,
      "text": "And now you could take that data structure"
    },
    {
      "index": 1550,
      "start_time": 3881230.0,
      "end_time": 3882432.0,
      "text": "and just serialize it to disk."
    },
    {
      "index": 1551,
      "start_time": 3882430.0,
      "end_time": 3884530.0,
      "text": "And now you&#39;ve got the whole structure of your network"
    },
    {
      "index": 1552,
      "start_time": 3884530.0,
      "end_time": 3885997.0,
      "text": "saved in some file."
    },
    {
      "index": 1553,
      "start_time": 3886000.0,
      "end_time": 3888715.0,
      "text": "And then you could later rear load that thing"
    },
    {
      "index": 1554,
      "start_time": 3888710.0,
      "end_time": 3891626.0,
      "text": "and then run that computational graph without access"
    },
    {
      "index": 1555,
      "start_time": 3891630.0,
      "end_time": 3893633.0,
      "text": "to the original code that built it."
    },
    {
      "index": 1556,
      "start_time": 3893630.0,
      "end_time": 3895450.0,
      "text": "So this would be kind of nice in a deployment scenario."
    },
    {
      "index": 1557,
      "start_time": 3895450.0,
      "end_time": 3897606.0,
      "text": "You might imagine that you might want to train your"
    },
    {
      "index": 1558,
      "start_time": 3897610.0,
      "end_time": 3900428.0,
      "text": "network in Python because it&#39;s maybe easier to work with,"
    },
    {
      "index": 1559,
      "start_time": 3900420.0,
      "end_time": 3901784.0,
      "text": "but then after you serialize that network"
    },
    {
      "index": 1560,
      "start_time": 3901790.0,
      "end_time": 3904172.0,
      "text": "and then you could deploy it now in maybe a C++"
    },
    {
      "index": 1561,
      "start_time": 3904170.0,
      "end_time": 3906409.0,
      "text": "environment where you don&#39;t need to use the original"
    },
    {
      "index": 1562,
      "start_time": 3906410.0,
      "end_time": 3907760.0,
      "text": "code that built the graph."
    },
    {
      "index": 1563,
      "start_time": 3907760.0,
      "end_time": 3910910.0,
      "text": "So that&#39;s kind of a nice advantage of static graphs."
    },
    {
      "index": 1564,
      "start_time": 3910910.0,
      "end_time": 3912511.0,
      "text": "Whereas with a dynamic graph, because we&#39;re interleaving"
    },
    {
      "index": 1565,
      "start_time": 3912510.0,
      "end_time": 3915793.0,
      "text": "these processes of graph building and graph execution,"
    },
    {
      "index": 1566,
      "start_time": 3915790.0,
      "end_time": 3917819.0,
      "text": "you kind of need the original code at all times"
    },
    {
      "index": 1567,
      "start_time": 3917820.0,
      "end_time": 3922118.0,
      "text": "if you want to reuse that model in the future."
    },
    {
      "index": 1568,
      "start_time": 3922120.0,
      "end_time": 3924390.0,
      "text": "On the other hand, some advantages for dynamic graphs"
    },
    {
      "index": 1569,
      "start_time": 3924390.0,
      "end_time": 3926921.0,
      "text": "are that it kind of makes, it just makes your code"
    },
    {
      "index": 1570,
      "start_time": 3926920.0,
      "end_time": 3929162.0,
      "text": "a lot cleaner and a lot easier in a lot of scenarios."
    },
    {
      "index": 1571,
      "start_time": 3929160.0,
      "end_time": 3931261.0,
      "text": "So for example, suppose that we want to do some"
    },
    {
      "index": 1572,
      "start_time": 3931260.0,
      "end_time": 3934497.0,
      "text": "conditional operation where depending on the value"
    },
    {
      "index": 1573,
      "start_time": 3934500.0,
      "end_time": 3937540.0,
      "text": "of some variable Z, we want to do different operations"
    },
    {
      "index": 1574,
      "start_time": 3937540.0,
      "end_time": 3938623.0,
      "text": "to compute Y."
    },
    {
      "index": 1575,
      "start_time": 3939720.0,
      "end_time": 3942120.0,
      "text": "Where if Z is positive, we want to use one weight matrix,"
    },
    {
      "index": 1576,
      "start_time": 3942120.0,
      "end_time": 3945697.0,
      "text": "if Z is negative we want to use a different weight matrix."
    },
    {
      "index": 1577,
      "start_time": 3945700.0,
      "end_time": 3947981.0,
      "text": "And we just want to switch off between these two alternatives."
    },
    {
      "index": 1578,
      "start_time": 3947980.0,
      "end_time": 3950719.0,
      "text": "In PyTorch because we&#39;re using dynamic graphs,"
    },
    {
      "index": 1579,
      "start_time": 3950720.0,
      "end_time": 3952110.0,
      "text": "it&#39;s super simple."
    },
    {
      "index": 1580,
      "start_time": 3952110.0,
      "end_time": 3954101.0,
      "text": "Your code kind of looks exactly like you would expect,"
    },
    {
      "index": 1581,
      "start_time": 3954100.0,
      "end_time": 3956399.0,
      "text": "exactly what you would do in Numpy."
    },
    {
      "index": 1582,
      "start_time": 3956400.0,
      "end_time": 3958877.0,
      "text": "You can just use normal Python control flow"
    },
    {
      "index": 1583,
      "start_time": 3958880.0,
      "end_time": 3960798.0,
      "text": "to handle this thing."
    },
    {
      "index": 1584,
      "start_time": 3960790.0,
      "end_time": 3963259.0,
      "text": "And now because we&#39;re building up the graph each time,"
    },
    {
      "index": 1585,
      "start_time": 3963260.0,
      "end_time": 3965559.0,
      "text": "each time we perform this operation will take one"
    },
    {
      "index": 1586,
      "start_time": 3965560.0,
      "end_time": 3968207.0,
      "text": "of the two paths and build up maybe a different graph"
    },
    {
      "index": 1587,
      "start_time": 3968210.0,
      "end_time": 3970864.0,
      "text": "on each forward pass, but for any graph that we do"
    },
    {
      "index": 1588,
      "start_time": 3970860.0,
      "end_time": 3973100.0,
      "text": "end up building up, we can back propagate through it"
    },
    {
      "index": 1589,
      "start_time": 3973100.0,
      "end_time": 3974333.0,
      "text": "just fine."
    },
    {
      "index": 1590,
      "start_time": 3974340.0,
      "end_time": 3975944.0,
      "text": "And the code is very clean, easy to work with."
    },
    {
      "index": 1591,
      "start_time": 3975940.0,
      "end_time": 3978842.0,
      "text": "Now in TensorFlow the situations is a little bit more"
    },
    {
      "index": 1592,
      "start_time": 3978840.0,
      "end_time": 3983198.0,
      "text": "complicated because we build the graph once,"
    },
    {
      "index": 1593,
      "start_time": 3983200.0,
      "end_time": 3985218.0,
      "text": "this control flow operator kind of needs to be"
    },
    {
      "index": 1594,
      "start_time": 3985220.0,
      "end_time": 3988401.0,
      "text": "an explicit operator in the TensorFlow graph."
    },
    {
      "index": 1595,
      "start_time": 3988400.0,
      "end_time": 3991301.0,
      "text": "And now, so them you can see that we have this"
    },
    {
      "index": 1596,
      "start_time": 3991300.0,
      "end_time": 3994318.0,
      "text": "tf.cond call which is kind of like a TensorFlow version"
    },
    {
      "index": 1597,
      "start_time": 3994320.0,
      "end_time": 3996818.0,
      "text": "of an if statement, but now it&#39;s baked into"
    },
    {
      "index": 1598,
      "start_time": 3996820.0,
      "end_time": 3998840.0,
      "text": "the computational graph rather than using sort of"
    },
    {
      "index": 1599,
      "start_time": 3998840.0,
      "end_time": 4000743.0,
      "text": "Python control flow."
    },
    {
      "index": 1600,
      "start_time": 4000740.0,
      "end_time": 4003472.0,
      "text": "And the problem is that because we only build the graph"
    },
    {
      "index": 1601,
      "start_time": 4003470.0,
      "end_time": 4006120.0,
      "text": "once, all the potential paths of control flow that"
    },
    {
      "index": 1602,
      "start_time": 4006120.0,
      "end_time": 4008726.0,
      "text": "our program might flow through need to be baked"
    },
    {
      "index": 1603,
      "start_time": 4008730.0,
      "end_time": 4011201.0,
      "text": "into the graph at the time we construct it before we ever"
    },
    {
      "index": 1604,
      "start_time": 4011200.0,
      "end_time": 4012522.0,
      "text": "run it."
    },
    {
      "index": 1605,
      "start_time": 4012520.0,
      "end_time": 4014350.0,
      "text": "So that means that any kind of control flow operators"
    },
    {
      "index": 1606,
      "start_time": 4014350.0,
      "end_time": 4018391.0,
      "text": "that you want to have need to be not Python control flow"
    },
    {
      "index": 1607,
      "start_time": 4018390.0,
      "end_time": 4020404.0,
      "text": "operators, you need to use some kind of magic,"
    },
    {
      "index": 1608,
      "start_time": 4020410.0,
      "end_time": 4023361.0,
      "text": "special tensor flow operations to do control flow."
    },
    {
      "index": 1609,
      "start_time": 4023360.0,
      "end_time": 4025527.0,
      "text": "In this case this tf.cond."
    },
    {
      "index": 1610,
      "start_time": 4026710.0,
      "end_time": 4029397.0,
      "text": "Another kind of similar situation happens if you want to"
    },
    {
      "index": 1611,
      "start_time": 4029400.0,
      "end_time": 4030763.0,
      "text": "have loops."
    },
    {
      "index": 1612,
      "start_time": 4030760.0,
      "end_time": 4032680.0,
      "text": "So suppose that we want to compute some kind of recurrent"
    },
    {
      "index": 1613,
      "start_time": 4032680.0,
      "end_time": 4036603.0,
      "text": "relationships where maybe Y T is equal to Y T minus one"
    },
    {
      "index": 1614,
      "start_time": 4036610.0,
      "end_time": 4039842.0,
      "text": "plus X T times some weight matrix W and depending on"
    },
    {
      "index": 1615,
      "start_time": 4039840.0,
      "end_time": 4043771.0,
      "text": "each time we do this, every time we compute this,"
    },
    {
      "index": 1616,
      "start_time": 4043770.0,
      "end_time": 4046436.0,
      "text": "we might have a different sized sequence of data."
    },
    {
      "index": 1617,
      "start_time": 4046440.0,
      "end_time": 4048269.0,
      "text": "And no matter the length of our sequence of data,"
    },
    {
      "index": 1618,
      "start_time": 4048260.0,
      "end_time": 4050212.0,
      "text": "we just want to compute this same recurrence relation"
    },
    {
      "index": 1619,
      "start_time": 4050220.0,
      "end_time": 4053374.0,
      "text": "no matter the size of the input sequence."
    },
    {
      "index": 1620,
      "start_time": 4053370.0,
      "end_time": 4055795.0,
      "text": "So in PyTorch this is super easy."
    },
    {
      "index": 1621,
      "start_time": 4055800.0,
      "end_time": 4059493.0,
      "text": "We can just kind of use a normal for loop in Python"
    },
    {
      "index": 1622,
      "start_time": 4059490.0,
      "end_time": 4061535.0,
      "text": "to just loop over the number of times that we want to"
    },
    {
      "index": 1623,
      "start_time": 4061530.0,
      "end_time": 4064432.0,
      "text": "unroll and now depending on the size of the input data,"
    },
    {
      "index": 1624,
      "start_time": 4064440.0,
      "end_time": 4067954.0,
      "text": "our computational graph will end up as different sizes,"
    },
    {
      "index": 1625,
      "start_time": 4067950.0,
      "end_time": 4069736.0,
      "text": "but that&#39;s fine, we can just back propagate through"
    },
    {
      "index": 1626,
      "start_time": 4069740.0,
      "end_time": 4071697.0,
      "text": "each one, one at a time."
    },
    {
      "index": 1627,
      "start_time": 4071690.0,
      "end_time": 4075778.0,
      "text": "Now in TensorFlow this becomes a little bit uglier."
    },
    {
      "index": 1628,
      "start_time": 4075780.0,
      "end_time": 4078492.0,
      "text": "And again, because we need to construct the graph"
    },
    {
      "index": 1629,
      "start_time": 4078490.0,
      "end_time": 4082394.0,
      "text": "all at once up front, this control flow looping construct"
    },
    {
      "index": 1630,
      "start_time": 4082400.0,
      "end_time": 4086366.0,
      "text": "again needs to be an explicit node in the TensorFlow graph."
    },
    {
      "index": 1631,
      "start_time": 4086360.0,
      "end_time": 4088836.0,
      "text": "So I hope you remember your functional programming"
    },
    {
      "index": 1632,
      "start_time": 4088840.0,
      "end_time": 4090432.0,
      "text": "because you&#39;ll have to use those kinds of operators"
    },
    {
      "index": 1633,
      "start_time": 4090430.0,
      "end_time": 4093515.0,
      "text": "to implement looping constructs in TensorFlow."
    },
    {
      "index": 1634,
      "start_time": 4093520.0,
      "end_time": 4096294.0,
      "text": "So in this case, for this particular recurrence relationship"
    },
    {
      "index": 1635,
      "start_time": 4096290.0,
      "end_time": 4098855.0,
      "text": "you can use a foldl operation and pass in,"
    },
    {
      "index": 1636,
      "start_time": 4098859.9999999995,
      "end_time": 4103242.9999999995,
      "text": "sort of implement this particular loop in terms of a foldl."
    },
    {
      "index": 1637,
      "start_time": 4104100.0000000005,
      "end_time": 4106201.0000000005,
      "text": "But what this basically means is that you have this sense"
    },
    {
      "index": 1638,
      "start_time": 4106200.0,
      "end_time": 4108733.0,
      "text": "that TensorFlow is almost building its own entire"
    },
    {
      "index": 1639,
      "start_time": 4108729.9999999995,
      "end_time": 4111209.9999999995,
      "text": "programming language, using the language of"
    },
    {
      "index": 1640,
      "start_time": 4111210.0,
      "end_time": 4113207.0,
      "text": "computational graphs."
    },
    {
      "index": 1641,
      "start_time": 4113210.0,
      "end_time": 4114819.0,
      "text": "And any kind of control flow operator,"
    },
    {
      "index": 1642,
      "start_time": 4114819.9999999995,
      "end_time": 4117213.9999999995,
      "text": "or any kind of data structure needs to be rolled"
    },
    {
      "index": 1643,
      "start_time": 4117210.0,
      "end_time": 4120135.0,
      "text": "into the computational graph so you can&#39;t really utilize"
    },
    {
      "index": 1644,
      "start_time": 4120140.0000000005,
      "end_time": 4122596.0000000005,
      "text": "all your favorite paradigms for working imperatively"
    },
    {
      "index": 1645,
      "start_time": 4122600.0000000005,
      "end_time": 4124221.0000000005,
      "text": "in Python."
    },
    {
      "index": 1646,
      "start_time": 4124220.0000000005,
      "end_time": 4126200.0000000005,
      "text": "You kind of need to relearn a whole separate set"
    },
    {
      "index": 1647,
      "start_time": 4126200.0,
      "end_time": 4127960.0,
      "text": "of control flow operators."
    },
    {
      "index": 1648,
      "start_time": 4127960.0,
      "end_time": 4129995.0,
      "text": "And if you want to do any kinds of control flow"
    },
    {
      "index": 1649,
      "start_time": 4129990.0,
      "end_time": 4132803.0,
      "text": "inside your computational graph using TensorFlow."
    },
    {
      "index": 1650,
      "start_time": 4132800.0,
      "end_time": 4136248.0,
      "text": "So at least for me, I find that kind of confusing,"
    },
    {
      "index": 1651,
      "start_time": 4136250.0,
      "end_time": 4138236.0,
      "text": "a little bit hard to wrap my head around sometimes,"
    },
    {
      "index": 1652,
      "start_time": 4138240.0,
      "end_time": 4141261.0,
      "text": "and I kind of like that using PyTorch dynamic graphs,"
    },
    {
      "index": 1653,
      "start_time": 4141260.0,
      "end_time": 4143556.0,
      "text": "you can just use your favorite imperative programming"
    },
    {
      "index": 1654,
      "start_time": 4143560.0000000005,
      "end_time": 4146728.0000000005,
      "text": "constructs and it all works just fine."
    },
    {
      "index": 1655,
      "start_time": 4147740.0,
      "end_time": 4152513.0,
      "text": "By the way, there actually is some very new library"
    },
    {
      "index": 1656,
      "start_time": 4152510.0,
      "end_time": 4155732.0,
      "text": "called TensorFlow Fold which is another one of these"
    },
    {
      "index": 1657,
      "start_time": 4155729.9999999995,
      "end_time": 4157659.9999999995,
      "text": "layers on top of TensorFlow that lets you implement"
    },
    {
      "index": 1658,
      "start_time": 4157660.0,
      "end_time": 4161578.0,
      "text": "dynamic graphs, you kind of write your own code"
    },
    {
      "index": 1659,
      "start_time": 4162420.0,
      "end_time": 4164990.0,
      "text": "using TensorFlow Fold that looks kind of like a dynamic"
    },
    {
      "index": 1660,
      "start_time": 4164990.0,
      "end_time": 4167981.0,
      "text": "graph operation and then TensorFlow Fold does some magic"
    },
    {
      "index": 1661,
      "start_time": 4167979.9999999995,
      "end_time": 4170619.9999999995,
      "text": "for you and somehow implements that in terms of the"
    },
    {
      "index": 1662,
      "start_time": 4170620.0,
      "end_time": 4172280.0,
      "text": "static TensorFlow graphs."
    },
    {
      "index": 1663,
      "start_time": 4172279.9999999995,
      "end_time": 4175227.9999999995,
      "text": "This is a super new paper that&#39;s being presented"
    },
    {
      "index": 1664,
      "start_time": 4175229.9999999995,
      "end_time": 4177361.9999999995,
      "text": "at ICLR this week in France."
    },
    {
      "index": 1665,
      "start_time": 4177359.9999999995,
      "end_time": 4179738.9999999995,
      "text": "So I haven&#39;t had the chance to like dive in and play"
    },
    {
      "index": 1666,
      "start_time": 4179740.0,
      "end_time": 4181697.0,
      "text": "with this yet."
    },
    {
      "index": 1667,
      "start_time": 4181689.9999999995,
      "end_time": 4184247.9999999995,
      "text": "But my initial impression was that it does add some"
    },
    {
      "index": 1668,
      "start_time": 4184250.0,
      "end_time": 4186453.0,
      "text": "amount of dynamic graphs to TensorFlow but it is still"
    },
    {
      "index": 1669,
      "start_time": 4186460.0,
      "end_time": 4188803.0,
      "text": "a bit more awkward to work with than the sort of native"
    },
    {
      "index": 1670,
      "start_time": 4188800.0,
      "end_time": 4191954.0,
      "text": "dynamic graphs you have in PyTorch."
    },
    {
      "index": 1671,
      "start_time": 4191950.0,
      "end_time": 4194525.0,
      "text": "So then, I thought it might be nice to motivate"
    },
    {
      "index": 1672,
      "start_time": 4194530.0,
      "end_time": 4197260.0,
      "text": "like why would we care about dynamic graphs in general?"
    },
    {
      "index": 1673,
      "start_time": 4197260.0,
      "end_time": 4200260.0,
      "text": "So one option is recurrent networks."
    },
    {
      "index": 1674,
      "start_time": 4201180.0,
      "end_time": 4203258.0,
      "text": "So you can see that for something like image captioning"
    },
    {
      "index": 1675,
      "start_time": 4203260.0,
      "end_time": 4205719.0,
      "text": "we use a recurrent network which operates over"
    },
    {
      "index": 1676,
      "start_time": 4205710.0,
      "end_time": 4207607.0,
      "text": "sequences of different lengths."
    },
    {
      "index": 1677,
      "start_time": 4207610.0,
      "end_time": 4210796.0,
      "text": "In this case, the sentence that we want to generate"
    },
    {
      "index": 1678,
      "start_time": 4210800.0,
      "end_time": 4213339.0,
      "text": "as a caption is a sequence and that sequence can vary"
    },
    {
      "index": 1679,
      "start_time": 4213340.0,
      "end_time": 4215639.0,
      "text": "depending on our input data."
    },
    {
      "index": 1680,
      "start_time": 4215640.0,
      "end_time": 4218418.0,
      "text": "So now you can see that we have this dynamism in the thing"
    },
    {
      "index": 1681,
      "start_time": 4218410.0,
      "end_time": 4221689.0,
      "text": "where depending on the size of the sentence,"
    },
    {
      "index": 1682,
      "start_time": 4221690.0,
      "end_time": 4224132.0,
      "text": "our computational graph might need to have more"
    },
    {
      "index": 1683,
      "start_time": 4224140.0,
      "end_time": 4225720.0,
      "text": "or fewer elements."
    },
    {
      "index": 1684,
      "start_time": 4225720.0,
      "end_time": 4229924.0,
      "text": "So that&#39;s one kind of common application of dynamic graphs."
    },
    {
      "index": 1685,
      "start_time": 4229920.0,
      "end_time": 4234115.0,
      "text": "For those of you who took CS224N last quarter,"
    },
    {
      "index": 1686,
      "start_time": 4234120.0,
      "end_time": 4236381.0,
      "text": "you saw this idea of recursive networks"
    },
    {
      "index": 1687,
      "start_time": 4236380.0,
      "end_time": 4238677.0,
      "text": "where sometimes in natural language processing"
    },
    {
      "index": 1688,
      "start_time": 4238670.0,
      "end_time": 4241312.0,
      "text": "you might, for example, compute a parsed tree"
    },
    {
      "index": 1689,
      "start_time": 4241320.0,
      "end_time": 4243938.0,
      "text": "of a sentence and then you want to have a neural"
    },
    {
      "index": 1690,
      "start_time": 4243930.0,
      "end_time": 4247333.0,
      "text": "network kind of operate recursively up this parse tree."
    },
    {
      "index": 1691,
      "start_time": 4247340.0,
      "end_time": 4249294.0,
      "text": "So having a neural network that kind of works,"
    },
    {
      "index": 1692,
      "start_time": 4249290.0,
      "end_time": 4251816.0,
      "text": "it&#39;s not just a sequential sequence of layers,"
    },
    {
      "index": 1693,
      "start_time": 4251820.0,
      "end_time": 4254519.0,
      "text": "but instead it&#39;s kind of working over some graph"
    },
    {
      "index": 1694,
      "start_time": 4254520.0,
      "end_time": 4256860.0,
      "text": "or tree structure instead where now each data point"
    },
    {
      "index": 1695,
      "start_time": 4256860.0,
      "end_time": 4258736.0,
      "text": "might have a different graph or tree structure"
    },
    {
      "index": 1696,
      "start_time": 4258730.0,
      "end_time": 4260754.0,
      "text": "so the structure of the computational graph"
    },
    {
      "index": 1697,
      "start_time": 4260760.0,
      "end_time": 4263198.0,
      "text": "then kind of mirrors the structure of the input data."
    },
    {
      "index": 1698,
      "start_time": 4263190.0,
      "end_time": 4265710.0,
      "text": "And it could vary from data point to data point."
    },
    {
      "index": 1699,
      "start_time": 4265710.0,
      "end_time": 4267930.0,
      "text": "So this type of thing seems kind of complicated and"
    },
    {
      "index": 1700,
      "start_time": 4267930.0,
      "end_time": 4270312.0,
      "text": "hairy to implement using TensorFlow,"
    },
    {
      "index": 1701,
      "start_time": 4270320.0,
      "end_time": 4272482.0,
      "text": "but in PyTorch you can just kind of use"
    },
    {
      "index": 1702,
      "start_time": 4272480.0,
      "end_time": 4274542.0,
      "text": "like normal Python control flow and it&#39;ll work out"
    },
    {
      "index": 1703,
      "start_time": 4274540.0,
      "end_time": 4274887.0,
      "text": "just fine."
    },
    {
      "index": 1704,
      "start_time": 4276570.0,
      "end_time": 4279193.0,
      "text": "Another bit of more researchy application is this really"
    },
    {
      "index": 1705,
      "start_time": 4279200.0,
      "end_time": 4281616.0,
      "text": "cool idea that I like called neuromodule networks"
    },
    {
      "index": 1706,
      "start_time": 4281610.0,
      "end_time": 4283674.0,
      "text": "for visual question answering."
    },
    {
      "index": 1707,
      "start_time": 4283680.0,
      "end_time": 4286720.0,
      "text": "So here the idea is that we want to ask some questions"
    },
    {
      "index": 1708,
      "start_time": 4286720.0,
      "end_time": 4289280.0,
      "text": "about images where we maybe input this image"
    },
    {
      "index": 1709,
      "start_time": 4289280.0,
      "end_time": 4291739.0,
      "text": "of cats and dogs, there&#39;s some question,"
    },
    {
      "index": 1710,
      "start_time": 4291740.0,
      "end_time": 4294759.0,
      "text": "what color is the cat, and then internally the system"
    },
    {
      "index": 1711,
      "start_time": 4294760.0,
      "end_time": 4297618.0,
      "text": "can read the question and that has these different"
    },
    {
      "index": 1712,
      "start_time": 4297610.0,
      "end_time": 4299754.0,
      "text": "specialized neural network modules for performing"
    },
    {
      "index": 1713,
      "start_time": 4299760.0,
      "end_time": 4303596.0,
      "text": "operations like asking for colors and finding cats."
    },
    {
      "index": 1714,
      "start_time": 4303590.0,
      "end_time": 4305911.0,
      "text": "And then depending on the text of the question,"
    },
    {
      "index": 1715,
      "start_time": 4305920.0,
      "end_time": 4308198.0,
      "text": "it can compile this custom architecture for answering"
    },
    {
      "index": 1716,
      "start_time": 4308190.0,
      "end_time": 4309835.0,
      "text": "the question."
    },
    {
      "index": 1717,
      "start_time": 4309840.0,
      "end_time": 4312296.0,
      "text": "And now if we asked a different question,"
    },
    {
      "index": 1718,
      "start_time": 4312290.0,
      "end_time": 4315936.0,
      "text": "like are there more cats than dogs?"
    },
    {
      "index": 1719,
      "start_time": 4315940.0,
      "end_time": 4318241.0,
      "text": "Now we have maybe the same basic set of modules"
    },
    {
      "index": 1720,
      "start_time": 4318240.0,
      "end_time": 4320533.0,
      "text": "for doing things like finding cats and dogs and counting,"
    },
    {
      "index": 1721,
      "start_time": 4320530.0,
      "end_time": 4323756.0,
      "text": "but they&#39;re arranged in a different order."
    },
    {
      "index": 1722,
      "start_time": 4323760.0,
      "end_time": 4325177.0,
      "text": "So we get this dynamism again where different data points"
    },
    {
      "index": 1723,
      "start_time": 4325180.0,
      "end_time": 4327718.0,
      "text": "might give rise to different computational graphs."
    },
    {
      "index": 1724,
      "start_time": 4327720.0,
      "end_time": 4329639.0,
      "text": "But this is a bit more of a researchy thing"
    },
    {
      "index": 1725,
      "start_time": 4329630.0,
      "end_time": 4332569.0,
      "text": "and maybe not so main stream right now."
    },
    {
      "index": 1726,
      "start_time": 4332570.0,
      "end_time": 4335356.0,
      "text": "But as kind of a bigger point, I think that there&#39;s"
    },
    {
      "index": 1727,
      "start_time": 4335370.0,
      "end_time": 4337198.0,
      "text": "a lot of cool, creative applications that people"
    },
    {
      "index": 1728,
      "start_time": 4337200.0,
      "end_time": 4339216.0,
      "text": "could do with dynamic computational graphs"
    },
    {
      "index": 1729,
      "start_time": 4339210.0,
      "end_time": 4341573.0,
      "text": "and maybe there aren&#39;t so many right now,"
    },
    {
      "index": 1730,
      "start_time": 4341580.0,
      "end_time": 4343474.0,
      "text": "just because it&#39;s been so painful to work with them."
    },
    {
      "index": 1731,
      "start_time": 4343470.0,
      "end_time": 4345575.0,
      "text": "So I think that there&#39;s a lot of opportunity"
    },
    {
      "index": 1732,
      "start_time": 4345580.0,
      "end_time": 4347399.0,
      "text": "for doing cool, creative things with"
    },
    {
      "index": 1733,
      "start_time": 4347400.0,
      "end_time": 4350600.0,
      "text": "dynamic computational graphs."
    },
    {
      "index": 1734,
      "start_time": 4350600.0,
      "end_time": 4352301.0,
      "text": "And maybe if you come up with cool ideas,"
    },
    {
      "index": 1735,
      "start_time": 4352300.0,
      "end_time": 4354773.0,
      "text": "we&#39;ll feature it in lecture next year."
    },
    {
      "index": 1736,
      "start_time": 4354780.0,
      "end_time": 4357612.0,
      "text": "So I wanted to talk very briefly about Caffe"
    },
    {
      "index": 1737,
      "start_time": 4357610.0,
      "end_time": 4359852.0,
      "text": "which is this framework from Berkeley."
    },
    {
      "index": 1738,
      "start_time": 4359850.0,
      "end_time": 4363791.0,
      "text": "Which Caffe is somewhat different from the other"
    },
    {
      "index": 1739,
      "start_time": 4363790.0,
      "end_time": 4365769.0,
      "text": "deep learning frameworks where you in many cases"
    },
    {
      "index": 1740,
      "start_time": 4365770.0,
      "end_time": 4367450.0,
      "text": "you can actually train networks without writing"
    },
    {
      "index": 1741,
      "start_time": 4367450.0,
      "end_time": 4368811.0,
      "text": "any code yourself."
    },
    {
      "index": 1742,
      "start_time": 4368810.0,
      "end_time": 4370793.0,
      "text": "You kind of just call into these pre-existing binaries,"
    },
    {
      "index": 1743,
      "start_time": 4370800.0,
      "end_time": 4373216.0,
      "text": "set up some configuration files and in many cases"
    },
    {
      "index": 1744,
      "start_time": 4373210.0,
      "end_time": 4376693.0,
      "text": "you can train on data without writing any of your own code."
    },
    {
      "index": 1745,
      "start_time": 4376700.0,
      "end_time": 4380783.0,
      "text": "So, you may be first, you convert your data"
    },
    {
      "index": 1746,
      "start_time": 4380780.0,
      "end_time": 4383540.0,
      "text": "into some format like HDF5 or LMDB and there exists"
    },
    {
      "index": 1747,
      "start_time": 4383540.0,
      "end_time": 4386140.0,
      "text": "some scripts inside Caffe that can just convert like"
    },
    {
      "index": 1748,
      "start_time": 4386140.0,
      "end_time": 4388638.0,
      "text": "folders of images and text files into these formats for you."
    },
    {
      "index": 1749,
      "start_time": 4388640.0,
      "end_time": 4392539.0,
      "text": "You need to define, now instead of writing code"
    },
    {
      "index": 1750,
      "start_time": 4392540.0,
      "end_time": 4394481.0,
      "text": "to define the structure of your computational graph,"
    },
    {
      "index": 1751,
      "start_time": 4394480.0,
      "end_time": 4397416.0,
      "text": "instead you edit some text file called a prototxt"
    },
    {
      "index": 1752,
      "start_time": 4397410.0,
      "end_time": 4399930.0,
      "text": "which sets up the structure of the computational graph."
    },
    {
      "index": 1753,
      "start_time": 4399930.0,
      "end_time": 4402993.0,
      "text": "Here the structure is that we read from some input"
    },
    {
      "index": 1754,
      "start_time": 4403000.0,
      "end_time": 4406540.0,
      "text": "HDF5 file, we perform some inner product,"
    },
    {
      "index": 1755,
      "start_time": 4406540.0,
      "end_time": 4408977.0,
      "text": "we compute some loss and the whole structure"
    },
    {
      "index": 1756,
      "start_time": 4408970.0,
      "end_time": 4410871.0,
      "text": "of the graph is set up in this text file."
    },
    {
      "index": 1757,
      "start_time": 4410880.0,
      "end_time": 4413658.0,
      "text": "One kind of downside here is that these files"
    },
    {
      "index": 1758,
      "start_time": 4413650.0,
      "end_time": 4415953.0,
      "text": "can get really ugly for very large networks."
    },
    {
      "index": 1759,
      "start_time": 4415960.0,
      "end_time": 4418459.0,
      "text": "So for something like the 152 layer ResNet model,"
    },
    {
      "index": 1760,
      "start_time": 4418460.0,
      "end_time": 4421540.0,
      "text": "which by the way was trained in Caffe originally,"
    },
    {
      "index": 1761,
      "start_time": 4421540.0,
      "end_time": 4424258.0,
      "text": "then this prototxt file ends up almost 7000 lines long."
    },
    {
      "index": 1762,
      "start_time": 4424250.0,
      "end_time": 4427274.0,
      "text": "So people are not writing these by hand."
    },
    {
      "index": 1763,
      "start_time": 4427280.0,
      "end_time": 4429889.0,
      "text": "People will sometimes will like write python scripts"
    },
    {
      "index": 1764,
      "start_time": 4429890.0,
      "end_time": 4431820.0,
      "text": "to generate these prototxt files."
    },
    {
      "index": 1765,
      "start_time": 4431820.0,
      "end_time": 4433278.0,
      "text": "[laughter]"
    },
    {
      "index": 1766,
      "start_time": 4433270.0,
      "end_time": 4435149.0,
      "text": "Then you&#39;re kind in the realm of rolling your own"
    },
    {
      "index": 1767,
      "start_time": 4435150.0,
      "end_time": 4436314.0,
      "text": "computational graph abstraction."
    },
    {
      "index": 1768,
      "start_time": 4436320.0,
      "end_time": 4438976.0,
      "text": "That&#39;s probably not a good idea, but I&#39;ve seen that before."
    },
    {
      "index": 1769,
      "start_time": 4438970.0,
      "end_time": 4442234.0,
      "text": "Then, rather than having some optimizer object,"
    },
    {
      "index": 1770,
      "start_time": 4442240.0,
      "end_time": 4445318.0,
      "text": "instead there&#39;s some solver, you define some solver things"
    },
    {
      "index": 1771,
      "start_time": 4445320.0,
      "end_time": 4447500.0,
      "text": "inside another prototxt."
    },
    {
      "index": 1772,
      "start_time": 4447500.0,
      "end_time": 4449121.0,
      "text": "This defines your learning rate,"
    },
    {
      "index": 1773,
      "start_time": 4449120.0,
      "end_time": 4451362.0,
      "text": "your optimization algorithm and whatnot."
    },
    {
      "index": 1774,
      "start_time": 4451360.0,
      "end_time": 4452334.0,
      "text": "And then once you do all these things,"
    },
    {
      "index": 1775,
      "start_time": 4452330.0,
      "end_time": 4454170.0,
      "text": "you can just run the Caffe binary with the train command"
    },
    {
      "index": 1776,
      "start_time": 4454170.0,
      "end_time": 4457274.0,
      "text": "and it all happens magically."
    },
    {
      "index": 1777,
      "start_time": 4457280.0,
      "end_time": 4459579.0,
      "text": "Cafee has a model zoo with a bunch of pretrained models,"
    },
    {
      "index": 1778,
      "start_time": 4459580.0,
      "end_time": 4461297.0,
      "text": "that&#39;s pretty useful."
    },
    {
      "index": 1779,
      "start_time": 4461290.0,
      "end_time": 4463450.0,
      "text": "Caffe has a Python interface but it&#39;s not super"
    },
    {
      "index": 1780,
      "start_time": 4463450.0,
      "end_time": 4465434.0,
      "text": "well documented."
    },
    {
      "index": 1781,
      "start_time": 4465440.0,
      "end_time": 4467360.0,
      "text": "You kind of need to read the source code of the python"
    },
    {
      "index": 1782,
      "start_time": 4467360.0,
      "end_time": 4469172.0,
      "text": "interface to see what it can do,"
    },
    {
      "index": 1783,
      "start_time": 4469170.0,
      "end_time": 4470116.0,
      "text": "so that&#39;s kind of annoying."
    },
    {
      "index": 1784,
      "start_time": 4470120.0,
      "end_time": 4471459.0,
      "text": "But it does work."
    },
    {
      "index": 1785,
      "start_time": 4471460.0,
      "end_time": 4475627.0,
      "text": "So, kind of my general thing about Caffe is that it&#39;s"
    },
    {
      "index": 1786,
      "start_time": 4476600.0,
      "end_time": 4478338.0,
      "text": "maybe good for feed forward models,"
    },
    {
      "index": 1787,
      "start_time": 4478330.0,
      "end_time": 4480170.0,
      "text": "it&#39;s maybe good for production scenarios,"
    },
    {
      "index": 1788,
      "start_time": 4480170.0,
      "end_time": 4482792.0,
      "text": "because it doesn&#39;t depend on Python."
    },
    {
      "index": 1789,
      "start_time": 4482800.0,
      "end_time": 4485754.0,
      "text": "But probably for research these days, I&#39;ve seen Caffe"
    },
    {
      "index": 1790,
      "start_time": 4485750.0,
      "end_time": 4487358.0,
      "text": "being used maybe a little bit less."
    },
    {
      "index": 1791,
      "start_time": 4487360.0,
      "end_time": 4489599.0,
      "text": "Although I think it is still pretty commonly used"
    },
    {
      "index": 1792,
      "start_time": 4489600.0,
      "end_time": 4491419.0,
      "text": "in industry again for production."
    },
    {
      "index": 1793,
      "start_time": 4491420.0,
      "end_time": 4494413.0,
      "text": "I promise one slide, one or two slides on Caffe 2."
    },
    {
      "index": 1794,
      "start_time": 4494410.0,
      "end_time": 4498596.0,
      "text": "So Caffe 2 is the successor to Caffe which is from Facebook."
    },
    {
      "index": 1795,
      "start_time": 4498600.0,
      "end_time": 4502436.0,
      "text": "It&#39;s super new, it was only released a week ago."
    },
    {
      "index": 1796,
      "start_time": 4502430.0,
      "end_time": 4504434.0,
      "text": "[laughter]"
    },
    {
      "index": 1797,
      "start_time": 4504440.0,
      "end_time": 4506620.0,
      "text": "So I really haven&#39;t had the time to form a super"
    },
    {
      "index": 1798,
      "start_time": 4506620.0,
      "end_time": 4509317.0,
      "text": "educated opinion about Caffe 2 yet,"
    },
    {
      "index": 1799,
      "start_time": 4509310.0,
      "end_time": 4512314.0,
      "text": "but it uses static graphs kind of similar to TensorFlow."
    },
    {
      "index": 1800,
      "start_time": 4512320.0,
      "end_time": 4515200.0,
      "text": "Kind of like Caffe one the core is written in C++"
    },
    {
      "index": 1801,
      "start_time": 4515200.0,
      "end_time": 4517819.0,
      "text": "and they have some Python interface."
    },
    {
      "index": 1802,
      "start_time": 4517820.0,
      "end_time": 4519697.0,
      "text": "The difference is that now you no longer need to"
    },
    {
      "index": 1803,
      "start_time": 4519690.0,
      "end_time": 4521514.0,
      "text": "write your own Python scripts to generate prototxt files."
    },
    {
      "index": 1804,
      "start_time": 4521520.0,
      "end_time": 4525314.0,
      "text": "You can kind of define your computational graph structure"
    },
    {
      "index": 1805,
      "start_time": 4525310.0,
      "end_time": 4528168.0,
      "text": "all in Python, kind of looking with an API that looks"
    },
    {
      "index": 1806,
      "start_time": 4528170.0,
      "end_time": 4529657.0,
      "text": "kind of like TensorFlow."
    },
    {
      "index": 1807,
      "start_time": 4529660.0,
      "end_time": 4531857.0,
      "text": "But then you can spit out, you can serialize this"
    },
    {
      "index": 1808,
      "start_time": 4531850.0,
      "end_time": 4534592.0,
      "text": "computational graph structure to a prototxt file."
    },
    {
      "index": 1809,
      "start_time": 4534600.0,
      "end_time": 4536780.0,
      "text": "And then once your model is trained and whatnot,"
    },
    {
      "index": 1810,
      "start_time": 4536780.0,
      "end_time": 4538679.0,
      "text": "then we get this benefit that we talked about of static"
    },
    {
      "index": 1811,
      "start_time": 4538680.0,
      "end_time": 4541261.0,
      "text": "graphs where you can, you don&#39;t need the original"
    },
    {
      "index": 1812,
      "start_time": 4541260.0,
      "end_time": 4543537.0,
      "text": "training code now in order to deploy a trained model."
    },
    {
      "index": 1813,
      "start_time": 4543530.0,
      "end_time": 4546954.0,
      "text": "So one interesting thing is that you&#39;ve seen Google"
    },
    {
      "index": 1814,
      "start_time": 4546960.0,
      "end_time": 4549418.0,
      "text": "maybe has one major deep running framework,"
    },
    {
      "index": 1815,
      "start_time": 4549420.0,
      "end_time": 4552943.0,
      "text": "which is TensorFlow, where Facebook has these two,"
    },
    {
      "index": 1816,
      "start_time": 4552940.0,
      "end_time": 4553761.0,
      "text": "PyTorch and Caffe 2."
    },
    {
      "index": 1817,
      "start_time": 4554600.0,
      "end_time": 4557255.0,
      "text": "So these are kind of different philosophies."
    },
    {
      "index": 1818,
      "start_time": 4557250.0,
      "end_time": 4559749.0,
      "text": "Google&#39;s kind of trying to build one framework to rule"
    },
    {
      "index": 1819,
      "start_time": 4559750.0,
      "end_time": 4561568.0,
      "text": "them all that maybe works for every possible scenario"
    },
    {
      "index": 1820,
      "start_time": 4561570.0,
      "end_time": 4562848.0,
      "text": "for deep learning."
    },
    {
      "index": 1821,
      "start_time": 4562850.0,
      "end_time": 4564611.0,
      "text": "This is kind of nice because it consolidates all efforts"
    },
    {
      "index": 1822,
      "start_time": 4564610.0,
      "end_time": 4566210.0,
      "text": "onto one framework."
    },
    {
      "index": 1823,
      "start_time": 4566210.0,
      "end_time": 4567853.0,
      "text": "It means you only need to learn one thing"
    },
    {
      "index": 1824,
      "start_time": 4567850.0,
      "end_time": 4569462.0,
      "text": "and it&#39;ll work across many different scenarios"
    },
    {
      "index": 1825,
      "start_time": 4569460.0,
      "end_time": 4571704.0,
      "text": "including like distributed systems, production,"
    },
    {
      "index": 1826,
      "start_time": 4571710.0,
      "end_time": 4573774.0,
      "text": "deployment, mobile, research, everything."
    },
    {
      "index": 1827,
      "start_time": 4573770.0,
      "end_time": 4575704.0,
      "text": "Only need to learn one framework to do all these things."
    },
    {
      "index": 1828,
      "start_time": 4575710.0,
      "end_time": 4578155.0,
      "text": "Whereas Facebook is taking a bit of a different approach."
    },
    {
      "index": 1829,
      "start_time": 4578150.0,
      "end_time": 4580848.0,
      "text": "Where PyTorch is really more specialized,"
    },
    {
      "index": 1830,
      "start_time": 4580850.0,
      "end_time": 4583592.0,
      "text": "more geared towards research so in terms of writing"
    },
    {
      "index": 1831,
      "start_time": 4583590.0,
      "end_time": 4586709.0,
      "text": "research code and quickly iterating on your ideas,"
    },
    {
      "index": 1832,
      "start_time": 4586710.0,
      "end_time": 4587948.0,
      "text": "that&#39;s super easy in PyTorch, but for things like"
    },
    {
      "index": 1833,
      "start_time": 4587950.0,
      "end_time": 4590871.0,
      "text": "running in production, running on mobile devices,"
    },
    {
      "index": 1834,
      "start_time": 4590870.0,
      "end_time": 4592952.0,
      "text": "PyTorch doesn&#39;t have a lot of great support."
    },
    {
      "index": 1835,
      "start_time": 4592950.0,
      "end_time": 4595209.0,
      "text": "Instead, Caffe 2 is kind of geared toward those more"
    },
    {
      "index": 1836,
      "start_time": 4595210.0,
      "end_time": 4597710.0,
      "text": "production oriented use cases."
    },
    {
      "index": 1837,
      "start_time": 4599570.0,
      "end_time": 4602932.0,
      "text": "So my kind of general study, my general, overall advice"
    },
    {
      "index": 1838,
      "start_time": 4602930.0,
      "end_time": 4605410.0,
      "text": "about like which framework to use for which problems"
    },
    {
      "index": 1839,
      "start_time": 4605410.0,
      "end_time": 4607350.0,
      "text": "is kind of that both,"
    },
    {
      "index": 1840,
      "start_time": 4607350.0,
      "end_time": 4610172.0,
      "text": "I think TensorFlow is a pretty safe bet for just about"
    },
    {
      "index": 1841,
      "start_time": 4610170.0,
      "end_time": 4613507.0,
      "text": "any project that you want to start new, right?"
    },
    {
      "index": 1842,
      "start_time": 4613510.0,
      "end_time": 4616168.0,
      "text": "Because it is sort of one framework to rule them all,"
    },
    {
      "index": 1843,
      "start_time": 4616170.0,
      "end_time": 4618850.0,
      "text": "it can be used for just about any circumstance."
    },
    {
      "index": 1844,
      "start_time": 4618850.0,
      "end_time": 4621167.0,
      "text": "However, you probably need to pair it with a"
    },
    {
      "index": 1845,
      "start_time": 4621170.0,
      "end_time": 4623514.0,
      "text": "higher level wrapper and if you want dynamic graphs,"
    },
    {
      "index": 1846,
      "start_time": 4623510.0,
      "end_time": 4625207.0,
      "text": "you&#39;re maybe out of luck."
    },
    {
      "index": 1847,
      "start_time": 4625210.0,
      "end_time": 4627155.0,
      "text": "Some of the code ends up looking a little bit uglier"
    },
    {
      "index": 1848,
      "start_time": 4627150.0,
      "end_time": 4630224.0,
      "text": "in my opinion, but maybe that&#39;s kind of a cosmetic detail"
    },
    {
      "index": 1849,
      "start_time": 4630230.0,
      "end_time": 4633194.0,
      "text": "and it doesn&#39;t really matter that much."
    },
    {
      "index": 1850,
      "start_time": 4633190.0,
      "end_time": 4635808.0,
      "text": "I personally think PyTorch is really great for research."
    },
    {
      "index": 1851,
      "start_time": 4635810.0,
      "end_time": 4638676.0,
      "text": "If you&#39;re focused on just writing research code,"
    },
    {
      "index": 1852,
      "start_time": 4638670.0,
      "end_time": 4641228.0,
      "text": "I think PyTorch is a great choice."
    },
    {
      "index": 1853,
      "start_time": 4641230.0,
      "end_time": 4643827.0,
      "text": "But it&#39;s a bit newer, has less community support,"
    },
    {
      "index": 1854,
      "start_time": 4643830.0,
      "end_time": 4645649.0,
      "text": "less code out there, so it could be a bit of an adventure."
    },
    {
      "index": 1855,
      "start_time": 4645650.0,
      "end_time": 4648413.0,
      "text": "If you want more of a well trodden path, TensorFlow"
    },
    {
      "index": 1856,
      "start_time": 4648410.0,
      "end_time": 4649967.0,
      "text": "might be a better choice."
    },
    {
      "index": 1857,
      "start_time": 4649970.0,
      "end_time": 4652366.0,
      "text": "If you&#39;re interested in production deployment,"
    },
    {
      "index": 1858,
      "start_time": 4652370.0,
      "end_time": 4654715.0,
      "text": "you should probably look at Caffe, Caffe 2 or TensorFlow."
    },
    {
      "index": 1859,
      "start_time": 4654710.0,
      "end_time": 4657170.0,
      "text": "And if you&#39;re really focused on mobile deployment,"
    },
    {
      "index": 1860,
      "start_time": 4657170.0,
      "end_time": 4659312.0,
      "text": "I think TensorFlow and Caffe 2 both have some built in"
    },
    {
      "index": 1861,
      "start_time": 4659310.0,
      "end_time": 4661267.0,
      "text": "support for that."
    },
    {
      "index": 1862,
      "start_time": 4661270.0,
      "end_time": 4663325.0,
      "text": "So it&#39;s kind of unfortunately, there&#39;s not just like"
    },
    {
      "index": 1863,
      "start_time": 4663330.0,
      "end_time": 4665905.0,
      "text": "one global best framework, it kind of depends"
    },
    {
      "index": 1864,
      "start_time": 4665900.0,
      "end_time": 4667393.0,
      "text": "on what you&#39;re actually trying to do,"
    },
    {
      "index": 1865,
      "start_time": 4667390.0,
      "end_time": 4669209.0,
      "text": "what applications you anticipate but theses are kind of"
    },
    {
      "index": 1866,
      "start_time": 4669210.0,
      "end_time": 4672448.0,
      "text": "my general advice on those things."
    },
    {
      "index": 1867,
      "start_time": 4673170.0,
      "end_time": 4675692.0,
      "text": "So next time we&#39;ll talk about some case studies"
    },
    {
      "index": 1868,
      "start_time": 4675690.0,
      "end_time": 4678440.0,
      "text": "about various CNN architectures."
    }
  ]
}