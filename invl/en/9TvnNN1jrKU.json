{
  "video_id": "9TvnNN1jrKU",
  "title": "Logistic regression",
  "es": 0,
  "json": [
    {
      "index": 1,
      "start_time": 70.0,
      "end_time": 6130.0,
      "text": "In statistics, logistic regression, or logit regression, is a type of probabilistic statistical"
    },
    {
      "index": 2,
      "start_time": 6130.0,
      "end_time": 12509.0,
      "text": "classification model. It is also used to predict a binary response from a binary predictor,"
    },
    {
      "index": 3,
      "start_time": 12509.0,
      "end_time": 17650.0,
      "text": "used for predicting the outcome of a categorical dependent variable based on one or more predictor"
    },
    {
      "index": 4,
      "start_time": 17650.0,
      "end_time": 24689.0,
      "text": "variables. That is, it is used in estimating the parameters of a qualitative response model."
    },
    {
      "index": 5,
      "start_time": 24689.0,
      "end_time": 29029.0,
      "text": "The probabilities describing the possible outcomes of a single trial are modeled, as"
    },
    {
      "index": 6,
      "start_time": 29029.0,
      "end_time": 35320.0,
      "text": "a function of the explanatory variables, using a logistic function. Frequently &quot;logistic"
    },
    {
      "index": 7,
      "start_time": 35320.0,
      "end_time": 39860.0,
      "text": "regression&quot; is used to refer specifically to the problem in which the dependent variable"
    },
    {
      "index": 8,
      "start_time": 39860.0,
      "end_time": 45300.0,
      "text": "is binary—that is, the number of available categories is two—while problems with more"
    },
    {
      "index": 9,
      "start_time": 45300.0,
      "end_time": 50949.0,
      "text": "than two categories are referred to as multinomial logistic regression or, if the multiple categories"
    },
    {
      "index": 10,
      "start_time": 50949.0,
      "end_time": 56710.0,
      "text": "are ordered, as ordered logistic regression. Logistic regression measures the relationship"
    },
    {
      "index": 11,
      "start_time": 56710.0,
      "end_time": 62019.0,
      "text": "between a categorical dependent variable and one or more independent variables, which are"
    },
    {
      "index": 12,
      "start_time": 62019.0,
      "end_time": 68700.0,
      "text": "usually continuous, by using probability scores as the predicted values of the dependent variable."
    },
    {
      "index": 13,
      "start_time": 68700.0,
      "end_time": 74140.0,
      "text": "As such it treats the same set of problems as does probit regression using similar techniques."
    },
    {
      "index": 14,
      "start_time": 74140.0,
      "end_time": 79680.0,
      "text": "Fields and examples of applications Logistic regression was put forth in the 1940s"
    },
    {
      "index": 15,
      "start_time": 79680.0,
      "end_time": 87189.0,
      "text": "as an alternative to Fisher&#39;s 1936 classification method, linear discriminant analysis. It is"
    },
    {
      "index": 16,
      "start_time": 87189.0,
      "end_time": 93270.0,
      "text": "used extensively in numerous disciplines, including the medical and social science fields."
    },
    {
      "index": 17,
      "start_time": 93270.0,
      "end_time": 99000.0,
      "text": "For example, the Trauma and Injury Severity Score, which is widely used to predict mortality"
    },
    {
      "index": 18,
      "start_time": 99000.0,
      "end_time": 106149.0,
      "text": "in injured patients, was originally developed by Boyd et al. using logistic regression."
    },
    {
      "index": 19,
      "start_time": 106149.0,
      "end_time": 110409.0,
      "text": "Logistic regression might be used to predict whether a patient has a given disease, based"
    },
    {
      "index": 20,
      "start_time": 110409.0,
      "end_time": 115689.0,
      "text": "on observed characteristics of the patient. Another example might be to predict whether"
    },
    {
      "index": 21,
      "start_time": 115689.0,
      "end_time": 121789.0,
      "text": "an American voter will vote Democratic or Republican, based on age, income, gender,"
    },
    {
      "index": 22,
      "start_time": 121789.0,
      "end_time": 128370.0,
      "text": "race, state of residence, votes in previous elections, etc. The technique can also be"
    },
    {
      "index": 23,
      "start_time": 128370.0,
      "end_time": 134200.0,
      "text": "used in engineering, especially for predicting the probability of failure of a given process,"
    },
    {
      "index": 24,
      "start_time": 134200.0,
      "end_time": 139910.0,
      "text": "system or product. It is also used in marketing applications such as prediction of a customer&#39;s"
    },
    {
      "index": 25,
      "start_time": 139910.0,
      "end_time": 146220.0,
      "text": "propensity to purchase a product or cease a subscription, etc. In economics it can be"
    },
    {
      "index": 26,
      "start_time": 146220.0,
      "end_time": 151260.0,
      "text": "used to predict the likelihood of a person&#39;s choosing to be in the labor force, and a business"
    },
    {
      "index": 27,
      "start_time": 151260.0,
      "end_time": 156840.0,
      "text": "application would be to predict the likehood of a homeowner defaulting on a mortgage. Conditional"
    },
    {
      "index": 28,
      "start_time": 156840.0,
      "end_time": 163400.0,
      "text": "random fields, an extension of logistic regression to sequential data, are used in natural language"
    },
    {
      "index": 29,
      "start_time": 163400.0,
      "end_time": 165980.0,
      "text": "processing. Basics"
    },
    {
      "index": 30,
      "start_time": 165980.0,
      "end_time": 172370.0,
      "text": "Logistic regression can be binomial or multinomial. Binomial or binary logistic regression deals"
    },
    {
      "index": 31,
      "start_time": 172370.0,
      "end_time": 176890.0,
      "text": "with situations in which the observed outcome for a dependent variable can have only two"
    },
    {
      "index": 32,
      "start_time": 176890.0,
      "end_time": 183140.0,
      "text": "possible types. Multinomial logistic regression deals with situations where the outcome can"
    },
    {
      "index": 33,
      "start_time": 183140.0,
      "end_time": 188770.0,
      "text": "have three or more possible types. In binary logistic regression, the outcome is usually"
    },
    {
      "index": 34,
      "start_time": 188770.0,
      "end_time": 194780.0,
      "text": "coded as &quot;0&quot; or &quot;1&quot;, as this leads to the most straightforward interpretation. If a"
    },
    {
      "index": 35,
      "start_time": 194780.0,
      "end_time": 199710.0,
      "text": "particular observed outcome for the dependent variable is the noteworthy possible outcome"
    },
    {
      "index": 36,
      "start_time": 199710.0,
      "end_time": 205910.0,
      "text": "it is usually coded as &quot;1&quot; and the contrary outcome as &quot;0&quot;. Logistic regression is used"
    },
    {
      "index": 37,
      "start_time": 205910.0,
      "end_time": 211220.0,
      "text": "to predict the odds of being a case based on the values of the independent variables."
    },
    {
      "index": 38,
      "start_time": 211220.0,
      "end_time": 215700.0,
      "text": "The odds are defined as the probability that a particular outcome is a case divided by"
    },
    {
      "index": 39,
      "start_time": 215700.0,
      "end_time": 221610.0,
      "text": "the probability that it is a noncase. Like other forms of regression analysis, logistic"
    },
    {
      "index": 40,
      "start_time": 221610.0,
      "end_time": 226190.0,
      "text": "regression makes use of one or more predictor variables that may be either continuous or"
    },
    {
      "index": 41,
      "start_time": 226190.0,
      "end_time": 233440.0,
      "text": "categorical data. Unlike ordinary linear regression, however, logistic regression is used for predicting"
    },
    {
      "index": 42,
      "start_time": 233440.0,
      "end_time": 239550.0,
      "text": "binary outcomes of the dependent variable rather than continuous outcomes. Given this"
    },
    {
      "index": 43,
      "start_time": 239550.0,
      "end_time": 243670.0,
      "text": "difference, it is necessary that logistic regression take the natural logarithm of the"
    },
    {
      "index": 44,
      "start_time": 243670.0,
      "end_time": 248670.0,
      "text": "odds of the dependent variable being a case to create a continuous criterion as a transformed"
    },
    {
      "index": 45,
      "start_time": 248670.0,
      "end_time": 253930.0,
      "text": "version of the dependent variable. Thus the logit transformation is referred to as the"
    },
    {
      "index": 46,
      "start_time": 253930.0,
      "end_time": 258970.0,
      "text": "link function in logistic regression—although the dependent variable in logistic regression"
    },
    {
      "index": 47,
      "start_time": 258970.00000000003,
      "end_time": 265460.0,
      "text": "is binomial, the logit is the continuous criterion upon which linear regression is conducted."
    },
    {
      "index": 48,
      "start_time": 265460.0,
      "end_time": 271780.0,
      "text": "The logit of success is then fit to the predictors using linear regression analysis. The predicted"
    },
    {
      "index": 49,
      "start_time": 271780.0,
      "end_time": 276070.0,
      "text": "value of the logit is converted back into predicted odds via the inverse of the natural"
    },
    {
      "index": 50,
      "start_time": 276070.0,
      "end_time": 282470.0,
      "text": "logarithm, namely the exponential function. Therefore, although the observed dependent"
    },
    {
      "index": 51,
      "start_time": 282470.0,
      "end_time": 287260.0,
      "text": "variable in logistic regression is a zero-or-one variable, the logistic regression estimates"
    },
    {
      "index": 52,
      "start_time": 287260.0,
      "end_time": 294220.0,
      "text": "the odds, as a continuous variable, that the dependent variable is a success. In some applications"
    },
    {
      "index": 53,
      "start_time": 294220.0,
      "end_time": 299680.0,
      "text": "the odds are all that is needed. In others, a specific yes-or-no prediction is needed"
    },
    {
      "index": 54,
      "start_time": 299680.0,
      "end_time": 305370.0,
      "text": "for whether the dependent variable is or is not a case; this categorical prediction can"
    },
    {
      "index": 55,
      "start_time": 305370.0,
      "end_time": 310330.0,
      "text": "be based on the computed odds of a success, with predicted odds above some chosen cut-off"
    },
    {
      "index": 56,
      "start_time": 310330.0,
      "end_time": 314540.0,
      "text": "value being translated into a prediction of a success."
    },
    {
      "index": 57,
      "start_time": 314540.0,
      "end_time": 318290.0,
      "text": "Logistic function, odds ratio, and logit"
    },
    {
      "index": 58,
      "start_time": 318290.0,
      "end_time": 323540.0,
      "text": "An explanation of logistic regression begins with an explanation of the logistic function,"
    },
    {
      "index": 59,
      "start_time": 323540.0,
      "end_time": 327020.0,
      "text": "which always takes on values between zero and one:"
    },
    {
      "index": 60,
      "start_time": 327020.0,
      "end_time": 332090.0,
      "text": "and viewing as a linear function of an explanatory variable , the logistic function can be written"
    },
    {
      "index": 61,
      "start_time": 332090.0,
      "end_time": 333480.0,
      "text": "as:"
    },
    {
      "index": 62,
      "start_time": 333480.0,
      "end_time": 337710.0,
      "text": "This will be interpreted as the probability of the dependent variable equalling a &quot;success&quot;"
    },
    {
      "index": 63,
      "start_time": 337710.0,
      "end_time": 343540.0,
      "text": "or &quot;case&quot; rather than a failure or non-case. We also define the inverse of the logistic"
    },
    {
      "index": 64,
      "start_time": 343540.0,
      "end_time": 345970.0,
      "text": "function, the logit:"
    },
    {
      "index": 65,
      "start_time": 345970.0,
      "end_time": 347660.0,
      "text": "and equivalently:"
    },
    {
      "index": 66,
      "start_time": 347660.0,
      "end_time": 352750.0,
      "text": "A graph of the logistic function is shown in Figure 1. The input is the value of and"
    },
    {
      "index": 67,
      "start_time": 352750.0,
      "end_time": 358420.0,
      "text": "the output is . The logistic function is useful because it can take an input with any value"
    },
    {
      "index": 68,
      "start_time": 358420.0,
      "end_time": 363920.0,
      "text": "from negative infinity to positive infinity, whereas the output is confined to values between"
    },
    {
      "index": 69,
      "start_time": 363920.0,
      "end_time": 370720.0,
      "text": "0 and 1 and hence is interpretable as a probability. In the above equations, refers to the logit"
    },
    {
      "index": 70,
      "start_time": 370720.0,
      "end_time": 375990.0,
      "text": "function of some given linear combination of the predictors, denotes the natural logarithm,"
    },
    {
      "index": 71,
      "start_time": 375990.0,
      "end_time": 381000.0,
      "text": "is the probability that the dependent variable equals a case, is the intercept from the linear"
    },
    {
      "index": 72,
      "start_time": 381000.0,
      "end_time": 386500.0,
      "text": "regression equation, is the regression coefficient multiplied by some value of the predictor,"
    },
    {
      "index": 73,
      "start_time": 386500.0,
      "end_time": 391940.0,
      "text": "and base denotes the exponential function. The formula for illustrates that the probability"
    },
    {
      "index": 74,
      "start_time": 391940.0,
      "end_time": 396590.0,
      "text": "of the dependent variable equaling a case is equal to the value of the logistic function"
    },
    {
      "index": 75,
      "start_time": 396590.0,
      "end_time": 401700.0,
      "text": "of the linear regression expression. This is important in that it shows that the value"
    },
    {
      "index": 76,
      "start_time": 401700.0,
      "end_time": 407000.0,
      "text": "of the linear regression expression can vary from negative to positive infinity and yet,"
    },
    {
      "index": 77,
      "start_time": 407000.0,
      "end_time": 413050.0,
      "text": "after transformation, the resulting expression for the probability ranges between 0 and 1."
    },
    {
      "index": 78,
      "start_time": 413050.0,
      "end_time": 418410.0,
      "text": "The equation for illustrates that the logit is equivalent to the linear regression expression."
    },
    {
      "index": 79,
      "start_time": 418410.0,
      "end_time": 423690.0,
      "text": "Likewise, the next equation illustrates that the odds of the dependent variable equaling"
    },
    {
      "index": 80,
      "start_time": 423690.0,
      "end_time": 429260.0,
      "text": "a case is equivalent to the exponential function of the linear regression expression. This"
    },
    {
      "index": 81,
      "start_time": 429260.0,
      "end_time": 433620.0,
      "text": "illustrates how the logit serves as a link function between the probability and the linear"
    },
    {
      "index": 82,
      "start_time": 433620.0,
      "end_time": 439310.0,
      "text": "regression expression. Given that the logit ranges between negative infinity and positive"
    },
    {
      "index": 83,
      "start_time": 439310.0,
      "end_time": 444490.0,
      "text": "infinity, it provides an adequate criterion upon which to conduct linear regression and"
    },
    {
      "index": 84,
      "start_time": 444490.0,
      "end_time": 448410.0,
      "text": "the logit is easily converted back into the odds."
    },
    {
      "index": 85,
      "start_time": 448410.0,
      "end_time": 452889.0,
      "text": "Multiple explanatory variables If there are multiple explanatory variables,"
    },
    {
      "index": 86,
      "start_time": 452889.0,
      "end_time": 457230.0,
      "text": "then the above expression can be revised to Then when this is used in the equation relating"
    },
    {
      "index": 87,
      "start_time": 457230.0,
      "end_time": 461530.0,
      "text": "the logged odds of a success to the values of the predictors, the linear regression will"
    },
    {
      "index": 88,
      "start_time": 461530.0,
      "end_time": 469350.0,
      "text": "be a multiple regression with m explanators; the parameters for all j = 0, 1, 2, ..., m"
    },
    {
      "index": 89,
      "start_time": 469350.0,
      "end_time": 472990.0,
      "text": "are all estimated. Model fitting"
    },
    {
      "index": 90,
      "start_time": 472990.0,
      "end_time": 475610.0,
      "text": "Estimation Maximum likelihood estimation"
    },
    {
      "index": 91,
      "start_time": 475610.0,
      "end_time": 481830.0,
      "text": "The regression coefficients are usually estimated using maximum likelihood estimation. Unlike"
    },
    {
      "index": 92,
      "start_time": 481830.0,
      "end_time": 487250.0,
      "text": "linear regression with normally distributed residuals, it is not possible to find a closed-form"
    },
    {
      "index": 93,
      "start_time": 487250.0,
      "end_time": 492960.0,
      "text": "expression for the coefficient values that maximizes the likelihood function, so an iterative"
    },
    {
      "index": 94,
      "start_time": 492960.0,
      "end_time": 498820.0,
      "text": "process must be used instead, for example Newton&#39;s method. This process begins with"
    },
    {
      "index": 95,
      "start_time": 498820.0,
      "end_time": 503820.0,
      "text": "a tentative solution, revises it slightly to see if it can be improved, and repeats"
    },
    {
      "index": 96,
      "start_time": 503820.0,
      "end_time": 508419.0,
      "text": "this revision until improvement is minute, at which point the process is said to have"
    },
    {
      "index": 97,
      "start_time": 508419.0,
      "end_time": 512479.0,
      "text": "converged. In some instances the model may not reach"
    },
    {
      "index": 98,
      "start_time": 512479.00000000006,
      "end_time": 517240.00000000006,
      "text": "convergence. When a model does not converge this indicates that the coefficients are not"
    },
    {
      "index": 99,
      "start_time": 517240.0,
      "end_time": 523120.0,
      "text": "meaningful because the iterative process was unable to find appropriate solutions. A failure"
    },
    {
      "index": 100,
      "start_time": 523120.0,
      "end_time": 528200.0,
      "text": "to converge may occur for a number of reasons: having a large proportion of predictors to"
    },
    {
      "index": 101,
      "start_time": 528200.0,
      "end_time": 533930.0,
      "text": "cases, multicollinearity, sparseness, or complete separation."
    },
    {
      "index": 102,
      "start_time": 533930.0,
      "end_time": 538410.0,
      "text": "Having a large proportion of variables to cases results in an overly conservative Wald"
    },
    {
      "index": 103,
      "start_time": 538410.0,
      "end_time": 544370.0,
      "text": "statistic and can lead to nonconvergence. Multicollinearity refers to unacceptably high"
    },
    {
      "index": 104,
      "start_time": 544370.0,
      "end_time": 551500.0,
      "text": "correlations between predictors. As multicollinearity increases, coefficients remain unbiased but"
    },
    {
      "index": 105,
      "start_time": 551500.0,
      "end_time": 557050.0,
      "text": "standard errors increase and the likelihood of model convergence decreases. To detect"
    },
    {
      "index": 106,
      "start_time": 557050.0,
      "end_time": 562180.0,
      "text": "multicollinearity amongst the predictors, one can conduct a linear regression analysis"
    },
    {
      "index": 107,
      "start_time": 562180.0,
      "end_time": 566470.0,
      "text": "with the predictors of interest for the sole purpose of examining the tolerance statistic"
    },
    {
      "index": 108,
      "start_time": 566470.0,
      "end_time": 571070.0,
      "text": "used to assess whether multicollinearity is unacceptably high."
    },
    {
      "index": 109,
      "start_time": 571070.0,
      "end_time": 576600.0,
      "text": "Sparseness in the data refers to having a large proportion of empty cells. Zero cell"
    },
    {
      "index": 110,
      "start_time": 576600.0,
      "end_time": 582980.0,
      "text": "counts are particularly problematic with categorical predictors. With continuous predictors, the"
    },
    {
      "index": 111,
      "start_time": 582980.0,
      "end_time": 588200.0,
      "text": "model can infer values for the zero cell counts, but this is not the case with categorical"
    },
    {
      "index": 112,
      "start_time": 588200.0,
      "end_time": 593440.0,
      "text": "predictors. The reason the model will not converge with zero cell counts for categorical"
    },
    {
      "index": 113,
      "start_time": 593440.0,
      "end_time": 598940.0,
      "text": "predictors is because the natural logarithm of zero is an undefined value, so final solutions"
    },
    {
      "index": 114,
      "start_time": 598940.0,
      "end_time": 604839.0,
      "text": "to the model cannot be reached. To remedy this problem, researchers may collapse categories"
    },
    {
      "index": 115,
      "start_time": 604839.0,
      "end_time": 610310.0,
      "text": "in a theoretically meaningful way or may consider adding a constant to all cells."
    },
    {
      "index": 116,
      "start_time": 610310.0,
      "end_time": 615029.0,
      "text": "Another numerical problem that may lead to a lack of convergence is complete separation,"
    },
    {
      "index": 117,
      "start_time": 615029.0,
      "end_time": 619210.0,
      "text": "which refers to the instance in which the predictors perfectly predict the criterion"
    },
    {
      "index": 118,
      "start_time": 619210.0,
      "end_time": 625990.0,
      "text": "– all cases are accurately classified. In such instances, one should reexamine the data,"
    },
    {
      "index": 119,
      "start_time": 625990.0,
      "end_time": 630830.0,
      "text": "as there is likely some kind of error. Although not a precise number, as a general"
    },
    {
      "index": 120,
      "start_time": 630830.0,
      "end_time": 636410.0,
      "text": "rule of thumb, logistic regression models require a minimum of 10 events per explaining"
    },
    {
      "index": 121,
      "start_time": 636410.0,
      "end_time": 640050.0,
      "text": "variable. Minimum chi-squared estimator for grouped"
    },
    {
      "index": 122,
      "start_time": 640050.0,
      "end_time": 643060.0,
      "text": "data While individual data will have a dependent"
    },
    {
      "index": 123,
      "start_time": 643060.0,
      "end_time": 647800.0,
      "text": "variable with a value of zero or one for every observation, with grouped data one observation"
    },
    {
      "index": 124,
      "start_time": 647800.0,
      "end_time": 653040.0,
      "text": "is on a group of people who all share the same characteristics; in this case the researcher"
    },
    {
      "index": 125,
      "start_time": 653040.0,
      "end_time": 657560.0,
      "text": "observes the proportion of people in the group for whom the response variable falls into"
    },
    {
      "index": 126,
      "start_time": 657560.0,
      "end_time": 663790.0,
      "text": "one category or the other. If this proportion is neither zero nor one for any group, the"
    },
    {
      "index": 127,
      "start_time": 663790.0,
      "end_time": 668350.0,
      "text": "minimum chi-squared estimator involves using weighted least squares to estimate a linear"
    },
    {
      "index": 128,
      "start_time": 668350.0,
      "end_time": 673390.0,
      "text": "model in which the dependent variable is the logit of the proportion: that is, the log"
    },
    {
      "index": 129,
      "start_time": 673390.0,
      "end_time": 678290.0,
      "text": "of the ratio of the fraction in one group to the fraction in the other group."
    },
    {
      "index": 130,
      "start_time": 678290.0,
      "end_time": 681770.0,
      "text": "Evaluating goodness of fit Goodness of fit in linear regression models"
    },
    {
      "index": 131,
      "start_time": 681770.0,
      "end_time": 688500.0,
      "text": "is generally measured using the R2. Since this has no direct analog in logistic regression,"
    },
    {
      "index": 132,
      "start_time": 688500.0,
      "end_time": 692690.0,
      "text": "various methods including the following can be used instead."
    },
    {
      "index": 133,
      "start_time": 692690.0,
      "end_time": 697980.0,
      "text": "Deviance and likelihood ratio tests In linear regression analysis, one is concerned"
    },
    {
      "index": 134,
      "start_time": 697980.0,
      "end_time": 703460.0,
      "text": "with partitioning variance via the sum of squares calculations – variance in the criterion"
    },
    {
      "index": 135,
      "start_time": 703460.0,
      "end_time": 709250.0,
      "text": "is essentially divided into variance accounted for by the predictors and residual variance."
    },
    {
      "index": 136,
      "start_time": 709250.0,
      "end_time": 716050.0,
      "text": "In logistic regression analysis, deviance is used in lieu of sum of squares calculations."
    },
    {
      "index": 137,
      "start_time": 716050.0,
      "end_time": 720110.0,
      "text": "Deviance is analogous to the sum of squares calculations in linear regression and is a"
    },
    {
      "index": 138,
      "start_time": 720110.0,
      "end_time": 725770.0,
      "text": "measure of the lack of fit to the data in a logistic regression model. Deviance is calculated"
    },
    {
      "index": 139,
      "start_time": 725770.0,
      "end_time": 731270.0,
      "text": "by comparing a given model with the saturated model – a model with a theoretically perfect"
    },
    {
      "index": 140,
      "start_time": 731270.0,
      "end_time": 736070.0,
      "text": "fit. This computation is called the likelihood-ratio test:"
    },
    {
      "index": 141,
      "start_time": 736070.0,
      "end_time": 742140.0,
      "text": "In the above equation D represents the deviance and ln represents the natural logarithm. The"
    },
    {
      "index": 142,
      "start_time": 742140.0,
      "end_time": 746930.0,
      "text": "log of the likelihood ratio will produce a negative value, so the product is multiplied"
    },
    {
      "index": 143,
      "start_time": 746930.0,
      "end_time": 752839.0,
      "text": "by negative two times its natural logarithm to produce a value with an approximate chi-squared"
    },
    {
      "index": 144,
      "start_time": 752839.0,
      "end_time": 757770.0,
      "text": "distribution. Smaller values indicate better fit as the fitted model deviates less from"
    },
    {
      "index": 145,
      "start_time": 757770.0,
      "end_time": 764290.0,
      "text": "the saturated model. When assessed upon a chi-square distribution, nonsignificant chi-square"
    },
    {
      "index": 146,
      "start_time": 764290.0,
      "end_time": 771300.0,
      "text": "values indicate very little unexplained variance and thus, good model fit. Conversely, a significant"
    },
    {
      "index": 147,
      "start_time": 771300.0,
      "end_time": 776580.0,
      "text": "chi-square value indicates that a significant amount of the variance is unexplained."
    },
    {
      "index": 148,
      "start_time": 776580.0,
      "end_time": 781450.0,
      "text": "Two measures of deviance are particularly important in logistic regression: null deviance"
    },
    {
      "index": 149,
      "start_time": 781450.0,
      "end_time": 786959.0,
      "text": "and model deviance. The null deviance represents the difference between a model with only the"
    },
    {
      "index": 150,
      "start_time": 786959.0,
      "end_time": 792860.0,
      "text": "intercept and the saturated model. And, the model deviance represents the difference between"
    },
    {
      "index": 151,
      "start_time": 792860.0,
      "end_time": 798470.0,
      "text": "a model with at least one predictor and the saturated model. In this respect, the null"
    },
    {
      "index": 152,
      "start_time": 798470.0,
      "end_time": 804220.0,
      "text": "model provides a baseline upon which to compare predictor models. Given that deviance is a"
    },
    {
      "index": 153,
      "start_time": 804220.0,
      "end_time": 809000.0,
      "text": "measure of the difference between a given model and the saturated model, smaller values"
    },
    {
      "index": 154,
      "start_time": 809000.0,
      "end_time": 814420.0,
      "text": "indicate better fit. Therefore, to assess the contribution of a predictor or set of"
    },
    {
      "index": 155,
      "start_time": 814420.0,
      "end_time": 819250.0,
      "text": "predictors, one can subtract the model deviance from the null deviance and assess the difference"
    },
    {
      "index": 156,
      "start_time": 819250.0,
      "end_time": 823580.0,
      "text": "on a chi-square distribution with degree of freedom equal to the difference in the number"
    },
    {
      "index": 157,
      "start_time": 823580.0,
      "end_time": 826640.0,
      "text": "of parameters estimated. Let"
    },
    {
      "index": 158,
      "start_time": 826640.0,
      "end_time": 827470.0,
      "text": "Then"
    },
    {
      "index": 159,
      "start_time": 827470.0,
      "end_time": 832680.0,
      "text": "If the model deviance is significantly smaller than the null deviance then one can conclude"
    },
    {
      "index": 160,
      "start_time": 832680.0,
      "end_time": 838670.0,
      "text": "that the predictor or set of predictors significantly improved model fit. This is analogous to the"
    },
    {
      "index": 161,
      "start_time": 838670.0,
      "end_time": 844060.0,
      "text": "F-test used in linear regression analysis to assess the significance of prediction."
    },
    {
      "index": 162,
      "start_time": 844060.0,
      "end_time": 847410.0,
      "text": "Pseudo-R2s In linear regression the squared multiple"
    },
    {
      "index": 163,
      "start_time": 847410.0,
      "end_time": 852720.0,
      "text": "correlation, R2 is used to assess goodness of fit as it represents the proportion of"
    },
    {
      "index": 164,
      "start_time": 852720.0,
      "end_time": 857880.0,
      "text": "variance in the criterion that is explained by the predictors. In logistic regression"
    },
    {
      "index": 165,
      "start_time": 857880.0,
      "end_time": 862920.0,
      "text": "analysis, there is no agreed upon analogous measure, but there are several competing measures"
    },
    {
      "index": 166,
      "start_time": 862920.0,
      "end_time": 868899.0,
      "text": "each with limitations. Three of the most commonly used indices are examined on this page beginning"
    },
    {
      "index": 167,
      "start_time": 868899.0,
      "end_time": 872750.0,
      "text": "with the likelihood ratio R2, R2L:"
    },
    {
      "index": 168,
      "start_time": 872750.0,
      "end_time": 878180.0,
      "text": "This is the most analogous index to the squared multiple correlation in linear regression."
    },
    {
      "index": 169,
      "start_time": 878180.0,
      "end_time": 882560.0,
      "text": "It represents the proportional reduction in the deviance wherein the deviance is treated"
    },
    {
      "index": 170,
      "start_time": 882560.0,
      "end_time": 887470.0,
      "text": "as a measure of variation analogous but not identical to the variance in linear regression"
    },
    {
      "index": 171,
      "start_time": 887470.0,
      "end_time": 893709.0,
      "text": "analysis. One limitation of the likelihood ratio R2 is that it is not monotonically related"
    },
    {
      "index": 172,
      "start_time": 893709.0,
      "end_time": 899080.0,
      "text": "to the odds ratio, meaning that it does not necessarily increase as the odds ratio increases"
    },
    {
      "index": 173,
      "start_time": 899080.0,
      "end_time": 903500.0,
      "text": "and does not necessarily decrease as the odds ratio decreases."
    },
    {
      "index": 174,
      "start_time": 903500.0,
      "end_time": 908680.0,
      "text": "The Cox and Snell R2 is an alternative index of goodness of fit related to the R2 value"
    },
    {
      "index": 175,
      "start_time": 908680.0,
      "end_time": 913990.0,
      "text": "from linear regression. The Cox and Snell index is problematic as its maximum value"
    },
    {
      "index": 176,
      "start_time": 913990.0,
      "end_time": 920459.0,
      "text": "is .75, when the variance is at its maximum. The Nagelkerke R2 provides a correction to"
    },
    {
      "index": 177,
      "start_time": 920459.0,
      "end_time": 926750.0,
      "text": "the Cox and Snell R2 so that the maximum value is equal to one. Nevertheless, the Cox and"
    },
    {
      "index": 178,
      "start_time": 926750.0,
      "end_time": 931570.0,
      "text": "Snell and likelihood ratio R2s show greater agreement with each other than either does"
    },
    {
      "index": 179,
      "start_time": 931570.0,
      "end_time": 938480.0,
      "text": "with the Nagelkerke R2. Of course, this might not be the case for values exceeding .75 as"
    },
    {
      "index": 180,
      "start_time": 938480.0,
      "end_time": 944440.0,
      "text": "the Cox and Snell index is capped at this value. The likelihood ratio R2 is often preferred"
    },
    {
      "index": 181,
      "start_time": 944440.0,
      "end_time": 949279.0,
      "text": "to the alternatives as it is most analogous to R2 in linear regression, is independent"
    },
    {
      "index": 182,
      "start_time": 949279.0,
      "end_time": 952860.0,
      "text": "of the base rate and varies between 0 and 1."
    },
    {
      "index": 183,
      "start_time": 952860.0,
      "end_time": 958930.0,
      "text": "A word of caution is in order when interpreting pseudo-R2 statistics. The reason these indices"
    },
    {
      "index": 184,
      "start_time": 958930.0,
      "end_time": 963899.0,
      "text": "of fit are referred to as pseudo R2 is because they do not represent the proportionate reduction"
    },
    {
      "index": 185,
      "start_time": 963899.0,
      "end_time": 970370.0,
      "text": "in error as the R2 in linear regression does. Linear regression assumes homoscedasticity,"
    },
    {
      "index": 186,
      "start_time": 970370.0,
      "end_time": 975579.0,
      "text": "that the error variance is the same for all values of the criterion. Logistic regression"
    },
    {
      "index": 187,
      "start_time": 975579.0,
      "end_time": 980480.0,
      "text": "will always be heteroscedastic – the error variances differ for each value of the predicted"
    },
    {
      "index": 188,
      "start_time": 980480.0,
      "end_time": 985820.0,
      "text": "score. For each value of the predicted score there would be a different value of the proportionate"
    },
    {
      "index": 189,
      "start_time": 985820.0,
      "end_time": 991660.0,
      "text": "reduction in error. Therefore, it is inappropriate to think of R2 as a proportionate reduction"
    },
    {
      "index": 190,
      "start_time": 991660.0,
      "end_time": 995670.0,
      "text": "in error in a universal sense in logistic regression."
    },
    {
      "index": 191,
      "start_time": 995670.0,
      "end_time": 1000860.0,
      "text": "Hosmer–Lemeshow test The Hosmer–Lemeshow test uses a test statistic"
    },
    {
      "index": 192,
      "start_time": 1000860.0,
      "end_time": 1005120.0,
      "text": "that asymptotically follows a distribution to assess whether or not the observed event"
    },
    {
      "index": 193,
      "start_time": 1005120.0,
      "end_time": 1010649.0,
      "text": "rates match expected event rates in subgroups of the model population."
    },
    {
      "index": 194,
      "start_time": 1010650.0,
      "end_time": 1015411.0,
      "text": "Evaluating binary classification performance If the estimated probabilities are to be used"
    },
    {
      "index": 195,
      "start_time": 1015410.0,
      "end_time": 1020300.0,
      "text": "to classify each observation of independent variable values as predicting the category"
    },
    {
      "index": 196,
      "start_time": 1020300.0,
      "end_time": 1025439.0,
      "text": "that the dependent variable is found in, the various methods below for judging the model&#39;s"
    },
    {
      "index": 197,
      "start_time": 1025440.0,
      "end_time": 1030830.0,
      "text": "suitability in out-of-sample forecasting can also be used on the data that were used for"
    },
    {
      "index": 198,
      "start_time": 1030829.9999999999,
      "end_time": 1037369.9999999999,
      "text": "estimation—accuracy, precision, recall, specificity and negative predictive value."
    },
    {
      "index": 199,
      "start_time": 1037369.9999999999,
      "end_time": 1042289.9999999999,
      "text": "In each of these evaluative methods, an aspect of the model&#39;s effectiveness in assigning"
    },
    {
      "index": 200,
      "start_time": 1042290.0,
      "end_time": 1047150.0,
      "text": "instances to the correct categories is measured. Coefficients"
    },
    {
      "index": 201,
      "start_time": 1047150.0000000001,
      "end_time": 1051620.0,
      "text": "After fitting the model, it is likely that researchers will want to examine the contribution"
    },
    {
      "index": 202,
      "start_time": 1051620.0,
      "end_time": 1058240.0,
      "text": "of individual predictors. To do so, they will want to examine the regression coefficients."
    },
    {
      "index": 203,
      "start_time": 1058240.0,
      "end_time": 1063170.0,
      "text": "In linear regression, the regression coefficients represent the change in the criterion for"
    },
    {
      "index": 204,
      "start_time": 1063170.0,
      "end_time": 1069510.0,
      "text": "each unit change in the predictor. In logistic regression, however, the regression coefficients"
    },
    {
      "index": 205,
      "start_time": 1069510.0,
      "end_time": 1074691.0,
      "text": "represent the change in the logit for each unit change in the predictor. Given that the"
    },
    {
      "index": 206,
      "start_time": 1074690.0,
      "end_time": 1080220.0,
      "text": "logit is not intuitive, researchers are likely to focus on a predictor&#39;s effect on the exponential"
    },
    {
      "index": 207,
      "start_time": 1080220.0,
      "end_time": 1086649.0,
      "text": "function of the regression coefficient – the odds ratio. In linear regression, the significance"
    },
    {
      "index": 208,
      "start_time": 1086650.0,
      "end_time": 1093040.0,
      "text": "of a regression coefficient is assessed by computing a t-test. In logistic regression,"
    },
    {
      "index": 209,
      "start_time": 1093040.0,
      "end_time": 1097140.0,
      "text": "there are several different tests designed to assess the significance of an individual"
    },
    {
      "index": 210,
      "start_time": 1097140.0,
      "end_time": 1103110.0,
      "text": "predictor, most notably the likelihood ratio test and the Wald statistic."
    },
    {
      "index": 211,
      "start_time": 1103110.0,
      "end_time": 1106731.0,
      "text": "Likelihood ratio test The likelihood-ratio test discussed above"
    },
    {
      "index": 212,
      "start_time": 1106730.0,
      "end_time": 1111840.0,
      "text": "to assess model fit is also the recommended procedure to assess the contribution of individual"
    },
    {
      "index": 213,
      "start_time": 1111840.0,
      "end_time": 1117480.0,
      "text": "&quot;predictors&quot; to a given model. In the case of a single predictor model, one simply compares"
    },
    {
      "index": 214,
      "start_time": 1117480.0,
      "end_time": 1122009.0,
      "text": "the deviance of the predictor model with that of the null model on a chi-square distribution"
    },
    {
      "index": 215,
      "start_time": 1122010.0,
      "end_time": 1128050.0,
      "text": "with a single degree of freedom. If the predictor model has a significantly smaller deviance,"
    },
    {
      "index": 216,
      "start_time": 1128050.0,
      "end_time": 1132920.0,
      "text": "then one can conclude that there is a significant association between the &quot;predictor&quot; and the"
    },
    {
      "index": 217,
      "start_time": 1132920.0,
      "end_time": 1138170.0,
      "text": "outcome. Although some common statistical packages do provide likelihood ratio test"
    },
    {
      "index": 218,
      "start_time": 1138170.0,
      "end_time": 1143150.0,
      "text": "statistics, without this computationally intensive test it would be more difficult to assess"
    },
    {
      "index": 219,
      "start_time": 1143150.0,
      "end_time": 1148481.0,
      "text": "the contribution of individual predictors in the multiple logistic regression case."
    },
    {
      "index": 220,
      "start_time": 1148480.0,
      "end_time": 1153909.0,
      "text": "To assess the contribution of individual predictors one can enter the predictors hierarchically,"
    },
    {
      "index": 221,
      "start_time": 1153910.0,
      "end_time": 1158410.0,
      "text": "comparing each new model with the previous to determine the contribution of each predictor."
    },
    {
      "index": 222,
      "start_time": 1158410.0,
      "end_time": 1163961.0,
      "text": "(There is considerable debate among statisticians regarding the appropriateness of so-called"
    },
    {
      "index": 223,
      "start_time": 1163960.0,
      "end_time": 1169039.0,
      "text": "&quot;stepwise&quot; procedures. They do not preserve the nominal statistical properties and can"
    },
    {
      "index": 224,
      "start_time": 1169040.0,
      "end_time": 1172490.0,
      "text": "be very misleading.[1] Wald statistic"
    },
    {
      "index": 225,
      "start_time": 1172490.0,
      "end_time": 1178160.0,
      "text": "Alternatively, when assessing the contribution of individual predictors in a given model,"
    },
    {
      "index": 226,
      "start_time": 1178160.0,
      "end_time": 1183831.0,
      "text": "one may examine the significance of the Wald statistic. The Wald statistic, analogous to"
    },
    {
      "index": 227,
      "start_time": 1183830.0,
      "end_time": 1189609.0,
      "text": "the t-test in linear regression, is used to assess the significance of coefficients. The"
    },
    {
      "index": 228,
      "start_time": 1189610.0,
      "end_time": 1193961.0,
      "text": "Wald statistic is the ratio of the square of the regression coefficient to the square"
    },
    {
      "index": 229,
      "start_time": 1193960.0,
      "end_time": 1198859.0,
      "text": "of the standard error of the coefficient and is asymptotically distributed as a chi-square"
    },
    {
      "index": 230,
      "start_time": 1198860.0,
      "end_time": 1200831.0,
      "text": "distribution."
    },
    {
      "index": 231,
      "start_time": 1200830.0,
      "end_time": 1205429.0,
      "text": "Although several statistical packages report the Wald statistic to assess the contribution"
    },
    {
      "index": 232,
      "start_time": 1205430.0,
      "end_time": 1211520.0,
      "text": "of individual predictors, the Wald statistic has limitations. When the regression coefficient"
    },
    {
      "index": 233,
      "start_time": 1211520.0,
      "end_time": 1216971.0,
      "text": "is large, the standard error of the regression coefficient also tends to be large increasing"
    },
    {
      "index": 234,
      "start_time": 1216970.0,
      "end_time": 1222729.0,
      "text": "the probability of Type-II error. The Wald statistic also tends to be biased when data"
    },
    {
      "index": 235,
      "start_time": 1222730.0,
      "end_time": 1226430.0,
      "text": "are sparse. Case-control sampling"
    },
    {
      "index": 236,
      "start_time": 1226430.0,
      "end_time": 1231180.0,
      "text": "Suppose cases are rare. Then we might wish to sample them more frequently than their"
    },
    {
      "index": 237,
      "start_time": 1231180.0,
      "end_time": 1237221.0,
      "text": "prevalence in the population. For example, suppose there is a disease that affects 1"
    },
    {
      "index": 238,
      "start_time": 1237220.0,
      "end_time": 1242539.0,
      "text": "person in 10,000 and to collect our data we need to do a complete physical. It may be"
    },
    {
      "index": 239,
      "start_time": 1242540.0,
      "end_time": 1246951.0,
      "text": "too expensive to do thousands of physicals of healthy people in order to get data on"
    },
    {
      "index": 240,
      "start_time": 1246950.0,
      "end_time": 1253840.0,
      "text": "only a few diseased individuals. Thus, we may evaluate more diseased individuals. This"
    },
    {
      "index": 241,
      "start_time": 1253840.0,
      "end_time": 1259529.0,
      "text": "is also called unbalanced data. As a rule of thumb, sampling controls at a rate of five"
    },
    {
      "index": 242,
      "start_time": 1259530.0,
      "end_time": 1263441.0,
      "text": "times the number of cases is sufficient to get enough control data."
    },
    {
      "index": 243,
      "start_time": 1263440.0,
      "end_time": 1269239.0,
      "text": "If we form a logistic model from such data, if the model is correct, the parameters are"
    },
    {
      "index": 244,
      "start_time": 1269240.0,
      "end_time": 1275191.0,
      "text": "all correct except for . We can correct if we know the true prevalence as follows:"
    },
    {
      "index": 245,
      "start_time": 1275190.0,
      "end_time": 1279029.0,
      "text": "where is the true prevalence and is the prevalence in the sample."
    },
    {
      "index": 246,
      "start_time": 1279030.0,
      "end_time": 1283461.0,
      "text": "Formal mathematical specification There are various equivalent specifications"
    },
    {
      "index": 247,
      "start_time": 1283460.0,
      "end_time": 1288909.0,
      "text": "of logistic regression, which fit into different types of more general models. These different"
    },
    {
      "index": 248,
      "start_time": 1288910.0,
      "end_time": 1293321.0,
      "text": "specifications allow for different sorts of useful generalizations."
    },
    {
      "index": 249,
      "start_time": 1293320.0,
      "end_time": 1296649.0,
      "text": "Setup The basic setup of logistic regression is"
    },
    {
      "index": 250,
      "start_time": 1296650.0,
      "end_time": 1302110.0,
      "text": "the same as for standard linear regression. It is assumed that we have a series of N observed"
    },
    {
      "index": 251,
      "start_time": 1302110.0,
      "end_time": 1311331.0,
      "text": "data points. Each data point i consists of a set of m explanatory variables x1,i ... xm,i,"
    },
    {
      "index": 252,
      "start_time": 1311330.0,
      "end_time": 1317289.0,
      "text": "and an associated binary-valued outcome variable Yi, i.e. it can assume only the two possible"
    },
    {
      "index": 253,
      "start_time": 1317290.0,
      "end_time": 1322780.0,
      "text": "values 0 or 1. The goal of logistic regression is to explain the relationship between the"
    },
    {
      "index": 254,
      "start_time": 1322780.0,
      "end_time": 1327540.0,
      "text": "explanatory variables and the outcome, so that an outcome can be predicted for a new"
    },
    {
      "index": 255,
      "start_time": 1327540.0,
      "end_time": 1331750.0,
      "text": "set of explanatory variables. Some examples:"
    },
    {
      "index": 256,
      "start_time": 1331750.0,
      "end_time": 1336730.0,
      "text": "The observed outcomes are the presence or absence of a given disease in a set of patients,"
    },
    {
      "index": 257,
      "start_time": 1336730.0,
      "end_time": 1342601.0,
      "text": "and the explanatory variables might be characteristics of the patients thought to be pertinent."
    },
    {
      "index": 258,
      "start_time": 1342600.0,
      "end_time": 1347299.0,
      "text": "The observed outcomes are the votes of a set of people in an election, and the explanatory"
    },
    {
      "index": 259,
      "start_time": 1347300.0,
      "end_time": 1353060.0,
      "text": "variables are the demographic characteristics of each person. In such a case, one of the"
    },
    {
      "index": 260,
      "start_time": 1353060.0,
      "end_time": 1358071.0,
      "text": "two outcomes is arbitrarily coded as 1, and the other as 0."
    },
    {
      "index": 261,
      "start_time": 1358070.0,
      "end_time": 1363080.0,
      "text": "As in linear regression, the outcome variables Yi are assumed to depend on the explanatory"
    },
    {
      "index": 262,
      "start_time": 1363080.0,
      "end_time": 1369799.0,
      "text": "variables x1,i ... xm,i. Explanatory variables"
    },
    {
      "index": 263,
      "start_time": 1369800.0,
      "end_time": 1375341.0,
      "text": "As shown above in the above examples, the explanatory variables may be of any type:"
    },
    {
      "index": 264,
      "start_time": 1375340.0,
      "end_time": 1382229.0,
      "text": "real-valued, binary, categorical, etc. The main distinction is between continuous variables"
    },
    {
      "index": 265,
      "start_time": 1382230.0,
      "end_time": 1387971.0,
      "text": "and discrete variables. Discrete variables referring to more than two possible choices"
    },
    {
      "index": 266,
      "start_time": 1387970.0,
      "end_time": 1393809.0,
      "text": "are typically coded using dummy variables, that is, separate explanatory variables taking"
    },
    {
      "index": 267,
      "start_time": 1393810.0,
      "end_time": 1399890.0,
      "text": "the value 0 or 1 are created for each possible value of the discrete variable, with a 1 meaning"
    },
    {
      "index": 268,
      "start_time": 1399890.0,
      "end_time": 1405120.0,
      "text": "&quot;variable does have the given value&quot; and a 0 meaning &quot;variable does not have that value&quot;."
    },
    {
      "index": 269,
      "start_time": 1405120.0,
      "end_time": 1410050.0,
      "text": "For example, a four-way discrete variable of blood type with the possible values &quot;A,"
    },
    {
      "index": 270,
      "start_time": 1410050.0,
      "end_time": 1417260.0,
      "text": "B, AB, O&quot; can be converted to four separate two-way dummy variables, &quot;is-A, is-B, is-AB,"
    },
    {
      "index": 271,
      "start_time": 1417260.0,
      "end_time": 1422461.0,
      "text": "is-O&quot;, where only one of them has the value 1 and all the rest have the value 0. This"
    },
    {
      "index": 272,
      "start_time": 1422460.0,
      "end_time": 1427049.0,
      "text": "allows for separate regression coefficients to be matched for each possible value of the"
    },
    {
      "index": 273,
      "start_time": 1427050.0,
      "end_time": 1430000.0,
      "text": "discrete variable. Outcome variables"
    },
    {
      "index": 274,
      "start_time": 1430000.0,
      "end_time": 1435461.0,
      "text": "Formally, the outcomes Yi are described as being Bernoulli-distributed data, where each"
    },
    {
      "index": 275,
      "start_time": 1435460.0,
      "end_time": 1441220.0,
      "text": "outcome is determined by an unobserved probability pi that is specific to the outcome at hand,"
    },
    {
      "index": 276,
      "start_time": 1441220.0,
      "end_time": 1446349.0,
      "text": "but related to the explanatory variables. This can be expressed in any of the following"
    },
    {
      "index": 277,
      "start_time": 1446350.0,
      "end_time": 1448030.0,
      "text": "equivalent forms:"
    },
    {
      "index": 278,
      "start_time": 1448030.0,
      "end_time": 1453280.0,
      "text": "The meanings of these four lines are: The first line expresses the probability distribution"
    },
    {
      "index": 279,
      "start_time": 1453280.0,
      "end_time": 1458471.0,
      "text": "of each Yi: Conditioned on the explanatory variables, it follows a Bernoulli distribution"
    },
    {
      "index": 280,
      "start_time": 1458470.0,
      "end_time": 1464889.0,
      "text": "with parameters pi, the probability of the outcome of 1 for trial i. As noted above,"
    },
    {
      "index": 281,
      "start_time": 1464890.0,
      "end_time": 1469500.0,
      "text": "each separate trial has its own probability of success, just as each trial has its own"
    },
    {
      "index": 282,
      "start_time": 1469500.0,
      "end_time": 1476170.0,
      "text": "explanatory variables. The probability of success pi is not observed, only the outcome"
    },
    {
      "index": 283,
      "start_time": 1476170.0,
      "end_time": 1480050.0,
      "text": "of an individual Bernoulli trial using that probability."
    },
    {
      "index": 284,
      "start_time": 1480050.0,
      "end_time": 1485060.0,
      "text": "The second line expresses the fact that the expected value of each Yi is equal to the"
    },
    {
      "index": 285,
      "start_time": 1485060.0,
      "end_time": 1490290.0,
      "text": "probability of success pi, which is a general property of the Bernoulli distribution. In"
    },
    {
      "index": 286,
      "start_time": 1490290.0,
      "end_time": 1495831.0,
      "text": "other words, if we run a large number of Bernoulli trials using the same probability of success"
    },
    {
      "index": 287,
      "start_time": 1495830.0,
      "end_time": 1501239.0,
      "text": "pi, then take the average of all the 1 and 0 outcomes, then the result would be close"
    },
    {
      "index": 288,
      "start_time": 1501240.0,
      "end_time": 1507560.0,
      "text": "to pi. This is because doing an average this way simply computes the proportion of successes"
    },
    {
      "index": 289,
      "start_time": 1507560.0,
      "end_time": 1512760.0,
      "text": "seen, which we expect to converge to the underlying probability of success."
    },
    {
      "index": 290,
      "start_time": 1512760.0,
      "end_time": 1517920.0,
      "text": "The third line writes out the probability mass function of the Bernoulli distribution,"
    },
    {
      "index": 291,
      "start_time": 1517920.0,
      "end_time": 1522150.0,
      "text": "specifying the probability of seeing each of the two possible outcomes."
    },
    {
      "index": 292,
      "start_time": 1522150.0,
      "end_time": 1526660.0,
      "text": "The fourth line is another way of writing the probability mass function, which avoids"
    },
    {
      "index": 293,
      "start_time": 1526660.0,
      "end_time": 1532560.0,
      "text": "having to write separate cases and is more convenient for certain types of calculations."
    },
    {
      "index": 294,
      "start_time": 1532560.0,
      "end_time": 1538841.0,
      "text": "This relies on the fact that Yi can take only the value 0 or 1. In each case, one of the"
    },
    {
      "index": 295,
      "start_time": 1538840.0,
      "end_time": 1543609.0,
      "text": "exponents will be 1, &quot;choosing&quot; the value under it, while the other is 0, &quot;canceling"
    },
    {
      "index": 296,
      "start_time": 1543610.0,
      "end_time": 1550730.0,
      "text": "out&quot; the value under it. Hence, the outcome is either pi or 1 − pi, as in the previous"
    },
    {
      "index": 297,
      "start_time": 1550730.0,
      "end_time": 1552910.0,
      "text": "line. Linear predictor function"
    },
    {
      "index": 298,
      "start_time": 1552910.0,
      "end_time": 1557980.0,
      "text": "The basic idea of logistic regression is to use the mechanism already developed for linear"
    },
    {
      "index": 299,
      "start_time": 1557980.0,
      "end_time": 1563010.0,
      "text": "regression by modeling the probability pi using a linear predictor function, i.e. a"
    },
    {
      "index": 300,
      "start_time": 1563010.0,
      "end_time": 1567850.0,
      "text": "linear combination of the explanatory variables and a set of regression coefficients that"
    },
    {
      "index": 301,
      "start_time": 1567850.0,
      "end_time": 1573170.0,
      "text": "are specific to the model at hand but the same for all trials. The linear predictor"
    },
    {
      "index": 302,
      "start_time": 1573170.0,
      "end_time": 1576260.0,
      "text": "function for a particular data point i is written as:"
    },
    {
      "index": 303,
      "start_time": 1576260.0,
      "end_time": 1581760.0,
      "text": "where are regression coefficients indicating the relative effect of a particular explanatory"
    },
    {
      "index": 304,
      "start_time": 1581760.0,
      "end_time": 1586520.0,
      "text": "variable on the outcome. The model is usually put into a more compact"
    },
    {
      "index": 305,
      "start_time": 1586520.0,
      "end_time": 1592250.0,
      "text": "form as follows: The regression coefficients β0, β1, ..., βm"
    },
    {
      "index": 306,
      "start_time": 1592250.0,
      "end_time": 1597711.0,
      "text": "are grouped into a single vector β of size m + 1."
    },
    {
      "index": 307,
      "start_time": 1597710.0,
      "end_time": 1604320.0,
      "text": "For each data point i, an additional explanatory pseudo-variable x0,i is added, with a fixed"
    },
    {
      "index": 308,
      "start_time": 1604320.0,
      "end_time": 1609639.0,
      "text": "value of 1, corresponding to the intercept coefficient β0."
    },
    {
      "index": 309,
      "start_time": 1609640.0,
      "end_time": 1617591.0,
      "text": "The resulting explanatory variables x0,i, x1,i, ..., xm,i are then grouped into a single"
    },
    {
      "index": 310,
      "start_time": 1617590.0,
      "end_time": 1623190.0,
      "text": "vector Xi of size m + 1. This makes it possible to write the linear"
    },
    {
      "index": 311,
      "start_time": 1623190.0,
      "end_time": 1625639.0,
      "text": "predictor function as follows:"
    },
    {
      "index": 312,
      "start_time": 1625640.0,
      "end_time": 1628870.0,
      "text": "using the notation for a dot product between two vectors."
    },
    {
      "index": 313,
      "start_time": 1628870.0,
      "end_time": 1634630.0,
      "text": "As a generalized linear model The particular model used by logistic regression,"
    },
    {
      "index": 314,
      "start_time": 1634630.0,
      "end_time": 1639130.0,
      "text": "which distinguishes it from standard linear regression and from other types of regression"
    },
    {
      "index": 315,
      "start_time": 1639130.0,
      "end_time": 1644081.0,
      "text": "analysis used for binary-valued outcomes, is the way the probability of a particular"
    },
    {
      "index": 316,
      "start_time": 1644080.0,
      "end_time": 1647739.0,
      "text": "outcome is linked to the linear predictor function:"
    },
    {
      "index": 317,
      "start_time": 1647740.0,
      "end_time": 1652470.0,
      "text": "Written using the more compact notation described above, this is:"
    },
    {
      "index": 318,
      "start_time": 1652470.0,
      "end_time": 1657720.0,
      "text": "This formulation expresses logistic regression as a type of generalized linear model, which"
    },
    {
      "index": 319,
      "start_time": 1657720.0,
      "end_time": 1663140.0,
      "text": "predicts variables with various types of probability distributions by fitting a linear predictor"
    },
    {
      "index": 320,
      "start_time": 1663140.0,
      "end_time": 1668030.0,
      "text": "function of the above form to some sort of arbitrary transformation of the expected value"
    },
    {
      "index": 321,
      "start_time": 1668030.0,
      "end_time": 1672341.0,
      "text": "of the variable. The intuition for transforming using the logit"
    },
    {
      "index": 322,
      "start_time": 1672340.0,
      "end_time": 1677840.0,
      "text": "function was explained above. It also has the practical effect of converting the probability"
    },
    {
      "index": 323,
      "start_time": 1677840.0,
      "end_time": 1682840.0,
      "text": "to a variable that ranges over — thereby matching the potential range of the linear"
    },
    {
      "index": 324,
      "start_time": 1682840.0,
      "end_time": 1686349.0,
      "text": "prediction function on the right side of the equation."
    },
    {
      "index": 325,
      "start_time": 1686350.0,
      "end_time": 1691140.0,
      "text": "Note that both the probabilities pi and the regression coefficients are unobserved, and"
    },
    {
      "index": 326,
      "start_time": 1691140.0,
      "end_time": 1696240.0,
      "text": "the means of determining them is not part of the model itself. They are typically determined"
    },
    {
      "index": 327,
      "start_time": 1696240.0,
      "end_time": 1702441.0,
      "text": "by some sort of optimization procedure, e.g. maximum likelihood estimation, that finds"
    },
    {
      "index": 328,
      "start_time": 1702440.0,
      "end_time": 1707960.0,
      "text": "values that best fit the observed data, usually subject to regularization conditions that"
    },
    {
      "index": 329,
      "start_time": 1707960.0,
      "end_time": 1714700.0,
      "text": "seek to exclude unlikely values, e.g. extremely large values for any of the regression coefficients."
    },
    {
      "index": 330,
      "start_time": 1714700.0,
      "end_time": 1721269.0,
      "text": "The use of a regularization condition is equivalent to doing maximum a posteriori estimation,"
    },
    {
      "index": 331,
      "start_time": 1721270.0,
      "end_time": 1727290.0,
      "text": "an extension of maximum likelihood. Whether or not regularization is used, it is usually"
    },
    {
      "index": 332,
      "start_time": 1727290.0,
      "end_time": 1733530.0,
      "text": "not possible to find a closed-form solution; instead, an iterative numerical method must"
    },
    {
      "index": 333,
      "start_time": 1733530.0,
      "end_time": 1740110.0,
      "text": "be used, such as iteratively reweighted least squares or, more commonly these days, a quasi-Newton"
    },
    {
      "index": 334,
      "start_time": 1740110.0,
      "end_time": 1746691.0,
      "text": "method such as the L-BFGS method. The interpretation of the βj parameter estimates"
    },
    {
      "index": 335,
      "start_time": 1746690.0,
      "end_time": 1752299.0,
      "text": "is as the additive effect on the log of the odds for a unit change in the jth explanatory"
    },
    {
      "index": 336,
      "start_time": 1752300.0,
      "end_time": 1758490.0,
      "text": "variable. In the case of a dichotomous explanatory variable, for instance gender, is the estimate"
    },
    {
      "index": 337,
      "start_time": 1758490.0,
      "end_time": 1763920.0,
      "text": "of the odds of having the outcome for, say, males compared with females."
    },
    {
      "index": 338,
      "start_time": 1763920.0,
      "end_time": 1768410.0,
      "text": "An equivalent formula uses the inverse of the logit function, which is the logistic"
    },
    {
      "index": 339,
      "start_time": 1768410.0,
      "end_time": 1770720.0,
      "text": "function, i.e.:"
    },
    {
      "index": 340,
      "start_time": 1770720.0,
      "end_time": 1774870.0,
      "text": "The formula can also be written as a probability distribution:"
    },
    {
      "index": 341,
      "start_time": 1774870.0,
      "end_time": 1779071.0,
      "text": "As a latent-variable model The above model has an equivalent formulation"
    },
    {
      "index": 342,
      "start_time": 1779070.0,
      "end_time": 1784309.0,
      "text": "as a latent-variable model. This formulation is common in the theory of discrete choice"
    },
    {
      "index": 343,
      "start_time": 1784310.0,
      "end_time": 1790640.0,
      "text": "models, and makes it easier to extend to certain more complicated models with multiple, correlated"
    },
    {
      "index": 344,
      "start_time": 1790640.0,
      "end_time": 1796130.0,
      "text": "choices, as well as to compare logistic regression to the closely related probit model."
    },
    {
      "index": 345,
      "start_time": 1796130.0,
      "end_time": 1801740.0,
      "text": "Imagine that, for each trial i, there is a continuous latent variable Yi* that is distributed"
    },
    {
      "index": 346,
      "start_time": 1801740.0,
      "end_time": 1803060.0,
      "text": "as follows:"
    },
    {
      "index": 347,
      "start_time": 1803060.0,
      "end_time": 1803951.0,
      "text": "where"
    },
    {
      "index": 348,
      "start_time": 1803950.0,
      "end_time": 1809059.0,
      "text": "i.e. the latent variable can be written directly in terms of the linear predictor function"
    },
    {
      "index": 349,
      "start_time": 1809060.0,
      "end_time": 1813951.0,
      "text": "and an additive random error variable that is distributed according to a standard logistic"
    },
    {
      "index": 350,
      "start_time": 1813950.0,
      "end_time": 1817469.0,
      "text": "distribution. Then Yi can be viewed as an indicator for"
    },
    {
      "index": 351,
      "start_time": 1817470.0,
      "end_time": 1820780.0,
      "text": "whether this latent variable is positive:"
    },
    {
      "index": 352,
      "start_time": 1820780.0,
      "end_time": 1825990.0,
      "text": "The choice of modeling the error variable specifically with a standard logistic distribution,"
    },
    {
      "index": 353,
      "start_time": 1825990.0,
      "end_time": 1830560.0,
      "text": "rather than a general logistic distribution with the location and scale set to arbitrary"
    },
    {
      "index": 354,
      "start_time": 1830560.0,
      "end_time": 1836800.0,
      "text": "values, seems restrictive, but in fact it is not. It must be kept in mind that we can"
    },
    {
      "index": 355,
      "start_time": 1836800.0,
      "end_time": 1842050.0,
      "text": "choose the regression coefficients ourselves, and very often can use them to offset changes"
    },
    {
      "index": 356,
      "start_time": 1842050.0,
      "end_time": 1848390.0,
      "text": "in the parameters of the error variable&#39;s distribution. For example, a logistic error-variable"
    },
    {
      "index": 357,
      "start_time": 1848390.0,
      "end_time": 1854040.0,
      "text": "distribution with a non-zero location parameter μ is equivalent to a distribution with a"
    },
    {
      "index": 358,
      "start_time": 1854040.0,
      "end_time": 1861020.0,
      "text": "zero location parameter, where μ has been added to the intercept coefficient. Both situations"
    },
    {
      "index": 359,
      "start_time": 1861020.0,
      "end_time": 1867540.0,
      "text": "produce the same value for Yi* regardless of settings of explanatory variables. Similarly,"
    },
    {
      "index": 360,
      "start_time": 1867540.0,
      "end_time": 1872280.0,
      "text": "an arbitrary scale parameter s is equivalent to setting the scale parameter to 1 and then"
    },
    {
      "index": 361,
      "start_time": 1872280.0,
      "end_time": 1878211.0,
      "text": "dividing all regression coefficients by s. In the latter case, the resulting value of"
    },
    {
      "index": 362,
      "start_time": 1878210.0,
      "end_time": 1883739.0,
      "text": "Yi* will be smaller by a factor of s than in the former case, for all sets of explanatory"
    },
    {
      "index": 363,
      "start_time": 1883740.0,
      "end_time": 1889120.0,
      "text": "variables — but critically, it will always remain on the same side of 0, and hence lead"
    },
    {
      "index": 364,
      "start_time": 1889120.0,
      "end_time": 1893120.0,
      "text": "to the same Yi choice. (Note that this predicts that the irrelevancy"
    },
    {
      "index": 365,
      "start_time": 1893120.0,
      "end_time": 1897711.0,
      "text": "of the scale parameter may not carry over into more complex models where more than two"
    },
    {
      "index": 366,
      "start_time": 1897710.0,
      "end_time": 1902389.0,
      "text": "choices are available.) It turns out that this formulation is exactly"
    },
    {
      "index": 367,
      "start_time": 1902390.0,
      "end_time": 1907201.0,
      "text": "equivalent to the preceding one, phrased in terms of the generalized linear model and"
    },
    {
      "index": 368,
      "start_time": 1907200.0,
      "end_time": 1912789.0,
      "text": "without any latent variables. This can be shown as follows, using the fact that the"
    },
    {
      "index": 369,
      "start_time": 1912790.0,
      "end_time": 1918400.0,
      "text": "cumulative distribution function of the standard logistic distribution is the logistic function,"
    },
    {
      "index": 370,
      "start_time": 1918400.0,
      "end_time": 1922170.0,
      "text": "which is the inverse of the logit function, i.e."
    },
    {
      "index": 371,
      "start_time": 1922170.0,
      "end_time": 1923310.0,
      "text": "Then:"
    },
    {
      "index": 372,
      "start_time": 1923310.0,
      "end_time": 1928300.0,
      "text": "This formulation — which is standard in discrete choice models — makes clear the"
    },
    {
      "index": 373,
      "start_time": 1928300.0,
      "end_time": 1933451.0,
      "text": "relationship between logistic regression and the probit model, which uses an error variable"
    },
    {
      "index": 374,
      "start_time": 1933450.0,
      "end_time": 1938169.0,
      "text": "distributed according to a standard normal distribution instead of a standard logistic"
    },
    {
      "index": 375,
      "start_time": 1938170.0,
      "end_time": 1943910.0,
      "text": "distribution. Both the logistic and normal distributions are symmetric with a basic unimodal,"
    },
    {
      "index": 376,
      "start_time": 1943910.0,
      "end_time": 1948840.0,
      "text": "&quot;bell curve&quot; shape. The only difference is that the logistic distribution has somewhat"
    },
    {
      "index": 377,
      "start_time": 1948840.0,
      "end_time": 1953760.0,
      "text": "heavier tails, which means that it is less sensitive to outlying data."
    },
    {
      "index": 378,
      "start_time": 1953760.0,
      "end_time": 1958550.0,
      "text": "As a two-way latent-variable model Yet another formulation uses two separate"
    },
    {
      "index": 379,
      "start_time": 1958550.0,
      "end_time": 1960740.0,
      "text": "latent variables:"
    },
    {
      "index": 380,
      "start_time": 1960740.0,
      "end_time": 1961941.0,
      "text": "where"
    },
    {
      "index": 381,
      "start_time": 1961940.0,
      "end_time": 1968809.0,
      "text": "where EV1(0,1) is a standard type-1 extreme value distribution: i.e."
    },
    {
      "index": 382,
      "start_time": 1968810.0,
      "end_time": 1970071.0,
      "text": "Then"
    },
    {
      "index": 383,
      "start_time": 1970070.0,
      "end_time": 1974729.0,
      "text": "This model has a separate latent variable and a separate set of regression coefficients"
    },
    {
      "index": 384,
      "start_time": 1974730.0,
      "end_time": 1979821.0,
      "text": "for each possible outcome of the dependent variable. The reason for this separation is"
    },
    {
      "index": 385,
      "start_time": 1979820.0,
      "end_time": 1985570.0,
      "text": "that it makes it easy to extend logistic regression to multi-outcome categorical variables, as"
    },
    {
      "index": 386,
      "start_time": 1985570.0,
      "end_time": 1991249.0,
      "text": "in the multinomial logit model. In such a model, it is natural to model each possible"
    },
    {
      "index": 387,
      "start_time": 1991250.0,
      "end_time": 1996821.0,
      "text": "outcome using a different set of regression coefficients. It is also possible to motivate"
    },
    {
      "index": 388,
      "start_time": 1996820.0,
      "end_time": 2001969.0,
      "text": "each of the separate latent variables as the theoretical utility associated with making"
    },
    {
      "index": 389,
      "start_time": 2001970.0,
      "end_time": 2008420.0,
      "text": "the associated choice, and thus motivate logistic regression in terms of utility theory. This"
    },
    {
      "index": 390,
      "start_time": 2008420.0,
      "end_time": 2014201.0,
      "text": "is the approach taken by economists when formulating discrete choice models, because it both provides"
    },
    {
      "index": 391,
      "start_time": 2014200.0,
      "end_time": 2019409.0,
      "text": "a theoretically strong foundation and facilitates intuitions about the model, which in turn"
    },
    {
      "index": 392,
      "start_time": 2019410.0,
      "end_time": 2023290.0,
      "text": "makes it easy to consider various sorts of extensions."
    },
    {
      "index": 393,
      "start_time": 2023290.0,
      "end_time": 2029420.0,
      "text": "The choice of the type-1 extreme value distribution seems fairly arbitrary, but it makes the mathematics"
    },
    {
      "index": 394,
      "start_time": 2029420.0,
      "end_time": 2035071.0,
      "text": "work out, and it may be possible to justify its use through rational choice theory."
    },
    {
      "index": 395,
      "start_time": 2035070.0,
      "end_time": 2039369.0,
      "text": "It turns out that this model is equivalent to the previous model, although this seems"
    },
    {
      "index": 396,
      "start_time": 2039370.0,
      "end_time": 2044860.0,
      "text": "non-obvious, since there are now two sets of regression coefficients and error variables,"
    },
    {
      "index": 397,
      "start_time": 2044860.0,
      "end_time": 2051101.0,
      "text": "and the error variables have a different distribution. In fact, this model reduces directly to the"
    },
    {
      "index": 398,
      "start_time": 2051100.0,
      "end_time": 2054419.0,
      "text": "previous one with the following substitutions:"
    },
    {
      "index": 399,
      "start_time": 2054420.0,
      "end_time": 2058831.0,
      "text": "An intuition for this comes from the fact that, since we choose based on the maximum"
    },
    {
      "index": 400,
      "start_time": 2058830.0,
      "end_time": 2064980.0,
      "text": "of two values, only their difference matters, not the exact values — and this effectively"
    },
    {
      "index": 401,
      "start_time": 2064980.0,
      "end_time": 2070790.0,
      "text": "removes one degree of freedom. Another critical fact is that the difference of two type-1"
    },
    {
      "index": 402,
      "start_time": 2070790.0,
      "end_time": 2075060.0,
      "text": "extreme-value-distributed variables is a logistic distribution, i.e. if"
    },
    {
      "index": 403,
      "start_time": 2075060.0,
      "end_time": 2079140.0,
      "text": "We can demonstrate the equivalent as follows:"
    },
    {
      "index": 404,
      "start_time": 2079139.9999999998,
      "end_time": 2082769.9999999998,
      "text": "Example As an example, consider a province-level election"
    },
    {
      "index": 405,
      "start_time": 2082770.0,
      "end_time": 2088210.0,
      "text": "where the choice is between a right-of-center party, a left-of-center party, and a secessionist"
    },
    {
      "index": 406,
      "start_time": 2088210.0,
      "end_time": 2095350.0,
      "text": "party. We would then use three latent variables, one for each choice. Then, in accordance with"
    },
    {
      "index": 407,
      "start_time": 2095350.0,
      "end_time": 2100600.0,
      "text": "utility theory, we can then interpret the latent variables as expressing the utility"
    },
    {
      "index": 408,
      "start_time": 2100600.0,
      "end_time": 2106140.0,
      "text": "that results from making each of the choices. We can also interpret the regression coefficients"
    },
    {
      "index": 409,
      "start_time": 2106140.0,
      "end_time": 2111020.0,
      "text": "as indicating the strength that the associated factor has in contributing to the utility"
    },
    {
      "index": 410,
      "start_time": 2111020.0,
      "end_time": 2116600.0,
      "text": "— or more correctly, the amount by which a unit change in an explanatory variable changes"
    },
    {
      "index": 411,
      "start_time": 2116600.0,
      "end_time": 2122050.0,
      "text": "the utility of a given choice. A voter might expect that the right-of-center party would"
    },
    {
      "index": 412,
      "start_time": 2122050.0,
      "end_time": 2128470.0,
      "text": "lower taxes, especially on rich people. This would give low-income people no benefit, i.e."
    },
    {
      "index": 413,
      "start_time": 2128470.0,
      "end_time": 2134850.0,
      "text": "no change in utility; would cause moderate benefit for middle-incoming people; and would"
    },
    {
      "index": 414,
      "start_time": 2134850.0,
      "end_time": 2140110.0,
      "text": "cause significant benefits for high-income people. On the other hand, the left-of-center"
    },
    {
      "index": 415,
      "start_time": 2140110.0,
      "end_time": 2144700.0,
      "text": "party might be expected to raise taxes and offset it with increased welfare and other"
    },
    {
      "index": 416,
      "start_time": 2144700.0,
      "end_time": 2150090.0,
      "text": "assistance for the lower and middle classes. This would cause significant positive benefit"
    },
    {
      "index": 417,
      "start_time": 2150090.0,
      "end_time": 2155610.0,
      "text": "to low-income people, perhaps weak benefit to middle-income people, and significant negative"
    },
    {
      "index": 418,
      "start_time": 2155610.0,
      "end_time": 2162100.0,
      "text": "benefit to high-income people. Finally, the secessionist party would take no direct actions"
    },
    {
      "index": 419,
      "start_time": 2162100.0,
      "end_time": 2168350.0,
      "text": "on the economy, but simply secede. A low-income or middle-income voter might expect basically"
    },
    {
      "index": 420,
      "start_time": 2168350.0,
      "end_time": 2173610.0,
      "text": "no clear utility gain or loss from this, but a high-income voter might expect negative"
    },
    {
      "index": 421,
      "start_time": 2173610.0,
      "end_time": 2178820.0,
      "text": "utility, since he/she is likely to own companies, which will have a harder time doing business"
    },
    {
      "index": 422,
      "start_time": 2178820.0,
      "end_time": 2185050.0,
      "text": "in such an environment and probably lose money. These intuitions can be expressed as follows:"
    },
    {
      "index": 423,
      "start_time": 2185050.0,
      "end_time": 2189110.0,
      "text": "This clearly shows that Separate sets of regression coefficients need"
    },
    {
      "index": 424,
      "start_time": 2189110.0,
      "end_time": 2196300.0,
      "text": "to exist for each choice. When phrased in terms of utility, this can be seen very easily."
    },
    {
      "index": 425,
      "start_time": 2196300.0,
      "end_time": 2201480.0,
      "text": "Different choices have different effects on net utility; furthermore, the effects vary"
    },
    {
      "index": 426,
      "start_time": 2201480.0,
      "end_time": 2207160.0,
      "text": "in complex ways that depend on the characteristics of each individual, so there need to be separate"
    },
    {
      "index": 427,
      "start_time": 2207160.0,
      "end_time": 2212940.0,
      "text": "sets of coefficients for each characteristic, not simply a single extra per-choice characteristic."
    },
    {
      "index": 428,
      "start_time": 2212940.0,
      "end_time": 2218780.0,
      "text": "Even though income is a continuous variable, its effect on utility is too complex for it"
    },
    {
      "index": 429,
      "start_time": 2218780.0,
      "end_time": 2224960.0,
      "text": "to be treated as a single variable. Either it needs to be directly split up into ranges,"
    },
    {
      "index": 430,
      "start_time": 2224960.0,
      "end_time": 2229560.0,
      "text": "or higher powers of income need to be added so that polynomial regression on income is"
    },
    {
      "index": 431,
      "start_time": 2229560.0,
      "end_time": 2232470.0,
      "text": "effectively done. As a &quot;log-linear&quot; model"
    },
    {
      "index": 432,
      "start_time": 2232470.0,
      "end_time": 2237770.0,
      "text": "Yet another formulation combines the two-way latent variable formulation above with the"
    },
    {
      "index": 433,
      "start_time": 2237770.0,
      "end_time": 2243090.0,
      "text": "original formulation higher up without latent variables, and in the process provides a link"
    },
    {
      "index": 434,
      "start_time": 2243090.0,
      "end_time": 2247410.0,
      "text": "to one of the standard formulations of the multinomial logit."
    },
    {
      "index": 435,
      "start_time": 2247410.0,
      "end_time": 2252170.0,
      "text": "Here, instead of writing the logit of the probabilities pi as a linear predictor, we"
    },
    {
      "index": 436,
      "start_time": 2252170.0,
      "end_time": 2257390.0,
      "text": "separate the linear predictor into two, one for each of the two outcomes:"
    },
    {
      "index": 437,
      "start_time": 2257390.0,
      "end_time": 2261850.0,
      "text": "Note that two separate sets of regression coefficients have been introduced, just as"
    },
    {
      "index": 438,
      "start_time": 2261850.0,
      "end_time": 2266700.0,
      "text": "in the two-way latent variable model, and the two equations appear a form that writes"
    },
    {
      "index": 439,
      "start_time": 2266700.0,
      "end_time": 2271380.0,
      "text": "the logarithm of the associated probability as a linear predictor, with an extra term"
    },
    {
      "index": 440,
      "start_time": 2271380.0,
      "end_time": 2277890.0,
      "text": "at the end. This term, as it turns out, serves as the normalizing factor ensuring that the"
    },
    {
      "index": 441,
      "start_time": 2277890.0,
      "end_time": 2283470.0,
      "text": "result is a distribution. This can be seen by exponentiating both sides:"
    },
    {
      "index": 442,
      "start_time": 2283470.0,
      "end_time": 2287980.0,
      "text": "In this form it is clear that the purpose of Z is to ensure that the resulting distribution"
    },
    {
      "index": 443,
      "start_time": 2287980.0,
      "end_time": 2294540.0,
      "text": "over Yi is in fact a probability distribution, i.e. it sums to 1. This means that Z is simply"
    },
    {
      "index": 444,
      "start_time": 2294540.0,
      "end_time": 2300530.0,
      "text": "the sum of all un-normalized probabilities, and by dividing each probability by Z, the"
    },
    {
      "index": 445,
      "start_time": 2300530.0,
      "end_time": 2304030.0,
      "text": "probabilities become &quot;normalized&quot;. That is:"
    },
    {
      "index": 446,
      "start_time": 2304030.0,
      "end_time": 2306630.0,
      "text": "and the resulting equations are"
    },
    {
      "index": 447,
      "start_time": 2306630.0,
      "end_time": 2308140.0,
      "text": "Or generally:"
    },
    {
      "index": 448,
      "start_time": 2308140.0,
      "end_time": 2313010.0,
      "text": "This shows clearly how to generalize this formulation to more than two outcomes, as"
    },
    {
      "index": 449,
      "start_time": 2313010.0,
      "end_time": 2317050.0,
      "text": "in multinomial logit. In order to prove that this is equivalent"
    },
    {
      "index": 450,
      "start_time": 2317050.0,
      "end_time": 2321850.0,
      "text": "to the previous model, note that the above model is overspecified, in that and cannot"
    },
    {
      "index": 451,
      "start_time": 2321850.0,
      "end_time": 2327710.0,
      "text": "be independently specified: rather so knowing one automatically determines the other. As"
    },
    {
      "index": 452,
      "start_time": 2327710.0,
      "end_time": 2334030.0,
      "text": "a result, the model is nonidentifiable, in that multiple combinations of β0 and β1"
    },
    {
      "index": 453,
      "start_time": 2334030.0,
      "end_time": 2340380.0,
      "text": "will produce the same probabilities for all possible explanatory variables. In fact, it"
    },
    {
      "index": 454,
      "start_time": 2340380.0,
      "end_time": 2345500.0,
      "text": "can be seen that adding any constant vector to both of them will produce the same probabilities:"
    },
    {
      "index": 455,
      "start_time": 2345500.0,
      "end_time": 2351970.0,
      "text": "As a result, we can simplify matters, and restore identifiability, by picking an arbitrary"
    },
    {
      "index": 456,
      "start_time": 2351970.0,
      "end_time": 2356720.0,
      "text": "value for one of the two vectors. We choose to set Then,"
    },
    {
      "index": 457,
      "start_time": 2356720.0,
      "end_time": 2357990.0,
      "text": "and so"
    },
    {
      "index": 458,
      "start_time": 2357990.0,
      "end_time": 2363390.0,
      "text": "which shows that this formulation is indeed equivalent to the previous formulation."
    },
    {
      "index": 459,
      "start_time": 2363390.0,
      "end_time": 2367950.0,
      "text": "Note that most treatments of the multinomial logit model start out either by extending"
    },
    {
      "index": 460,
      "start_time": 2367950.0,
      "end_time": 2373020.0,
      "text": "the &quot;log-linear&quot; formulation presented here or the two-way latent variable formulation"
    },
    {
      "index": 461,
      "start_time": 2373020.0,
      "end_time": 2378800.0,
      "text": "presented above, since both clearly show the way that the model could be extended to multi-way"
    },
    {
      "index": 462,
      "start_time": 2378800.0,
      "end_time": 2384680.0,
      "text": "outcomes. In general, the presentation with latent variables is more common in econometrics"
    },
    {
      "index": 463,
      "start_time": 2384680.0,
      "end_time": 2389950.0,
      "text": "and political science, where discrete choice models and utility theory reign, while the"
    },
    {
      "index": 464,
      "start_time": 2389950.0,
      "end_time": 2395220.0,
      "text": "&quot;log-linear&quot; formulation here is more common in computer science, e.g. machine learning"
    },
    {
      "index": 465,
      "start_time": 2395220.0,
      "end_time": 2399950.0,
      "text": "and natural language processing. As a single-layer perceptron"
    },
    {
      "index": 466,
      "start_time": 2399950.0,
      "end_time": 2402890.0,
      "text": "The model has an equivalent formulation"
    },
    {
      "index": 467,
      "start_time": 2402890.0,
      "end_time": 2407610.0,
      "text": "This functional form is commonly called a single-layer perceptron or single-layer artificial"
    },
    {
      "index": 468,
      "start_time": 2407610.0,
      "end_time": 2413500.0,
      "text": "neural network. A single-layer neural network computes a continuous output instead of a"
    },
    {
      "index": 469,
      "start_time": 2413500.0,
      "end_time": 2421590.0,
      "text": "step function. The derivative of pi with respect to X = (x1, ..., xk) is computed from the"
    },
    {
      "index": 470,
      "start_time": 2421590.0,
      "end_time": 2423180.0,
      "text": "general form:"
    },
    {
      "index": 471,
      "start_time": 2423180.0,
      "end_time": 2430300.0,
      "text": "where f(X) is an analytic function in X. With this choice, the single-layer neural network"
    },
    {
      "index": 472,
      "start_time": 2430300.0,
      "end_time": 2436210.0,
      "text": "is identical to the logistic regression model. This function has a continuous derivative,"
    },
    {
      "index": 473,
      "start_time": 2436210.0,
      "end_time": 2441520.0,
      "text": "which allows it to be used in backpropagation. This function is also preferred because its"
    },
    {
      "index": 474,
      "start_time": 2441520.0,
      "end_time": 2444320.0,
      "text": "derivative is easily calculated:"
    },
    {
      "index": 475,
      "start_time": 2444320.0,
      "end_time": 2448770.0,
      "text": "In terms of binomial data A closely related model assumes that each"
    },
    {
      "index": 476,
      "start_time": 2448770.0,
      "end_time": 2453610.0,
      "text": "i is associated not with a single Bernoulli trial but with ni independent identically"
    },
    {
      "index": 477,
      "start_time": 2453610.0,
      "end_time": 2458770.0,
      "text": "distributed trials, where the observation Yi is the number of successes observed, and"
    },
    {
      "index": 478,
      "start_time": 2458770.0,
      "end_time": 2462080.0,
      "text": "hence follows a binomial distribution:"
    },
    {
      "index": 479,
      "start_time": 2462080.0,
      "end_time": 2468160.0,
      "text": "An example of this distribution is the fraction of seeds that germinate after ni are planted."
    },
    {
      "index": 480,
      "start_time": 2468160.0,
      "end_time": 2473180.0,
      "text": "In terms of expected values, this model is expressed as follows:"
    },
    {
      "index": 481,
      "start_time": 2473180.0,
      "end_time": 2474500.0,
      "text": "so that"
    },
    {
      "index": 482,
      "start_time": 2474500.0,
      "end_time": 2476290.0,
      "text": "Or equivalently:"
    },
    {
      "index": 483,
      "start_time": 2476290.0,
      "end_time": 2481210.0,
      "text": "This model can be fit using the same sorts of methods as the above more basic model."
    },
    {
      "index": 484,
      "start_time": 2481210.0,
      "end_time": 2483730.0,
      "text": "Bayesian logistic regression"
    },
    {
      "index": 485,
      "start_time": 2483730.0,
      "end_time": 2490340.0,
      "text": "In a Bayesian statistics context, prior distributions are normally placed on the regression coefficients,"
    },
    {
      "index": 486,
      "start_time": 2490340.0,
      "end_time": 2496300.0,
      "text": "usually in the form of Gaussian distributions. Unfortunately, the Gaussian distribution is"
    },
    {
      "index": 487,
      "start_time": 2496300.0,
      "end_time": 2502020.0,
      "text": "not the conjugate prior of the likelihood function in logistic regression; in fact,"
    },
    {
      "index": 488,
      "start_time": 2502020.0,
      "end_time": 2506590.0,
      "text": "the likelihood function is not an exponential family and thus does not have a conjugate"
    },
    {
      "index": 489,
      "start_time": 2506590.0,
      "end_time": 2513730.0,
      "text": "prior at all. As a result, the posterior distribution is difficult to calculate, even using standard"
    },
    {
      "index": 490,
      "start_time": 2513730.0,
      "end_time": 2518330.0,
      "text": "simulation algorithms. There are various possibilities:"
    },
    {
      "index": 491,
      "start_time": 2518330.0,
      "end_time": 2524090.0,
      "text": "Don&#39;t do a proper Bayesian analysis, but simply compute a maximum a posteriori point estimate"
    },
    {
      "index": 492,
      "start_time": 2524090.0,
      "end_time": 2530470.0,
      "text": "of the parameters. This is common, for example, in &quot;maximum entropy&quot; classifiers in machine"
    },
    {
      "index": 493,
      "start_time": 2530470.0,
      "end_time": 2534310.0,
      "text": "learning. Use a more general approximation method such"
    },
    {
      "index": 494,
      "start_time": 2534310.0,
      "end_time": 2540130.0,
      "text": "as the Metropolis–Hastings algorithm. Draw a Markov chain Monte Carlo sample from"
    },
    {
      "index": 495,
      "start_time": 2540130.0,
      "end_time": 2545930.0,
      "text": "the exact posterior by using the Independent Metropolis–Hastings algorithm with heavy-tailed"
    },
    {
      "index": 496,
      "start_time": 2545930.0,
      "end_time": 2550570.0,
      "text": "multivariate candidate distribution found by matching the mode and curvature at the"
    },
    {
      "index": 497,
      "start_time": 2550570.0,
      "end_time": 2557390.0,
      "text": "mode of the normal approximation to the posterior and then using the Student’s t shape with"
    },
    {
      "index": 498,
      "start_time": 2557390.0,
      "end_time": 2562350.0,
      "text": "low degrees of freedom. This is shown to have excellent convergence properties."
    },
    {
      "index": 499,
      "start_time": 2562350.0,
      "end_time": 2569040.0,
      "text": "Use a latent variable model and approximate the logistic distribution using a more tractable"
    },
    {
      "index": 500,
      "start_time": 2569040.0,
      "end_time": 2574590.0,
      "text": "distribution, e.g. a Student&#39;s t-distribution or a mixture of normal distributions."
    },
    {
      "index": 501,
      "start_time": 2574590.0,
      "end_time": 2580770.0,
      "text": "Do probit regression instead of logistic regression. This is actually a special case of the previous"
    },
    {
      "index": 502,
      "start_time": 2580770.0,
      "end_time": 2586860.0,
      "text": "situation, using a normal distribution in place of a Student&#39;s t, mixture of normals,"
    },
    {
      "index": 503,
      "start_time": 2586860.0,
      "end_time": 2592770.0,
      "text": "etc. This will be less accurate but has the advantage that probit regression is extremely"
    },
    {
      "index": 504,
      "start_time": 2592770.0,
      "end_time": 2597550.0,
      "text": "common, and a ready-made Bayesian implementation may already be available."
    },
    {
      "index": 505,
      "start_time": 2597550.0,
      "end_time": 2603200.0,
      "text": "Use the Laplace approximation of the posterior distribution. This approximates the posterior"
    },
    {
      "index": 506,
      "start_time": 2603200.0,
      "end_time": 2608890.0,
      "text": "with a Gaussian distribution. This is not a terribly good approximation, but it suffices"
    },
    {
      "index": 507,
      "start_time": 2608890.0,
      "end_time": 2614880.0,
      "text": "if all that is desired is an estimate of the posterior mean and variance. In such a case,"
    },
    {
      "index": 508,
      "start_time": 2614880.0,
      "end_time": 2619630.0,
      "text": "an approximation scheme such as variational Bayes can be used."
    },
    {
      "index": 509,
      "start_time": 2619630.0,
      "end_time": 2625520.0,
      "text": "Gibbs sampling with an approximating distribution As shown above, logistic regression is equivalent"
    },
    {
      "index": 510,
      "start_time": 2625520.0,
      "end_time": 2630710.0,
      "text": "to a latent variable model with an error variable distributed according to a standard logistic"
    },
    {
      "index": 511,
      "start_time": 2630710.0,
      "end_time": 2637230.0,
      "text": "distribution. The overall distribution of the latent variable is also a logistic distribution,"
    },
    {
      "index": 512,
      "start_time": 2637230.0,
      "end_time": 2643180.0,
      "text": "with the mean equal to . This model considerably simplifies the application of techniques such"
    },
    {
      "index": 513,
      "start_time": 2643180.0,
      "end_time": 2649500.0,
      "text": "as Gibbs sampling. However, sampling the regression coefficients is still difficult, because of"
    },
    {
      "index": 514,
      "start_time": 2649500.0,
      "end_time": 2654900.0,
      "text": "the lack of conjugacy between the normal and logistic distributions. Changing the prior"
    },
    {
      "index": 515,
      "start_time": 2654900.0,
      "end_time": 2660130.0,
      "text": "distribution over the regression coefficients is of no help, because the logistic distribution"
    },
    {
      "index": 516,
      "start_time": 2660130.0,
      "end_time": 2664730.0,
      "text": "is not in the exponential family and thus has no conjugate prior."
    },
    {
      "index": 517,
      "start_time": 2664730.0,
      "end_time": 2671190.0,
      "text": "One possibility is to use a more general Markov chain Monte Carlo technique, such as the Metropolis–Hastings"
    },
    {
      "index": 518,
      "start_time": 2671190.0,
      "end_time": 2678440.0,
      "text": "algorithm, which can sample arbitrary distributions. Another possibility, however, is to replace"
    },
    {
      "index": 519,
      "start_time": 2678440.0,
      "end_time": 2683190.0,
      "text": "the logistic distribution with a similar-shaped distribution that is easier to work with using"
    },
    {
      "index": 520,
      "start_time": 2683190.0,
      "end_time": 2688860.0,
      "text": "Gibbs sampling. In fact, the logistic and normal distributions have a similar shape,"
    },
    {
      "index": 521,
      "start_time": 2688860.0,
      "end_time": 2695010.0,
      "text": "and thus one possibility is simply to have normally distributed errors. Because the normal"
    },
    {
      "index": 522,
      "start_time": 2695010.0,
      "end_time": 2700390.0,
      "text": "distribution is conjugate to itself, sampling the regression coefficients becomes easy."
    },
    {
      "index": 523,
      "start_time": 2700390.0,
      "end_time": 2704940.0,
      "text": "In fact, this model is exactly the model used in probit regression."
    },
    {
      "index": 524,
      "start_time": 2704940.0,
      "end_time": 2710860.0,
      "text": "However, the normal and logistic distributions differ in that the logistic has heavier tails."
    },
    {
      "index": 525,
      "start_time": 2710860.0,
      "end_time": 2716170.0,
      "text": "As a result, it is more robust to inaccuracies in the underlying model or to errors in the"
    },
    {
      "index": 526,
      "start_time": 2716170.0,
      "end_time": 2721200.0,
      "text": "data. Probit regression loses some of this robustness."
    },
    {
      "index": 527,
      "start_time": 2721200.0,
      "end_time": 2726720.0,
      "text": "Another alternative is to use errors distributed as a Student&#39;s t-distribution. The Student&#39;s"
    },
    {
      "index": 528,
      "start_time": 2726720.0,
      "end_time": 2731610.0,
      "text": "t-distribution has heavy tails, and is easy to sample from because it is the compound"
    },
    {
      "index": 529,
      "start_time": 2731610.0,
      "end_time": 2737630.0,
      "text": "distribution of a normal distribution with variance distributed as an inverse gamma distribution."
    },
    {
      "index": 530,
      "start_time": 2737630.0,
      "end_time": 2743230.0,
      "text": "In other words, if a normal distribution is used for the error variable, and another latent"
    },
    {
      "index": 531,
      "start_time": 2743230.0,
      "end_time": 2748160.0,
      "text": "variable, following an inverse gamma distribution, is added corresponding to the variance of"
    },
    {
      "index": 532,
      "start_time": 2748160.0,
      "end_time": 2753120.0,
      "text": "this error variable, the marginal distribution of the error variable will follow a Student&#39;s"
    },
    {
      "index": 533,
      "start_time": 2753120.0,
      "end_time": 2759570.0,
      "text": "t-distribution. Because of the various conjugacy relationships, all variables in this model"
    },
    {
      "index": 534,
      "start_time": 2759570.0,
      "end_time": 2764640.0,
      "text": "are easy to sample from. The Student&#39;s t-distribution that best approximates"
    },
    {
      "index": 535,
      "start_time": 2764640.0,
      "end_time": 2770460.0,
      "text": "a standard logistic distribution can be determined by matching the moments of the two distributions."
    },
    {
      "index": 536,
      "start_time": 2770460.0,
      "end_time": 2776030.0,
      "text": "The Student&#39;s t-distribution has three parameters, and since the skewness of both distributions"
    },
    {
      "index": 537,
      "start_time": 2776030.0,
      "end_time": 2782410.0,
      "text": "is always 0, the first four moments can all be matched, using the following equations:"
    },
    {
      "index": 538,
      "start_time": 2782410.0,
      "end_time": 2784800.0,
      "text": "This yields the following values:"
    },
    {
      "index": 539,
      "start_time": 2784800.0,
      "end_time": 2789840.0,
      "text": "The following graphs compare the standard logistic distribution with the Student&#39;s t-distribution"
    },
    {
      "index": 540,
      "start_time": 2789840.0,
      "end_time": 2794760.0,
      "text": "that matches the first four moments using the above-determined values, as well as the"
    },
    {
      "index": 541,
      "start_time": 2794760.0,
      "end_time": 2799990.0,
      "text": "normal distribution that matches the first two moments. Note how much closer the Student&#39;s"
    },
    {
      "index": 542,
      "start_time": 2799990.0,
      "end_time": 2806470.0,
      "text": "t-distribution agrees, especially in the tails. Beyond about two standard deviations from"
    },
    {
      "index": 543,
      "start_time": 2806470.0,
      "end_time": 2813200.0,
      "text": "the mean, the logistic and normal distributions diverge rapidly, but the logistic and Student&#39;s"
    },
    {
      "index": 544,
      "start_time": 2813200.0,
      "end_time": 2818710.0,
      "text": "t-distributions don&#39;t start diverging significantly until more than 5 standard deviations away."
    },
    {
      "index": 545,
      "start_time": 2818710.0,
      "end_time": 2825000.0,
      "text": "(Another possibility, also amenable to Gibbs sampling, is to approximate the logistic distribution"
    },
    {
      "index": 546,
      "start_time": 2825000.0,
      "end_time": 2829740.0,
      "text": "using a mixture density of normal distributions.) Extensions"
    },
    {
      "index": 547,
      "start_time": 2829740.0,
      "end_time": 2834320.0,
      "text": "There are large numbers of extensions: Multinomial logistic regression handles the"
    },
    {
      "index": 548,
      "start_time": 2834320.0,
      "end_time": 2839890.0,
      "text": "case of a multi-way categorical dependent variable. Note that the general case of having"
    },
    {
      "index": 549,
      "start_time": 2839890.0,
      "end_time": 2845330.0,
      "text": "dependent variables with more than two values is termed polytomous regression."
    },
    {
      "index": 550,
      "start_time": 2845330.0,
      "end_time": 2849320.0,
      "text": "Ordered logistic regression handles ordinal dependent variables."
    },
    {
      "index": 551,
      "start_time": 2849320.0,
      "end_time": 2854660.0,
      "text": "Mixed logit is an extension of multinomial logit that allows for correlations among the"
    },
    {
      "index": 552,
      "start_time": 2854660.0,
      "end_time": 2859780.0,
      "text": "choices of the dependent variable. An extension of the logistic model to sets"
    },
    {
      "index": 553,
      "start_time": 2859780.0,
      "end_time": 2863570.0,
      "text": "of interdependent variables is the conditional random field."
    },
    {
      "index": 554,
      "start_time": 2863570.0,
      "end_time": 2867740.0,
      "text": "Model suitability A way to measure a model&#39;s suitability is"
    },
    {
      "index": 555,
      "start_time": 2867740.0,
      "end_time": 2873320.0,
      "text": "to assess the model against a set of data that was not used to create the model. The"
    },
    {
      "index": 556,
      "start_time": 2873320.0,
      "end_time": 2879370.0,
      "text": "class of techniques is called cross-validation. This holdout model assessment method is particularly"
    },
    {
      "index": 557,
      "start_time": 2879370.0,
      "end_time": 2884600.0,
      "text": "valuable when data are collected in different settings or when models are assumed to be"
    },
    {
      "index": 558,
      "start_time": 2884600.0,
      "end_time": 2888430.0,
      "text": "generalizable. To measure the suitability of a binary regression"
    },
    {
      "index": 559,
      "start_time": 2888430.0,
      "end_time": 2893240.0,
      "text": "model, one can classify both the actual value and the predicted value of each observation"
    },
    {
      "index": 560,
      "start_time": 2893240.0,
      "end_time": 2900230.0,
      "text": "as either 0 or 1. The predicted value of an observation can be set equal to 1 if the estimated"
    },
    {
      "index": 561,
      "start_time": 2900230.0,
      "end_time": 2905640.0,
      "text": "probability that the observation equals 1 is above , and set equal to 0 if the estimated"
    },
    {
      "index": 562,
      "start_time": 2905640.0,
      "end_time": 2911640.0,
      "text": "probability is below . Here logistic regression is being used as a binary classification model."
    },
    {
      "index": 563,
      "start_time": 2911640.0,
      "end_time": 2917400.0,
      "text": "There are four possible combined classifications: prediction of 0 when the holdout sample has"
    },
    {
      "index": 564,
      "start_time": 2917400.0,
      "end_time": 2920770.0,
      "text": "a 0 prediction of 0 when the holdout sample has"
    },
    {
      "index": 565,
      "start_time": 2920770.0,
      "end_time": 2923850.0,
      "text": "a 1 prediction of 1 when the holdout sample has"
    },
    {
      "index": 566,
      "start_time": 2923850.0,
      "end_time": 2927090.0,
      "text": "a 0 prediction of 1 when the holdout sample has"
    },
    {
      "index": 567,
      "start_time": 2927090.0,
      "end_time": 2930100.0,
      "text": "a 1 These classifications are used to calculate"
    },
    {
      "index": 568,
      "start_time": 2930100.0,
      "end_time": 2936320.0,
      "text": "accuracy, precision, recall, specificity and negative predictive value:"
    },
    {
      "index": 569,
      "start_time": 2936320.0,
      "end_time": 2939240.0,
      "text": "= fraction of observations with correct predicted classification"
    },
    {
      "index": 570,
      "start_time": 2939240.0,
      "end_time": 2942260.0,
      "text": "= Fraction of predicted positives that are correct"
    },
    {
      "index": 571,
      "start_time": 2942260.0,
      "end_time": 2945310.0,
      "text": "= fraction of predicted negatives that are correct"
    },
    {
      "index": 572,
      "start_time": 2945310.0,
      "end_time": 2950450.0,
      "text": "= fraction of observations that are actually 1 with a correct predicted classification"
    },
    {
      "index": 573,
      "start_time": 2950450.0,
      "end_time": 2957150.0,
      "text": "= fraction of observations that are actually 0 with a correct predicted classification"
    },
    {
      "index": 574,
      "start_time": 2957150.0,
      "end_time": 2958990.0,
      "text": "See also"
    },
    {
      "index": 575,
      "start_time": 2958990.0,
      "end_time": 2960660.0,
      "text": "Logistic function Discrete choice"
    },
    {
      "index": 576,
      "start_time": 2960660.0,
      "end_time": 2965880.0,
      "text": "Jarrow–Turnbull model Limited dependent variable"
    },
    {
      "index": 577,
      "start_time": 2965880.0,
      "end_time": 2967870.0,
      "text": "Multinomial logit model Ordered logit"
    },
    {
      "index": 578,
      "start_time": 2967870.0,
      "end_time": 2972270.0,
      "text": "Hosmer–Lemeshow test Brier score"
    },
    {
      "index": 579,
      "start_time": 2972270.0,
      "end_time": 2977100.0,
      "text": "MLPACK - contains a C++ implementation of logistic regression"
    },
    {
      "index": 580,
      "start_time": 2977100.0,
      "end_time": 2978700.0,
      "text": "References"
    },
    {
      "index": 581,
      "start_time": 2978700.0,
      "end_time": 2983770.0,
      "text": "Further reading Agresti, Alan.. Categorical Data Analysis."
    },
    {
      "index": 582,
      "start_time": 2983770.0,
      "end_time": 2996400.0,
      "text": "New York: Wiley-Interscience. ISBN 0-471-36093-7.  Amemiya, T.. Advanced Econometrics. Harvard"
    },
    {
      "index": 583,
      "start_time": 2996400.0,
      "end_time": 3006740.0,
      "text": "University Press. ISBN 0-674-00560-0.  Balakrishnan, N.. Handbook of the Logistic"
    },
    {
      "index": 584,
      "start_time": 3006740.0,
      "end_time": 3020920.0,
      "text": "Distribution. Marcel Dekker, Inc. ISBN 978-0-8247-8587-1.  Greene, William H.. Econometric Analysis,"
    },
    {
      "index": 585,
      "start_time": 3020920.0,
      "end_time": 3033490.0,
      "text": "fifth edition. Prentice Hall. ISBN 0-13-066189-9.  Hilbe, Joseph M.. Logistic Regression Models."
    },
    {
      "index": 586,
      "start_time": 3033490.0,
      "end_time": 3045200.0,
      "text": "Chapman &amp; Hall/CRC Press. ISBN 978-1-4200-7575-5.  Howell, David C.. Statistical Methods for"
    },
    {
      "index": 587,
      "start_time": 3045200.0,
      "end_time": 3057340.0,
      "text": "Psychology, 7th ed. Belmont, CA; Thomson Wadsworth. ISBN 978-0-495-59786-5. "
    },
    {
      "index": 588,
      "start_time": 3057340.0,
      "end_time": 3067380.0,
      "text": "Peduzzi, P.; J. Concato, E. Kemper, T.R. Holford, A.R. Feinstein. &quot;A simulation study of the"
    },
    {
      "index": 589,
      "start_time": 3067380.0,
      "end_time": 3072660.0,
      "text": "number of events per variable in logistic regression analysis&quot;. Journal of Clinical"
    },
    {
      "index": 590,
      "start_time": 3072660.0,
      "end_time": 3076690.0,
      "text": "Epidemiology 49: 1373–1379. doi:10.1016/s0895-4356(96)00236-3. PMID 8970487. "
    },
    {
      "index": 591,
      "start_time": 3076690.0,
      "end_time": 3080450.0,
      "text": "External links Econometrics Lecture on YouTube by Mark Thoma"
    },
    {
      "index": 592,
      "start_time": 3080450.0,
      "end_time": 3081710.0,
      "text": "Logistic Regression Interpretation Logistic Regression tutorial"
    },
    {
      "index": 593,
      "start_time": 3081710.0,
      "end_time": 3091710.0,
      "text": "Using open source software for building Logistic Regression models"
    }
  ]
}