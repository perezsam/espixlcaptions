{
  "video_id": "s0Q3CojqRfM",
  "title": "Vectors - The Math of Intelligence #3",
  "es": 0,
  "json": [
    {
      "index": 1,
      "start_time": 0.0,
      "end_time": 1620.0,
      "text": "Hello world. It's Siraj,"
    },
    {
      "index": 2,
      "start_time": 1620.0,
      "end_time": 3980.0,
      "text": "and what's the deal with vectors!"
    },
    {
      "index": 3,
      "start_time": 3980.0,
      "end_time": 6750.0,
      "text": "You're going to see this word a lot in machine learning"
    },
    {
      "index": 4,
      "start_time": 6750.0,
      "end_time": 10660.0,
      "text": "And it's one of the most crucial concepts to understand."
    },
    {
      "index": 5,
      "start_time": 10660.0,
      "end_time": 12509.0,
      "text": "A huge part of Machine learning is"
    },
    {
      "index": 6,
      "start_time": 12820.0,
      "end_time": 16360.0,
      "text": "finding a way to properly represent some data sets"
    },
    {
      "index": 7,
      "start_time": 16580.0,
      "end_time": 17420.0,
      "text": "programmatically"
    },
    {
      "index": 8,
      "start_time": 17640.0,
      "end_time": 20400.0,
      "text": "Let's say you're a manager at Tesla"
    },
    {
      "index": 9,
      "start_time": 20400.0,
      "end_time": 23500.0,
      "text": "And you're given a data set of some measurements"
    },
    {
      "index": 10,
      "start_time": 23500.0,
      "end_time": 26160.0,
      "text": "for each car that was produced in the past week."
    },
    {
      "index": 11,
      "start_time": 26760.0,
      "end_time": 30000.0,
      "text": "Each car on the list has three measurements"
    },
    {
      "index": 12,
      "start_time": 30000.0,
      "end_time": 32980.0,
      "text": "or features its length width and height"
    },
    {
      "index": 13,
      "start_time": 33180.0,
      "end_time": 37140.0,
      "text": "So a given car can then be represented as a point"
    },
    {
      "index": 14,
      "start_time": 37809.0,
      "end_time": 40619.0,
      "text": "in three-dimensional space where the values in each dimension"
    },
    {
      "index": 15,
      "start_time": 41350.0,
      "end_time": 43350.0,
      "text": "correlates to one of the features we are measuring."
    },
    {
      "index": 16,
      "start_time": 43720.0,
      "end_time": 48880.0,
      "text": "This same logic applies to data points that have 300 features."
    },
    {
      "index": 17,
      "start_time": 49140.0,
      "end_time": 50040.0,
      "text": "We can represent them in"
    },
    {
      "index": 18,
      "start_time": 50350.0,
      "end_time": 52220.0,
      "text": "300-dimensional space."
    },
    {
      "index": 19,
      "start_time": 52220.0,
      "end_time": 57419.0,
      "text": "While this is intuitively hard for us to understand as three dimensional beings."
    },
    {
      "index": 20,
      "start_time": 57820.0,
      "end_time": 59820.0,
      "text": "Machines can do this very well."
    },
    {
      "index": 21,
      "start_time": 60480.0,
      "end_time": 62960.0,
      "text": "Robot: Right, what do you want t..... Mother *****"
    },
    {
      "index": 22,
      "start_time": 65319.99999999999,
      "end_time": 68080.0,
      "text": "This data point X is considered a Vector."
    },
    {
      "index": 23,
      "start_time": 68080.0,
      "end_time": 70559.0,
      "text": "A vector is a 1-dimensional array."
    },
    {
      "index": 24,
      "start_time": 70960.0,
      "end_time": 74592.0,
      "text": "Think of it as a list of values or a row in a table."
    },
    {
      "index": 25,
      "start_time": 74592.0,
      "end_time": 75570.0,
      "text": "A vector of n-"
    },
    {
      "index": 26,
      "start_time": 75640.0,
      "end_time": 78280.0,
      "text": "-elements is an n-Dimensional Vector"
    },
    {
      "index": 27,
      "start_time": 78280.0,
      "end_time": 80340.0,
      "text": "with one dimension for each element."
    },
    {
      "index": 28,
      "start_time": 80340.0,
      "end_time": 81750.0,
      "text": "So for a 4-dimensional Data point."
    },
    {
      "index": 29,
      "start_time": 81790.0,
      "end_time": 86500.0,
      "text": "We can use a 1-by-4 array to hold its 4 feature values"
    },
    {
      "index": 30,
      "start_time": 86500.0,
      "end_time": 88499.0,
      "text": "and because it represents a set of features."
    },
    {
      "index": 31,
      "start_time": 88660.0,
      "end_time": 90660.0,
      "text": "We call it a feature vector."
    },
    {
      "index": 32,
      "start_time": 90760.0,
      "end_time": 93840.0,
      "text": "More general than a Vector is a Matrix."
    },
    {
      "index": 33,
      "start_time": 93840.0,
      "end_time": 97420.0,
      "text": "A Matrix is a rectangular array of numbers"
    },
    {
      "index": 34,
      "start_time": 97420.0,
      "end_time": 100080.0,
      "text": "and a Vector is a row or column of a Matrix."
    },
    {
      "index": 35,
      "start_time": 100280.0,
      "end_time": 104160.0,
      "text": "So each row in a Matrix could represent a different data point"
    },
    {
      "index": 36,
      "start_time": 104380.0,
      "end_time": 107120.0,
      "text": "with each column being its respective features."
    },
    {
      "index": 37,
      "start_time": 107120.0,
      "end_time": 109340.0,
      "text": "Less general than a vector is a Scalar"
    },
    {
      "index": 38,
      "start_time": 109570.0,
      "end_time": 111700.0,
      "text": "which is a single number."
    },
    {
      "index": 39,
      "start_time": 111700.0,
      "end_time": 115769.0,
      "text": "The most general term for all of these concepts is a Tensor."
    },
    {
      "index": 40,
      "start_time": 116160.0,
      "end_time": 118320.0,
      "text": "A Tensor is a multi-dimensional array"
    },
    {
      "index": 41,
      "start_time": 118540.0,
      "end_time": 121060.0,
      "text": "so a First-order Tensor is a Vector,"
    },
    {
      "index": 42,
      "start_time": 121060.0,
      "end_time": 123380.0,
      "text": "a Second-order Tensor is a Matrix and"
    },
    {
      "index": 43,
      "start_time": 123600.0,
      "end_time": 125069.0,
      "text": "Tensors of order three and higher are"
    },
    {
      "index": 44,
      "start_time": 125080.0,
      "end_time": 127620.0,
      "text": "called higher-order Tensors."
    },
    {
      "index": 45,
      "start_time": 127840.0,
      "end_time": 130280.0,
      "text": "So if a 1-D te  nsor looks like a line..."
    },
    {
      "index": 46,
      "start_time": 130280.0,
      "end_time": 131080.0,
      "text": "Stop."
    },
    {
      "index": 47,
      "start_time": 131080.0,
      "end_time": 131628.0,
      "text": "Who are you?"
    },
    {
      "index": 48,
      "start_time": 131628.0,
      "end_time": 132540.0,
      "text": "I think they get it."
    },
    {
      "index": 49,
      "start_time": 133140.0,
      "end_time": 135540.0,
      "text": "I  think they get it."
    },
    {
      "index": 50,
      "start_time": 135720.0,
      "end_time": 137200.0,
      "text": "You could represent a social graph that contains"
    },
    {
      "index": 51,
      "start_time": 137480.0,
      "end_time": 141380.0,
      "text": "friends of friends of friends as a higher-order Tensor."
    },
    {
      "index": 52,
      "start_time": 141380.0,
      "end_time": 143640.0,
      "text": "This is why Google built a library called"
    },
    {
      "index": 53,
      "start_time": 143720.0,
      "end_time": 145220.0,
      "text": "TensorFlow."
    },
    {
      "index": 54,
      "start_time": 145220.0,
      "end_time": 147500.0,
      "text": "It allows you to create a computational graph"
    },
    {
      "index": 55,
      "start_time": 147500.0,
      "end_time": 150340.0,
      "text": "where Tensors created from data sets can"
    },
    {
      "index": 56,
      "start_time": 150680.0,
      "end_time": 156040.0,
      "text": "flow through a series of mathematical operations that optimize for an objective."
    },
    {
      "index": 57,
      "start_time": 156320.0,
      "end_time": 162520.0,
      "text": "and while they built an entirely new type of chip called a TPU  or Tensor Processing Unit."
    },
    {
      "index": 58,
      "start_time": 162760.0,
      "end_time": 165000.0,
      "text": "As computational power and the amount of data we have"
    },
    {
      "index": 59,
      "start_time": 165709.0,
      "end_time": 168638.0,
      "text": "increases we are becoming more capable of processing"
    },
    {
      "index": 60,
      "start_time": 169879.0,
      "end_time": 171349.0,
      "text": "multi-dimensional data."
    },
    {
      "index": 61,
      "start_time": 171349.0,
      "end_time": 175460.0,
      "text": "Vectors are typically represented in a multitude of ways,"
    },
    {
      "index": 62,
      "start_time": 175460.0,
      "end_time": 178449.0,
      "text": "and they're used in many different fields of science,"
    },
    {
      "index": 63,
      "start_time": 178579.0,
      "end_time": 184659.0,
      "text": "Especially physics since vectors act as a bookkeeping tool to keep track of two pieces of information,"
    },
    {
      "index": 64,
      "start_time": 185360.0,
      "end_time": 189260.0,
      "text": "typically a magnitude and a direction for physical quantity."
    },
    {
      "index": 65,
      "start_time": 211100.0,
      "end_time": 213260.0,
      "text": "For example in Einstein's General theory of relativity"
    },
    {
      "index": 66,
      "start_time": 213900.0,
      "end_time": 216360.0,
      "text": "The Curvature of space-time"
    },
    {
      "index": 67,
      "start_time": 216360.0,
      "end_time": 218000.0,
      "text": "which gives rise to gravity"
    },
    {
      "index": 68,
      "start_time": 218000.0,
      "end_time": 219660.0,
      "text": "is described by what's called"
    },
    {
      "index": 69,
      "start_time": 219660.0,
      "end_time": 220560.0,
      "text": "a Riemann Curvature Tensor"
    },
    {
      "index": 70,
      "start_time": 220940.0,
      "end_time": 223800.0,
      "text": "which is a tensor of order 4."
    },
    {
      "index": 71,
      "start_time": 223960.0,
      "end_time": 225260.0,
      "text": "So badass."
    },
    {
      "index": 72,
      "start_time": 225500.0,
      "end_time": 228300.0,
      "text": "So we can represent not only the fabric of reality this way."
    },
    {
      "index": 73,
      "start_time": 228300.0,
      "end_time": 232100.0,
      "text": "But the gradient of our optimization problem as well."
    },
    {
      "index": 74,
      "start_time": 232100.0,
      "end_time": 234160.0,
      "text": "During first order optimization,"
    },
    {
      "index": 75,
      "start_time": 234167.0,
      "end_time": 236100.0,
      "text": "the weights of our model are"
    },
    {
      "index": 76,
      "start_time": 236410.0,
      "end_time": 240402.0,
      "text": "updated incrementally after each pass over the training data set,"
    },
    {
      "index": 77,
      "start_time": 240402.0,
      "end_time": 243779.0,
      "text": "given an Error Function like the Sum of Squared Errors,"
    },
    {
      "index": 78,
      "start_time": 243790.0,
      "end_time": 245790.0,
      "text": "We can compute the magnitude and"
    },
    {
      "index": 79,
      "start_time": 246280.0,
      "end_time": 252200.0,
      "text": "direction of the weight update by taking a step in the opposite direction of the error gradient."
    },
    {
      "index": 80,
      "start_time": 252200.0,
      "end_time": 253800.0,
      "text": "This all comes from Linear Algebra"
    },
    {
      "index": 81,
      "start_time": 254350.0,
      "end_time": 255400.0,
      "text": "Algebra"
    },
    {
      "index": 82,
      "start_time": 255400.0,
      "end_time": 257660.0,
      "text": "roughly means relationships,"
    },
    {
      "index": 83,
      "start_time": 257660.00000000003,
      "end_time": 260970.00000000003,
      "text": "and it explores the relationships between unknown numbers."
    },
    {
      "index": 84,
      "start_time": 262120.0,
      "end_time": 265530.0,
      "text": "Linear Algebra roughly means line-like relationships."
    },
    {
      "index": 85,
      "start_time": 265530.0,
      "end_time": 269020.0,
      "text": "It's the way of organizing information about vector spaces"
    },
    {
      "index": 86,
      "start_time": 269020.0,
      "end_time": 271540.0,
      "text": "that makes manipulating groups of numbers"
    },
    {
      "index": 87,
      "start_time": 271740.0,
      "end_time": 273840.0,
      "text": "simultaneously easy."
    },
    {
      "index": 88,
      "start_time": 274080.0,
      "end_time": 276580.0,
      "text": "It defines these structures like Vectors and Matrices"
    },
    {
      "index": 89,
      "start_time": 277210.0,
      "end_time": 282090.0,
      "text": "to hold these numbers and introduces new rules on how to add,"
    },
    {
      "index": 90,
      "start_time": 282600.0,
      "end_time": 285560.0,
      "text": "multiply, subtract and divide them."
    },
    {
      "index": 91,
      "start_time": 285800.0,
      "end_time": 287740.0,
      "text": "So given two arrays,"
    },
    {
      "index": 92,
      "start_time": 287740.0,
      "end_time": 290080.0,
      "text": "the algebraic way to multiply them would be to do it like this"
    },
    {
      "index": 93,
      "start_time": 290280.0,
      "end_time": 293320.0,
      "text": "and the linear algebraic way would look like this"
    },
    {
      "index": 94,
      "start_time": 293320.0,
      "end_time": 295480.0,
      "text": "We compute the dot product,"
    },
    {
      "index": 95,
      "start_time": 295480.0,
      "end_time": 296280.0,
      "text": "instead of"
    },
    {
      "index": 96,
      "start_time": 296530.0,
      "end_time": 298820.0,
      "text": "multiplying each number like this."
    },
    {
      "index": 97,
      "start_time": 298820.0,
      "end_time": 300940.0,
      "text": "The linear algebraic approach is"
    },
    {
      "index": 98,
      "start_time": 300940.0,
      "end_time": 303060.0,
      "text": "three times faster in this case."
    },
    {
      "index": 99,
      "start_time": 303260.0,
      "end_time": 305260.0,
      "text": "Any type of data can be represented as a vector,"
    },
    {
      "index": 100,
      "start_time": 305800.0,
      "end_time": 307880.0,
      "text": "images, videos, stock indices,"
    },
    {
      "index": 101,
      "start_time": 308100.0,
      "end_time": 310780.0,
      "text": "text,  audio signals,"
    },
    {
      "index": 102,
      "start_time": 310780.0,
      "end_time": 311980.0,
      "text": "dougie dancing."
    },
    {
      "index": 103,
      "start_time": 311980.0,
      "end_time": 312900.0,
      "text": "No matter the type of data,"
    },
    {
      "index": 104,
      "start_time": 312900.0,
      "end_time": 315240.0,
      "text": "it can be broken down into a set of numbers"
    },
    {
      "index": 105,
      "start_time": 317360.0,
      "end_time": 319660.0,
      "text": "The model is not really accepting the data."
    },
    {
      "index": 106,
      "start_time": 319660.0,
      "end_time": 320620.0,
      "text": "It keeps throwing errors."
    },
    {
      "index": 107,
      "start_time": 320620.0,
      "end_time": 322480.0,
      "text": "Let me see."
    },
    {
      "index": 108,
      "start_time": 322480.0,
      "end_time": 323460.0,
      "text": "Oh it looks like you got to vectorize it."
    },
    {
      "index": 109,
      "start_time": 323460.0,
      "end_time": 324500.0,
      "text": "What do you mean?"
    },
    {
      "index": 110,
      "start_time": 324500.0,
      "end_time": 327750.0,
      "text": "The model you wrote expected tensors of a certain size as its input."
    },
    {
      "index": 111,
      "start_time": 327750.0,
      "end_time": 329750.0,
      "text": "So we basically got to reshape the input data."
    },
    {
      "index": 112,
      "start_time": 329950.0,
      "end_time": 331940.0,
      "text": "so it's in the right vector space"
    },
    {
      "index": 113,
      "start_time": 331940.0,
      "end_time": 332720.0,
      "text": "and then once it is"
    },
    {
      "index": 114,
      "start_time": 332720.0,
      "end_time": 335669.0,
      "text": "we can compute things like the Cosine distance between Data points and"
    },
    {
      "index": 115,
      "start_time": 335870.0,
      "end_time": 336740.0,
      "text": "the Vector norm."
    },
    {
      "index": 116,
      "start_time": 336740.0,
      "end_time": 338000.0,
      "text": "Is there a Python library to do that?"
    },
    {
      "index": 117,
      "start_time": 338640.0,
      "end_time": 339960.0,
      "text": "You gotta love NumPy"
    },
    {
      "index": 118,
      "start_time": 339960.0,
      "end_time": 342340.0,
      "text": "Vectorization is essentially just a matrix operation,"
    },
    {
      "index": 119,
      "start_time": 342340.0,
      "end_time": 343640.0,
      "text": "and I can do it in a single line"
    },
    {
      "index": 120,
      "start_time": 344520.0,
      "end_time": 345020.0,
      "text": "Awesome."
    },
    {
      "index": 121,
      "start_time": 345020.0,
      "end_time": 346840.0,
      "text": "Well you vectorize it up."
    },
    {
      "index": 122,
      "start_time": 346840.0,
      "end_time": 348680.0,
      "text": "I've gotta back-propagate out for today."
    },
    {
      "index": 123,
      "start_time": 348680.0,
      "end_time": 349701.0,
      "text": "Cool, where to?"
    },
    {
      "index": 124,
      "start_time": 349701.0,
      "end_time": 350449.0,
      "text": "Tinder date"
    },
    {
      "index": 125,
      "start_time": 351510.0,
      "end_time": 353510.0,
      "text": "All right, yeah. See ya ..."
    },
    {
      "index": 126,
      "start_time": 356460.0,
      "end_time": 357900.0,
      "text": "A researcher named McCullough"
    },
    {
      "index": 127,
      "start_time": 357900.0,
      "end_time": 361040.0,
      "text": "used the machine learning model called a neural network"
    },
    {
      "index": 128,
      "start_time": 361040.0,
      "end_time": 362810.0,
      "text": "to create vectors for words"
    },
    {
      "index": 129,
      "start_time": 363360.0,
      "end_time": 364980.0,
      "text": "WORD2VEC."
    },
    {
      "index": 130,
      "start_time": 364980.0,
      "end_time": 367700.0,
      "text": "Given some input corpus of text,"
    },
    {
      "index": 131,
      "start_time": 367700.0,
      "end_time": 368810.0,
      "text": "like thousands of news articles,"
    },
    {
      "index": 132,
      "start_time": 369090.0,
      "end_time": 371580.0,
      "text": "it would try to predict the next word"
    },
    {
      "index": 133,
      "start_time": 371580.0,
      "end_time": 374050.0,
      "text": "in a sentence given the words around it."
    },
    {
      "index": 134,
      "start_time": 374050.0,
      "end_time": 375470.0,
      "text": "So a given word is"
    },
    {
      "index": 135,
      "start_time": 375630.0,
      "end_time": 377360.0,
      "text": "encoded into a vector."
    },
    {
      "index": 136,
      "start_time": 377360.0,
      "end_time": 381500.0,
      "text": "The model then uses that vector to try and predict the next word"
    },
    {
      "index": 137,
      "start_time": 381780.0,
      "end_time": 384980.0,
      "text": "if it's prediction doesn't match the actual next word,"
    },
    {
      "index": 138,
      "start_time": 384980.0,
      "end_time": 388280.0,
      "text": "the components of this vector are adjusted."
    },
    {
      "index": 139,
      "start_time": 388280.0,
      "end_time": 390260.0,
      "text": "Each words context in the corpus"
    },
    {
      "index": 140,
      "start_time": 390260.0,
      "end_time": 392880.0,
      "text": "acts as a teacher,"
    },
    {
      "index": 141,
      "start_time": 392880.0,
      "end_time": 393640.0,
      "text": "sending error signals back to adjust the vector."
    },
    {
      "index": 142,
      "start_time": 393800.0,
      "end_time": 395860.0,
      "text": "The vectors of words that are judged"
    },
    {
      "index": 143,
      "start_time": 396090.0,
      "end_time": 399649.0,
      "text": "similarly by their context are iteratively nudged closer together"
    },
    {
      "index": 144,
      "start_time": 399780.0,
      "end_time": 404690.0,
      "text": "by adjusting the numbers in the vector and so after training the model learns"
    },
    {
      "index": 145,
      "start_time": 405180.0,
      "end_time": 406920.0,
      "text": "thousands of Vectors for words."
    },
    {
      "index": 146,
      "start_time": 406920.0,
      "end_time": 407930.0,
      "text": "Give it a new word"
    },
    {
      "index": 147,
      "start_time": 407930.0,
      "end_time": 411200.0,
      "text": "and it will find its associated word vector"
    },
    {
      "index": 148,
      "start_time": 411200.0,
      "end_time": 413220.0,
      "text": "also called word embedding."
    },
    {
      "index": 149,
      "start_time": 413220.0,
      "end_time": 414889.0,
      "text": "Vectors don't just represent data."
    },
    {
      "index": 150,
      "start_time": 414890.0,
      "end_time": 418160.0,
      "text": "They help represent our models too."
    },
    {
      "index": 151,
      "start_time": 418160.0,
      "end_time": 422419.0,
      "text": "Many types of machine learning models represent their Learnings as vectors."
    },
    {
      "index": 152,
      "start_time": 423000.0,
      "end_time": 425340.0,
      "text": "All types of Neural networks do this."
    },
    {
      "index": 153,
      "start_time": 425340.0,
      "end_time": 427129.0,
      "text": "Given some data it will learn Dense"
    },
    {
      "index": 154,
      "start_time": 427740.0,
      "end_time": 430660.0,
      "text": "Representations of that data"
    },
    {
      "index": 155,
      "start_time": 430660.0,
      "end_time": 431840.0,
      "text": "These representations are essentially"
    },
    {
      "index": 156,
      "start_time": 432060.0,
      "end_time": 436640.0,
      "text": "categories akin to if you have a data set of different colored eye pictures."
    },
    {
      "index": 157,
      "start_time": 436640.0,
      "end_time": 438199.0,
      "text": "It will learn a general"
    },
    {
      "index": 158,
      "start_time": 438780.0,
      "end_time": 441129.0,
      "text": "representation for all eye colors."
    },
    {
      "index": 159,
      "start_time": 441129.0,
      "end_time": 444640.0,
      "text": "So given a new unlabeled eye picture,"
    },
    {
      "index": 160,
      "start_time": 444640.0,
      "end_time": 446449.0,
      "text": "it would be able to recognize it as an eye"
    },
    {
      "index": 161,
      "start_time": 447630.0,
      "end_time": 448680.0,
      "text": "I see vectors"
    },
    {
      "index": 162,
      "start_time": 448680.0,
      "end_time": 449680.0,
      "text": "Good."
    },
    {
      "index": 163,
      "start_time": 449680.0,
      "end_time": 451040.0,
      "text": "Once data is vectorized,"
    },
    {
      "index": 164,
      "start_time": 451040.0,
      "end_time": 453780.0,
      "text": "we can do so many things with it"
    },
    {
      "index": 165,
      "start_time": 453780.0,
      "end_time": 456590.0,
      "text": "A trained Word2Vec model turns words into vectors,"
    },
    {
      "index": 166,
      "start_time": 456810.0,
      "end_time": 458929.0,
      "text": "then we can perform mathematical"
    },
    {
      "index": 167,
      "start_time": 459660.0,
      "end_time": 461860.0,
      "text": "operations on these vectors."
    },
    {
      "index": 168,
      "start_time": 461860.0,
      "end_time": 465040.0,
      "text": "We can see how closely related words are"
    },
    {
      "index": 169,
      "start_time": 465040.0,
      "end_time": 468120.0,
      "text": "by computing the distance between their vectors."
    },
    {
      "index": 170,
      "start_time": 468340.0,
      "end_time": 469880.0,
      "text": "The word Sweden, for example,"
    },
    {
      "index": 171,
      "start_time": 469880.0,
      "end_time": 473000.0,
      "text": "is closely related to other wealthy Northern European countries"
    },
    {
      "index": 172,
      "start_time": 473199.0,
      "end_time": 475660.0,
      "text": "Because the distance between them"
    },
    {
      "index": 173,
      "start_time": 475660.0,
      "end_time": 477449.0,
      "text": "is small when plotted on a graph"
    },
    {
      "index": 174,
      "start_time": 477879.0,
      "end_time": 480400.0,
      "text": "Word vectors that are similar tend to"
    },
    {
      "index": 175,
      "start_time": 480400.0,
      "end_time": 483029.0,
      "text": "cluster together like types of animals."
    },
    {
      "index": 176,
      "start_time": 483789.0,
      "end_time": 487109.0,
      "text": "Associations can be built like Rome is to Italy as"
    },
    {
      "index": 177,
      "start_time": 487660.0,
      "end_time": 489840.0,
      "text": "Beijing is to China"
    },
    {
      "index": 178,
      "start_time": 489960.0,
      "end_time": 493800.0,
      "text": "and operations like performing hotels plus motel gives us Holiday Inn"
    },
    {
      "index": 179,
      "start_time": 494500.0,
      "end_time": 496940.0,
      "text": "Incredibly, vectorizing words is able to"
    },
    {
      "index": 180,
      "start_time": 496940.0,
      "end_time": 499140.0,
      "text": "capture their semantic meanings numerically."
    },
    {
      "index": 181,
      "start_time": 500160.0,
      "end_time": 501880.0,
      "text": "The way we're able to compute the distance"
    },
    {
      "index": 182,
      "start_time": 501880.0,
      "end_time": 503940.0,
      "text": "between two vectors"
    },
    {
      "index": 183,
      "start_time": 503940.0,
      "end_time": 506520.0,
      "text": "is by using the notion of a vector Norm"
    },
    {
      "index": 184,
      "start_time": 506740.0,
      "end_time": 511260.0,
      "text": "A norm is any function G that maps Vectors to real numbers"
    },
    {
      "index": 185,
      "start_time": 511260.0,
      "end_time": 513300.0,
      "text": "that satisfies the following conditions"
    },
    {
      "index": 186,
      "start_time": 513578.99999999994,
      "end_time": 516259.99999999994,
      "text": "The lengths are always positive."
    },
    {
      "index": 187,
      "start_time": 516260.0,
      "end_time": 517709.0,
      "text": "The length of zero implies zero."
    },
    {
      "index": 188,
      "start_time": 518229.00000000006,
      "end_time": 519360.00000000006,
      "text": "Scalar multiplication"
    },
    {
      "index": 189,
      "start_time": 519360.0,
      "end_time": 522389.0,
      "text": "extends lengths in a predictable way"
    },
    {
      "index": 190,
      "start_time": 523000.0,
      "end_time": 524169.0,
      "text": "and distances add"
    },
    {
      "index": 191,
      "start_time": 524169.0,
      "end_time": 525980.0,
      "text": "reasonably"
    },
    {
      "index": 192,
      "start_time": 525980.0,
      "end_time": 527968.0,
      "text": "so in a basic vector space the norm of a vector"
    },
    {
      "index": 193,
      "start_time": 528190.0,
      "end_time": 530620.0,
      "text": "would be its absolute value"
    },
    {
      "index": 194,
      "start_time": 530620.0,
      "end_time": 532976.0,
      "text": "and the distance between two numbers like this."
    },
    {
      "index": 195,
      "start_time": 532976.0,
      "end_time": 534630.0,
      "text": "Usually the length of a vector is"
    },
    {
      "index": 196,
      "start_time": 534790.0,
      "end_time": 537060.0,
      "text": "calculated using the Euclidean norm"
    },
    {
      "index": 197,
      "start_time": 537060.0,
      "end_time": 538760.0,
      "text": "which is defined like so"
    },
    {
      "index": 198,
      "start_time": 538760.0,
      "end_time": 541220.0,
      "text": "but this isn't the only way to define length."
    },
    {
      "index": 199,
      "start_time": 541220.0,
      "end_time": 541860.0,
      "text": "There are others."
    },
    {
      "index": 200,
      "start_time": 542170.0,
      "end_time": 544600.0,
      "text": "You'll see the terms L1 norm"
    },
    {
      "index": 201,
      "start_time": 544600.0,
      "end_time": 547520.0,
      "text": "and L2 norm used a lot in machine learning."
    },
    {
      "index": 202,
      "start_time": 547520.0,
      "end_time": 549300.0,
      "text": "The L2 norm is the Euclidean norm."
    },
    {
      "index": 203,
      "start_time": 549610.0,
      "end_time": 552810.0,
      "text": "The L1 norm is also called the Manhattan distance."
    },
    {
      "index": 204,
      "start_time": 552970.0,
      "end_time": 557195.0,
      "text": "We can use either to normalize a vector to get its unit vector"
    },
    {
      "index": 205,
      "start_time": 557195.0,
      "end_time": 559649.0,
      "text": "and use that to compute the distance."
    },
    {
      "index": 206,
      "start_time": 560280.0,
      "end_time": 563160.0,
      "text": "Computing the distance between vectors is useful"
    },
    {
      "index": 207,
      "start_time": 563160.0,
      "end_time": 565440.0,
      "text": "for showing users recommendations."
    },
    {
      "index": 208,
      "start_time": 565900.0,
      "end_time": 568820.0,
      "text": "Both of these terms are also used in the process of regularization."
    },
    {
      "index": 209,
      "start_time": 569410.0,
      "end_time": 572190.0,
      "text": "We train models to fit a set of training data"
    },
    {
      "index": 210,
      "start_time": 572190.0,
      "end_time": 576620.0,
      "text": "But sometimes the model gets so fit to the training data"
    },
    {
      "index": 211,
      "start_time": 576620.0,
      "end_time": 578190.0,
      "text": "that it doesn't have good prediction performance."
    },
    {
      "index": 212,
      "start_time": 578440.0,
      "end_time": 581840.0,
      "text": "It can't generalize well to new data points."
    },
    {
      "index": 213,
      "start_time": 582060.0,
      "end_time": 584520.0,
      "text": "To prevent this overfitting,"
    },
    {
      "index": 214,
      "start_time": 584520.0,
      "end_time": 586640.0,
      "text": "we have to regularize our model."
    },
    {
      "index": 215,
      "start_time": 586640.0,
      "end_time": 588480.0,
      "text": "The common method to finding the best"
    },
    {
      "index": 216,
      "start_time": 588670.0,
      "end_time": 591659.0,
      "text": "model is by defining a Loss function that describes"
    },
    {
      "index": 217,
      "start_time": 592149.0,
      "end_time": 595220.0,
      "text": "how well the model fits the data."
    },
    {
      "index": 218,
      "start_time": 595220.0,
      "end_time": 598469.0,
      "text": "To sum things up, feature vectors are used to represent numeric"
    },
    {
      "index": 219,
      "start_time": 598899.0,
      "end_time": 601800.0,
      "text": "or symbolic characteristics of data called features"
    },
    {
      "index": 220,
      "start_time": 601800.0,
      "end_time": 603960.0,
      "text": "in a mathematical way."
    },
    {
      "index": 221,
      "start_time": 603980.0,
      "end_time": 605180.0,
      "text": "They can be represented in"
    },
    {
      "index": 222,
      "start_time": 605360.0,
      "end_time": 608660.0,
      "text": "multi-dimensional vector spaces where we can perform"
    },
    {
      "index": 223,
      "start_time": 609040.0,
      "end_time": 610020.0,
      "text": "operations on them"
    },
    {
      "index": 224,
      "start_time": 610020.0,
      "end_time": 612560.0,
      "text": "like computing their distance and adding them"
    },
    {
      "index": 225,
      "start_time": 612560.0,
      "end_time": 614620.0,
      "text": "and we can do this by computing the vector norm"
    },
    {
      "index": 226,
      "start_time": 614709.0,
      "end_time": 617070.0,
      "text": "which describes the size of a vector."
    },
    {
      "index": 227,
      "start_time": 617070.0,
      "end_time": 618119.0,
      "text": "Also useful for"
    },
    {
      "index": 228,
      "start_time": 618370.0,
      "end_time": 620360.0,
      "text": "preventing overfitting."
    },
    {
      "index": 229,
      "start_time": 620360.0,
      "end_time": 623060.0,
      "text": "The Wizard of the week Award goes to Vishnu Kumar."
    },
    {
      "index": 230,
      "start_time": 623060.0,
      "end_time": 624719.0,
      "text": "He implemented both gradient descent and"
    },
    {
      "index": 231,
      "start_time": 625029.0,
      "end_time": 627080.0,
      "text": "Newton's method to create a model"
    },
    {
      "index": 232,
      "start_time": 627080.0,
      "end_time": 630894.0,
      "text": "able to predict the amount of calories burned for cycling a certain distance"
    },
    {
      "index": 233,
      "start_time": 630894.0,
      "end_time": 632249.0,
      "text": "the plots are great and the"
    },
    {
      "index": 234,
      "start_time": 632250.0,
      "end_time": 634720.0,
      "text": "code is architected very legibly."
    },
    {
      "index": 235,
      "start_time": 634720.0,
      "end_time": 636720.0,
      "text": "Check it out. Amazing work, Vishnu."
    },
    {
      "index": 236,
      "start_time": 636720.0,
      "end_time": 637919.0,
      "text": "And the runner up for the last-minute"
    },
    {
      "index": 237,
      "start_time": 637920.0,
      "end_time": 640020.0,
      "text": "entry is Hamad Shaikh"
    },
    {
      "index": 238,
      "start_time": 640020.0,
      "end_time": 641760.0,
      "text": "I'd love to have details your notebook was"
    },
    {
      "index": 239,
      "start_time": 641760.0,
      "end_time": 643649.0,
      "text": "This week's challenge is to implement both"
    },
    {
      "index": 240,
      "start_time": 643779.0,
      "end_time": 647698.0,
      "text": "L1 and L2 regularization on a linear regression model"
    },
    {
      "index": 241,
      "start_time": 648100.0,
      "end_time": 652230.0,
      "text": "Check the Github readme in the description for details and winners will be announced in a week."
    }
  ]
}