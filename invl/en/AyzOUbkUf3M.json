{
  "video_id": "AyzOUbkUf3M",
  "title": "The Next Generation of Neural Networks",
  "es": 0,
  "json": [
    {
      "index": 1,
      "start_time": 17600.0,
      "end_time": 22650.0,
      "text": "&gt;&gt; It&#39;s always fun introducing people who need no introduction. But for those of you"
    },
    {
      "index": 2,
      "start_time": 22650.0,
      "end_time": 29600.0,
      "text": "who don&#39;t know Geoff and his work, he pretty much created--he helped create the field of"
    },
    {
      "index": 3,
      "start_time": 29600.0,
      "end_time": 35580.0,
      "text": "machine learning as it now exists and was on the cutting edge back when it was the bleeding"
    },
    {
      "index": 4,
      "start_time": 35580.0,
      "end_time": 41590.0,
      "text": "edge of statistical machine learning and neural nets when they first made their resurgence"
    },
    {
      "index": 5,
      "start_time": 41590.0,
      "end_time": 49260.0,
      "text": "for the first time in our lifetime, and has been a constant force pushing it--pushing"
    },
    {
      "index": 6,
      "start_time": 49260.0,
      "end_time": 55330.0,
      "text": "the analysis in the field away from just sort of the touchy-feely, let&#39;s tweak something"
    },
    {
      "index": 7,
      "start_time": 55330.0,
      "end_time": 60089.0,
      "text": "until it thinks and towards getting--building systems that we can understand and that actually"
    },
    {
      "index": 8,
      "start_time": 60089.0,
      "end_time": 66290.0,
      "text": "do useful things that make our lives better. So you--if you read the talk announcement,"
    },
    {
      "index": 9,
      "start_time": 66290.0,
      "end_time": 72080.0,
      "text": "you&#39;ve seen all of his many accomplishments and members of various royal societies, etcetera,"
    },
    {
      "index": 10,
      "start_time": 72080.0,
      "end_time": 76100.0,
      "text": "so I won&#39;t list those. I think instead of taking up more of his time, I&#39;m just going"
    },
    {
      "index": 11,
      "start_time": 76100.0,
      "end_time": 85289.0,
      "text": "to hand the microphone over to Geoff. &gt;&gt; HINTON: Thank you. I&#39;ve got--I got it."
    },
    {
      "index": 12,
      "start_time": 85289.0,
      "end_time": 91380.0,
      "text": "So the main aim of neural network research is to make computers recognize patterns better"
    },
    {
      "index": 13,
      "start_time": 91380.0,
      "end_time": 95609.0,
      "text": "by emulating the way the brain does it. We know the brain learns to extract many layers"
    },
    {
      "index": 14,
      "start_time": 95609.0,
      "end_time": 99899.0,
      "text": "of features from the sensory data. We don&#39;t know how it does it. So it&#39;s a sort of joint"
    },
    {
      "index": 15,
      "start_time": 99899.0,
      "end_time": 106020.0,
      "text": "enterprise of science and engineering. The first generation of neural networks--I can"
    },
    {
      "index": 16,
      "start_time": 106020.0,
      "end_time": 110909.0,
      "text": "give you a two minute history of neural networks. The first generation with things like Perceptrons,"
    },
    {
      "index": 17,
      "start_time": 110909.0,
      "end_time": 116609.0,
      "text": "where you had hand coded features, they didn&#39;t adapt so you might put an image--the pixels"
    },
    {
      "index": 18,
      "start_time": 116609.0,
      "end_time": 122039.0,
      "text": "of an image here, has some hand coded features, and you&#39;d learn the weights to decision units"
    },
    {
      "index": 19,
      "start_time": 122039.0,
      "end_time": 126979.0,
      "text": "and if you wanted funding, you&#39;d make decision units like that. These were fundamentally"
    },
    {
      "index": 20,
      "start_time": 126979.0,
      "end_time": 134620.0,
      "text": "limited in what they could do as these points out in 1969, and so people stopped doing them."
    },
    {
      "index": 21,
      "start_time": 134620.0,
      "end_time": 140870.0,
      "text": "Then sometime later, people figured out how to change the weights of the feature detectors"
    },
    {
      "index": 22,
      "start_time": 140870.0,
      "end_time": 145530.0,
      "text": "as well as the weights of the decision units. So what you would do is take an image share,"
    },
    {
      "index": 23,
      "start_time": 145530.0,
      "end_time": 150650.0,
      "text": "you&#39;d go forwards through a feed-forward neural network, you will compare the answer the network"
    },
    {
      "index": 24,
      "start_time": 150650.0,
      "end_time": 155400.0,
      "text": "gave with the correct answer, you take some measure of that discrepancy and you send it"
    },
    {
      "index": 25,
      "start_time": 155400.0,
      "end_time": 160120.0,
      "text": "backwards through the net and as you go backwards through the net, you compute the derivatives"
    },
    {
      "index": 26,
      "start_time": 160120.0,
      "end_time": 165850.0,
      "text": "for all of the connections strings here both those once and those once and those once of"
    },
    {
      "index": 27,
      "start_time": 165850.0,
      "end_time": 170280.0,
      "text": "the discrepancy between the correct answer and what you got, and you change all these"
    },
    {
      "index": 28,
      "start_time": 170280.0,
      "end_time": 173660.0,
      "text": "weights to get closer to the correct answer. That&#39;s backpropagation, and it&#39;s just the"
    },
    {
      "index": 29,
      "start_time": 173660.0,
      "end_time": 178960.0,
      "text": "chain rule. It works for non-linear units so potentially, these can learn very powerful"
    },
    {
      "index": 30,
      "start_time": 178960.0,
      "end_time": 184510.0,
      "text": "things and it was a huge disappointment. I can say that now because I got something better."
    },
    {
      "index": 31,
      "start_time": 184510.0,
      "end_time": 189170.0,
      "text": "Basically, we thought when we got this that we cannot learn anything and we&#39;ll get lots"
    },
    {
      "index": 32,
      "start_time": 189170.0,
      "end_time": 194520.0,
      "text": "and lots of features, object recognition, speech recognition, it&#39;ll be easy. There&#39;s"
    },
    {
      "index": 33,
      "start_time": 194520.0,
      "end_time": 199810.0,
      "text": "some problems, it worked for some things, [INDISTINCT] can make it work for more or"
    },
    {
      "index": 34,
      "start_time": 199810.0,
      "end_time": 205650.0,
      "text": "less anything. But in the hands of other people, it has its limitations and something else"
    },
    {
      "index": 35,
      "start_time": 205650.0,
      "end_time": 214870.0,
      "text": "came along so there was a temporary digression called kernel methods where what you do is"
    },
    {
      "index": 36,
      "start_time": 214870.0,
      "end_time": 219660.0,
      "text": "you do Perceptrons in a cleverer way. You take each training example and you turn the"
    },
    {
      "index": 37,
      "start_time": 219660.0,
      "end_time": 223780.0,
      "text": "training example into feature. Basically the feature is how similar are you to this training"
    },
    {
      "index": 38,
      "start_time": 223780.0,
      "end_time": 229670.0,
      "text": "example. And then, you have a clever optimization algorithm that decides to throw away some"
    },
    {
      "index": 39,
      "start_time": 229670.0,
      "end_time": 234940.0,
      "text": "of those features and also decides how to weight the ones it keeps. But when you&#39;re"
    },
    {
      "index": 40,
      "start_time": 234940.0,
      "end_time": 239420.0,
      "text": "finished, you just got these fixed features produced according to a fixed recipe that"
    },
    {
      "index": 41,
      "start_time": 239420.0,
      "end_time": 243900.0,
      "text": "didn&#39;t learn and some weights on these features to make your decision. So it&#39;s just a Perceptron."
    },
    {
      "index": 42,
      "start_time": 243900.0,
      "end_time": 247210.0,
      "text": "There&#39;s a lot of clever math to how you optimize it, but it&#39;s just a Perceptron. And what happened"
    },
    {
      "index": 43,
      "start_time": 247210.0,
      "end_time": 250450.0,
      "text": "was people forgot all of Minsky and Papert&#39;s criticisms about Perceptrons not being able"
    },
    {
      "index": 44,
      "start_time": 250450.0,
      "end_time": 255430.0,
      "text": "to do much. Also it worked better than backpropagation in quite a few things which was deeply embarrassing,"
    },
    {
      "index": 45,
      "start_time": 255430.0,
      "end_time": 261400.0,
      "text": "but it says a lot more about how bad backpropagation was and about how good support in fact the"
    },
    {
      "index": 46,
      "start_time": 261399.99999999997,
      "end_time": 267350.0,
      "text": "machines are. So if you ask what&#39;s wrong with backpropagation, it requires labeled data"
    },
    {
      "index": 47,
      "start_time": 267350.0,
      "end_time": 272449.0,
      "text": "and some of you here may know it&#39;s easy to get data than labels. If you have a--there&#39;s"
    },
    {
      "index": 48,
      "start_time": 272449.0,
      "end_time": 275400.0,
      "text": "a model of the brain, you [INDISTINCT] about that many parameters and you [INDISTINCT]"
    },
    {
      "index": 49,
      "start_time": 275400.0,
      "end_time": 281890.0,
      "text": "for about that many seconds. Actually, twice as many which is important to some of us."
    },
    {
      "index": 50,
      "start_time": 281890.0,
      "end_time": 285750.0,
      "text": "There&#39;s not enough information in labels to constrain that many parameters. You need ten"
    },
    {
      "index": 51,
      "start_time": 285750.0,
      "end_time": 290260.0,
      "text": "to the five bits or bytes per second. There&#39;s only one place you&#39;re going to get that and"
    },
    {
      "index": 52,
      "start_time": 290260.0,
      "end_time": 294000.0,
      "text": "that&#39;s the sensory input. So the brain must be building a model of the sensory input,"
    },
    {
      "index": 53,
      "start_time": 294000.0,
      "end_time": 298820.0,
      "text": "not of these labels. The labels don&#39;t have enough information. Also the learning time"
    },
    {
      "index": 54,
      "start_time": 298820.0,
      "end_time": 302400.0,
      "text": "didn&#39;t scale well. You couldn&#39;t learn lots of layers. The whole point of backpropagation"
    },
    {
      "index": 55,
      "start_time": 302400.0,
      "end_time": 306270.0,
      "text": "was to learn lots of layers and if you gave it like ten layers to learn, it would just"
    },
    {
      "index": 56,
      "start_time": 306270.0,
      "end_time": 312570.0,
      "text": "take forever. And then there&#39;s some neural things I won&#39;t talk about. So if you want"
    },
    {
      "index": 57,
      "start_time": 312570.0,
      "end_time": 316600.0,
      "text": "to overcome these limitations, we want to keep the efficiency of a gradient method for"
    },
    {
      "index": 58,
      "start_time": 316600.0,
      "end_time": 320820.0,
      "text": "updating the parameters but instead of trying to learn the probability of a label given"
    },
    {
      "index": 59,
      "start_time": 320820.0,
      "end_time": 324570.0,
      "text": "an image, where you need the labels, we&#39;re just going to try and learn the probability"
    },
    {
      "index": 60,
      "start_time": 324570.0,
      "end_time": 328810.0,
      "text": "of an image. That is, we&#39;re going to try and build a generative model that if you run it"
    },
    {
      "index": 61,
      "start_time": 328810.0,
      "end_time": 333820.0,
      "text": "will produce stuff that looks like the sensory data. Another is we&#39;re going to try and learn"
    },
    {
      "index": 62,
      "start_time": 333820.0,
      "end_time": 337570.0,
      "text": "to do computer graphics, and once we can do that, then computer vision is just going to"
    },
    {
      "index": 63,
      "start_time": 337570.0,
      "end_time": 342070.0,
      "text": "be inferring how the computer graphics produce this image. So what kind of a model could"
    },
    {
      "index": 64,
      "start_time": 342070.0,
      "end_time": 348530.0,
      "text": "the brain be using for that? The building blocks I&#39;m going to use are a bit like neurons."
    },
    {
      "index": 65,
      "start_time": 348530.0,
      "end_time": 351990.0,
      "text": "They&#39;re intended to be a bit like neurons. They&#39;re these binaries stochastic neurons."
    },
    {
      "index": 66,
      "start_time": 351990.0,
      "end_time": 356420.0,
      "text": "They get some input, they&#39;re given--I put this either a one or a zero, so it&#39;s easy"
    },
    {
      "index": 67,
      "start_time": 356420.0,
      "end_time": 361150.0,
      "text": "to communicate and it&#39;s probabilistic. So this is the probability of giving a one as"
    },
    {
      "index": 68,
      "start_time": 361150.0,
      "end_time": 364280.0,
      "text": "a function of the total input you get which is your external input plus what you get for"
    },
    {
      "index": 69,
      "start_time": 364280.0,
      "end_time": 371030.0,
      "text": "other neurons times the weights on the connections. And we&#39;re going to hook those up into a little"
    },
    {
      "index": 70,
      "start_time": 371030.0,
      "end_time": 376120.0,
      "text": "module that I call a restricted Boltzmann Machine. This is the module here, it has a"
    },
    {
      "index": 71,
      "start_time": 376120.0,
      "end_time": 381310.0,
      "text": "layer of pixels and a layer of feature detectors. So it looks like he&#39;s never going to learn"
    },
    {
      "index": 72,
      "start_time": 381310.0,
      "end_time": 385360.0,
      "text": "lots and lots of layers of feature detectors. It looks like we thrown out the baby with"
    },
    {
      "index": 73,
      "start_time": 385360.0,
      "end_time": 389870.0,
      "text": "the bath water and we&#39;re now just restricted to learning one layer of features but we&#39;ll"
    },
    {
      "index": 74,
      "start_time": 389870.0,
      "end_time": 395520.0,
      "text": "fixed that later. We&#39;re going to have a very restricting connectivity, hence the name,"
    },
    {
      "index": 75,
      "start_time": 395520.0,
      "end_time": 399810.0,
      "text": "where this is going to be a bipartite graph. The visible units for now don&#39;t connect to"
    },
    {
      "index": 76,
      "start_time": 399810.0,
      "end_time": 404300.0,
      "text": "each other and the hidden units don&#39;t connect to each other. The advantage of that is if"
    },
    {
      "index": 77,
      "start_time": 404300.0,
      "end_time": 408860.0,
      "text": "I tell you the state of the pixels, these become independent and so you can update them"
    },
    {
      "index": 78,
      "start_time": 408860.0,
      "end_time": 413169.0,
      "text": "independently and in parallel. So given some pixels and given that you know the weights"
    },
    {
      "index": 79,
      "start_time": 413169.0,
      "end_time": 418510.0,
      "text": "on the connections, you can update all these units in parallel, and so you&#39;ve got your"
    },
    {
      "index": 80,
      "start_time": 418510.0,
      "end_time": 427169.0,
      "text": "feature activations very simply, there&#39;s no lateral interactions there. These networks"
    },
    {
      "index": 81,
      "start_time": 427169.0,
      "end_time": 434860.0,
      "text": "are governed by an energy function and the energy function determines the probability"
    },
    {
      "index": 82,
      "start_time": 434860.0,
      "end_time": 438990.0,
      "text": "of the network adopting particular states just like in a physical system. These stochastic"
    },
    {
      "index": 83,
      "start_time": 438990.0,
      "end_time": 442590.0,
      "text": "units will kind of rattle around and they&#39;ll tend to enter low energy states and avoid"
    },
    {
      "index": 84,
      "start_time": 442590.0,
      "end_time": 447710.0,
      "text": "high energy states. The weights determine the energies linearly. The probabilities are"
    },
    {
      "index": 85,
      "start_time": 447710.0,
      "end_time": 453690.0,
      "text": "an exponential function of the images so the probabilities, the log probabilities are a"
    },
    {
      "index": 86,
      "start_time": 453690.0,
      "end_time": 459230.0,
      "text": "linear function of the weights, and that makes learning easy. There&#39;s a very simple algorithm"
    },
    {
      "index": 87,
      "start_time": 459230.0,
      "end_time": 466919.0,
      "text": "that Terry Sejnowski and me invented in--back in 1982. In a general network, you can run"
    },
    {
      "index": 88,
      "start_time": 466919.0,
      "end_time": 471980.0,
      "text": "it but it&#39;s very, very slow. In this restricted Boltzmann Machine, it&#39;s much more efficient."
    },
    {
      "index": 89,
      "start_time": 471980.0,
      "end_time": 476730.0,
      "text": "And I&#39;m just going to show you what the Maximum Likelihood Learning Algorithm looks like."
    },
    {
      "index": 90,
      "start_time": 476730.0,
      "end_time": 481290.0,
      "text": "That is, suppose you said take one of your parameter on your connection, how do I change"
    },
    {
      "index": 91,
      "start_time": 481290.0,
      "end_time": 487070.0,
      "text": "that parameter so that when I run this machine in generative mode, in computer graphics mode,"
    },
    {
      "index": 92,
      "start_time": 487070.0,
      "end_time": 492330.0,
      "text": "it&#39;s more likely to generate stuff like the stuff I&#39;ve observed? And so here&#39;s what you"
    },
    {
      "index": 93,
      "start_time": 492330.0,
      "end_time": 497100.0,
      "text": "should do, you should take a data vector, an image, and you should put it here on the"
    },
    {
      "index": 94,
      "start_time": 497100.0,
      "end_time": 502900.0,
      "text": "visible units and then you should let the visible units via their current weights activate"
    },
    {
      "index": 95,
      "start_time": 502900.0,
      "end_time": 509290.0,
      "text": "the feature detectors. So you provide input to each feature detector and you now make"
    },
    {
      "index": 96,
      "start_time": 509290.0,
      "end_time": 513320.0,
      "text": "a stochastic decision about what the feature detector should turn on. Lots of positive"
    },
    {
      "index": 97,
      "start_time": 513320.00000000006,
      "end_time": 516490.00000000006,
      "text": "input, it almost certainly turns on, lots of negative input it almost certainly turns"
    },
    {
      "index": 98,
      "start_time": 516490.0,
      "end_time": 523070.0,
      "text": "off. Then, given the binary state of the feature detectors, we now reconstruct the pixels from"
    },
    {
      "index": 99,
      "start_time": 523070.00000000006,
      "end_time": 528350.0,
      "text": "the feature detectors and we just keep going like that. And if we run this chain for a"
    },
    {
      "index": 100,
      "start_time": 528350.0,
      "end_time": 532749.0,
      "text": "long time, this is called a Markov chain, and this process is called alternating Gibbs"
    },
    {
      "index": 101,
      "start_time": 532749.0,
      "end_time": 537779.0,
      "text": "sampling, If we go back [INDISTINCT] for a long time, we&#39;ll get fantasies from the model."
    },
    {
      "index": 102,
      "start_time": 537779.0,
      "end_time": 541509.0,
      "text": "This is the kind of stuff the model would like to produce. These are the things that"
    },
    {
      "index": 103,
      "start_time": 541509.0,
      "end_time": 545579.0,
      "text": "the model shows you when it&#39;s in its low energy states given its current parameters. So that&#39;s"
    },
    {
      "index": 104,
      "start_time": 545579.0,
      "end_time": 549990.0,
      "text": "the sort of stuff it believes in, this is the data and obviously you want to say to"
    },
    {
      "index": 105,
      "start_time": 549990.0,
      "end_time": 555300.0,
      "text": "it, believe in the data, not your own fantasies. And so we&#39;d like to change the parameters"
    },
    {
      "index": 106,
      "start_time": 555300.0,
      "end_time": 559639.0,
      "text": "the way it&#39;s on the connections, so as to make this more likely and that less likely."
    },
    {
      "index": 107,
      "start_time": 559639.0,
      "end_time": 566790.0,
      "text": "And the way to do that is to say, measure how often a pixel i and a feature detector"
    },
    {
      "index": 108,
      "start_time": 566790.0,
      "end_time": 572579.0,
      "text": "j on together when I&#39;m showing you the data vector v. And then measure how often they&#39;re"
    },
    {
      "index": 109,
      "start_time": 572579.0,
      "end_time": 579850.0,
      "text": "on together when the model is just fantasizing and raise the weights by how often they&#39;re"
    },
    {
      "index": 110,
      "start_time": 579850.0,
      "end_time": 583769.0,
      "text": "on together when it&#39;s seeing data and lower the weights by how often they&#39;re on together"
    },
    {
      "index": 111,
      "start_time": 583769.0,
      "end_time": 588029.0,
      "text": "when it&#39;s fantasizing. And what that will do is it&#39;ll make it happy with the data, low"
    },
    {
      "index": 112,
      "start_time": 588029.0,
      "end_time": 592279.0,
      "text": "energy, and less happy with its fantasies. And so it will--its fantasies will gradually"
    },
    {
      "index": 113,
      "start_time": 592279.0,
      "end_time": 598389.0,
      "text": "move towards the data. If its fantasies are just like the data, then these correlations,"
    },
    {
      "index": 114,
      "start_time": 598389.0,
      "end_time": 602930.0,
      "text": "the probability of pixel i and feature detector j being on together in the fantasies will"
    },
    {
      "index": 115,
      "start_time": 602930.0,
      "end_time": 607170.0,
      "text": "be just the same as in the data, and so it&#39;ll stop learning. So it&#39;s a very simple local"
    },
    {
      "index": 116,
      "start_time": 607170.0,
      "end_time": 610699.0,
      "text": "learning rule that a neuron could implement because it just involves learning the activity"
    },
    {
      "index": 117,
      "start_time": 610699.0,
      "end_time": 615199.0,
      "text": "of a neuron and the other neuron it connects to. And that will do Maximum Likelihood Learning,"
    },
    {
      "index": 118,
      "start_time": 615199.0,
      "end_time": 619879.0,
      "text": "but it&#39;s slow. You have to settle for like a hundred steps. So, I think about how to"
    },
    {
      "index": 119,
      "start_time": 619879.0,
      "end_time": 624420.0,
      "text": "make this algorithm go a hundred thousand times faster. The way you do it is instead"
    },
    {
      "index": 120,
      "start_time": 624420.0,
      "end_time": 632790.0,
      "text": "of running for a hundred steps, you just run for one step. So now you go up, you come down"
    },
    {
      "index": 121,
      "start_time": 632790.0,
      "end_time": 637529.0,
      "text": "and you go up again. And you take this difference in statistics and that&#39;s quite efficient to"
    },
    {
      "index": 122,
      "start_time": 637529.0,
      "end_time": 641720.0,
      "text": "do. It took me 17 years to figure this out and in that time computers got a thousand"
    },
    {
      "index": 123,
      "start_time": 641720.0,
      "end_time": 651569.0,
      "text": "times faster. So, the change in the weight now is the difference--is a learning rate"
    },
    {
      "index": 124,
      "start_time": 651569.0,
      "end_time": 656610.0,
      "text": "times the difference between statistics measured with data and statistics measured with reconstructions"
    },
    {
      "index": 125,
      "start_time": 656610.0,
      "end_time": 663059.0,
      "text": "of the data. That&#39;s not doing Maximum Likelihood Learning but it works well anyway. So I&#39;m"
    },
    {
      "index": 126,
      "start_time": 663059.0,
      "end_time": 667220.0,
      "text": "going to show you a little example, we are going to take a little image where we&#39;re going"
    },
    {
      "index": 127,
      "start_time": 667220.0,
      "end_time": 671139.0,
      "text": "to have handwritten digits, this is just a toy sample. We&#39;re going to put random weights"
    },
    {
      "index": 128,
      "start_time": 671139.0,
      "end_time": 676920.0,
      "text": "on the connections then we&#39;re going to activate the binary feature detectors given the input"
    },
    {
      "index": 129,
      "start_time": 676920.0,
      "end_time": 681869.0,
      "text": "they&#39;re getting from the pixels, then we&#39;re going to reconstruct the image and initially"
    },
    {
      "index": 130,
      "start_time": 681869.0,
      "end_time": 684569.0,
      "text": "we can get a lousy reconstruction, this will be very different from the data because they&#39;re"
    },
    {
      "index": 131,
      "start_time": 684569.0,
      "end_time": 689360.0,
      "text": "random weights. And then we&#39;re going to activate the feature detectors again and we&#39;re going"
    },
    {
      "index": 132,
      "start_time": 689360.0,
      "end_time": 694939.0,
      "text": "to increment the connections on the data and we&#39;re going to decrement the connections on"
    },
    {
      "index": 133,
      "start_time": 694939.0,
      "end_time": 699449.0,
      "text": "the reconstructions and that is neither going to learn nice weight for us as I&#39;ll show you,"
    },
    {
      "index": 134,
      "start_time": 699449.0,
      "end_time": 703970.0,
      "text": "nice connection strengths that will make this be a very good model of [INDISTINCT]. It&#39;s"
    },
    {
      "index": 135,
      "start_time": 703970.0,
      "end_time": 708389.0,
      "text": "important to run the algorithm where you take the data and on the data you increment connection"
    },
    {
      "index": 136,
      "start_time": 708389.0,
      "end_time": 714869.0,
      "text": "strengths and on your--this is really a sort of screwed up version of the data that&#39;s being"
    },
    {
      "index": 137,
      "start_time": 714869.0,
      "end_time": 719389.0,
      "text": "infected by the prejudices of the model. So the model kind of interprets the data in terms"
    },
    {
      "index": 138,
      "start_time": 719389.0,
      "end_time": 724499.0,
      "text": "of its features then it reconstructs something, it would rather see than the data. Now you"
    },
    {
      "index": 139,
      "start_time": 724499.0,
      "end_time": 729629.0,
      "text": "could try running a learning algorithm where you take the data, you interpret it, you imagine"
    },
    {
      "index": 140,
      "start_time": 729629.0,
      "end_time": 734809.0,
      "text": "the data is what you would like to see and then you learn on that. That&#39;s the algorithm"
    },
    {
      "index": 141,
      "start_time": 734809.0,
      "end_time": 743449.0,
      "text": "George Bush runs and it doesn&#39;t work very well. So, after you&#39;ve been doing some learning"
    },
    {
      "index": 142,
      "start_time": 743449.0,
      "end_time": 750350.0,
      "text": "on this for not very long, I&#39;m now showing you 25,000 connection strengths. Each of these"
    },
    {
      "index": 143,
      "start_time": 750350.0,
      "end_time": 756589.0,
      "text": "is one of the features, take this slide. That&#39;s a feature and the intensity here shows you"
    },
    {
      "index": 144,
      "start_time": 756589.0,
      "end_time": 761129.0,
      "text": "the strength of the connection to the pixels. So this feature really wants to have these"
    },
    {
      "index": 145,
      "start_time": 761129.0,
      "end_time": 765220.0,
      "text": "pixels off and it really wants to have these pixels on and it doesn&#39;t care much about the"
    },
    {
      "index": 146,
      "start_time": 765220.0,
      "end_time": 771649.0,
      "text": "other ones, mid-gray means zero. And you can see the features are fairly local and these"
    },
    {
      "index": 147,
      "start_time": 771649.0,
      "end_time": 777269.0,
      "text": "features are now very good at reconstructing twos. It was trained on twos. So if I show"
    },
    {
      "index": 148,
      "start_time": 777269.0,
      "end_time": 782170.0,
      "text": "you--show it some twos it never saw before, and get it to reconstruct them, you can see"
    },
    {
      "index": 149,
      "start_time": 782170.0,
      "end_time": 788339.0,
      "text": "it reconstructs them pretty well. The funny pixels here which aren&#39;t quite right is because"
    },
    {
      "index": 150,
      "start_time": 788339.0,
      "end_time": 801970.0,
      "text": "I&#39;m using Vista. So you can see the reconstruction is very like the data and the--it&#39;s not quite"
    },
    {
      "index": 151,
      "start_time": 801970.0,
      "end_time": 805939.0,
      "text": "identical but it&#39;s a very good reconstruction for a wide variety of twos and these are ones"
    },
    {
      "index": 152,
      "start_time": 805939.0,
      "end_time": 813369.0,
      "text": "it didn&#39;t see during training, okay. Now what I&#39;m going to do--that&#39;s no that surprising,"
    },
    {
      "index": 153,
      "start_time": 813369.0,
      "end_time": 817410.0,
      "text": "if you just copied the pixels and copy them back, you&#39;d get the same thing, right? So"
    },
    {
      "index": 154,
      "start_time": 817410.0,
      "end_time": 827149.0,
      "text": "that would work very well. But now I&#39;m going to show it something it didn&#39;t train on. And"
    },
    {
      "index": 155,
      "start_time": 827149.0,
      "end_time": 831429.0,
      "text": "what you have to imagine is that Iraq is made of threes but George Bush thinks it&#39;s made"
    },
    {
      "index": 156,
      "start_time": 831429.0,
      "end_time": 840519.0,
      "text": "of twos, okay? So here&#39;s the real data and this is what George Bush sees. That&#39;s actually"
    },
    {
      "index": 157,
      "start_time": 840519.0,
      "end_time": 844889.0,
      "text": "inconsistent with my previous joke because [INDISTINCT] this learning algorithm. Sorry"
    },
    {
      "index": 158,
      "start_time": 844889.0,
      "end_time": 850959.0,
      "text": "about that. Okay, so you see that it perverts the data into what it would like to believe"
    },
    {
      "index": 159,
      "start_time": 850959.0,
      "end_time": 856110.0,
      "text": "which is like what it&#39;s trained on. Okay, that was just a toy example. Now what we&#39;re"
    },
    {
      "index": 160,
      "start_time": 856110.0,
      "end_time": 862449.0,
      "text": "going to do is train the letter features like that in the way I just showed you. Forget"
    },
    {
      "index": 161,
      "start_time": 862449.0,
      "end_time": 865769.0,
      "text": "these features that are good at reconstructing the data, at least for the kind of data it&#39;s"
    },
    {
      "index": 162,
      "start_time": 865769.0,
      "end_time": 870009.0,
      "text": "trained on. And then we&#39;re going to take the activations of those features and we&#39;re going"
    },
    {
      "index": 163,
      "start_time": 870009.0,
      "end_time": 876119.0,
      "text": "to make those data and train another layer, okay. And then we&#39;re going to keep doing that"
    },
    {
      "index": 164,
      "start_time": 876119.0,
      "end_time": 881259.0,
      "text": "and for reasons that are slightly complicated and I will partially explain, this works extremely"
    },
    {
      "index": 165,
      "start_time": 881259.0,
      "end_time": 885739.0,
      "text": "well. You get more and more abstract features as you go up and once you&#39;ve gone up through"
    },
    {
      "index": 166,
      "start_time": 885739.0,
      "end_time": 890369.0,
      "text": "about three layers, you got very nice abstract features that are very good then for doing"
    },
    {
      "index": 167,
      "start_time": 890369.0,
      "end_time": 894230.0,
      "text": "things like classification. But all these features were learned without ever knowing"
    },
    {
      "index": 168,
      "start_time": 894230.0,
      "end_time": 901769.0,
      "text": "the labels. It can be proved that every time we add another layer, we get a better model"
    },
    {
      "index": 169,
      "start_time": 901769.0,
      "end_time": 906369.0,
      "text": "of the training data or to be more precise, we improve a lower band on how good a model"
    },
    {
      "index": 170,
      "start_time": 906369.0,
      "end_time": 914749.0,
      "text": "we got of the training data. So here&#39;s a quick explanation on what&#39;s going on. When we learn"
    },
    {
      "index": 171,
      "start_time": 914749.0,
      "end_time": 920290.0,
      "text": "the weights in this little restrictive Boltzmann Machine, those weights define the probability"
    },
    {
      "index": 172,
      "start_time": 920290.0,
      "end_time": 925579.0,
      "text": "of given a vector here, we&#39;re constructing a particular vector there. So that&#39;s the probability"
    },
    {
      "index": 173,
      "start_time": 925579.0,
      "end_time": 931809.0,
      "text": "of a visible vector given a hidden vector. They also define this whole Markov chain,"
    },
    {
      "index": 174,
      "start_time": 931809.0,
      "end_time": 934829.0,
      "text": "if you went backwards and forwards many times. And so if you went backwards and forwards"
    },
    {
      "index": 175,
      "start_time": 934829.0,
      "end_time": 939160.0,
      "text": "many times, and then looked to see what you got here, you&#39;ll get some probability distribution"
    },
    {
      "index": 176,
      "start_time": 939160.0,
      "end_time": 943290.0,
      "text": "of the hidden vectors and the weights defining that. And so you can think of the weights"
    },
    {
      "index": 177,
      "start_time": 943290.0,
      "end_time": 950670.0,
      "text": "as defining both a mapping from these vectors of activity over the hidden units to the pixels,"
    },
    {
      "index": 178,
      "start_time": 950670.0,
      "end_time": 959410.0,
      "text": "to images, that&#39;s this term and the same weights define a prior over these tons of hidden activities."
    },
    {
      "index": 179,
      "start_time": 959410.0,
      "end_time": 962829.0,
      "text": "When you learn the next level of Boltzmann Machine up, you&#39;re going to say, &quot;Let&#39;s keep"
    },
    {
      "index": 180,
      "start_time": 962829.0,
      "end_time": 968910.0,
      "text": "this, keep this mapping, and let&#39;s learn a better model of the posterior that we&#39;ve got"
    },
    {
      "index": 181,
      "start_time": 968910.0,
      "end_time": 975249.0,
      "text": "here when we use this mapping,&quot; and you keep replacing the posterior--implicit posterior"
    },
    {
      "index": 182,
      "start_time": 975249.0,
      "end_time": 980309.0,
      "text": "defined by these weights by a better one which is the p of v given h defined by the next"
    },
    {
      "index": 183,
      "start_time": 980309.0,
      "end_time": 984359.0,
      "text": "Boltzmann Machine. And so what you&#39;re really doing is dividing this task into two tasks."
    },
    {
      "index": 184,
      "start_time": 984359.0,
      "end_time": 989949.0,
      "text": "One is, find me a distribution that&#39;s a little bit simpler than the data distribution. Don&#39;t"
    },
    {
      "index": 185,
      "start_time": 989949.0,
      "end_time": 993259.0,
      "text": "go the whole way to try and find a full model, just find me something a bit simpler than"
    },
    {
      "index": 186,
      "start_time": 993259.0,
      "end_time": 997429.0,
      "text": "the data distribution. This is going to be easy [INDISTINCT] Boltzmann Machine to model,"
    },
    {
      "index": 187,
      "start_time": 997429.0,
      "end_time": 1002809.0,
      "text": "that&#39;s very nonparametric. And then find me a parametric mapping from that slightly simpler"
    },
    {
      "index": 188,
      "start_time": 1002810.0,
      "end_time": 1007780.0,
      "text": "distribution to the data distribution. So I call this creeping parameterization. What"
    },
    {
      "index": 189,
      "start_time": 1007780.0,
      "end_time": 1011120.0,
      "text": "you&#39;re really doing is--it&#39;s like taking the shell off an onion, you got this distribution"
    },
    {
      "index": 190,
      "start_time": 1011120.0,
      "end_time": 1018130.0,
      "text": "you want to model. Let&#39;s take off one shell which is this and get a very similar distribution"
    },
    {
      "index": 191,
      "start_time": 1018130.0,
      "end_time": 1021520.0,
      "text": "that&#39;s a bit easier to model and some parameters that tell us how to turn this one to this"
    },
    {
      "index": 192,
      "start_time": 1021520.0,
      "end_time": 1025450.0,
      "text": "one and then that&#39;s going to solve the problem of modeling this distribution. So that&#39;s what&#39;s"
    },
    {
      "index": 193,
      "start_time": 1025450.0,
      "end_time": 1031840.0,
      "text": "going on when you learn these multiple layers. After you&#39;ve learned say three layers, you"
    },
    {
      "index": 194,
      "start_time": 1031839.9999999999,
      "end_time": 1037209.9999999999,
      "text": "have a model that&#39;s a bit surprising. This is the last restrictive Boltzmann Machine"
    },
    {
      "index": 195,
      "start_time": 1037210.0,
      "end_time": 1041271.0,
      "text": "we learned. So here we have this sort of model that says, &quot;To generate from the model, go"
    },
    {
      "index": 196,
      "start_time": 1041270.0,
      "end_time": 1046110.0,
      "text": "backwards and forwards.&quot; But because we just kept the p of v given h from the previous"
    },
    {
      "index": 197,
      "start_time": 1046109.9999999999,
      "end_time": 1050970.0,
      "text": "models, this is a directed model where you sort of get chunk, chunk to generate. So the"
    },
    {
      "index": 198,
      "start_time": 1050970.0,
      "end_time": 1055350.0,
      "text": "right way to generate from this combined model when you&#39;ve learned three layers of features,"
    },
    {
      "index": 199,
      "start_time": 1055350.0,
      "end_time": 1060799.0,
      "text": "is to take the top two layers and go backwards and forwards for a long time. It&#39;s fortunate"
    },
    {
      "index": 200,
      "start_time": 1060800.0,
      "end_time": 1063881.0,
      "text": "you don&#39;t actually need to generate from it, I&#39;m just telling you how you would if you"
    },
    {
      "index": 201,
      "start_time": 1063880.0,
      "end_time": 1067740.0,
      "text": "did. We want this for perception so really, you just need to do perceptual imprint which"
    },
    {
      "index": 202,
      "start_time": 1067740.0,
      "end_time": 1071940.0,
      "text": "is chunk, chunk, chunk, it&#39;s very fast. But to generate, you&#39;d have to get backwards and"
    },
    {
      "index": 203,
      "start_time": 1071940.0,
      "end_time": 1076179.0,
      "text": "forwards for a long time and then once you&#39;ve decided on a pattern here, you go--just go"
    },
    {
      "index": 204,
      "start_time": 1076180.0,
      "end_time": 1083310.0,
      "text": "chunk, chunk, that&#39;s very directed and easy. So I&#39;m now going to learn a particular model"
    },
    {
      "index": 205,
      "start_time": 1083310.0,
      "end_time": 1087770.0,
      "text": "of some handwritten digits but all the digit classes now. So we&#39;re going to put slightly"
    },
    {
      "index": 206,
      "start_time": 1087770.0,
      "end_time": 1091481.0,
      "text": "bigger images of handwritten digits from a very standard data set where we know how well"
    },
    {
      "index": 207,
      "start_time": 1091480.0,
      "end_time": 1097519.0,
      "text": "other methods do. In fact it&#39;s a data set on which support back the machine&#39;s beat backpropagation"
    },
    {
      "index": 208,
      "start_time": 1097520.0,
      "end_time": 1102981.0,
      "text": "which was bad news backpropagation but we&#39;re going to reverse that in a minute. We&#39;re going"
    },
    {
      "index": 209,
      "start_time": 1102980.0,
      "end_time": 1107269.0,
      "text": "to learn 500 features now instead of 50. Once we&#39;ve learned those, we&#39;re going to take the"
    },
    {
      "index": 210,
      "start_time": 1107270.0,
      "end_time": 1112821.0,
      "text": "data, map it through these weights which are just these weights in the opposite direction,"
    },
    {
      "index": 211,
      "start_time": 1112820.0,
      "end_time": 1118000.0,
      "text": "and get some feature vectors. We&#39;re going to treat those as data and learn this guy,"
    },
    {
      "index": 212,
      "start_time": 1118000.0,
      "end_time": 1121889.0,
      "text": "then we&#39;re going to take these feature vectors, we&#39;re going to tack on ten labeled units."
    },
    {
      "index": 213,
      "start_time": 1121890.0,
      "end_time": 1127150.0,
      "text": "So now we needed the labels but I&#39;ll get rid of that later. And so we&#39;ve got a 510 dimensional"
    },
    {
      "index": 214,
      "start_time": 1127150.0,
      "end_time": 1132711.0,
      "text": "vector here and we&#39;re going to learn a joint density model of the labels and the features."
    },
    {
      "index": 215,
      "start_time": 1132710.0,
      "end_time": 1136389.0,
      "text": "We&#39;re not trying to get from the features to the labels, we&#39;re trying to say why do"
    },
    {
      "index": 216,
      "start_time": 1136390.0,
      "end_time": 1142071.0,
      "text": "these two things go together? So we&#39;re learning a joint model of both, not a discriminative"
    },
    {
      "index": 217,
      "start_time": 1142070.0,
      "end_time": 1146309.0,
      "text": "model. When we&#39;ve completed this learning, what we&#39;re going to end up with is, the top"
    },
    {
      "index": 218,
      "start_time": 1146310.0,
      "end_time": 1151290.0,
      "text": "level here is a Boltzmann Machine and so it has an energy function, and you can think"
    },
    {
      "index": 219,
      "start_time": 1151290.0,
      "end_time": 1157111.0,
      "text": "of that as a landscape. When the weights are all small here or close to zero, then the"
    },
    {
      "index": 220,
      "start_time": 1157110.0,
      "end_time": 1162080.0,
      "text": "energy landscape is very flat. All the different configurations here are more or less equally"
    },
    {
      "index": 221,
      "start_time": 1162080.0,
      "end_time": 1166960.0,
      "text": "good. As it learns, it&#39;s going to carve ravines in this energy landscape. If you think of"
    },
    {
      "index": 222,
      "start_time": 1166960.0,
      "end_time": 1172080.0,
      "text": "it as a 510 dimensional energy landscape, these ravines are going to have the property"
    },
    {
      "index": 223,
      "start_time": 1172080.0,
      "end_time": 1178029.0,
      "text": "that in the floor of the ravine, there&#39;s about ten degrees of freedom and those are the ways"
    },
    {
      "index": 224,
      "start_time": 1178030.0,
      "end_time": 1181731.0,
      "text": "in which a digit can [INDISTINCT] and still be a good instance of that digit, like a two"
    },
    {
      "index": 225,
      "start_time": 1181730.0,
      "end_time": 1187620.0,
      "text": "with a bigger loop or a longer tail. Up the sides of the ravine, there&#39;s like 490 directions"
    },
    {
      "index": 226,
      "start_time": 1187620.0,
      "end_time": 1191159.0,
      "text": "and those are the ways in which, if you vary the image, it wouldn&#39;t be such a good two"
    },
    {
      "index": 227,
      "start_time": 1191160.0,
      "end_time": 1199351.0,
      "text": "anymore. But the nice thing is, it&#39;s going to learn long narrow ravine so that one two"
    },
    {
      "index": 228,
      "start_time": 1199350.0,
      "end_time": 1204220.0,
      "text": "can be very different from another two and yet connected by this ravine, the rings captured"
    },
    {
      "index": 229,
      "start_time": 1204220.0,
      "end_time": 1207960.0,
      "text": "the manifold, so it could wander from one to another in a way that it won&#39;t wander from"
    },
    {
      "index": 230,
      "start_time": 1207960.0,
      "end_time": 1213950.0,
      "text": "a two to a three even though the three might be more similar in pixels to the two. Okay."
    },
    {
      "index": 231,
      "start_time": 1213950.0,
      "end_time": 1219500.0,
      "text": "I want to show you this generative model actually generating. Before I do that, I want to own"
    },
    {
      "index": 232,
      "start_time": 1219500.0,
      "end_time": 1224360.0,
      "text": "up, we did a little bit of fine tuning which actually took longer than the original learning,"
    },
    {
      "index": 233,
      "start_time": 1224360.0,
      "end_time": 1229620.0,
      "text": "where you--after you&#39;ve done that greedy layer by layer learning, you do a bit of fine tuning"
    },
    {
      "index": 234,
      "start_time": 1229620.0,
      "end_time": 1235549.0,
      "text": "where you put in images, you do a forward pass, bottom up with binary states and when"
    },
    {
      "index": 235,
      "start_time": 1235550.0,
      "end_time": 1239731.0,
      "text": "you do this forward pass, you adjust the connections slightly so that what you get in one layer"
    },
    {
      "index": 236,
      "start_time": 1239730.0,
      "end_time": 1245419.0,
      "text": "would be better at reconstructing what caused you in the layer below. Then you do a few"
    },
    {
      "index": 237,
      "start_time": 1245420.0,
      "end_time": 1248790.0,
      "text": "iterations at the top level Boltzmann Machine, you go backwards and forwards a few times"
    },
    {
      "index": 238,
      "start_time": 1248790.0,
      "end_time": 1253751.0,
      "text": "to get the learning signal there. And then you do a down pass. And during the down pass,"
    },
    {
      "index": 239,
      "start_time": 1253750.0,
      "end_time": 1258450.0,
      "text": "you adjust the connections going upwards so they&#39;re better at reconstructing what caused"
    },
    {
      "index": 240,
      "start_time": 1258450.0,
      "end_time": 1262240.0,
      "text": "the activity in that layer. So during the down pass, you know what caused activity because"
    },
    {
      "index": 241,
      "start_time": 1262240.0,
      "end_time": 1267179.0,
      "text": "you caused it and you&#39;re trying to recover those causes. That fine tuning helps but it"
    },
    {
      "index": 242,
      "start_time": 1267180.0,
      "end_time": 1286140.0,
      "text": "will work without it. So now I&#39;m going to attempt to show you a movie. That&#39;s not very"
    },
    {
      "index": 243,
      "start_time": 1286140.0,
      "end_time": 1296321.0,
      "text": "nice. Okay, there&#39;s that network. Here where we&#39;re going to put images. Here&#39;s 500 features,"
    },
    {
      "index": 244,
      "start_time": 1296320.0,
      "end_time": 1302139.0,
      "text": "500 features, 2,000 features and the ten labels. First of all, we&#39;re going to do some perception."
    },
    {
      "index": 245,
      "start_time": 1302140.0,
      "end_time": 1309131.0,
      "text": "So I&#39;m going to give it an image and tell it to run forwards. Oops, sorry? I didn&#39;t"
    },
    {
      "index": 246,
      "start_time": 1309130.0,
      "end_time": 1318330.0,
      "text": "mean that. I meant that. And you&#39;ll see, these are stochastic, they keep changing, but it&#39;s"
    },
    {
      "index": 247,
      "start_time": 1318330.0,
      "end_time": 1323679.0,
      "text": "very sure that it&#39;s a four. See, those are the identities of these neurons. It knows"
    },
    {
      "index": 248,
      "start_time": 1323680.0,
      "end_time": 1328461.0,
      "text": "that&#39;s a four and it has no doubt about it, even though its feature detectors are fluctuating"
    },
    {
      "index": 249,
      "start_time": 1328460.0,
      "end_time": 1335139.0,
      "text": "a bit. If I give it a five, hopefully it&#39;ll think it&#39;s a five. Yeah, it doesn&#39;t have any"
    },
    {
      "index": 250,
      "start_time": 1335140.0,
      "end_time": 1341160.0,
      "text": "doubt. So now let&#39;s be mean to it because that&#39;s a lot more fun. I&#39;m going to give it"
    },
    {
      "index": 251,
      "start_time": 1341160.0,
      "end_time": 1347780.0,
      "text": "that. So, it says, so, four, six, eight, four, eight, eight, eight, eight, eight, eight,"
    },
    {
      "index": 252,
      "start_time": 1347780.0,
      "end_time": 1355540.0,
      "text": "four. It can&#39;t make up its mind whether it&#39;s a four or an eight, and that&#39;s pretty reasonable"
    },
    {
      "index": 253,
      "start_time": 1355540.0,
      "end_time": 1358951.0,
      "text": "in those circumstances. It will actually, for that one, say eight a bit more often than"
    },
    {
      "index": 254,
      "start_time": 1358950.0,
      "end_time": 1362840.0,
      "text": "anything else. So, we&#39;ve classed it as getting that right but it&#39;s very unsure whether it&#39;s"
    },
    {
      "index": 255,
      "start_time": 1362840.0,
      "end_time": 1365380.0,
      "text": "an eight or a four. And just occasionally, it thinks it can be other things like a two,"
    },
    {
      "index": 256,
      "start_time": 1365380.0,
      "end_time": 1373269.0,
      "text": "but it basically thinks four or eight. I can make it run faster so you can--okay. It&#39;s"
    },
    {
      "index": 257,
      "start_time": 1373270.0,
      "end_time": 1380631.0,
      "text": "basically four or eight, an occasional six. I could give it something like this and it"
    },
    {
      "index": 258,
      "start_time": 1380630.0,
      "end_time": 1385970.0,
      "text": "thinks basically one or seven and occasionally a four. Because I programmed this myself,"
    },
    {
      "index": 259,
      "start_time": 1385970.0,
      "end_time": 1390529.0,
      "text": "I want to point out that it&#39;s very reasonable for this--this is my baby, and it&#39;s very reasonable"
    },
    {
      "index": 260,
      "start_time": 1390530.0,
      "end_time": 1395680.0,
      "text": "for it to think that I might be four, because, look, you could see the four in there, okay."
    },
    {
      "index": 261,
      "start_time": 1395680.0,
      "end_time": 1401851.0,
      "text": "Okay. Now, that was just doing perception but the very same model does generation. So,"
    },
    {
      "index": 262,
      "start_time": 1401850.0,
      "end_time": 1407090.0,
      "text": "what I can do is I can fix the top level unit and all I&#39;ve done is I&#39;ve fixed the state"
    },
    {
      "index": 263,
      "start_time": 1407090.0,
      "end_time": 1412909.0,
      "text": "of one neuron. There&#39;s a million connections there because that&#39;s 2,500. I just fixed this"
    },
    {
      "index": 264,
      "start_time": 1412910.0,
      "end_time": 1418091.0,
      "text": "one neuron but when I fix that state, then the weights, the 2,000 weights coming out"
    },
    {
      "index": 265,
      "start_time": 1418090.0,
      "end_time": 1424019.0,
      "text": "of there to these neurons here, what they&#39;ll do is they&#39;ll lower the energy of the ravine"
    },
    {
      "index": 266,
      "start_time": 1424020.0,
      "end_time": 1428321.0,
      "text": "for twos and they&#39;ll raise the energy of the ravine for all of the other guys. So, now"
    },
    {
      "index": 267,
      "start_time": 1428320.0,
      "end_time": 1431889.0,
      "text": "we&#39;ve got this landscape in which you got all these ravines but the two ravine has been"
    },
    {
      "index": 268,
      "start_time": 1431890.0,
      "end_time": 1436191.0,
      "text": "lowered. And if you put it at a random point, it will eventually stumble into the two ravine"
    },
    {
      "index": 269,
      "start_time": 1436190.0,
      "end_time": 1445059.0,
      "text": "and then it will stay there and wander around. So, let&#39;s see if we can do that. So, what&#39;s"
    },
    {
      "index": 270,
      "start_time": 1445060.0,
      "end_time": 1450341.0,
      "text": "really going on here is I&#39;m just going backwards and forwards up here. Ignore that for now."
    },
    {
      "index": 271,
      "start_time": 1450340.0,
      "end_time": 1454559.0,
      "text": "I&#39;m going backwards and forwards here and letting it gradually settle until it&#39;s into"
    },
    {
      "index": 272,
      "start_time": 1454560.0,
      "end_time": 1459670.0,
      "text": "a state that this network&#39;s happy with. So, that&#39;s his brain state and that doesn&#39;t mean"
    },
    {
      "index": 273,
      "start_time": 1459670.0,
      "end_time": 1465040.0,
      "text": "much to you. If you look at that, you don&#39;t really know what it means. So, what we&#39;re"
    },
    {
      "index": 274,
      "start_time": 1465040.0,
      "end_time": 1470361.0,
      "text": "going to do is, as it&#39;s settling, we&#39;re going to play out the generative model here. We&#39;re"
    },
    {
      "index": 275,
      "start_time": 1470360.0,
      "end_time": 1474700.0,
      "text": "going to do computer graphics to see what that would have generated. And so, what you"
    },
    {
      "index": 276,
      "start_time": 1474700.0,
      "end_time": 1478669.0,
      "text": "got here is that&#39;s what&#39;s going on in its brain and this is what&#39;s going on in its mind."
    },
    {
      "index": 277,
      "start_time": 1478670.0,
      "end_time": 1483420.0,
      "text": "So, you can see what this is thinking and I&#39;m serious about that. That is--I know it"
    },
    {
      "index": 278,
      "start_time": 1483420.0,
      "end_time": 1490030.0,
      "text": "sounds crazy, when I say to you I&#39;m seeing a pink elephant, what I mean is, I&#39;ve got"
    },
    {
      "index": 279,
      "start_time": 1490030.0,
      "end_time": 1494670.0,
      "text": "a brain state such that, if there were a pink elephant out there, this will be perception."
    },
    {
      "index": 280,
      "start_time": 1494670.0,
      "end_time": 1498140.0,
      "text": "That&#39;s how mental states work. They&#39;re funny because they&#39;re hypothetical, not because"
    },
    {
      "index": 281,
      "start_time": 1498140.0,
      "end_time": 1504971.0,
      "text": "they&#39;re made of spooky stuff. So, I use this language where the terms refer to things in"
    },
    {
      "index": 282,
      "start_time": 1504970.0,
      "end_time": 1508279.0,
      "text": "the world because I was saying, &quot;What would have to be in the world for this brain state"
    },
    {
      "index": 283,
      "start_time": 1508280.0,
      "end_time": 1512861.0,
      "text": "to be perception?&quot; Now, if I got a generative model, I can take the--take the brain state"
    },
    {
      "index": 284,
      "start_time": 1512860.0,
      "end_time": 1516519.0,
      "text": "and say, &quot;Well, what would have to be in the world for that to be perception?&quot; Well, that."
    },
    {
      "index": 285,
      "start_time": 1516520.0,
      "end_time": 1520071.0,
      "text": "So, that&#39;s what it&#39;s thinking, that&#39;s its mental state right there. So, you got brain"
    },
    {
      "index": 286,
      "start_time": 1520070.0,
      "end_time": 1530779.0,
      "text": "states and mental states and most psychologists won&#39;t show you both. Let&#39;s go a bit faster."
    },
    {
      "index": 287,
      "start_time": 1530780.0,
      "end_time": 1534251.0,
      "text": "And it still hasn&#39;t settled into the two ravine. And now it&#39;s about in the two ravine. And"
    },
    {
      "index": 288,
      "start_time": 1534250.0,
      "end_time": 1539710.0,
      "text": "now it&#39;s just wandering around in that two ravine and this is what it&#39;s thinking. It"
    },
    {
      "index": 289,
      "start_time": 1539710.0,
      "end_time": 1542990.0,
      "text": "knows about all sorts of different twos and it&#39;s very good that it does because that means"
    },
    {
      "index": 290,
      "start_time": 1542990.0,
      "end_time": 1553590.0,
      "text": "it can recognize weird twos. Let&#39;s give it another one. It hasn&#39;t got into the eight"
    },
    {
      "index": 291,
      "start_time": 1553590.0,
      "end_time": 1557370.0,
      "text": "ravine properly yet. It will jump [INDISTINCT] the ravines, he&#39;s not really there. But by"
    },
    {
      "index": 292,
      "start_time": 1557370.0,
      "end_time": 1561029.0,
      "text": "now, it will be in the eight ravine and it will show you all the sorts of different eights"
    },
    {
      "index": 293,
      "start_time": 1561030.0,
      "end_time": 1564871.0,
      "text": "it believes in, if you run it long enough. If you run it for an hour now, it would probably"
    },
    {
      "index": 294,
      "start_time": 1564870.0,
      "end_time": 1569220.0,
      "text": "just stay in the eight ravine showing you all sorts of different eights, okay. Let&#39;s"
    },
    {
      "index": 295,
      "start_time": 1569220.0,
      "end_time": 1580450.0,
      "text": "do one more because I liked it so much. Again, it&#39;s not really in the five ravine properly"
    },
    {
      "index": 296,
      "start_time": 1580450.0,
      "end_time": 1584889.0,
      "text": "yet. No, that was a six. By now it&#39;s in the five ravine and it will show you all sorts"
    },
    {
      "index": 297,
      "start_time": 1584890.0,
      "end_time": 1591341.0,
      "text": "of weird fives, ones without tops, some occasional sixes. And it ends up with a pretty weird"
    },
    {
      "index": 298,
      "start_time": 1591340.0,
      "end_time": 1594379.0,
      "text": "one but that&#39;s definitely a five and it&#39;s very good that it knows that that&#39;s definitely"
    },
    {
      "index": 299,
      "start_time": 1594380.0,
      "end_time": 1602971.0,
      "text": "a five because it lies to recognize things like that. Okay. That&#39;s it for the demo. I"
    },
    {
      "index": 300,
      "start_time": 1602970.0,
      "end_time": 1621519.0,
      "text": "have to get rid of that. Okay. So, here&#39;s some examples of things it can recognize."
    },
    {
      "index": 301,
      "start_time": 1621520.0,
      "end_time": 1624691.0,
      "text": "These are all the ones it got right and you can see it. It recognizes a wide variety of"
    },
    {
      "index": 302,
      "start_time": 1624690.0,
      "end_time": 1630230.0,
      "text": "twos. It recognizes that this is a one despite that and it recognizes that this is a seven"
    },
    {
      "index": 303,
      "start_time": 1630230.0,
      "end_time": 1634440.0,
      "text": "because of that. If you try writing a program by hand, it will do that. You&#39;ll find it&#39;s"
    },
    {
      "index": 304,
      "start_time": 1634440.0,
      "end_time": 1640529.0,
      "text": "kind of tricky if you&#39;d never thought of these examples in advance. If you compare it with"
    },
    {
      "index": 305,
      "start_time": 1640530.0,
      "end_time": 1645270.0,
      "text": "support vector machines, now what we&#39;re doing here is we&#39;re taking a pure machine learning"
    },
    {
      "index": 306,
      "start_time": 1645270.0,
      "end_time": 1649231.0,
      "text": "task. We&#39;re not giving it any prior knowledge about pixels being next to other pixels. We&#39;re"
    },
    {
      "index": 307,
      "start_time": 1649230.0,
      "end_time": 1653399.0,
      "text": "not giving it extra transformations of the data. So, this is without--it&#39;s a pure machine"
    },
    {
      "index": 308,
      "start_time": 1653400.0,
      "end_time": 1657560.0,
      "text": "learning task without any extra help. If you get extra help, you could make all the methods"
    },
    {
      "index": 309,
      "start_time": 1657560.0,
      "end_time": 1662660.0,
      "text": "a lot better. But a support vector machine done by DeCoste and Scholkopf were very good,"
    },
    {
      "index": 310,
      "start_time": 1662660.0,
      "end_time": 1670030.0,
      "text": "it got 1.4%. The best you can do with standard backpropagations is about 1.6%. This gets"
    },
    {
      "index": 311,
      "start_time": 1670030.0,
      "end_time": 1675010.0,
      "text": "1.25% and significance here is about a difference of 0.1. So, this is significantly better than"
    },
    {
      "index": 312,
      "start_time": 1675010.0,
      "end_time": 1685170.0,
      "text": "that. [INDISTINCT] maybe gets 3.3%. Now, I fine-tune that to be good at generations so"
    },
    {
      "index": 313,
      "start_time": 1685170.0,
      "end_time": 1689140.0,
      "text": "I could show you it generating using this sort of up down algorithm but we can also"
    },
    {
      "index": 314,
      "start_time": 1689140.0,
      "end_time": 1694121.0,
      "text": "use backpropagation for fine-tuning. And now that I&#39;ve got this way of finding features"
    },
    {
      "index": 315,
      "start_time": 1694120.0,
      "end_time": 1700159.0,
      "text": "from the sensory data, I can say things like nobody in their right mind would ever suggest"
    },
    {
      "index": 316,
      "start_time": 1700160.0,
      "end_time": 1705260.0,
      "text": "that you would use a local search technique like backpropagation to search some huge non-linear"
    },
    {
      "index": 317,
      "start_time": 1705260.0,
      "end_time": 1712750.0,
      "text": "space by starting with small random weights. It will get stuck in local [INDISTINCT]. And"
    },
    {
      "index": 318,
      "start_time": 1712750.0,
      "end_time": 1716571.0,
      "text": "that is indeed true. What we&#39;re going to do is we&#39;re going to search this huge non-linear"
    },
    {
      "index": 319,
      "start_time": 1716570.0,
      "end_time": 1722309.0,
      "text": "space of possible features by finding features in the sensory data and then finding features"
    },
    {
      "index": 320,
      "start_time": 1722310.0,
      "end_time": 1726461.0,
      "text": "in the combinations of features we find in the sensory data and keep doing that. And"
    },
    {
      "index": 321,
      "start_time": 1726460.0,
      "end_time": 1731980.0,
      "text": "we&#39;ll design our features like that. So, we didn&#39;t need labels, we just need sensory data."
    },
    {
      "index": 322,
      "start_time": 1731980.0,
      "end_time": 1736330.0,
      "text": "Once we designed all our features we can then use backpropagation too slightly fine-tune"
    },
    {
      "index": 323,
      "start_time": 1736330.0,
      "end_time": 1740919.0,
      "text": "them to make the category boundaries be in the right place. So, a pure version of that"
    },
    {
      "index": 324,
      "start_time": 1740920.0,
      "end_time": 1745280.0,
      "text": "would be to say let&#39;s learn the same net but without any labels. Okay? So, we do all the"
    },
    {
      "index": 325,
      "start_time": 1745280.0,
      "end_time": 1750481.0,
      "text": "pre-training like this. After we pre-trained now, what we&#39;re going to do is we&#39;re going"
    },
    {
      "index": 326,
      "start_time": 1750480.0,
      "end_time": 1755639.0,
      "text": "to attach ten label units to the top and we&#39;re going to use backpropagation to fine-tune"
    },
    {
      "index": 327,
      "start_time": 1755640.0,
      "end_time": 1759691.0,
      "text": "these and the fine-tuning is hardly going to change the weights at all but is going"
    },
    {
      "index": 328,
      "start_time": 1759690.0,
      "end_time": 1763529.0,
      "text": "to make the discrimination performance a lot better. So, this is going to be discriminative"
    },
    {
      "index": 329,
      "start_time": 1763530.0,
      "end_time": 1768231.0,
      "text": "fine-tuning and [INDISTINCT] 1.15% errors and all the code for doing the pre-training"
    },
    {
      "index": 330,
      "start_time": 1768230.0,
      "end_time": 1776299.0,
      "text": "and the fine-tuning is on my webpage, if you want to try it. Now, given that we now know"
    },
    {
      "index": 331,
      "start_time": 1776300.0,
      "end_time": 1782260.0,
      "text": "how to get features from data, we can now train things we never used to be able to train"
    },
    {
      "index": 332,
      "start_time": 1782260.0,
      "end_time": 1785611.0,
      "text": "with backpropagation. If you take a net like this where we&#39;re going to put in the digit,"
    },
    {
      "index": 333,
      "start_time": 1785610.0,
      "end_time": 1789590.0,
      "text": "and we&#39;re going to try and get out the same digit but we&#39;re going to put like eight layers"
    },
    {
      "index": 334,
      "start_time": 1789590.0,
      "end_time": 1795490.0,
      "text": "of non-linearities in between, if you start with small random weights and you backpropagate,"
    },
    {
      "index": 335,
      "start_time": 1795490.0,
      "end_time": 1799179.0,
      "text": "you get small, small times small, and by the time you get back here, you get small to the"
    },
    {
      "index": 336,
      "start_time": 1799180.0,
      "end_time": 1804441.0,
      "text": "power eight and you don&#39;t get any gradient. If you wrote in big random weights, you&#39;ll"
    },
    {
      "index": 337,
      "start_time": 1804440.0,
      "end_time": 1808100.0,
      "text": "get a gradient but you&#39;ll have decided in advance where you&#39;re going to be in the search"
    },
    {
      "index": 338,
      "start_time": 1808100.0,
      "end_time": 1812320.0,
      "text": "space. What we&#39;re going to do is learn this Boltzmann Machine here. After we&#39;ve learned"
    },
    {
      "index": 339,
      "start_time": 1812320.0,
      "end_time": 1818379.0,
      "text": "that, we&#39;re going to map the data to get activity patterns and then this Boltzmann Machine."
    },
    {
      "index": 340,
      "start_time": 1818380.0,
      "end_time": 1823701.0,
      "text": "Then we&#39;re going to learn this Boltzmann Machine but with linear hidden units. And then what"
    },
    {
      "index": 341,
      "start_time": 1823700.0,
      "end_time": 1829299.0,
      "text": "we&#39;re going to do is put the transposed weights here because this is good at reconstructing"
    },
    {
      "index": 342,
      "start_time": 1829300.0,
      "end_time": 1835221.0,
      "text": "that. So, this should be good and so on. And we&#39;re going to use that as a starting point"
    },
    {
      "index": 343,
      "start_time": 1835220.0,
      "end_time": 1840429.0,
      "text": "and then we do backpropagation from there and it will slightly change all of these weights"
    },
    {
      "index": 344,
      "start_time": 1840430.0,
      "end_time": 1845081.0,
      "text": "and it will make this work really well. And so now what it&#39;s done is this communicated"
    },
    {
      "index": 345,
      "start_time": 1845080.0,
      "end_time": 1852220.0,
      "text": "this 28 by 28 image via this bottleneck of 30 units but using a highly non-linear transformation"
    },
    {
      "index": 346,
      "start_time": 1852220.0,
      "end_time": 1856769.0,
      "text": "to compress it. If you make everything linear here, you leave out all these layers and make"
    },
    {
      "index": 347,
      "start_time": 1856770.0,
      "end_time": 1860300.0,
      "text": "everything linear, this is PCA, Principal Components, which is a standard way to compress"
    },
    {
      "index": 348,
      "start_time": 1860300.0,
      "end_time": 1867760.0,
      "text": "things. If you put in all these non-linear layers, it&#39;s much better than PCA. So, this"
    },
    {
      "index": 349,
      "start_time": 1867760.0,
      "end_time": 1870741.0,
      "text": "is all done without labels, now. You just give it the digits, you don&#39;t tell it which"
    },
    {
      "index": 350,
      "start_time": 1870740.0,
      "end_time": 1877509.0,
      "text": "is which. These are examples of the real digits, just one example of each class. These are"
    },
    {
      "index": 351,
      "start_time": 1877510.0,
      "end_time": 1882591.0,
      "text": "the reconstructions from those 30 activities in the hidden layer and you can see they&#39;re"
    },
    {
      "index": 352,
      "start_time": 1882590.0,
      "end_time": 1892480.0,
      "text": "actually better than the data. This is a dangerous line of thought. PCA does this and you can"
    },
    {
      "index": 353,
      "start_time": 1892480.0,
      "end_time": 1897869.0,
      "text": "see it&#39;s kind of hopeless compared to this method. At least that&#39;s what you&#39;re meant"
    },
    {
      "index": 354,
      "start_time": 1897870.0,
      "end_time": 1903241.0,
      "text": "to see. Now, we can apply this to document vectors. I don&#39;t find documents as interesting"
    },
    {
      "index": 355,
      "start_time": 1903240.0,
      "end_time": 1908470.0,
      "text": "as digits but I know some people are interested in them. You could take a document vector"
    },
    {
      "index": 356,
      "start_time": 1908470.0,
      "end_time": 1913649.0,
      "text": "and you could take the counts of the 2000 most common words and there&#39;s a big database"
    },
    {
      "index": 357,
      "start_time": 1913650.0,
      "end_time": 1920861.0,
      "text": "like this of 800,000 documents. And so we took 400,000--sorry. Yeah, I know. I see people"
    },
    {
      "index": 358,
      "start_time": 1920860.0,
      "end_time": 1930889.0,
      "text": "smiling. [INDISTINCT] 100,000, I&#39;m an academic, okay. We then train up a neural net like this,"
    },
    {
      "index": 359,
      "start_time": 1930890.0,
      "end_time": 1934441.0,
      "text": "where these are now [INDISTINCT] units. For those of you who know machine learning, we"
    },
    {
      "index": 360,
      "start_time": 1934440.0,
      "end_time": 1939559.0,
      "text": "can use any units in the exponential family, where the log probability is linear in the"
    },
    {
      "index": 361,
      "start_time": 1939560.0,
      "end_time": 1944361.0,
      "text": "parameters. So, we train up this to get some features, we train up this to get some features,"
    },
    {
      "index": 362,
      "start_time": 1944360.0,
      "end_time": 1949919.0,
      "text": "and then we train up this until you get just two linear features. That seems a little excessive"
    },
    {
      "index": 363,
      "start_time": 1949920.0,
      "end_time": 1954721.0,
      "text": "and obviously when we reconstruct, we&#39;re not going to get quite the right counts. But you&#39;ll"
    },
    {
      "index": 364,
      "start_time": 1954720.0,
      "end_time": 1959639.0,
      "text": "get a--you&#39;ll get counts that are much closer to the right counts in the base rates. So,"
    },
    {
      "index": 365,
      "start_time": 1959640.0,
      "end_time": 1965180.0,
      "text": "we&#39;ve done here, you have a high count for Iraq and Cheney and torture, up here, you&#39;ll"
    },
    {
      "index": 366,
      "start_time": 1965180.0,
      "end_time": 1971991.0,
      "text": "get high counts for similar things. So, we can turn a document into a point in the two"
    },
    {
      "index": 367,
      "start_time": 1971990.0,
      "end_time": 1976929.0,
      "text": "dimensional space. And of course once we got a point in two dimensional space, we can plot"
    },
    {
      "index": 368,
      "start_time": 1976930.0,
      "end_time": 1982670.0,
      "text": "it in 2D. And for this database, someone had gone through by hand, more or less by hand,"
    },
    {
      "index": 369,
      "start_time": 1982670.0,
      "end_time": 1986971.0,
      "text": "and labeled all the documents. We didn&#39;t use the labels, okay. But now when we plot the"
    },
    {
      "index": 370,
      "start_time": 1986970.0,
      "end_time": 1992830.0,
      "text": "point in 2D, we can color the point by the class of the document. So, if you do the standard"
    },
    {
      "index": 371,
      "start_time": 1992830.0,
      "end_time": 1998769.0,
      "text": "technique which is Latent Semantic Analysis which is just a version of PCA, and you layout"
    },
    {
      "index": 372,
      "start_time": 1998770.0,
      "end_time": 2003941.0,
      "text": "these documents in 2D, that&#39;s what you get. And you can see the green ones are in a slightly"
    },
    {
      "index": 373,
      "start_time": 2003940.0,
      "end_time": 2008470.0,
      "text": "different place from these blue once but it&#39;s a bit of a mess. If you use our method, it"
    },
    {
      "index": 374,
      "start_time": 2008470.0,
      "end_time": 2015980.0,
      "text": "does a little bit better. You get that. And so now, if you look at these documents--these"
    },
    {
      "index": 375,
      "start_time": 2015980.0,
      "end_time": 2020080.0,
      "text": "are business documents, right? If you look at these documents here, you can see there&#39;s"
    },
    {
      "index": 376,
      "start_time": 2020080.0,
      "end_time": 2023799.0,
      "text": "lots of different kinds of documents about accounts and earnings. Presumably, there&#39;s"
    },
    {
      "index": 377,
      "start_time": 2023800.0,
      "end_time": 2028111.0,
      "text": "an Enron cluster in here somewhere and it would be very nice to know which are the companies"
    },
    {
      "index": 378,
      "start_time": 2028110.0,
      "end_time": 2035889.0,
      "text": "that are in this Enron cluster. Okay. But there&#39;s something more interesting you can"
    },
    {
      "index": 379,
      "start_time": 2035890.0,
      "end_time": 2041680.0,
      "text": "do. That&#39;s just for visualization. But now I&#39;m going to show you how to solve the following"
    },
    {
      "index": 380,
      "start_time": 2041680.0,
      "end_time": 2046091.0,
      "text": "problem. Suppose I&#39;d give you a document. So, this isn&#39;t like what I call Google Search"
    },
    {
      "index": 381,
      "start_time": 2046090.0,
      "end_time": 2051350.0,
      "text": "where you use a few key words and you find what you want. This is--I give you a document"
    },
    {
      "index": 382,
      "start_time": 2051350.0,
      "end_time": 2055830.0,
      "text": "and I ask you to find similar documents to the one I gave you. Okay? Documents with similar"
    },
    {
      "index": 383,
      "start_time": 2055830.0,
      "end_time": 2062139.0,
      "text": "semantic content. So, I&#39;m using a document as a query. What we&#39;re going to do is we&#39;re"
    },
    {
      "index": 384,
      "start_time": 2062139.9999999998,
      "end_time": 2067210.9999999998,
      "text": "going to take our big database of documents, a whole million of them, and we&#39;re going to"
    },
    {
      "index": 385,
      "start_time": 2067210.0,
      "end_time": 2073210.0,
      "text": "train up this network and it&#39;s going to convert these documents into 30 numbers. I&#39;m going"
    },
    {
      "index": 386,
      "start_time": 2073210.0,
      "end_time": 2079440.0,
      "text": "to use logistic units here, that is numbers that range between 1 and 0 and we&#39;re going"
    },
    {
      "index": 387,
      "start_time": 2079440.0,
      "end_time": 2084550.0,
      "text": "to train it as Boltzmann Machines. Then we&#39;re going to back propagate and we&#39;ll get intermediate"
    },
    {
      "index": 388,
      "start_time": 2084550.0000000002,
      "end_time": 2088940.0000000002,
      "text": "values here that convey lots of information. And then we&#39;re going to start adding noise"
    },
    {
      "index": 389,
      "start_time": 2088940.0,
      "end_time": 2094920.0,
      "text": "here and we&#39;re going to add lots and lots of noise. Now, if I add lots and lots of noise"
    },
    {
      "index": 390,
      "start_time": 2094920.0,
      "end_time": 2099270.0,
      "text": "to something that has an output between 0 and 1, there&#39;s only one way it can transmit"
    },
    {
      "index": 391,
      "start_time": 2099270.0,
      "end_time": 2104080.0,
      "text": "a lot of information. It&#39;s got to make the total input that comes from below be either"
    },
    {
      "index": 392,
      "start_time": 2104080.0,
      "end_time": 2108300.0,
      "text": "very big and positive, in which case it&#39;ll give one, or very big and negative, in which"
    },
    {
      "index": 393,
      "start_time": 2108300.0,
      "end_time": 2112290.0,
      "text": "case it&#39;ll give a zero. And in both those cases, it will resist the noise. If it uses"
    },
    {
      "index": 394,
      "start_time": 2112290.0,
      "end_time": 2117270.0,
      "text": "any intermediate value, the outcome will be determined by the noise. So, it won&#39;t transmit"
    },
    {
      "index": 395,
      "start_time": 2117270.0,
      "end_time": 2119280.0,
      "text": "information, so it won&#39;t be very good at getting the right answers."
    },
    {
      "index": 396,
      "start_time": 2119280.0,
      "end_time": 2122560.0,
      "text": "&gt;&gt; So the noise is something like Gaussian, it&#39;s not binary flipping."
    },
    {
      "index": 397,
      "start_time": 2122560.0,
      "end_time": 2126960.0,
      "text": "&gt;&gt; HINTON: It&#39;s Gaussian noise. And we gradually increase the standard deviation and it&#39;s noise"
    },
    {
      "index": 398,
      "start_time": 2126960.0,
      "end_time": 2131130.0,
      "text": "in the input to the unit. And we gradually increase this, and we use a funny kind of"
    },
    {
      "index": 399,
      "start_time": 2131130.0,
      "end_time": 2134690.0,
      "text": "noise that I don&#39;t want to get into, that makes it easier to use conjugate gradient"
    },
    {
      "index": 400,
      "start_time": 2134690.0,
      "end_time": 2140730.0,
      "text": "descent. And what will happen is, these will turn into binary units. So, we now have a"
    },
    {
      "index": 401,
      "start_time": 2140730.0,
      "end_time": 2148570.0,
      "text": "way of converting the word can&#39;t vector a document into a 30 bit binary vector. And"
    },
    {
      "index": 402,
      "start_time": 2148570.0,
      "end_time": 2154640.0,
      "text": "now we can do what I call supermarket search. So, suppose you want to find things that are"
    },
    {
      "index": 403,
      "start_time": 2154640.0,
      "end_time": 2159160.0,
      "text": "like a can of sardines. What you do is you go to your local supermarket and you say to"
    },
    {
      "index": 404,
      "start_time": 2159160.0,
      "end_time": 2164150.0,
      "text": "the cashier, &quot;Where do you keep the sardines?&quot; And you go to where the sardines are and then"
    },
    {
      "index": 405,
      "start_time": 2164150.0,
      "end_time": 2167510.0,
      "text": "you just look around and there&#39;s all the things similar to sardines because the supermarket"
    },
    {
      "index": 406,
      "start_time": 2167510.0,
      "end_time": 2172630.0,
      "text": "arrange things sensibly. Now, it doesn&#39;t quite work because you don&#39;t find the anchovies,"
    },
    {
      "index": 407,
      "start_time": 2172630.0,
      "end_time": 2176250.0,
      "text": "as I discovered when I came to North America, I couldn&#39;t find the anchovies. They weren&#39;t"
    },
    {
      "index": 408,
      "start_time": 2176250.0,
      "end_time": 2181520.0,
      "text": "anywhere near the sardines and the tuna. That&#39;s because they&#39;re near the pizza toppings. But"
    },
    {
      "index": 409,
      "start_time": 2181520.0,
      "end_time": 2185210.0,
      "text": "that&#39;s just because it&#39;s a three dimensional supermarket. If there was a 30 dimensional"
    },
    {
      "index": 410,
      "start_time": 2185210.0,
      "end_time": 2189730.0,
      "text": "supermarket, they could be close to the pizza toppings and close to the sardines. So, what"
    },
    {
      "index": 411,
      "start_time": 2189730.0,
      "end_time": 2198530.0,
      "text": "we&#39;re going to do is we&#39;re going to take a document and using our learned network, we&#39;re"
    },
    {
      "index": 412,
      "start_time": 2198530.0,
      "end_time": 2203700.0,
      "text": "going to hash it to this 30-bit code. But this is a hash code that was learned. It&#39;s"
    },
    {
      "index": 413,
      "start_time": 2203700.0,
      "end_time": 2207450.0,
      "text": "not some random little thing. It was learned with lots of machine learning. So, it has"
    },
    {
      "index": 414,
      "start_time": 2207450.0,
      "end_time": 2213510.0,
      "text": "the property that similar documents mapped to similar codes. So, now we can use hashing"
    },
    {
      "index": 415,
      "start_time": 2213510.0,
      "end_time": 2217620.0,
      "text": "for doing approximate matches. Everybody knows hashing is nice and fast and everybody usually"
    },
    {
      "index": 416,
      "start_time": 2217620.0,
      "end_time": 2222790.0,
      "text": "can&#39;t do approximate matches. But with machine learning, you can have both. So, we take our"
    },
    {
      "index": 417,
      "start_time": 2222790.0,
      "end_time": 2228290.0,
      "text": "document, we hash it to a code and in this memory space, at each point in the memory"
    },
    {
      "index": 418,
      "start_time": 2228290.0,
      "end_time": 2234040.0,
      "text": "space, we put a pointer to the document that has that code and your [INDISTINCT] so if"
    },
    {
      "index": 419,
      "start_time": 2234040.0,
      "end_time": 2239670.0,
      "text": "two documents have the same code, you can figure out what to do. So now, with the query"
    },
    {
      "index": 420,
      "start_time": 2239670.0,
      "end_time": 2243560.0,
      "text": "document, we just go there and now we just look around like in the supermarket. And the"
    },
    {
      "index": 421,
      "start_time": 2243560.0,
      "end_time": 2247910.0,
      "text": "nearby similar documents will have nearby codes. And so, all you need to do to find"
    },
    {
      "index": 422,
      "start_time": 2247910.0,
      "end_time": 2254550.0,
      "text": "a similar document is flip a bit and do a memory access. Okay. That&#39;s two machine instructions."
    },
    {
      "index": 423,
      "start_time": 2254550.0,
      "end_time": 2258850.0,
      "text": "So, if you were to have a database, let&#39;s say 10 Billion documents, and I give you one"
    },
    {
      "index": 424,
      "start_time": 2258850.0,
      "end_time": 2264200.0,
      "text": "and say, &quot;Give me a 100,000 documents similar to this one,&quot; from my other search technique"
    },
    {
      "index": 425,
      "start_time": 2264200.0,
      "end_time": 2268310.0,
      "text": "I&#39;m going to use, it can only cope with a 100,000. You&#39;re going to have to do a 100,000"
    },
    {
      "index": 426,
      "start_time": 2268310.0,
      "end_time": 2273830.0,
      "text": "times, you&#39;re going to have to flip a bit and do a memory access. So, that&#39;s only 200,000"
    },
    {
      "index": 427,
      "start_time": 2273830.0,
      "end_time": 2279130.0,
      "text": "machine instructions. I need two machine instructions per document. It&#39;s completely independent"
    },
    {
      "index": 428,
      "start_time": 2279130.0,
      "end_time": 2283880.0,
      "text": "of the size of your database. Okay. Because you&#39;ve laid things out like in a supermarket,"
    },
    {
      "index": 429,
      "start_time": 2283880.0,
      "end_time": 2294860.0,
      "text": "you&#39;ve got a document supermarket now [INDISTINCT] so, if you compare it with--well, we&#39;ve actually"
    },
    {
      "index": 430,
      "start_time": 2294860.0,
      "end_time": 2298170.0,
      "text": "only tried it because we&#39;re academic, on 20-bit codes and a million documents and it works"
    },
    {
      "index": 431,
      "start_time": 2298170.0,
      "end_time": 2304100.0,
      "text": "just fine, but nothing could possibly go wrong when you scale it up. It&#39;s actually quite"
    },
    {
      "index": 432,
      "start_time": 2304100.0,
      "end_time": 2309220.0,
      "text": "accurate. That is, if you compare it with a sort of gold standard method, it&#39;s about"
    },
    {
      "index": 433,
      "start_time": 2309220.0,
      "end_time": 2313840.0,
      "text": "the same accuracy and when you now take your shortlist that you find in this very fast"
    },
    {
      "index": 434,
      "start_time": 2313840.0,
      "end_time": 2318880.0,
      "text": "way and you give those guys in the shortlist to the gold standard method, it works better"
    },
    {
      "index": 435,
      "start_time": 2318880.0,
      "end_time": 2323740.0,
      "text": "than the gold standard method alone. It&#39;s much better than locality sensitive hashing"
    },
    {
      "index": 436,
      "start_time": 2323740.0,
      "end_time": 2329030.0,
      "text": "but if in terms of speed, we use the code that&#39;s on the web for that and it&#39;s about"
    },
    {
      "index": 437,
      "start_time": 2329030.0,
      "end_time": 2333590.0,
      "text": "50 times faster. And in terms of accuracy, locality sensitive hashing will always be"
    },
    {
      "index": 438,
      "start_time": 2333590.0,
      "end_time": 2338380.0,
      "text": "less good than this because it&#39;s just a hack for doing this. And locality sensitive hashing"
    },
    {
      "index": 439,
      "start_time": 2338380.0,
      "end_time": 2343110.0,
      "text": "works on the count vector. If you work on the count vector, you will never understand"
    },
    {
      "index": 440,
      "start_time": 2343110.0,
      "end_time": 2348200.0,
      "text": "the similarity between the document that says, &quot;Gonzales quits,&quot; than the documents that"
    },
    {
      "index": 441,
      "start_time": 2348200.0,
      "end_time": 2353830.0,
      "text": "says &quot;Volfovich resigns.&quot; They&#39;re very similar but not in the word count vector. But if you&#39;ve"
    },
    {
      "index": 442,
      "start_time": 2353830.0,
      "end_time": 2362480.0,
      "text": "compress it down to some semantic features, they&#39;re very similar documents. So, the summary"
    },
    {
      "index": 443,
      "start_time": 2362480.0,
      "end_time": 2369180.0,
      "text": "is that I showed you how to use this simple little Boltzmann Machine with the bipartite"
    },
    {
      "index": 444,
      "start_time": 2369180.0,
      "end_time": 2374900.0,
      "text": "connections to learn a layer of features. Then I showed you that if you take those features,"
    },
    {
      "index": 445,
      "start_time": 2374900.0,
      "end_time": 2379550.0,
      "text": "you can learn more features. And as you go up this hierarchy, you get more and more complicated"
    },
    {
      "index": 446,
      "start_time": 2379550.0,
      "end_time": 2385320.0,
      "text": "features that are going to be better and better for doing classification. This produces good"
    },
    {
      "index": 447,
      "start_time": 2385320.0,
      "end_time": 2390150.0,
      "text": "generative models. So they&#39;re good at reconstructing data, or producing data like the data you"
    },
    {
      "index": 448,
      "start_time": 2390150.0,
      "end_time": 2396140.0,
      "text": "saw. If you fine-tune with this [INDISTINCT] algorithm which has this funny name, if you"
    },
    {
      "index": 449,
      "start_time": 2396140.0,
      "end_time": 2400670.0,
      "text": "want good discriminative models, what you do is then you fine-tune with backpropagation."
    },
    {
      "index": 450,
      "start_time": 2400670.0,
      "end_time": 2405070.0,
      "text": "But the good news is you don&#39;t need labels for all of your training data. You can learn"
    },
    {
      "index": 451,
      "start_time": 2405070.0,
      "end_time": 2410590.0,
      "text": "all these features on a very big data sets then with just a few million labels or even"
    },
    {
      "index": 452,
      "start_time": 2410590.0,
      "end_time": 2414980.0,
      "text": "a few hundred labels, you can backpropagate to fine-tune it for discrimination. And that"
    },
    {
      "index": 453,
      "start_time": 2414980.0,
      "end_time": 2419870.0,
      "text": "will work much better than for example using any machine learning method that just uses"
    },
    {
      "index": 454,
      "start_time": 2419870.0,
      "end_time": 2425480.0,
      "text": "the label data. It&#39;s a huge way. You can use the unlabeled data very effectively. And I&#39;ve"
    },
    {
      "index": 455,
      "start_time": 2425480.0,
      "end_time": 2430530.0,
      "text": "shown you that it can also be used for explicit dimensional [INDISTINCT] where you get [INDISTINCT]"
    },
    {
      "index": 456,
      "start_time": 2430530.0,
      "end_time": 2434590.0,
      "text": "bottleneck and that you can do search for similar things very fast. And of course we&#39;d"
    },
    {
      "index": 457,
      "start_time": 2434590.0,
      "end_time": 2439670.0,
      "text": "like to apply it to images, but for images you have a problem which is in documents,"
    },
    {
      "index": 458,
      "start_time": 2439670.0,
      "end_time": 2445070.0,
      "text": "a word is very indicative of what the document is about. In an image, what&#39;s indicative of"
    },
    {
      "index": 459,
      "start_time": 2445070.0,
      "end_time": 2449740.0,
      "text": "what the image is about is a recognized object and so what we are trying to do now is make"
    },
    {
      "index": 460,
      "start_time": 2449740.0,
      "end_time": 2453180.0,
      "text": "it recognize objects so that [INDISTINCT] then we can get the objects in the image and"
    },
    {
      "index": 461,
      "start_time": 2453180.0,
      "end_time": 2458010.0,
      "text": "then apply the semantic hashing technique. But we haven&#39;t done that yet. I see I&#39;ve manage"
    },
    {
      "index": 462,
      "start_time": 2458010.0,
      "end_time": 2462690.0,
      "text": "to talk very fast so I can show you a little bit about how we&#39;re going to do the image"
    },
    {
      "index": 463,
      "start_time": 2462690.0,
      "end_time": 2471830.0,
      "text": "recognition. Suppose you want to do generative model which would allow you, a graphics model,"
    },
    {
      "index": 464,
      "start_time": 2471830.0,
      "end_time": 2477810.0,
      "text": "to take a type of an object and produce an image of that object. So, I say square and"
    },
    {
      "index": 465,
      "start_time": 2477810.0,
      "end_time": 2482950.0,
      "text": "I say what it&#39;s pose is, its position orientation. Then we might have a top-down model of--from"
    },
    {
      "index": 466,
      "start_time": 2482950.0,
      "end_time": 2487850.0,
      "text": "this and this, predicts where the parts might be. And if it&#39;s a kind of sloppy model, it&#39;ll"
    },
    {
      "index": 467,
      "start_time": 2487850.0,
      "end_time": 2491230.0,
      "text": "say this [INDISTINCT] to be round about there, and this [INDISTINCT] to be round about there."
    },
    {
      "index": 468,
      "start_time": 2491230.0,
      "end_time": 2495090.0,
      "text": "And if we pick randomly from these distributions, we&#39;ll get a square where the edges don&#39;t meet"
    },
    {
      "index": 469,
      "start_time": 2495090.0,
      "end_time": 2501310.0,
      "text": "up. Now, one way we can solve that is to generate very accurately here. We could say, I&#39;m going"
    },
    {
      "index": 470,
      "start_time": 2501310.0,
      "end_time": 2505400.0,
      "text": "to generate each piece just right. But that requires high bandwidth and lots of work."
    },
    {
      "index": 471,
      "start_time": 2505400.0,
      "end_time": 2510090.0,
      "text": "We&#39;re going to generate sloppily. We&#39;re going to generate a redundant set of pieces and"
    },
    {
      "index": 472,
      "start_time": 2510090.0,
      "end_time": 2513450.0,
      "text": "then we&#39;re going to know how the pieces fit together. We&#39;re going to know a corner must"
    },
    {
      "index": 473,
      "start_time": 2513450.0,
      "end_time": 2518020.0,
      "text": "be co-linear with an edge and the edges here must be co-linear with corners. And now, by"
    },
    {
      "index": 474,
      "start_time": 2518020.0,
      "end_time": 2523090.0,
      "text": "lateral interactions here, using something called a Marker Finder Field, we can get it"
    },
    {
      "index": 475,
      "start_time": 2523090.0,
      "end_time": 2528390.0,
      "text": "to settle into that. And so now, [INDISTINCT] process is at each level, the level above"
    },
    {
      "index": 476,
      "start_time": 2528390.0,
      "end_time": 2534330.0,
      "text": "says where the major pieces should be, roughly, and a level that knows about how these pieces"
    },
    {
      "index": 477,
      "start_time": 2534330.0,
      "end_time": 2538590.0,
      "text": "go together, like how eyes and noses and mouths go together, says, &quot;Okay, the nose should"
    },
    {
      "index": 478,
      "start_time": 2538590.0,
      "end_time": 2542990.0,
      "text": "be exactly above the middle of the mouth and the eyes should be at exactly the same height.&quot;"
    },
    {
      "index": 479,
      "start_time": 2542990.0,
      "end_time": 2549370.0,
      "text": "The level above doesn&#39;t need to specify that, that&#39;s known locally. So, how are we going"
    },
    {
      "index": 480,
      "start_time": 2549370.0,
      "end_time": 2555840.0,
      "text": "to learn that? Well, we&#39;re going to introduce lateral interactions during the visible units."
    },
    {
      "index": 481,
      "start_time": 2555840.0,
      "end_time": 2559680.0,
      "text": "That&#39;s fine. The real crucial thing in these nets is you don&#39;t have lateral interactions"
    },
    {
      "index": 482,
      "start_time": 2559680.0,
      "end_time": 2567760.0,
      "text": "during the hidden units. So, we can learn that and the way we learn that is we put an"
    },
    {
      "index": 483,
      "start_time": 2567760.0,
      "end_time": 2573720.0,
      "text": "image in here, we activate the features then with the features fixed providing constant"
    },
    {
      "index": 484,
      "start_time": 2573720.0,
      "end_time": 2579290.0,
      "text": "top-down input, we run this lateral interactions to let this network settle down and we replace"
    },
    {
      "index": 485,
      "start_time": 2579290.0,
      "end_time": 2583720.0,
      "text": "the binary variables by real value variables. So, we&#39;re doing something called mean-field."
    },
    {
      "index": 486,
      "start_time": 2583720.0,
      "end_time": 2587570.0,
      "text": "We let this settle down with something it is happier with, a reconstruction. It doesn&#39;t"
    },
    {
      "index": 487,
      "start_time": 2587570.0,
      "end_time": 2591970.0,
      "text": "need to get all the way to equilibrium, it just needs to get a bit better than this."
    },
    {
      "index": 488,
      "start_time": 2591970.0,
      "end_time": 2597120.0,
      "text": "And then, we apply a normal learning algorithm to these correlations and these correlations,"
    },
    {
      "index": 489,
      "start_time": 2597120.0,
      "end_time": 2601010.0,
      "text": "like this. But we can also learn the lateral interactions by saying, &quot;Take the correlations"
    },
    {
      "index": 490,
      "start_time": 2601010.0,
      "end_time": 2605670.0,
      "text": "in the data minus the correlations in the reconstructions,&quot; and that&#39;ll learn all these"
    },
    {
      "index": 491,
      "start_time": 2605670.0,
      "end_time": 2614270.0,
      "text": "lateral interactions. So now what we&#39;re going to do is, we&#39;re going to learn a network with"
    },
    {
      "index": 492,
      "start_time": 2614270.0,
      "end_time": 2620320.0,
      "text": "400 input units for 20 by 20 patch of an image. This is just preliminary work. When we learn"
    },
    {
      "index": 493,
      "start_time": 2620320.0,
      "end_time": 2624690.0,
      "text": "the first network, these aren&#39;t connected. Then when we use these feature activities"
    },
    {
      "index": 494,
      "start_time": 2624690.0,
      "end_time": 2628430.0,
      "text": "to learn the second level Boltzmann Machine, we connect these together and we learn these"
    },
    {
      "index": 495,
      "start_time": 2628430.0,
      "end_time": 2632840.0,
      "text": "and these. Then when we learned the top Boltzmann Machine, we connect these together and we"
    },
    {
      "index": 496,
      "start_time": 2632840.0,
      "end_time": 2638290.0,
      "text": "learn these weights and these weights. When we&#39;re finished, we can generate from the model."
    },
    {
      "index": 497,
      "start_time": 2638290.0,
      "end_time": 2642410.0,
      "text": "And so as a control, what we&#39;re going to do is, we&#39;re going to learn this model on patches"
    },
    {
      "index": 498,
      "start_time": 2642410.0,
      "end_time": 2646340.0,
      "text": "and natural images which have notoriously [INDISTINCT] things to model because anything"
    },
    {
      "index": 499,
      "start_time": 2646340.0,
      "end_time": 2649880.0,
      "text": "could happen in a patch and natural image. So, it&#39;s a very hard thing to build identity"
    },
    {
      "index": 500,
      "start_time": 2649880.0,
      "end_time": 2655220.0,
      "text": "model of. We&#39;re going to learn it without lateral connections and we get a model that&#39;s"
    },
    {
      "index": 501,
      "start_time": 2655220.0,
      "end_time": 2663450.0,
      "text": "very like many other models. When you generate from it, what you get is clouds. So, here&#39;s"
    },
    {
      "index": 502,
      "start_time": 2663450.0,
      "end_time": 2668220.0,
      "text": "natural image patches and they have the property that there&#39;s not much going on and then there&#39;s"
    },
    {
      "index": 503,
      "start_time": 2668220.0,
      "end_time": 2673500.0,
      "text": "a sudden [INDISTINCT] of structure like here. So, if you apply a linear filter to these"
    },
    {
      "index": 504,
      "start_time": 2673500.0,
      "end_time": 2679860.0,
      "text": "things, the linear filter will usually produce a zero and occasionally produce a huge output."
    },
    {
      "index": 505,
      "start_time": 2679860.0,
      "end_time": 2685390.0,
      "text": "If you apply a linear filter to these things, it will produce some kind of Gaussian distribution."
    },
    {
      "index": 506,
      "start_time": 2685390.0,
      "end_time": 2689800.0,
      "text": "These have exactly the same [INDISTINCT] of spectrum as these. What they don&#39;t have is"
    },
    {
      "index": 507,
      "start_time": 2689800.0,
      "end_time": 2694510.0,
      "text": "this sort of heavy tailed distribution where there&#39;s not much happening and then a lot"
    },
    {
      "index": 508,
      "start_time": 2694510.0,
      "end_time": 2699790.0,
      "text": "happening, and long range structure. So, now what happens if we put in the lateral interactions"
    },
    {
      "index": 509,
      "start_time": 2699790.0,
      "end_time": 2703680.0,
      "text": "and do the learning again? If you put the lateral interactions in, they can say things"
    },
    {
      "index": 510,
      "start_time": 2703680.0,
      "end_time": 2707970.0,
      "text": "like if you have a piece [INDISTINCT] and you&#39;d like a piece of that somewhere around"
    },
    {
      "index": 511,
      "start_time": 2707970.0,
      "end_time": 2713480.0,
      "text": "here, put it here where it lines up. So, that will make much longer range interactions."
    },
    {
      "index": 512,
      "start_time": 2713480.0,
      "end_time": 2718990.0,
      "text": "And so now when we generate from the model with lateral interactions, we get that and"
    },
    {
      "index": 513,
      "start_time": 2718990.0,
      "end_time": 2723050.0,
      "text": "you can see that these are much more like real image patches. They pass many of the"
    },
    {
      "index": 514,
      "start_time": 2723050.0,
      "end_time": 2728720.0,
      "text": "statistical tests for being real image patches. They&#39;ve got this kind of much longer range"
    },
    {
      "index": 515,
      "start_time": 2728720.0,
      "end_time": 2733280.0,
      "text": "structure. They&#39;ve got sort of co-linear things and things at right angles and all sorts of"
    },
    {
      "index": 516,
      "start_time": 2733280.0,
      "end_time": 2737970.0,
      "text": "nice structure in them, which we didn&#39;t have before. And so we&#39;re getting--this is probably"
    },
    {
      "index": 517,
      "start_time": 2737970.0,
      "end_time": 2744140.0,
      "text": "the best model there is of natural image patches. If you ask anybody else who models them, &quot;Show"
    },
    {
      "index": 518,
      "start_time": 2744140.0,
      "end_time": 2748150.0,
      "text": "me samples from your generative model.&quot; They say, &quot;Oh, well, we tried that and it looked"
    },
    {
      "index": 519,
      "start_time": 2748150.0,
      "end_time": 2752290.0,
      "text": "terrible. So we never published those.&quot; This is, I think the first model, it generates"
    },
    {
      "index": 520,
      "start_time": 2752290.0,
      "end_time": 2757930.0,
      "text": "nice samples from the model. [INDISTINCT] has the models maybe comparable. What we&#39;d"
    },
    {
      "index": 521,
      "start_time": 2757930.0,
      "end_time": 2762930.0,
      "text": "like to do now is make more layers and we&#39;d also like to have attention. So, as you go"
    },
    {
      "index": 522,
      "start_time": 2762930.0,
      "end_time": 2767080.0,
      "text": "up, you focus on parts of the image. And what I want to do is get something--you&#39;re given"
    },
    {
      "index": 523,
      "start_time": 2767080.0,
      "end_time": 2772210.0,
      "text": "an image, you go up, it&#39;s focusing on parts and it gives you a figure at the top. It gives"
    },
    {
      "index": 524,
      "start_time": 2772210.0,
      "end_time": 2775400.0,
      "text": "you what you see, which is you look at an image and you see a face. And then you look"
    },
    {
      "index": 525,
      "start_time": 2775400.0,
      "end_time": 2779310.0,
      "text": "again, you see the eye. Then you look again, you see a group of four people. And those"
    },
    {
      "index": 526,
      "start_time": 2779310.0,
      "end_time": 2782930.0,
      "text": "are the things that come out and those are going to be like the words that need to go"
    },
    {
      "index": 527,
      "start_time": 2782930.0,
      "end_time": 2786650.0,
      "text": "and turn image retrieval system. You going to have--this is going to run for long time"
    },
    {
      "index": 528,
      "start_time": 2786650.0,
      "end_time": 2790750.0,
      "text": "learning and then it&#39;s going to run for quite a long time on each image, but that&#39;s all"
    },
    {
      "index": 529,
      "start_time": 2790750.0,
      "end_time": 2807140.0,
      "text": "[INDISTINCT] okay. I&#39;m done. &gt;&gt; So, it looks like we&#39;ve got time for questions."
    },
    {
      "index": 530,
      "start_time": 2807140.0,
      "end_time": 2811920.0,
      "text": "If you have questions can you--if you have questions, can you please hit the mic in the"
    },
    {
      "index": 531,
      "start_time": 2811920.0,
      "end_time": 2815210.0,
      "text": "middle so that the folks at their offices can hear."
    },
    {
      "index": 532,
      "start_time": 2815210.0,
      "end_time": 2821580.0,
      "text": "&gt;&gt; Okay. Hi. So, you were saying that this method doesn&#39;t require labels. I was just"
    },
    {
      "index": 533,
      "start_time": 2821580.0,
      "end_time": 2825590.0,
      "text": "wondering if it would actually help if you have labels for at least some of your training"
    },
    {
      "index": 534,
      "start_time": 2825590.0,
      "end_time": 2829700.0,
      "text": "data? &gt;&gt; HINTON: Oh, yes. Labels help. The main"
    },
    {
      "index": 535,
      "start_time": 2829700.0,
      "end_time": 2832930.0,
      "text": "thing is to show that you can do lot without them and therefore you can have much more"
    },
    {
      "index": 536,
      "start_time": 2832930.0,
      "end_time": 2835810.0,
      "text": "leverage from a few labels. Yeah. &gt;&gt; Okay. Thanks."
    },
    {
      "index": 537,
      "start_time": 2835810.0,
      "end_time": 2840450.0,
      "text": "&gt;&gt; HINTON: So, for example in the semantic hashing idea, you could, as you&#39;re learning"
    },
    {
      "index": 538,
      "start_time": 2840450.0,
      "end_time": 2845000.0,
      "text": "those 30 dimensional codes, you could say if two things are from the same class and"
    },
    {
      "index": 539,
      "start_time": 2845000.0,
      "end_time": 2849820.0,
      "text": "the codes are far apart, introduce a small force pulling them together. And we&#39;ve got"
    },
    {
      "index": 540,
      "start_time": 2849820.0,
      "end_time": 2856030.0,
      "text": "a paper on that in [INDISTINCT] last year. And that will improve the sort of clustering"
    },
    {
      "index": 541,
      "start_time": 2856030.0,
      "end_time": 2859630.0,
      "text": "of things of the same class. But the point is you can do it without knowing the classes"
    },
    {
      "index": 542,
      "start_time": 2859630.0,
      "end_time": 2864900.0,
      "text": "as well. &gt;&gt; Hi. Now, so, people have built all the"
    },
    {
      "index": 543,
      "start_time": 2864900.0,
      "end_time": 2869150.0,
      "text": "encoders for a long time before and they use regular sigmoid units and use backprop to"
    },
    {
      "index": 544,
      "start_time": 2869150.0,
      "end_time": 2871940.0,
      "text": "train them. &gt;&gt; HINTON: But they never work very well."
    },
    {
      "index": 545,
      "start_time": 2871940.0,
      "end_time": 2876280.0,
      "text": "&gt;&gt; Correct. Would--if we actually have multiple layers of these, over these sigmoid units"
    },
    {
      "index": 546,
      "start_time": 2876280.0,
      "end_time": 2880450.0,
      "text": "and use--and train them the same function as you&#39;re doing, one layer at a time, would"
    },
    {
      "index": 547,
      "start_time": 2880450.0,
      "end_time": 2885350.0,
      "text": "it work as well, as RBMs or not? &gt;&gt; HINTON: Okay. That&#39;s a very good question."
    },
    {
      "index": 548,
      "start_time": 2885350.0,
      "end_time": 2890360.0,
      "text": "So, it&#39;s a bit confusing. This deep thing with multiple layers trained with RBMs are"
    },
    {
      "index": 549,
      "start_time": 2890360.0,
      "end_time": 2894270.0,
      "text": "called mutli-layer auto encoder. But you could also have a very small auto encoder with one"
    },
    {
      "index": 550,
      "start_time": 2894270.0,
      "end_time": 2899020.0,
      "text": "hidden layer that&#39;s non-linear and train that up. And the RBM is just like that. So, you"
    },
    {
      "index": 551,
      "start_time": 2899020.0,
      "end_time": 2901720.0,
      "text": "could train these little auto encoders and stack them together and then train the whole"
    },
    {
      "index": 552,
      "start_time": 2901720.0,
      "end_time": 2907020.0,
      "text": "thing with backprop. That&#39;s what the question was. And that will work much better than the"
    },
    {
      "index": 553,
      "start_time": 2907020.0,
      "end_time": 2912600.0,
      "text": "old way, training auto encoders, but not quite as well as this. So, Yoshua Bengio has a paper."
    },
    {
      "index": 554,
      "start_time": 2912600.0,
      "end_time": 2916180.0,
      "text": "Where he compared doing auto encoders with doing restricted Boltzmann Machines, and the"
    },
    {
      "index": 555,
      "start_time": 2916180.0,
      "end_time": 2929140.0,
      "text": "restricted Boltzmann Machines worked better specially for things like [INDISTINCT] backgrounds."
    },
    {
      "index": 556,
      "start_time": 2929140.0,
      "end_time": 2931319.0,
      "text": "&gt;&gt; I&#39;ve got a--I&#39;ve got a question which--if I could ask..."
    },
    {
      "index": 557,
      "start_time": 2931320.0,
      "end_time": 2933411.0,
      "text": "&gt;&gt; HINTON: Okay. &gt;&gt; ...because I&#39;m holding a microphone. So,"
    },
    {
      "index": 558,
      "start_time": 2933410.0,
      "end_time": 2937900.0,
      "text": "this morning we were talking about the--about news with--where the problem with news is"
    },
    {
      "index": 559,
      "start_time": 2937900.0,
      "end_time": 2944430.0,
      "text": "that everything changes from day to day. Do you have any intuition--this is one of those"
    },
    {
      "index": 560,
      "start_time": 2944430.0,
      "end_time": 2949830.0,
      "text": "unfair, &quot;What do you think would happen,&quot; do you have any intuition on how hard it would"
    },
    {
      "index": 561,
      "start_time": 2949830.0,
      "end_time": 2955230.0,
      "text": "be to adapt a deep network like this once your input distribution changes or as it continues"
    },
    {
      "index": 562,
      "start_time": 2955230.0,
      "end_time": 2957230.0,
      "text": "to change? &gt;&gt; HINTON: Okay. So one good thing about this"
    },
    {
      "index": 563,
      "start_time": 2957230.0,
      "end_time": 2961730.0,
      "text": "learning is everything scales linearly with [INDISTINCT] training data. There&#39;s no quadratic"
    },
    {
      "index": 564,
      "start_time": 2961730.0,
      "end_time": 2966130.0,
      "text": "optimization anywhere that&#39;s going to screw you for big databases. The other thing is,"
    },
    {
      "index": 565,
      "start_time": 2966130.0,
      "end_time": 2972690.0,
      "text": "because it&#39;s basically stochastic online learning, if your distribution changes slightly, you"
    },
    {
      "index": 566,
      "start_time": 2972690.0,
      "end_time": 2977100.0,
      "text": "can track that very easily. You don&#39;t have to start again. So, if it&#39;s the case that"
    },
    {
      "index": 567,
      "start_time": 2977100.0,
      "end_time": 2981760.0,
      "text": "the news tomorrow has quite lot in common with the news over the last few months and"
    },
    {
      "index": 568,
      "start_time": 2981760.0,
      "end_time": 2986810.0,
      "text": "few years, and you just need to change your model a bit rather than start again, Then"
    },
    {
      "index": 569,
      "start_time": 2986810.0,
      "end_time": 2990420.0,
      "text": "this very good for--going to be good for tracking and it&#39;s not going to be as much work as learning"
    },
    {
      "index": 570,
      "start_time": 2990420.0,
      "end_time": 2994810.0,
      "text": "it all in the first place. And in fact, once you got all of these layers of features, basically"
    },
    {
      "index": 571,
      "start_time": 2994810.0,
      "end_time": 2999160.0,
      "text": "changing the interactions in high level features will get you lots of mileage without much"
    },
    {
      "index": 572,
      "start_time": 2999160.0,
      "end_time": 3008140.0,
      "text": "work. &gt;&gt; Sir I have another question about the a--so,"
    },
    {
      "index": 573,
      "start_time": 3008140.0,
      "end_time": 3014470.0,
      "text": "about the supermarket search. You were saying you just flip a bit in your hash code. So,"
    },
    {
      "index": 574,
      "start_time": 3014470.0,
      "end_time": 3020940.0,
      "text": "what I&#39;m wondering is, you know, one thing that I&#39;m not sure about is like if you flip"
    },
    {
      "index": 575,
      "start_time": 3020940.0,
      "end_time": 3024760.0,
      "text": "one of these bit you might not necessarily get something there?"
    },
    {
      "index": 576,
      "start_time": 3024760.0,
      "end_time": 3026690.0,
      "text": "&gt;&gt; HINTON: That&#39;s fine. &gt;&gt; I mean, how do you know that you&#39;re going"
    },
    {
      "index": 577,
      "start_time": 3026690.0,
      "end_time": 3031160.0,
      "text": "to find something there? And then also, maybe, is there some way of finding better bits to"
    },
    {
      "index": 578,
      "start_time": 3031160.0,
      "end_time": 3035990.0,
      "text": "flip and like how do you decided which ones? &gt;&gt; HINTON: So, of course. If you make the"
    },
    {
      "index": 579,
      "start_time": 3035990.0,
      "end_time": 3039440.0,
      "text": "number of addresses be about the same as the number of documents, the average answer is"
    },
    {
      "index": 580,
      "start_time": 3039440.0,
      "end_time": 3040040.0,
      "text": "one. &gt;&gt; Right."
    },
    {
      "index": 581,
      "start_time": 3040040.0,
      "end_time": 3043670.0,
      "text": "&gt;&gt; HINTON: Okay. And you&#39;ve--if there&#39;s nothing there, you can flip for more bits."
    },
    {
      "index": 582,
      "start_time": 3043670.0,
      "end_time": 3045650.0,
      "text": "&gt;&gt; Sure. &gt;&gt; HINTON: So, yes. You&#39;ll get some misses"
    },
    {
      "index": 583,
      "start_time": 3045650.0,
      "end_time": 3047960.0,
      "text": "but that&#39;s just sort of constant &gt;&gt; Right."
    },
    {
      "index": 584,
      "start_time": 3047960.0,
      "end_time": 3053820.0,
      "text": "&gt;&gt; HINTON: We can look at, actually, how evenly spread over addresses it is and typically,"
    },
    {
      "index": 585,
      "start_time": 3053820.0,
      "end_time": 3057800.0,
      "text": "most of the addresses won&#39;t be used and a typical address would be used like three or"
    },
    {
      "index": 586,
      "start_time": 3057800.0,
      "end_time": 3062610.0,
      "text": "four times. So, it&#39;s not as uniform as we&#39;d like but that could all be improved. And we&#39;ve"
    },
    {
      "index": 587,
      "start_time": 3062610.0,
      "end_time": 3066720.0,
      "text": "only done this once. We&#39;ve just trained this network once on one data set and that&#39;s all"
    },
    {
      "index": 588,
      "start_time": 3066720.0,
      "end_time": 3070950.0,
      "text": "the research we&#39;ve done so far, really. If we could get a tiny bit of money from someone,"
    },
    {
      "index": 589,
      "start_time": 3070950.0,
      "end_time": 3080440.0,
      "text": "we could make this whole thing work much better. &gt;&gt; So, one thing that is special about digits"
    },
    {
      "index": 590,
      "start_time": 3080440.0,
      "end_time": 3084090.0,
      "text": "is that they evolve in a way that they make them discriminative."
    },
    {
      "index": 591,
      "start_time": 3084090.0,
      "end_time": 3088050.0,
      "text": "&gt;&gt; HINTON: Yes. &gt;&gt; So, you would hope you--it&#39;s not that surprising"
    },
    {
      "index": 592,
      "start_time": 3088050.0,
      "end_time": 3092990.0,
      "text": "that it then unsupervised way can attract features that are discriminative. I was wondering"
    },
    {
      "index": 593,
      "start_time": 3092990.0,
      "end_time": 3097580.0,
      "text": "what happens with [INDISTINCT] the other applications where--so clearly, when you do unsupervised,"
    },
    {
      "index": 594,
      "start_time": 3097580.0,
      "end_time": 3101090.0,
      "text": "you might throw away some very indicative features right there."
    },
    {
      "index": 595,
      "start_time": 3101090.0,
      "end_time": 3104570.0,
      "text": "&gt;&gt; HINTON: Yes. So, basically, there&#39;s two kinds of learning, there&#39;s discriminative"
    },
    {
      "index": 596,
      "start_time": 3104570.0,
      "end_time": 3109530.0,
      "text": "learning where you take your input and your whole aim in life is to predict the label."
    },
    {
      "index": 597,
      "start_time": 3109530.0,
      "end_time": 3112280.0,
      "text": "And then there&#39;s generative learning where you take your input and your whole aim in"
    },
    {
      "index": 598,
      "start_time": 3112280.0,
      "end_time": 3117970.0,
      "text": "life is to understand what&#39;s going on in this input. You want to build a model that explains"
    },
    {
      "index": 599,
      "start_time": 3117970.0,
      "end_time": 3122720.0,
      "text": "why you got these inputs and not other inputs. Now, if you do that generative approach, you"
    },
    {
      "index": 600,
      "start_time": 3122720.0,
      "end_time": 3128580.0,
      "text": "need a big computer and you&#39;re going to explain all sort of stuff that&#39;s completely irrelevant"
    },
    {
      "index": 601,
      "start_time": 3128580.0,
      "end_time": 3133180.0,
      "text": "to the task you&#39;re interested in. So, you&#39;re going to waste lots of computation. On the"
    },
    {
      "index": 602,
      "start_time": 3133180.0,
      "end_time": 3137120.0,
      "text": "other hand, you&#39;re not going to need as much training data because each image is going"
    },
    {
      "index": 603,
      "start_time": 3137120.0,
      "end_time": 3142460.0,
      "text": "to contain lots of stuff and you can start building your features without yet using information"
    },
    {
      "index": 604,
      "start_time": 3142460.0,
      "end_time": 3147540.0,
      "text": "in the labels. So, if you&#39;ve got a very small computer, what you should do is discriminative"
    },
    {
      "index": 605,
      "start_time": 3147540.0,
      "end_time": 3153150.0,
      "text": "learning so you don&#39;t waste any effort. If you got a big computer, do generative learning,"
    },
    {
      "index": 606,
      "start_time": 3153150.0,
      "end_time": 3157190.0,
      "text": "you&#39;ll waste lots of the cycles but you&#39;ll make better use of the limited [INDISTINCT]"
    },
    {
      "index": 607,
      "start_time": 3157190.0,
      "end_time": 3166160.0,
      "text": "label data. That&#39;s my claim. &gt;&gt; Hi Geoff. I have a question. What happened"
    },
    {
      "index": 608,
      "start_time": 3166160.0,
      "end_time": 3171260.0,
      "text": "to regularization? What kind of regularization is implicit in all of your stages?"
    },
    {
      "index": 609,
      "start_time": 3171260.0,
      "end_time": 3175260.0,
      "text": "&gt;&gt; HINTON: Okay. So, we&#39;re using a little bit of weight decay and the way we set the"
    },
    {
      "index": 610,
      "start_time": 3175260.0,
      "end_time": 3179190.0,
      "text": "weight decay was just--we fiddled about it for a bit to see what worked on the--on a"
    },
    {
      "index": 611,
      "start_time": 3179190.0,
      "end_time": 3183980.0,
      "text": "validation set, the usual method. And if you don&#39;t use any weight decay, it works. If you"
    },
    {
      "index": 612,
      "start_time": 3183980.0,
      "end_time": 3187320.0,
      "text": "use weight decay, it works a bit better. And it&#39;s not crucial how much you use. So, we"
    },
    {
      "index": 613,
      "start_time": 3187320.0,
      "end_time": 3192390.0,
      "text": "are using some weight decays here but it&#39;s not a big deal. And like I say, all of the"
    },
    {
      "index": 614,
      "start_time": 3192390.0,
      "end_time": 3196230.0,
      "text": "code is in [INDISTINCT] on my web page. There&#39;s a pointer on my web page. So, you can go and"
    },
    {
      "index": 615,
      "start_time": 3196230.0,
      "end_time": 3198349.0,
      "text": "look at all those things and all the little fudges we use."
    },
    {
      "index": 616,
      "start_time": 3198350.0,
      "end_time": 3205791.0,
      "text": "&gt;&gt; Right. But the Boltzmann Machine is fundamentally sort of entropic regularization and then your"
    },
    {
      "index": 617,
      "start_time": 3205790.0,
      "end_time": 3209650.0,
      "text": "little pieces of tuning with weight decay are from the other family. So, you&#39;re blending"
    },
    {
      "index": 618,
      "start_time": 3209650.0,
      "end_time": 3212060.0,
      "text": "both [INDISTINCT] &gt;&gt; HINTON: No. The Boltzmann Machine, it&#39;s"
    },
    {
      "index": 619,
      "start_time": 3212060.0,
      "end_time": 3215540.0,
      "text": "true. There&#39;s a lot of regularization comes on from the fact that the hidden units are"
    },
    {
      "index": 620,
      "start_time": 3215540.0,
      "end_time": 3217710.0,
      "text": "binary stochastic. So, they can&#39;t transmit much information."
    },
    {
      "index": 621,
      "start_time": 3217710.0,
      "end_time": 3219470.0,
      "text": "&gt;&gt; Yes. &gt;&gt; HINTON: That does lots of regularization"
    },
    {
      "index": 622,
      "start_time": 3219470.0,
      "end_time": 3224450.0,
      "text": "for you, compared with the normal auto encoder. But in addition, we say don&#39;t make the weights"
    },
    {
      "index": 623,
      "start_time": 3224450.0,
      "end_time": 3229510.0,
      "text": "too big. And one reason for that is not just regularization, it&#39;s--it makes the Markov"
    },
    {
      "index": 624,
      "start_time": 3229510.0,
      "end_time": 3233099.0,
      "text": "chain mix faster if you don&#39;t make the weights too big."
    },
    {
      "index": 625,
      "start_time": 3233100.0,
      "end_time": 3238331.0,
      "text": "&gt;&gt; Thanks. &gt;&gt; Hi. So, in your example of digits, you"
    },
    {
      "index": 626,
      "start_time": 3238330.0,
      "end_time": 3243410.0,
      "text": "actually tell them--tell the algorithm that they are ten classes."
    },
    {
      "index": 627,
      "start_time": 3243410.0,
      "end_time": 3247460.0,
      "text": "&gt;&gt; HINTON: Yes. &gt;&gt; So, I wonder, well, what is the impact"
    },
    {
      "index": 628,
      "start_time": 3247460.0,
      "end_time": 3253170.0,
      "text": "if we do not give this number correct? So, yeah."
    },
    {
      "index": 629,
      "start_time": 3253170.0,
      "end_time": 3260350.0,
      "text": "&gt;&gt; HINTON: Okay. So, what you can do is you can take this auto encoder that goes down"
    },
    {
      "index": 630,
      "start_time": 3260350.0,
      "end_time": 3266540.0,
      "text": "to 30 real numbers and not tell it how many classes there are, just give it the images,"
    },
    {
      "index": 631,
      "start_time": 3266540.0,
      "end_time": 3271600.0,
      "text": "get these 30 real numbers. Then you can take those 30 real numbers and apply dimensionality"
    },
    {
      "index": 632,
      "start_time": 3271600.0,
      "end_time": 3276210.0,
      "text": "reduction technique that Sam Roweis and I have developed, and the latest version of"
    },
    {
      "index": 633,
      "start_time": 3276210.0,
      "end_time": 3284960.0,
      "text": "that, you can lay them out in 2D and you will get 11 classes. And it did that without ever"
    },
    {
      "index": 634,
      "start_time": 3284960.0,
      "end_time": 3293150.0,
      "text": "knowing any labels. You&#39;ll get just these 11 clusters which is close to 10. It often"
    },
    {
      "index": 635,
      "start_time": 3293150.0,
      "end_time": 3296180.0,
      "text": "thinks that the continental sevens are a separate clusters."
    },
    {
      "index": 636,
      "start_time": 3296180.0,
      "end_time": 3299350.0,
      "text": "&gt;&gt; So you are saying this is [INDISTINCT] you have try and that&#39;s what happened or?"
    },
    {
      "index": 637,
      "start_time": 3299350.0,
      "end_time": 3305910.0,
      "text": "&gt;&gt; HINTON: I might even have it in this talk somewhere. I might not, though. It&#39;s on my--it&#39;s--oh,"
    },
    {
      "index": 638,
      "start_time": 3305910.0,
      "end_time": 3313490.0,
      "text": "there you go. That&#39;s pure unsupervised on the digits. Now in this case, these are twos"
    },
    {
      "index": 639,
      "start_time": 3313490.0,
      "end_time": 3319830.0,
      "text": "and these are twos. In 30D, it&#39;s got the clusters. When you force it down to 2D, it wants to"
    },
    {
      "index": 640,
      "start_time": 3319830.0,
      "end_time": 3324210.0,
      "text": "keep the twos next to each other but it will also wants these--these are the spiky twos"
    },
    {
      "index": 641,
      "start_time": 3324210.0,
      "end_time": 3328460.0,
      "text": "and these are the sevens, and it wants those close. And these are the loopy twos and these"
    },
    {
      "index": 642,
      "start_time": 3328460.0,
      "end_time": 3331840.0,
      "text": "are the threes, and it wants those close. But it also wants the threes close to the"
    },
    {
      "index": 643,
      "start_time": 3331840.0,
      "end_time": 3338070.0,
      "text": "eights. And so in 2D, there just isn&#39;t enough space to make ten clusters. But look, it made"
    },
    {
      "index": 644,
      "start_time": 3338070.0,
      "end_time": 3342790.0,
      "text": "11 there and if I don&#39;t cheat and do this in black and white, you can still see there&#39;s"
    },
    {
      "index": 645,
      "start_time": 3342790.0,
      "end_time": 3347880.0,
      "text": "sort of roughly 11 clusters. So, this was pure unsupervised and it found that structure"
    },
    {
      "index": 646,
      "start_time": 3347880.0,
      "end_time": 3353060.0,
      "text": "in the data. So, when psychologists tell you, you impose categories on this data, they aren&#39;t"
    },
    {
      "index": 647,
      "start_time": 3353060.0,
      "end_time": 3359140.0,
      "text": "really there in the world, it&#39;s rubbish. I mean, they&#39;re really there."
    },
    {
      "index": 648,
      "start_time": 3359140.0,
      "end_time": 3364490.0,
      "text": "&gt;&gt; So the magic number is 30. Is it--if I choose other number, it will be fine with"
    },
    {
      "index": 649,
      "start_time": 3364490.0,
      "end_time": 3366390.0,
      "text": "it? &gt;&gt; HINTON: If you choose a smaller number,"
    },
    {
      "index": 650,
      "start_time": 3366390.0,
      "end_time": 3370640.0,
      "text": "you might not preserve enough information to be able to keep the classes. And if you"
    },
    {
      "index": 651,
      "start_time": 3370640.0,
      "end_time": 3374720.0,
      "text": "choose a bigger number, then PCA will do it better. So your comparison with PCA won&#39;t"
    },
    {
      "index": 652,
      "start_time": 3374720.0,
      "end_time": 3384040.0,
      "text": "be as good. &gt;&gt; Thank you."
    },
    {
      "index": 653,
      "start_time": 3384040.0,
      "end_time": 3390940.0,
      "text": "&gt;&gt; How does the performance of the digit classification vary according to the number of layers you"
    },
    {
      "index": 654,
      "start_time": 3390940.0,
      "end_time": 3393900.0,
      "text": "are using? &gt;&gt; HINTON: Okay. Obviously, using the number"
    },
    {
      "index": 655,
      "start_time": 3393900.0,
      "end_time": 3399690.0,
      "text": "of layers I showed you is one of the best numbers to use. If you use less layers, it"
    },
    {
      "index": 656,
      "start_time": 3399690.0,
      "end_time": 3405190.0,
      "text": "works a bit worse. If you use more layers, it works about the same. I&#39;ve now got a--I&#39;ve"
    },
    {
      "index": 657,
      "start_time": 3405190.0,
      "end_time": 3410340.0,
      "text": "got a very good Dutch student who has the [INDISTINCT] he doesn&#39;t believe a word I say,"
    },
    {
      "index": 658,
      "start_time": 3410340.0,
      "end_time": 3414000.0,
      "text": "and we will know--he&#39;s using like 40 cluster machines and he&#39;s going to get the answer"
    },
    {
      "index": 659,
      "start_time": 3414000.0,
      "end_time": 3419590.0,
      "text": "to this. But so far, I&#39;m right that using less layers isn&#39;t as good and he hasn&#39;t got"
    },
    {
      "index": 660,
      "start_time": 3419590.0,
      "end_time": 3423060.0,
      "text": "to more layers yet. He&#39;s actually made with the same number of layers, he can make it"
    },
    {
      "index": 661,
      "start_time": 3423060.0,
      "end_time": 3428010.0,
      "text": "work better and we&#39;ll see if he makes it work better with more layers."
    },
    {
      "index": 662,
      "start_time": 3428010.0,
      "end_time": 3432920.0,
      "text": "&gt;&gt; Just [INDISTINCT] guess a related question. So, it&#39;s clear how to evaluate this models"
    },
    {
      "index": 663,
      "start_time": 3432920.0,
      "end_time": 3437540.0,
      "text": "say if you have some labeled data and [INDISTINCT] you can try to see if you predict it similarly."
    },
    {
      "index": 664,
      "start_time": 3437540.0,
      "end_time": 3441910.0,
      "text": "But if you try generative, this Boltzmann Machines with like, especially [INDISTINCT]"
    },
    {
      "index": 665,
      "start_time": 3441910.0,
      "end_time": 3445850.0,
      "text": "interactions in the same levels and so on, if I gave you another set, can you say how"
    },
    {
      "index": 666,
      "start_time": 3445850.0,
      "end_time": 3448940.0,
      "text": "good generatively it is and is it easy? &gt;&gt; HINTON: Okay."
    },
    {
      "index": 667,
      "start_time": 3448940.0,
      "end_time": 3450810.0,
      "text": "&gt;&gt; How do you evaluate... &gt;&gt; HINTON: Yeah."
    },
    {
      "index": 668,
      "start_time": 3450810.0,
      "end_time": 3454350.0,
      "text": "&gt;&gt; ...that kind of part of it? &gt;&gt; HINTON: So, the problem with these Boltzmann"
    },
    {
      "index": 669,
      "start_time": 3454350.0,
      "end_time": 3459820.0,
      "text": "Machines, this is a partition function, and what you&#39;d love to do is take your data set,"
    },
    {
      "index": 670,
      "start_time": 3459820.0,
      "end_time": 3465440.0,
      "text": "hold out some examples, train your generative model on the training set and then say what"
    },
    {
      "index": 671,
      "start_time": 3465440.0,
      "end_time": 3468320.0,
      "text": "is the log probability of these held out examples? &gt;&gt; Exactly."
    },
    {
      "index": 672,
      "start_time": 3468320.0,
      "end_time": 3472130.0,
      "text": "&gt;&gt; HINTON: And that would be the sort of gold standard. And that&#39;s very hard to do. You"
    },
    {
      "index": 673,
      "start_time": 3472130.0,
      "end_time": 3476410.0,
      "text": "know the log probability up to a constant but you don&#39;t know the constant. So, people"
    },
    {
      "index": 674,
      "start_time": 3476410.0,
      "end_time": 3480420.0,
      "text": "in my group and I are working very hard on a method for interpolating between Boltzmann"
    },
    {
      "index": 675,
      "start_time": 3480420.0,
      "end_time": 3486260.0,
      "text": "Machines that allows you to use a Boltzmann Machine with zero weights which is a pretty"
    },
    {
      "index": 676,
      "start_time": 3486260.0,
      "end_time": 3492950.0,
      "text": "dumb model and then gradually change the weights towards the Boltzmann Machine that you eventually"
    },
    {
      "index": 677,
      "start_time": 3492950.0,
      "end_time": 3498330.0,
      "text": "learned and you can get the ratio of the partition functions of all these Boltzmann Machines"
    },
    {
      "index": 678,
      "start_time": 3498330.0,
      "end_time": 3502560.0,
      "text": "so in the end, you can get the partition function. You can get a pretty good estimate. This is"
    },
    {
      "index": 679,
      "start_time": 3502560.0,
      "end_time": 3509400.0,
      "text": "called--it&#39;s a version of a [INDISTINCT] important something called bridging. And we think we&#39;re"
    },
    {
      "index": 680,
      "start_time": 3509400.0,
      "end_time": 3514190.0,
      "text": "going to be able to get pretty accurate estimates of the partition function now by running for"
    },
    {
      "index": 681,
      "start_time": 3514190.0,
      "end_time": 3515619.0,
      "text": "like, you know, a 100 hours. &gt;&gt; Yes. Yes."
    },
    {
      "index": 682,
      "start_time": 3515620.0,
      "end_time": 3518991.0,
      "text": "&gt;&gt; HINTON: You do this after you&#39;ve learned just to show how good you are. But the other"
    },
    {
      "index": 683,
      "start_time": 3518990.0,
      "end_time": 3523160.0,
      "text": "thing you can do is you can generate from the model and you can see that the stuff it"
    },
    {
      "index": 684,
      "start_time": 3523160.0,
      "end_time": 3527160.0,
      "text": "generates looks good and you can then take the stuff you generated from the model and"
    },
    {
      "index": 685,
      "start_time": 3527160.0,
      "end_time": 3532730.0,
      "text": "you can apply statistical test to that and statistical test to the real data and statistical"
    },
    {
      "index": 686,
      "start_time": 3532730.0,
      "end_time": 3536390.0,
      "text": "test to the other guy&#39;s data, the other guy&#39;s generative data. And if you choose the right"
    },
    {
      "index": 687,
      "start_time": 3536390.0,
      "end_time": 3538550.0,
      "text": "statistical test, you can make the other guy&#39;s data look terrible."
    },
    {
      "index": 688,
      "start_time": 3538550.0,
      "end_time": 3548550.0,
      "text": "&gt;&gt; Okay. Okay. I think we&#39;re out of time now. I&#39;d like to thank Geoff again and..."
    }
  ]
}