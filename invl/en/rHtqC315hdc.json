{
  "video_id": "rHtqC315hdc",
  "title": "4   14   Counting 1 's 29 00 Advanced",
  "es": 0,
  "json": [
    {
      "index": 1,
      "start_time": 650.0,
      "end_time": 1250.0,
      "text": "We&#39;re now going to"
    },
    {
      "index": 2,
      "start_time": 1250.0,
      "end_time": 5270.0,
      "text": "take up a particular problem that has a very non-trivial solution."
    },
    {
      "index": 3,
      "start_time": 5270.0,
      "end_time": 8536.0,
      "text": "We assume the stream elements are bits, zeroes or"
    },
    {
      "index": 4,
      "start_time": 8536.0,
      "end_time": 12360.0,
      "text": "one, and we want to know how many bits in the last N are one."
    },
    {
      "index": 5,
      "start_time": 13760.0,
      "end_time": 15590.0,
      "text": "If we can store the most recent N bits,"
    },
    {
      "index": 6,
      "start_time": 15590.0,
      "end_time": 18360.0,
      "text": "we can use the solution like the one discussed for averages."
    },
    {
      "index": 7,
      "start_time": 18360.0,
      "end_time": 20240.0,
      "text": "In fact the algorithm would be even simpler."
    },
    {
      "index": 8,
      "start_time": 21520.0,
      "end_time": 24850.0,
      "text": "However, we&#39;re going to address the situation where N bits don&#39;t fit"
    },
    {
      "index": 9,
      "start_time": 24850.0,
      "end_time": 25680.0,
      "text": "in main memory."
    },
    {
      "index": 10,
      "start_time": 25680.0,
      "end_time": 30800.0,
      "text": "Perhaps N is a trillion or N is a reasonable number but"
    },
    {
      "index": 11,
      "start_time": 30800.0,
      "end_time": 34110.0,
      "text": "there, there are so many streams that we can&#39;t store complete windows for all."
    },
    {
      "index": 12,
      "start_time": 35380.0,
      "end_time": 39160.0,
      "text": "If we want exact answers then we can show that it is impossible to do"
    },
    {
      "index": 13,
      "start_time": 39160.0,
      "end_time": 42690.0,
      "text": "anything better than to store the entire window."
    },
    {
      "index": 14,
      "start_time": 42700.0,
      "end_time": 46484.0,
      "text": "However, what is interesting is that we can store on the order of"
    },
    {
      "index": 15,
      "start_time": 46484.0,
      "end_time": 50405.0,
      "text": "the square of log in bits, where N is the window size, and"
    },
    {
      "index": 16,
      "start_time": 50405.0,
      "end_time": 55475.0,
      "text": "still answer queries about the counted ones with answers that are off by at"
    },
    {
      "index": 17,
      "start_time": 55475.0,
      "end_time": 59688.0,
      "text": "most a small factor, as small as we like if we do enough work."
    },
    {
      "index": 18,
      "start_time": 64218.0,
      "end_time": 66970.0,
      "text": "The problem we&#39;re going to discuss is this."
    },
    {
      "index": 19,
      "start_time": 66970.0,
      "end_time": 68160.0,
      "text": "We&#39;re given a stream of 0&#39;s and 1&#39;s."
    },
    {
      "index": 20,
      "start_time": 68160.0,
      "end_time": 72649.0,
      "text": "At any time we have to be prepared to answer a query of the form."
    },
    {
      "index": 21,
      "start_time": 72650.0,
      "end_time": 75295.0,
      "text": "How many of the last k bits were one?"
    },
    {
      "index": 22,
      "start_time": 75295.0,
      "end_time": 79703.0,
      "text": "Here k can be any integer from one up to some large upper limit N."
    },
    {
      "index": 23,
      "start_time": 83942.0,
      "end_time": 89720.0,
      "text": "We can surely do this if we use a windows size N and store the last N bits."
    },
    {
      "index": 24,
      "start_time": 89720.0,
      "end_time": 93393.0,
      "text": "When a new bit arrives, we throw away the oldest bit in the windows since it"
    },
    {
      "index": 25,
      "start_time": 93393.0,
      "end_time": 96250.0,
      "text": "can never again be useful to answer one of these queries."
    },
    {
      "index": 26,
      "start_time": 98633.0,
      "end_time": 103223.0,
      "text": "But one disadvantage of this approach is that answering one query requires that we"
    },
    {
      "index": 27,
      "start_time": 103224.0,
      "end_time": 106748.0,
      "text": "examine k bits, since k can be quite large, and both inputs and"
    },
    {
      "index": 28,
      "start_time": 106748.0,
      "end_time": 110898.0,
      "text": "queries may be arriving very rapidly, that may be time we cannot afford."
    },
    {
      "index": 29,
      "start_time": 113406.0,
      "end_time": 116900.0,
      "text": "Another potential problem is that we may not be able to afford the space."
    },
    {
      "index": 30,
      "start_time": 116900.0,
      "end_time": 123200.0,
      "text": "As we just mentioned we could be trying to handle a large number of streams or"
    },
    {
      "index": 31,
      "start_time": 123200.0,
      "end_time": 126690.0,
      "text": "N could be so large that even one window does not fit in main memory."
    },
    {
      "index": 32,
      "start_time": 128620.0,
      "end_time": 132978.0,
      "text": "Both these concerns suggests that we should consider a method that uses less"
    },
    {
      "index": 33,
      "start_time": 132978.0,
      "end_time": 133806.0,
      "text": "than N space."
    },
    {
      "index": 34,
      "start_time": 133806.0,
      "end_time": 137272.0,
      "text": "And that also allows us to answer queries about the last k"
    },
    {
      "index": 35,
      "start_time": 137272.0,
      "end_time": 140700.0,
      "text": "bits much faster than on the order of k."
    },
    {
      "index": 36,
      "start_time": 140800.0,
      "end_time": 144313.0,
      "text": "It turns out that we can&#39;t get an exact answer to queries without using N"
    },
    {
      "index": 37,
      "start_time": 144313.0,
      "end_time": 145552.0,
      "text": "bits in the window."
    },
    {
      "index": 38,
      "start_time": 145552.0,
      "end_time": 148831.0,
      "text": "But we can get close using much less space than all of N,"
    },
    {
      "index": 39,
      "start_time": 148831.0,
      "end_time": 151550.0,
      "text": "and also much less time than all of k."
    },
    {
      "index": 40,
      "start_time": 154675.0,
      "end_time": 157619.0,
      "text": "We&#39;re going to introduce the right algorithm with the discussion of"
    },
    {
      "index": 41,
      "start_time": 157619.0,
      "end_time": 161100.0,
      "text": "something that seems like it should work but doesn&#39;t quite."
    },
    {
      "index": 42,
      "start_time": 161100.0,
      "end_time": 163640.0,
      "text": "Our goal was the be off by no more than a factor of 2 in"
    },
    {
      "index": 43,
      "start_time": 163640.0,
      "end_time": 167400.0,
      "text": "estimating the number of ones in the last k bits."
    },
    {
      "index": 44,
      "start_time": 167400.0,
      "end_time": 172790.0,
      "text": "So we will summarize blocks of the stream as blocks will have exponentially"
    },
    {
      "index": 45,
      "start_time": 172800.0,
      "end_time": 178250.0,
      "text": "increasing lengths, that is 1, 2, 4, 8, 16, so on."
    },
    {
      "index": 46,
      "start_time": 182590.0,
      "end_time": 185520.0,
      "text": "And the summary of a block will be simply the count of"
    },
    {
      "index": 47,
      "start_time": 185520.0,
      "end_time": 186780.0,
      "text": "the number of ones in that block."
    },
    {
      "index": 48,
      "start_time": 186780.0,
      "end_time": 191850.0,
      "text": "When we want to know the count of ones for last k bits, we can find"
    },
    {
      "index": 49,
      "start_time": 191850.0,
      "end_time": 196799.0,
      "text": "some blocks that lie wholly within the last k bits and we add up their counts."
    },
    {
      "index": 50,
      "start_time": 196800.0,
      "end_time": 200760.0,
      "text": "It is only the last block, the one furthest back in time that gives us pause."
    },
    {
      "index": 51,
      "start_time": 200760.0,
      "end_time": 205190.0,
      "text": "We don&#39;t know how many of its ones within the last k bits so we have to guess."
    },
    {
      "index": 52,
      "start_time": 209873.0,
      "end_time": 213225.0,
      "text": "But if we&#39;ve created these exponentially growing blocks for"
    },
    {
      "index": 53,
      "start_time": 213225.0,
      "end_time": 217543.0,
      "text": "all time units then there would be as many blocks of length one as there are bits in"
    },
    {
      "index": 54,
      "start_time": 217543.0,
      "end_time": 222500.0,
      "text": "the window, as well as blocks or size two, four, eight, and so on."
    },
    {
      "index": 55,
      "start_time": 222500.0,
      "end_time": 224140.0,
      "text": "So that saves us nothing."
    },
    {
      "index": 56,
      "start_time": 224140.0,
      "end_time": 227600.0,
      "text": "Instead, we have to drop blocks if their left end, that is, the end that is"
    },
    {
      "index": 57,
      "start_time": 227600.0,
      "end_time": 232239.0,
      "text": "earliest in time, coincides with the left end of the larger block."
    },
    {
      "index": 58,
      "start_time": 232240.0,
      "end_time": 237130.0,
      "text": "And we also drop a small block if there&#39;s a larger block completely to their right,"
    },
    {
      "index": 59,
      "start_time": 237130.0,
      "end_time": 238560.0,
      "text": "that is, later in the stream."
    },
    {
      "index": 60,
      "start_time": 239810.0,
      "end_time": 243340.0,
      "text": "As a result, you never have more than two blocks of any one size."
    },
    {
      "index": 61,
      "start_time": 246700.0,
      "end_time": 251149.0,
      "text": "So, here is an example of the blocks we might retain at some time."
    },
    {
      "index": 62,
      "start_time": 251150.0,
      "end_time": 258769.0,
      "text": "The five rows of blocks are of lengths 1, 2, 4, 8 and 16."
    },
    {
      "index": 63,
      "start_time": 263223.0,
      "end_time": 265564.0,
      "text": "Okay, there are two blocks of length 1."
    },
    {
      "index": 64,
      "start_time": 268460.0,
      "end_time": 273200.0,
      "text": "The more recent has a count of 0 because it consists of a single 0."
    },
    {
      "index": 65,
      "start_time": 273201.0,
      "end_time": 276740.0,
      "text": "That&#39;s this."
    },
    {
      "index": 66,
      "start_time": 276740.0,
      "end_time": 283234.0,
      "text": "While the other has a count of 1 because it consists of a single 1."
    },
    {
      "index": 67,
      "start_time": 283234.0,
      "end_time": 284159.0,
      "text": "&#39;Kay?"
    },
    {
      "index": 68,
      "start_time": 284160.0,
      "end_time": 286654.0,
      "text": "Here&#39;s a block of length 2."
    },
    {
      "index": 69,
      "start_time": 288380.0,
      "end_time": 293450.0,
      "text": "That has a count of 1 because it represents 0 1."
    },
    {
      "index": 70,
      "start_time": 293450.0,
      "end_time": 294440.0,
      "text": "That is, these two bits."
    },
    {
      "index": 71,
      "start_time": 295600.0,
      "end_time": 299640.0,
      "text": "Notice that we&#39;ve previously deleted the block of length 1 that would go here,"
    },
    {
      "index": 72,
      "start_time": 301820.0,
      "end_time": 308468.0,
      "text": "because it begins at the same point as the block of length 2 above it."
    },
    {
      "index": 73,
      "start_time": 308468.0,
      "end_time": 313442.0,
      "text": "Also all other blocks of length 1 are deleted because they have"
    },
    {
      "index": 74,
      "start_time": 313442.0,
      "end_time": 316950.0,
      "text": "a block of length 2 completely to their right."
    },
    {
      "index": 75,
      "start_time": 319200.0,
      "end_time": 322490.0,
      "text": "We also show a second block of length 2."
    },
    {
      "index": 76,
      "start_time": 322490.0,
      "end_time": 327560.0,
      "text": "Its count is 2 because it represents, this 1 1."
    },
    {
      "index": 77,
      "start_time": 329190.0,
      "end_time": 337510.0,
      "text": "There are two blocks of length 4 and they have counts of 2 and 3."
    },
    {
      "index": 78,
      "start_time": 337510.0,
      "end_time": 345679.0,
      "text": "They represent, well, this guy represents this sequence, 0 0 1 1, so it has two 1&#39;s."
    },
    {
      "index": 79,
      "start_time": 345679.0,
      "end_time": 350683.0,
      "text": "This represents 1 0 1 1 and"
    },
    {
      "index": 80,
      "start_time": 350684.0,
      "end_time": 355696.0,
      "text": "therefore gets a count of 3."
    },
    {
      "index": 81,
      "start_time": 355696.0,
      "end_time": 356445.0,
      "text": "&#39;Kay."
    },
    {
      "index": 82,
      "start_time": 362207.0,
      "end_time": 365342.0,
      "text": "We see one block of length 8."
    },
    {
      "index": 83,
      "start_time": 365342.0,
      "end_time": 367827.0,
      "text": "Its count is 4."
    },
    {
      "index": 84,
      "start_time": 367827.0,
      "end_time": 375850.0,
      "text": "Well let&#39;s see, because it represents these eight bits."
    },
    {
      "index": 85,
      "start_time": 379160.0,
      "end_time": 384800.0,
      "text": "And notice that, that the count for second block of length 8 is not"
    },
    {
      "index": 86,
      "start_time": 384800.0,
      "end_time": 388650.0,
      "text": "needed because we can figure out it has six ones."
    },
    {
      "index": 87,
      "start_time": 388650.0,
      "end_time": 394870.0,
      "text": "Since that&#39;s tad, that 6 is the difference between the number of"
    },
    {
      "index": 88,
      "start_time": 394880.0,
      "end_time": 400200.0,
      "text": "ones in this block of length 16 and that block of length 8."
    },
    {
      "index": 89,
      "start_time": 400200.0,
      "end_time": 405217.0,
      "text": "Or that is 10 minus 4 equals 6."
    },
    {
      "index": 90,
      "start_time": 405217.0,
      "end_time": 410974.0,
      "text": "So if this block existed, it would have, surely have six once."
    },
    {
      "index": 91,
      "start_time": 415120.0,
      "end_time": 415731.0,
      "text": "Okay."
    },
    {
      "index": 92,
      "start_time": 415731.0,
      "end_time": 422449.0,
      "text": "Now, suppose we get a query for how many ones there are in the most recent 28 bits."
    },
    {
      "index": 93,
      "start_time": 424290.0,
      "end_time": 426370.0,
      "text": "We can add up the counts of certain blocks."
    },
    {
      "index": 94,
      "start_time": 426370.0,
      "end_time": 430620.0,
      "text": "Some little blocks at the right end, and then some bigger blocks going to the left."
    },
    {
      "index": 95,
      "start_time": 430620.0,
      "end_time": 434710.0,
      "text": "We want to pick blocks so that each of the most recent 28 bits is covered by"
    },
    {
      "index": 96,
      "start_time": 434710.0,
      "end_time": 436700.0,
      "text": "exactly one of the blocks we choose."
    },
    {
      "index": 97,
      "start_time": 437920.0,
      "end_time": 442975.0,
      "text": "So, we pick this block of length 1."
    },
    {
      "index": 98,
      "start_time": 445800.0,
      "end_time": 447800.0,
      "text": "This block of length 2."
    },
    {
      "index": 99,
      "start_time": 447800.0,
      "end_time": 449150.0,
      "text": "This of length 4."
    },
    {
      "index": 100,
      "start_time": 449150.0,
      "end_time": 454409.0,
      "text": "We don&#39;t want this block of length 8 because we have this block of length"
    },
    {
      "index": 101,
      "start_time": 454410.0,
      "end_time": 461544.0,
      "text": "16 and that&#39;s still all within the last 28."
    },
    {
      "index": 102,
      "start_time": 461544.0,
      "end_time": 467770.0,
      "text": "so, so far we have covered 23 bits and"
    },
    {
      "index": 103,
      "start_time": 467771.0,
      "end_time": 473433.0,
      "text": "we know that among them the number of"
    },
    {
      "index": 104,
      "start_time": 473433.0,
      "end_time": 479282.0,
      "text": "1&#39;s is 0 plus 1 plus 2 plus 10,"
    },
    {
      "index": 105,
      "start_time": 479282.0,
      "end_time": 486750.0,
      "text": "which is 13 Okay but what do we do about the oldest five bits?"
    },
    {
      "index": 106,
      "start_time": 488380.0,
      "end_time": 493444.0,
      "text": "We that is, there are these bits now, if we could see the bits we would know"
    },
    {
      "index": 107,
      "start_time": 493444.0,
      "end_time": 499400.0,
      "text": "that they&#39;re 0 0 1 0 1 therefor they have two 1&#39;s, but we don&#39;t see them."
    },
    {
      "index": 108,
      "start_time": 499400.0,
      "end_time": 504120.0,
      "text": "All we see is that they are part of this block of 16 and"
    },
    {
      "index": 109,
      "start_time": 504120.0,
      "end_time": 509590.0,
      "text": "we know that block has a count of six,"
    },
    {
      "index": 110,
      "start_time": 510660.0,
      "end_time": 515700.0,
      "text": "okay, but we can&#39;t tell how many of those six are in the most recent five positions."
    },
    {
      "index": 111,
      "start_time": 515700.00000000006,
      "end_time": 519700.00000000006,
      "text": "Again, we don&#39;t ever get to see this anymore."
    },
    {
      "index": 112,
      "start_time": 519700.00000000006,
      "end_time": 523500.00000000006,
      "text": "Now if we could see them of course we would know there were two and"
    },
    {
      "index": 113,
      "start_time": 523490.0,
      "end_time": 524378.0,
      "text": "that the right answer is 15."
    },
    {
      "index": 114,
      "start_time": 526790.0,
      "end_time": 533150.0,
      "text": "But we need to estimate, without seeing how many ones there are in this region."
    },
    {
      "index": 115,
      "start_time": 535320.0,
      "end_time": 541313.0,
      "text": "Okay if we guess that half the count of the block that is 3,"
    },
    {
      "index": 116,
      "start_time": 541313.0,
      "end_time": 546696.0,
      "text": "6 divided by 2 in this case is is in the region"
    },
    {
      "index": 117,
      "start_time": 546696.0,
      "end_time": 552800.0,
      "text": "we don&#39;t see then we would guess 16 and"
    },
    {
      "index": 118,
      "start_time": 552800.0,
      "end_time": 557371.0,
      "text": "that&#39;s only off by 7% so that&#39;s not even bad."
    },
    {
      "index": 119,
      "start_time": 557371.0,
      "end_time": 562319.0,
      "text": "We could even try a proportional guess that is say,"
    },
    {
      "index": 120,
      "start_time": 562320.0,
      "end_time": 568720.0,
      "text": "we know that there is 6 with, in 6 divided by 16, well,"
    },
    {
      "index": 121,
      "start_time": 568720.0,
      "end_time": 573366.0,
      "text": "6 divided by 16 is the probability that any given bit"
    },
    {
      "index": 122,
      "start_time": 573366.0,
      "end_time": 579350.0,
      "text": "is 1 in the range represented by this, by this block of 16,"
    },
    {
      "index": 123,
      "start_time": 579350.0,
      "end_time": 583951.0,
      "text": "and we know that we have to count five of them, so"
    },
    {
      "index": 124,
      "start_time": 583951.0,
      "end_time": 589150.0,
      "text": "that&#39;s 30 divided by 16, which is roughly 2,"
    },
    {
      "index": 125,
      "start_time": 589150.0,
      "end_time": 594583.0,
      "text": "and so if we guess 2, and added that, we would get 15."
    },
    {
      "index": 126,
      "start_time": 594583.0,
      "end_time": 600199.0,
      "text": "And that happens to be right on the mark even though we didn&#39;t get to see the,"
    },
    {
      "index": 127,
      "start_time": 600199.0,
      "end_time": 603479.0,
      "text": "the, the five bits that we wanted to count those."
    },
    {
      "index": 128,
      "start_time": 605150.0,
      "end_time": 606986.0,
      "text": "This strategy has a lot to recommend it."
    },
    {
      "index": 129,
      "start_time": 608150.0,
      "end_time": 615449.0,
      "text": "Okay, first it stores only the square of log N bits."
    },
    {
      "index": 130,
      "start_time": 615450.0,
      "end_time": 622520.0,
      "text": "I might comment that we use log, we use this expression (log2N)"
    },
    {
      "index": 131,
      "start_time": 622520.0,
      "end_time": 627720.0,
      "text": "to mean the square of log N."
    },
    {
      "index": 132,
      "start_time": 627720.0,
      "end_time": 629480.0,
      "text": "Okay this is a, a, a common expression."
    },
    {
      "index": 133,
      "start_time": 629480.0,
      "end_time": 634690.0,
      "text": "You don&#39;t want to write it as log N squared because that&#39;s really 2 2 log N,"
    },
    {
      "index": 134,
      "start_time": 634690.0,
      "end_time": 636830.0,
      "text": "which is not what we mean."
    },
    {
      "index": 135,
      "start_time": 640210.0,
      "end_time": 643980.0,
      "text": "So I, I should, if you&#39;ve never seen this notation before again the putting"
    },
    {
      "index": 136,
      "start_time": 643980.0,
      "end_time": 649680.0,
      "text": "the square above the log means that you&#39;re actually squaring the whole thing."
    },
    {
      "index": 137,
      "start_time": 649680.0,
      "end_time": 651150.0,
      "text": "The, the squaring log N."
    },
    {
      "index": 138,
      "start_time": 652560.0,
      "end_time": 657459.0,
      "text": "okay, now."
    },
    {
      "index": 139,
      "start_time": 658870.0,
      "end_time": 662990.0,
      "text": "As I said, okay square, storing square of log N bits is not that bad, okay?"
    },
    {
      "index": 140,
      "start_time": 664276.0,
      "end_time": 668968.0,
      "text": "It&#39;s much less than N for, for for large N."
    },
    {
      "index": 141,
      "start_time": 668969.0,
      "end_time": 674169.0,
      "text": "So if N is a billion, then log squared N is about 900."
    },
    {
      "index": 142,
      "start_time": 674169.0,
      "end_time": 679390.0,
      "text": "Now why do we need only on the order of log squared N bits?"
    },
    {
      "index": 143,
      "start_time": 679390.0,
      "end_time": 680690.0,
      "text": "Well first of all,"
    },
    {
      "index": 144,
      "start_time": 680700.0,
      "end_time": 684540.0,
      "text": "if the window size is N bits, we never need any blocks of length greater than N."
    },
    {
      "index": 145,
      "start_time": 684540.0,
      "end_time": 688510.0,
      "text": "An account up to n can be stored in log based 2 of N bits."
    },
    {
      "index": 146,
      "start_time": 690700.0,
      "end_time": 692800.0,
      "text": "Now how many counts do we need?"
    },
    {
      "index": 147,
      "start_time": 693330.0,
      "end_time": 701600.0,
      "text": "Well, there are only log based 2 N box sizes from 1 1 to 4, 8, 16 and so on."
    },
    {
      "index": 148,
      "start_time": 702670.0,
      "end_time": 706589.0,
      "text": "Up to the largest power of 2 that are long, are no larger than N."
    },
    {
      "index": 149,
      "start_time": 706590.0,
      "end_time": 711529.0,
      "text": "So we never store more than two blocks of any size."
    },
    {
      "index": 150,
      "start_time": 711529.0,
      "end_time": 714240.0,
      "text": "And as a result, we need to store at most,"
    },
    {
      "index": 151,
      "start_time": 714240.0,
      "end_time": 719520.0,
      "text": "2 log N counts, of at most log in bits each, and that&#39;s 2 log squared N."
    },
    {
      "index": 152,
      "start_time": 726812.0,
      "end_time": 730620.0,
      "text": "Another good thing is that after each bit we do a limited amount of work."
    },
    {
      "index": 153,
      "start_time": 730620.0,
      "end_time": 732820.0,
      "text": "We have to create a new block of length 1 for"
    },
    {
      "index": 154,
      "start_time": 732820.0,
      "end_time": 735260.0,
      "text": "each of the lengths 1, 2, 4, 8, and so on."
    },
    {
      "index": 155,
      "start_time": 735260.0,
      "end_time": 739830.0,
      "text": "We may have to drop a block of that length or we may have to combine two blocks of"
    },
    {
      "index": 156,
      "start_time": 739830.0,
      "end_time": 743520.0,
      "text": "one length into two blocks of the next larger length."
    },
    {
      "index": 157,
      "start_time": 743520.0,
      "end_time": 747592.0,
      "text": "But that means that most order log N were total since there were log N sizes."
    },
    {
      "index": 158,
      "start_time": 752476.0,
      "end_time": 754780.0,
      "text": "And the error is frequently small."
    },
    {
      "index": 159,
      "start_time": 754780.0,
      "end_time": 757270.0,
      "text": "It can&#39;t be bigger than the count of the biggest block."
    },
    {
      "index": 160,
      "start_time": 757270.0,
      "end_time": 759987.0,
      "text": "The one that is only partially in the region we&#39;re counting."
    },
    {
      "index": 161,
      "start_time": 761610.0,
      "end_time": 763730.0,
      "text": "There&#39;s a problem with the scheme, however."
    },
    {
      "index": 162,
      "start_time": 763730.0,
      "end_time": 767494.0,
      "text": "When the 1&#39;s are distributed evenly among all the regions of the stream,"
    },
    {
      "index": 163,
      "start_time": 767494.0,
      "end_time": 770123.0,
      "text": "the number of 1&#39;s in the ambiguous region can&#39;t be"
    },
    {
      "index": 164,
      "start_time": 770123.0,
      "end_time": 773663.0,
      "text": "more than half the total number of 1&#39;s in the region we want to count."
    },
    {
      "index": 165,
      "start_time": 773663.0,
      "end_time": 778120.0,
      "text": "So our error is limited to 50%, but look what happens if all the ones in"
    },
    {
      "index": 166,
      "start_time": 778120.0,
      "end_time": 782212.0,
      "text": "the region we want to count are at the left end, and in particular,"
    },
    {
      "index": 167,
      "start_time": 782212.0,
      "end_time": 786700.0,
      "text": "are counted only by a block that is partially within the desired region."
    },
    {
      "index": 168,
      "start_time": 787960.0,
      "end_time": 791800.0,
      "text": "Then the true count could be anything from 0 up to the full count of that block."
    },
    {
      "index": 169,
      "start_time": 792950.0,
      "end_time": 795670.0,
      "text": "Anything we guess could be wildly wrong, and we&#39;ll never know."
    },
    {
      "index": 170,
      "start_time": 799680.0,
      "end_time": 803339.0,
      "text": "We&#39;re therefore going to discuss a similar algorithm that preserves the good and"
    },
    {
      "index": 171,
      "start_time": 803340.0,
      "end_time": 805560.0,
      "text": "avoids the problem with uneven distribution of 1&#39;s."
    },
    {
      "index": 172,
      "start_time": 805560.0,
      "end_time": 811690.0,
      "text": "We&#39;ll still divide the window into blocks, but instead of letting each block cover"
    },
    {
      "index": 173,
      "start_time": 811700.0,
      "end_time": 815580.0,
      "text": "a fixed segment of the string, we&#39;ll let each block cover a fixed number of 1&#39;s."
    },
    {
      "index": 174,
      "start_time": 816770.0,
      "end_time": 820819.0,
      "text": "The sizes of the blocks will still be limited to the powers of 2."
    },
    {
      "index": 175,
      "start_time": 820820.0,
      "end_time": 826860.0,
      "text": "That is 1, 2, 4, 8, and so on, but the notion of the size of a block changes."
    },
    {
      "index": 176,
      "start_time": 826860.0,
      "end_time": 829750.0,
      "text": "Now the size of a block will be the number of 1&#39;s."
    },
    {
      "index": 177,
      "start_time": 829750.0,
      "end_time": 832910.0,
      "text": "So we&#39;ll have blocks of size 1 to represent segments in"
    },
    {
      "index": 178,
      "start_time": 832910.0,
      "end_time": 834980.0,
      "text": "the stream that have a single 1."
    },
    {
      "index": 179,
      "start_time": 834980.0,
      "end_time": 839550.0,
      "text": "Blocks with twice that size will represent two 1&#39;s and number of 0&#39;s."
    },
    {
      "index": 180,
      "start_time": 839550.0,
      "end_time": 844805.0,
      "text": "And then there will be blocks representing four 1&#39;s and any number of 0&#39;s and so on."
    },
    {
      "index": 181,
      "start_time": 844806.0,
      "end_time": 849680.0,
      "text": "The advantage of this scheme is that there are few 1&#39;s in the resent stream,"
    },
    {
      "index": 182,
      "start_time": 849680.0,
      "end_time": 853319.0,
      "text": "the block size covering that region will stay small."
    },
    {
      "index": 183,
      "start_time": 853320.0,
      "end_time": 858597.0,
      "text": "They will cover large parts of the stream, while their size, or"
    },
    {
      "index": 184,
      "start_time": 858597.0,
      "end_time": 861439.0,
      "text": "number of 1&#39;s remains limited."
    },
    {
      "index": 185,
      "start_time": 861439.0,
      "end_time": 866964.0,
      "text": "I decided to call the algorithm I&#39;m going to describe the DGIM algorithm."
    },
    {
      "index": 186,
      "start_time": 866965.0,
      "end_time": 872647.0,
      "text": "The initials refers to the four guys who invented this algorithm Mayur Datar,"
    },
    {
      "index": 187,
      "start_time": 872647.0,
      "end_time": 877470.0,
      "text": "Aristides Gionis, Piotr Indyk, and Rajeev Motwani."
    },
    {
      "index": 188,
      "start_time": 877470.0,
      "end_time": 879240.0,
      "text": "And in fact, this is a good time to stop and"
    },
    {
      "index": 189,
      "start_time": 879240.0,
      "end_time": 884410.0,
      "text": "remember Rajeev Motwani who died shortly after this algorithm was published."
    },
    {
      "index": 190,
      "start_time": 884410.0,
      "end_time": 888600.0,
      "text": "He along with Gionis and Indyk is also responsible for"
    },
    {
      "index": 191,
      "start_time": 888600.0,
      "end_time": 891579.0,
      "text": "locality sensitive hashing which forms a major part of this course."
    },
    {
      "index": 192,
      "start_time": 894110.0,
      "end_time": 897443.0,
      "text": "Like our earlier attempt and an algorithm,"
    },
    {
      "index": 193,
      "start_time": 897443.0,
      "end_time": 903216.0,
      "text": "a DGIM stores on the order of (log2N)bits, to represent 1N bit window."
    },
    {
      "index": 194,
      "start_time": 903216.0,
      "end_time": 908167.0,
      "text": "There&#39;s an absolute guarantee of no more than 50% error in the answer to any query."
    },
    {
      "index": 195,
      "start_time": 911123.0,
      "end_time": 916240.0,
      "text": "And if 50% is too much, you can reduce the error to anything greater than 0."
    },
    {
      "index": 196,
      "start_time": 916240.0,
      "end_time": 920457.0,
      "text": "The algorithm becomes more complicated on the number of bits you need to"
    },
    {
      "index": 197,
      "start_time": 920457.0,
      "end_time": 925113.0,
      "text": "store grow although the number of bits remains proportionate to (log2N)."
    },
    {
      "index": 198,
      "start_time": 925113.0,
      "end_time": 928872.0,
      "text": "It&#39;s just the constant factor that grows in inverse proportion to"
    },
    {
      "index": 199,
      "start_time": 928872.0,
      "end_time": 930354.0,
      "text": "the desired error bound."
    },
    {
      "index": 200,
      "start_time": 935310.0,
      "end_time": 938439.0,
      "text": "Okay, to begin the story we need to introduce the idea of a timestamp."
    },
    {
      "index": 201,
      "start_time": 938440.0,
      "end_time": 941290.0,
      "text": "Every bit that arrives in the stream gets a timestamp."
    },
    {
      "index": 202,
      "start_time": 942870.0,
      "end_time": 945560.0,
      "text": "You might think that we need an arbitrary number of bits to"
    },
    {
      "index": 203,
      "start_time": 945560.0,
      "end_time": 949770.0,
      "text": "represent the time stamp since there&#39;s no limit on how long the stream can be."
    },
    {
      "index": 204,
      "start_time": 949770.0,
      "end_time": 953300.0,
      "text": "But it&#39;s really only necessary to represent timestamps modulo N,"
    },
    {
      "index": 205,
      "start_time": 953300.0,
      "end_time": 960790.0,
      "text": "the window size that is we can divide the timestamp by N and take the remainder."
    },
    {
      "index": 206,
      "start_time": 960800.0,
      "end_time": 964392.0,
      "text": "The net effect is the timestamp start out at 0, 1, and so"
    },
    {
      "index": 207,
      "start_time": 964392.0,
      "end_time": 968712.0,
      "text": "on up to N minus 1 and then go to 0 again, 1, 2 and so on."
    },
    {
      "index": 208,
      "start_time": 968712.0,
      "end_time": 971430.0,
      "text": "Regardless of where the window is in the stream,"
    },
    {
      "index": 209,
      "start_time": 971430.0,
      "end_time": 974930.0,
      "text": "its N bits will all have different timestamps."
    },
    {
      "index": 210,
      "start_time": 978466.0,
      "end_time": 982580.0,
      "text": "We&#39;re going to partition the window of length N into buckets."
    },
    {
      "index": 211,
      "start_time": 982580.0,
      "end_time": 984810.0,
      "text": "Each bucket is represented by a record, and"
    },
    {
      "index": 212,
      "start_time": 984810.0,
      "end_time": 987859.0,
      "text": "records can be stored in on the order of log N bits."
    },
    {
      "index": 213,
      "start_time": 989700.0,
      "end_time": 994170.0,
      "text": "As we shall see, we only need on the order of log N buckets to represent the window,"
    },
    {
      "index": 214,
      "start_time": 994170.0,
      "end_time": 997380.0,
      "text": "so on the order of log squared N bits suffices."
    },
    {
      "index": 215,
      "start_time": 997380.0,
      "end_time": 1000870.0,
      "text": "The record contents are the following."
    },
    {
      "index": 216,
      "start_time": 1002860.0,
      "end_time": 1004410.0,
      "text": "The timestamp of its end."
    },
    {
      "index": 217,
      "start_time": 1004410.0,
      "end_time": 1007390.0,
      "text": "The most recently arrived bit."
    },
    {
      "index": 218,
      "start_time": 1007390.0,
      "end_time": 1010690.0,
      "text": "As I mentioned we&#39;ll record timestamps modulo N."
    },
    {
      "index": 219,
      "start_time": 1010700.0,
      "end_time": 1012810.0,
      "text": "So we need log N bits to represent the timestamp."
    },
    {
      "index": 220,
      "start_time": 1014970.0,
      "end_time": 1019760.0,
      "text": "The number of 1&#39;s between beginning and the end of the segment."
    },
    {
      "index": 221,
      "start_time": 1019760.0,
      "end_time": 1024480.0,
      "text": "We call this count of 1&#39;s the size of the bucket."
    },
    {
      "index": 222,
      "start_time": 1024480.0,
      "end_time": 1028867.0,
      "text": "However the number of 1&#39;s in this segment represented by a bucket must be"
    },
    {
      "index": 223,
      "start_time": 1028869.9999999999,
      "end_time": 1029732.9999999999,
      "text": "a power of 2."
    },
    {
      "index": 224,
      "start_time": 1029730.0,
      "end_time": 1035248.0,
      "text": "That explains why we only need log log N bits to represent the count of 1&#39;s."
    },
    {
      "index": 225,
      "start_time": 1040829.9999999999,
      "end_time": 1044753.9999999999,
      "text": "We can store the logarithm of the count instead of the count itself since,"
    },
    {
      "index": 226,
      "start_time": 1044750.0,
      "end_time": 1048147.0,
      "text": "we know that log base to the count must be an integer."
    },
    {
      "index": 227,
      "start_time": 1048150.0000000001,
      "end_time": 1050740.0,
      "text": "The count itself can&#39;t be higher then N so"
    },
    {
      "index": 228,
      "start_time": 1050740.0,
      "end_time": 1054390.0,
      "text": "it&#39;s logarithm can&#39;t be higher than log base 2 of N."
    },
    {
      "index": 229,
      "start_time": 1054390.0,
      "end_time": 1057877.0,
      "text": "Since the logarithm is an integer r i, and"
    },
    {
      "index": 230,
      "start_time": 1057880.0,
      "end_time": 1063527.0,
      "text": "we only need log i bits to represent the i in binary, log log N bit suffices."
    },
    {
      "index": 231,
      "start_time": 1063520.0,
      "end_time": 1066759.0,
      "text": "It really doesn&#39;t matter much, since we still need order log N"
    },
    {
      "index": 232,
      "start_time": 1066760.0,
      "end_time": 1070563.0,
      "text": "bits in the record for the bucket, just to store the timestamp of its end."
    },
    {
      "index": 233,
      "start_time": 1076750.0,
      "end_time": 1082430.0,
      "text": "The partition into buckets must obey the following rules."
    },
    {
      "index": 234,
      "start_time": 1082430.0,
      "end_time": 1083438.0,
      "text": "There must be one or"
    },
    {
      "index": 235,
      "start_time": 1083440.0,
      "end_time": 1087452.0,
      "text": "two buckets of each allowed sides up to the maximum size we need."
    },
    {
      "index": 236,
      "start_time": 1087450.0,
      "end_time": 1089769.0,
      "text": "Remember that allowed size is of the power-of-2."
    },
    {
      "index": 237,
      "start_time": 1092560.0,
      "end_time": 1094666.0,
      "text": "No bit of the window is part of two buckets."
    },
    {
      "index": 238,
      "start_time": 1094670.0,
      "end_time": 1097264.0,
      "text": "Some 0&#39;s in the stream may not belong to any bucket."
    },
    {
      "index": 239,
      "start_time": 1097260.0,
      "end_time": 1099669.0,
      "text": "It, it, it doesn&#39;t matter."
    },
    {
      "index": 240,
      "start_time": 1099670.0,
      "end_time": 1103975.0,
      "text": "But buckets can only increase in size as we, as we go back in time."
    },
    {
      "index": 241,
      "start_time": 1103970.0,
      "end_time": 1110759.0,
      "text": "The most recent part of the window is represented by the smallest buckets."
    },
    {
      "index": 242,
      "start_time": 1110760.0,
      "end_time": 1114855.0,
      "text": "When the end time stamp of a bucket is more than end-time units in the past,"
    },
    {
      "index": 243,
      "start_time": 1114860.0,
      "end_time": 1117395.0,
      "text": "it no longer represents part of the window, so"
    },
    {
      "index": 244,
      "start_time": 1117390.0,
      "end_time": 1120770.0,
      "text": "we delete it from the set of buckets whose records are stored."
    },
    {
      "index": 245,
      "start_time": 1124480.0,
      "end_time": 1128449.0,
      "text": "Here is a picture of what the partition of a stream into buckets might look like at"
    },
    {
      "index": 246,
      "start_time": 1128450.0,
      "end_time": 1130803.0,
      "text": "some point."
    },
    {
      "index": 247,
      "start_time": 1130800.0,
      "end_time": 1136455.0,
      "text": "The most recent two 1&#39;s are in bucket of size 1 by themselves,"
    },
    {
      "index": 248,
      "start_time": 1136450.0,
      "end_time": 1138938.0,
      "text": "and it&#39;s here and here."
    },
    {
      "index": 249,
      "start_time": 1138940.0,
      "end_time": 1145883.0,
      "text": "Further back, the previous two 1&#39;s are grouped into a bucket of size 2."
    },
    {
      "index": 250,
      "start_time": 1145890.0,
      "end_time": 1149878.0,
      "text": "It&#39;s that there might be two buckets of size 2 but"
    },
    {
      "index": 251,
      "start_time": 1149870.0,
      "end_time": 1153436.0,
      "text": "there could also only be one as in this case."
    },
    {
      "index": 252,
      "start_time": 1154860.0,
      "end_time": 1162895.0,
      "text": "Then going further back in time we see the previous four 1&#39;s in a bucket of size 4,"
    },
    {
      "index": 253,
      "start_time": 1162900.0,
      "end_time": 1165235.0,
      "text": "and the four 1&#39;s before that are also in a bucket of size 4."
    },
    {
      "index": 254,
      "start_time": 1168620.0,
      "end_time": 1171912.0,
      "text": "Then we see two buckets of size 8."
    },
    {
      "index": 255,
      "start_time": 1171910.0,
      "end_time": 1174772.0,
      "text": "And finally a bucket of size 16."
    },
    {
      "index": 256,
      "start_time": 1174780.0,
      "end_time": 1179801.0,
      "text": "The end-time stamp of this bucket is still within the window of length N."
    },
    {
      "index": 257,
      "start_time": 1179800.0,
      "end_time": 1180724.0,
      "text": "That&#39;s this."
    },
    {
      "index": 258,
      "start_time": 1182820.0,
      "end_time": 1184759.0,
      "text": "Although its beginning is outside the window."
    },
    {
      "index": 259,
      "start_time": 1186970.0,
      "end_time": 1190790.0,
      "text": "We still need this bucket, but any previous buckets have a time stamp that is"
    },
    {
      "index": 260,
      "start_time": 1190790.0,
      "end_time": 1194730.0,
      "text": "prior to the beginning of the current window, so we have deleted their records."
    },
    {
      "index": 261,
      "start_time": 1196160.0,
      "end_time": 1199400.0,
      "text": "So let&#39;s see how we manage the buckets as bits arrive on the stream."
    },
    {
      "index": 262,
      "start_time": 1199400.0,
      "end_time": 1202650.0,
      "text": "The first thing we&#39;re going to do"
    },
    {
      "index": 263,
      "start_time": 1202650.0,
      "end_time": 1206500.0,
      "text": "is worry about whether we need to drop the oldest bucket."
    },
    {
      "index": 264,
      "start_time": 1206500.0,
      "end_time": 1208600.0,
      "text": "We need to keep outside the bucket representation,"
    },
    {
      "index": 265,
      "start_time": 1208600.0,
      "end_time": 1212230.0,
      "text": "the count of the number of bits that have ever arrived in the screen."
    },
    {
      "index": 266,
      "start_time": 1212230.0,
      "end_time": 1216810.0,
      "text": "However we only need this count modulo N so an extra log in bits is all we need."
    },
    {
      "index": 267,
      "start_time": 1218600.0,
      "end_time": 1221250.0,
      "text": "When a new bit come in, increment that count."
    },
    {
      "index": 268,
      "start_time": 1221250.0,
      "end_time": 1224430.0,
      "text": "Of course if the count reaches N then we set it back to 0."
    },
    {
      "index": 269,
      "start_time": 1224430.0,
      "end_time": 1227918.0,
      "text": "That&#39;s how modular arithmetic works."
    },
    {
      "index": 270,
      "start_time": 1227920.0,
      "end_time": 1230199.0,
      "text": "Now, look at the end-time of the oldest bucket."
    },
    {
      "index": 271,
      "start_time": 1232940.0,
      "end_time": 1236847.0,
      "text": "If its time stamp agrees with the current time, then that time stamp is"
    },
    {
      "index": 272,
      "start_time": 1236850.0,
      "end_time": 1241367.0,
      "text": "really the current time minus N since we&#39;re computing all time stamps modulo N."
    },
    {
      "index": 273,
      "start_time": 1242640.0,
      "end_time": 1247150.0,
      "text": "The entire oldest bucket is therefore out of the window and we delete its record."
    },
    {
      "index": 274,
      "start_time": 1247150.0,
      "end_time": 1252413.0,
      "text": "But if the time stamp is anything else then the oldest bucket still has"
    },
    {
      "index": 275,
      "start_time": 1252410.0,
      "end_time": 1255689.0,
      "text": "it&#39;s end within the window so it remains."
    },
    {
      "index": 276,
      "start_time": 1255690.0,
      "end_time": 1259567.0,
      "text": "What we do next depends on whether the bit that just entered is 0 or 1."
    },
    {
      "index": 277,
      "start_time": 1259570.0,
      "end_time": 1263461.0,
      "text": "If it&#39;s 0, then we make no further changes to the set of buckets."
    },
    {
      "index": 278,
      "start_time": 1263460.0,
      "end_time": 1264182.0,
      "text": "That was easy."
    },
    {
      "index": 279,
      "start_time": 1267720.0,
      "end_time": 1270334.0,
      "text": "If the current input is 1, we have some work to do."
    },
    {
      "index": 280,
      "start_time": 1270330.0,
      "end_time": 1275924.0,
      "text": "But the work is at most logarithmic in the window size N."
    },
    {
      "index": 281,
      "start_time": 1275920.0,
      "end_time": 1279412.0,
      "text": "First we create a new bucket for the new bit."
    },
    {
      "index": 282,
      "start_time": 1279420.0,
      "end_time": 1282954.0,
      "text": "The size of the bucket is 1, and its ending timestamp is the current time."
    },
    {
      "index": 283,
      "start_time": 1289120.0,
      "end_time": 1292440.0,
      "text": "There might have been one or two buckets of size 1 previously."
    },
    {
      "index": 284,
      "start_time": 1292450.0,
      "end_time": 1295870.0,
      "text": "If there&#39;s only one, now there are two, and that&#39;s fine."
    },
    {
      "index": 285,
      "start_time": 1297320.0,
      "end_time": 1299730.0,
      "text": "We are allowed to have one or two of any size."
    },
    {
      "index": 286,
      "start_time": 1299730.0,
      "end_time": 1303810.0,
      "text": "But, if there we previously two, now there are three."
    },
    {
      "index": 287,
      "start_time": 1303810.0,
      "end_time": 1305990.0,
      "text": "We can&#39;t have three buckets of size 1 so"
    },
    {
      "index": 288,
      "start_time": 1305990.0,
      "end_time": 1310340.0,
      "text": "we combine the oldest two into one bucket of size 2."
    },
    {
      "index": 289,
      "start_time": 1310340.0,
      "end_time": 1314760.0,
      "text": "Combining consecutive buckets of the same size is easy."
    },
    {
      "index": 290,
      "start_time": 1316130.0,
      "end_time": 1319638.0,
      "text": "We add 1 to the logarithm of the size, and"
    },
    {
      "index": 291,
      "start_time": 1319640.0,
      "end_time": 1326532.0,
      "text": "we take the N timestamp to be the N timestamp of the more recent of the two."
    },
    {
      "index": 292,
      "start_time": 1326530.0,
      "end_time": 1330370.0,
      "text": "So, for example here are two buckets could be of,"
    },
    {
      "index": 293,
      "start_time": 1330370.0,
      "end_time": 1334270.0,
      "text": "of consecutive buckets of any size, let&#39;s say 2 to the x."
    },
    {
      "index": 294,
      "start_time": 1337400.0,
      "end_time": 1343270.0,
      "text": "We combine them into one bucket of size 2 to the x plus 1,"
    },
    {
      "index": 295,
      "start_time": 1343270.0,
      "end_time": 1349980.0,
      "text": "by simply, this bucket gets this ending time."
    },
    {
      "index": 296,
      "start_time": 1349980.0,
      "end_time": 1351980.0,
      "text": "I just copy it from here."
    },
    {
      "index": 297,
      "start_time": 1353160.0,
      "end_time": 1359660.0,
      "text": "And we add 1 to the size, which essentially says, therefore it&#39;s,"
    },
    {
      "index": 298,
      "start_time": 1359660.0,
      "end_time": 1364590.0,
      "text": "sorry, the size is doubled and then we just make that go away."
    },
    {
      "index": 299,
      "start_time": 1366100.0,
      "end_time": 1367719.0,
      "text": "But our work might not be over."
    },
    {
      "index": 300,
      "start_time": 1367720.0,
      "end_time": 1372560.0,
      "text": "If we had to create a bucket of size 2 we might now have three of that size."
    },
    {
      "index": 301,
      "start_time": 1372560.0,
      "end_time": 1376530.0,
      "text": "So we combine the earliest two into one bucket of size 4."
    },
    {
      "index": 302,
      "start_time": 1376530.0,
      "end_time": 1379620.0,
      "text": "And the problem could ripple through the sizes."
    },
    {
      "index": 303,
      "start_time": 1379620.0,
      "end_time": 1383229.0,
      "text": "If we just created a third bucket of size 4 then we could have three buckets of"
    },
    {
      "index": 304,
      "start_time": 1383230.0,
      "end_time": 1384280.0,
      "text": "size 4."
    },
    {
      "index": 305,
      "start_time": 1384280.0,
      "end_time": 1388340.0,
      "text": "We need to combine the earliest two into a bucket of size 8 and so on."
    },
    {
      "index": 306,
      "start_time": 1388340.0,
      "end_time": 1391639.0,
      "text": "But because we&#39;re doubling the bucket&#39;s size each time we pass the problem to"
    },
    {
      "index": 307,
      "start_time": 1391640.0,
      "end_time": 1396360.0,
      "text": "the next level, after log N fix ups we&#39;ve reached a bucket size as large as"
    },
    {
      "index": 308,
      "start_time": 1396360.0,
      "end_time": 1399304.0,
      "text": "the entire window and there&#39;s never need for a larger bucket."
    },
    {
      "index": 309,
      "start_time": 1399310.0,
      "end_time": 1400275.0,
      "text": "&#39;Kay."
    },
    {
      "index": 310,
      "start_time": 1400270.0,
      "end_time": 1404670.0,
      "text": "The rippling effect therefore stops after at most log N rounds."
    },
    {
      "index": 311,
      "start_time": 1404670.0,
      "end_time": 1408720.0,
      "text": "And each round may, takes a constant amount of work."
    },
    {
      "index": 312,
      "start_time": 1408720.0,
      "end_time": 1411989.0,
      "text": "So O(logN) is a guaranteed upper bound on the total time needed"
    },
    {
      "index": 313,
      "start_time": 1411990.0,
      "end_time": 1413950.0,
      "text": "to process an incoming 1."
    },
    {
      "index": 314,
      "start_time": 1413950.0,
      "end_time": 1418330.0,
      "text": "Usually the, the time required is much less, and on the average, it is constant."
    },
    {
      "index": 315,
      "start_time": 1420510.0,
      "end_time": 1425200.0,
      "text": "On this slide, we&#39;ll see the changes that occur as bits enter the system."
    },
    {
      "index": 316,
      "start_time": 1425200.0,
      "end_time": 1427284.0,
      "text": "So here&#39;s the initial state of the window."
    },
    {
      "index": 317,
      "start_time": 1429730.0,
      "end_time": 1433248.0,
      "text": "A 1 enters."
    },
    {
      "index": 318,
      "start_time": 1433250.0,
      "end_time": 1439628.0,
      "text": "We create a bucket of size 1 for it, this."
    },
    {
      "index": 319,
      "start_time": 1443720.0,
      "end_time": 1445802.0,
      "text": "But now they have three buckets of size 1."
    },
    {
      "index": 320,
      "start_time": 1447900.0,
      "end_time": 1451129.0,
      "text": "So we&#39;re going to have to combine the two earliest 1&#39;s."
    },
    {
      "index": 321,
      "start_time": 1451130.0,
      "end_time": 1452242.0,
      "text": "This one."
    },
    {
      "index": 322,
      "start_time": 1452240.0,
      "end_time": 1453137.0,
      "text": "And that one."
    },
    {
      "index": 323,
      "start_time": 1456510.0,
      "end_time": 1460804.0,
      "text": "Okay, so here we&#39;ve done the combination."
    },
    {
      "index": 324,
      "start_time": 1460800.0,
      "end_time": 1466971.0,
      "text": "What has happened in terms of the records is that the record for"
    },
    {
      "index": 325,
      "start_time": 1466970.0,
      "end_time": 1470638.0,
      "text": "this bucket is deleted."
    },
    {
      "index": 326,
      "start_time": 1470640.0,
      "end_time": 1476611.0,
      "text": "The size for this record has changed from 1 to 2."
    },
    {
      "index": 327,
      "start_time": 1476610.0,
      "end_time": 1482499.0,
      "text": "And it&#39;s time stamp has not changed, it has therefor actually become this record."
    },
    {
      "index": 328,
      "start_time": 1482500.0,
      "end_time": 1483132.0,
      "text": "And notice that,"
    },
    {
      "index": 329,
      "start_time": 1483130.0,
      "end_time": 1488192.0,
      "text": "that 1 is really inside of the record that this slide is not shown perfectly there."
    },
    {
      "index": 330,
      "start_time": 1488190.0,
      "end_time": 1494546.0,
      "text": "Now I&#39;m showing what happens after another 101 arrives."
    },
    {
      "index": 331,
      "start_time": 1494550.0,
      "end_time": 1497948.0,
      "text": "Okay? The first of these 1&#39;s created this"
    },
    {
      "index": 332,
      "start_time": 1497950.0,
      "end_time": 1504531.0,
      "text": "bucket, and then the 0 came in represented that nothing changed."
    },
    {
      "index": 333,
      "start_time": 1504530.0,
      "end_time": 1505915.0,
      "text": "And then this next 1 arrives."
    },
    {
      "index": 334,
      "start_time": 1507870.0,
      "end_time": 1509800.0,
      "text": "And now, we get a third bucket of size 1."
    },
    {
      "index": 335,
      "start_time": 1509800.0,
      "end_time": 1516800.0,
      "text": "Okay, so that causes these two buckets to get combined into this guy."
    },
    {
      "index": 336,
      "start_time": 1521450.0,
      "end_time": 1525930.0,
      "text": "And now we have three buckets of size 2."
    },
    {
      "index": 337,
      "start_time": 1525930.0,
      "end_time": 1531639.0,
      "text": "So, we have to combine these two by that one really belongs"
    },
    {
      "index": 338,
      "start_time": 1531640.0,
      "end_time": 1536778.0,
      "text": "in the in, in, in the middle bucket of size 2."
    },
    {
      "index": 339,
      "start_time": 1536780.0,
      "end_time": 1544923.0,
      "text": "So, we combine these two into to a bucket size 4."
    },
    {
      "index": 340,
      "start_time": 1544920.0,
      "end_time": 1550621.0,
      "text": "And that made three buckets of size 4 so these guys got combined into"
    },
    {
      "index": 341,
      "start_time": 1550620.0,
      "end_time": 1555858.0,
      "text": "that bucket of size 8, but that was a third bucket of size 8."
    },
    {
      "index": 342,
      "start_time": 1555860.0,
      "end_time": 1560379.0,
      "text": "So these buckets of size 8 got combined into that bucket size 16"
    },
    {
      "index": 343,
      "start_time": 1561580.0,
      "end_time": 1563760.0,
      "text": "now there can&#39;t be more buckets of size 16."
    },
    {
      "index": 344,
      "start_time": 1563760.0,
      "end_time": 1568932.0,
      "text": "There&#39;s this one but that extends beyond the end of the of the window."
    },
    {
      "index": 345,
      "start_time": 1568930.0,
      "end_time": 1573339.0,
      "text": "So we&#39;re done rippling changes to larger and larger buckets."
    },
    {
      "index": 346,
      "start_time": 1580110.0,
      "end_time": 1582363.0,
      "text": "Now I want to explain how to query the system."
    },
    {
      "index": 347,
      "start_time": 1583670.0,
      "end_time": 1587130.0,
      "text": "So suppose we want to know how many 1&#39;s there are in the last k"
    },
    {
      "index": 348,
      "start_time": 1587130.0,
      "end_time": 1590450.0,
      "text": "bits where k is any integer less than or equal to N, the window size."
    },
    {
      "index": 349,
      "start_time": 1594410.0,
      "end_time": 1598253.0,
      "text": "First thing we want to do is to ignore all buckets whose ending timestamp is"
    },
    {
      "index": 350,
      "start_time": 1598250.0,
      "end_time": 1600837.0,
      "text": "earlier than k bits prior to the current time."
    },
    {
      "index": 351,
      "start_time": 1600840.0,
      "end_time": 1604129.0,
      "text": "Those buckets are all outside the range we want to count so"
    },
    {
      "index": 352,
      "start_time": 1604130.0,
      "end_time": 1605600.0,
      "text": "they make no contribution."
    },
    {
      "index": 353,
      "start_time": 1607670.0,
      "end_time": 1612534.0,
      "text": "Start by summing the sizes of all the buckets except the oldest bucket that is"
    },
    {
      "index": 354,
      "start_time": 1612530.0,
      "end_time": 1615124.0,
      "text": "still in the range we are interested in."
    },
    {
      "index": 355,
      "start_time": 1615130.0,
      "end_time": 1617112.0,
      "text": "Then add half the size of that bucket."
    },
    {
      "index": 356,
      "start_time": 1620120.0,
      "end_time": 1621212.0,
      "text": "Okay."
    },
    {
      "index": 357,
      "start_time": 1621210.0,
      "end_time": 1624790.0,
      "text": "The reason we only had half the oldest bucket size is that we really don&#39;t know"
    },
    {
      "index": 358,
      "start_time": 1624790.0,
      "end_time": 1628590.0,
      "text": "how many ones from that bucket are still within the range of interest."
    },
    {
      "index": 359,
      "start_time": 1628590.0,
      "end_time": 1634674.0,
      "text": "By guessing half, we minimize the maximum error as we&#39;ll discuss on the next slide."
    },
    {
      "index": 360,
      "start_time": 1634670.0,
      "end_time": 1637531.0,
      "text": "So here is why the estimate can&#39;t be off by a factor of"
    },
    {
      "index": 361,
      "start_time": 1637540.0,
      "end_time": 1639695.0,
      "text": "more than 50% from the true answer."
    },
    {
      "index": 362,
      "start_time": 1642320.0,
      "end_time": 1646794.0,
      "text": "For a supposed that the oldest bucket in the range we&#39;re interested in has size 2i."
    },
    {
      "index": 363,
      "start_time": 1649480.0,
      "end_time": 1650780.0,
      "text": "We assumed half, or"
    },
    {
      "index": 364,
      "start_time": 1650780.0,
      "end_time": 1655650.0,
      "text": "2i minus 1 of its 1&#39;s are among the most recent k bits to arrive."
    },
    {
      "index": 365,
      "start_time": 1655650.0,
      "end_time": 1658415.0,
      "text": "The true number could be anything between 1 and 2i so"
    },
    {
      "index": 366,
      "start_time": 1658420.0,
      "end_time": 1661105.0,
      "text": "our error is upper bounded by 2i minus 1."
    },
    {
      "index": 367,
      "start_time": 1663880.0,
      "end_time": 1666288.0,
      "text": "Now what&#39;s the smallest the true answer could be?"
    },
    {
      "index": 368,
      "start_time": 1667760.0,
      "end_time": 1670535.0,
      "text": "There is at least one bucket of each of the sizes less than"
    },
    {
      "index": 369,
      "start_time": 1670540.0,
      "end_time": 1674585.0,
      "text": "2i that lies completely within the last, k bits."
    },
    {
      "index": 370,
      "start_time": 1675790.0,
      "end_time": 1680856.0,
      "text": "These account for at least 1 plus 2"
    },
    {
      "index": 371,
      "start_time": 1680860.0,
      "end_time": 1685633.0,
      "text": "plus 4 plus so on, up to 2i minus 1."
    },
    {
      "index": 372,
      "start_time": 1686770.0,
      "end_time": 1694828.0,
      "text": "And that&#39;s 2 to the, that sum is 2i minus 1."
    },
    {
      "index": 373,
      "start_time": 1694830.0,
      "end_time": 1697859.0,
      "text": "Now we add 1 for the 1 that is at the end of the oldest bucket."
    },
    {
      "index": 374,
      "start_time": 1697860.0,
      "end_time": 1700825.0,
      "text": "That bucket has an ending timestamp that&#39;s within range."
    },
    {
      "index": 375,
      "start_time": 1700820.0,
      "end_time": 1703354.0,
      "text": "And buckets always end in a 1 so"
    },
    {
      "index": 376,
      "start_time": 1703360.0,
      "end_time": 1708511.0,
      "text": "there is, there are at least 2i 1&#39;s within the range."
    },
    {
      "index": 377,
      "start_time": 1712220.0,
      "end_time": 1715566.0,
      "text": "Okay, since our error is no more than 2i minus 1."
    },
    {
      "index": 378,
      "start_time": 1715570.0,
      "end_time": 1718700.0,
      "text": "That error is at most 50%, you know?"
    },
    {
      "index": 379,
      "start_time": 1718700.0,
      "end_time": 1721500.0,
      "text": "We&#39;re not going to discuss the extensions here but"
    },
    {
      "index": 380,
      "start_time": 1721500.0,
      "end_time": 1725120.0,
      "text": "it is possible to modify the algorithm described to limit the error to"
    },
    {
      "index": 381,
      "start_time": 1725120.0,
      "end_time": 1729379.0,
      "text": "any fraction we like greater than 0, while still using only on the order of"
    },
    {
      "index": 382,
      "start_time": 1729380.0,
      "end_time": 1734260.0,
      "text": "log squared N bits to represent all the buckets we need to represent."
    },
    {
      "index": 383,
      "start_time": 1734260.0,
      "end_time": 1736170.0,
      "text": "The textbook describes how to do this."
    }
  ]
}