{
  "video_id": "zqMnvgccibs",
  "title": "Large Scale Machine Learning",
  "es": 0,
  "json": [
    {
      "index": 1,
      "start_time": 506.0,
      "end_time": 6516.0,
      "text": "[ MUSIC ]"
    },
    {
      "index": 2,
      "start_time": 7516.0,
      "end_time": 12356.0,
      "text": "[ APPLAUSE ]"
    },
    {
      "index": 3,
      "start_time": 12856.0,
      "end_time": 13626.0,
      "text": "BENGIO: Thank you."
    },
    {
      "index": 4,
      "start_time": 13746.0,
      "end_time": 14106.0,
      "text": "All right."
    },
    {
      "index": 5,
      "start_time": 14106.0,
      "end_time": 19695.0,
      "text": "Thank you for being here and participating in this colloquium."
    },
    {
      "index": 6,
      "start_time": 20266.0,
      "end_time": 26895.0,
      "text": "So, I&#39;ll tell you about some of the things that are happening in deep learning,"
    },
    {
      "index": 7,
      "start_time": 26896.0,
      "end_time": 34216.0,
      "text": "but I only have 30 minutes so I&#39;ll be kind of quickly going through some subjects"
    },
    {
      "index": 8,
      "start_time": 34216.0,
      "end_time": 38426.0,
      "text": "and some challenges for scaling up deep learning towards AI."
    },
    {
      "index": 9,
      "start_time": 38986.0,
      "end_time": 42546.0,
      "text": "Hopefully you&#39;ll have chances to ask me some questions during the panel that follows."
    },
    {
      "index": 10,
      "start_time": 44316.0,
      "end_time": 48336.0,
      "text": "One thing I want to mention is I&#39;m writing a book."
    },
    {
      "index": 11,
      "start_time": 48336.0,
      "end_time": 53866.0,
      "text": "It&#39;s called Deep Learning, and you can already download most of the chapters."
    },
    {
      "index": 12,
      "start_time": 53866.0,
      "end_time": 56525.0,
      "text": "These are draft versions of the chapters from my web page."
    },
    {
      "index": 13,
      "start_time": 56686.0,
      "end_time": 60916.0,
      "text": "It&#39;s going to be an MIT Press book hopefully next year."
    },
    {
      "index": 14,
      "start_time": 62686.0,
      "end_time": 67226.0,
      "text": "So, what is deep learning and why is everybody excited about it?"
    },
    {
      "index": 15,
      "start_time": 67596.0,
      "end_time": 71646.0,
      "text": "First of all, deep learning is just an approach to machine learning."
    },
    {
      "index": 16,
      "start_time": 72286.0,
      "end_time": 78896.0,
      "text": "And what&#39;s particular about it, as Terry was saying, it&#39;s inspired by brains."
    },
    {
      "index": 17,
      "start_time": 79336.0,
      "end_time": 83960.0,
      "text": "Inspired, we&#39;re trying to understand some of the principles, computational"
    },
    {
      "index": 18,
      "start_time": 83960.0,
      "end_time": 87666.0,
      "text": "and mathematical principles that could explain the kind of intelligence based"
    },
    {
      "index": 19,
      "start_time": 87666.0,
      "end_time": 89155.0,
      "text": "on learning that we see in brains."
    },
    {
      "index": 20,
      "start_time": 89646.0,
      "end_time": 91576.0,
      "text": "But from a computer science perspective,"
    },
    {
      "index": 21,
      "start_time": 91576.0,
      "end_time": 96905.0,
      "text": "the idea is that these algorithms learn representations."
    },
    {
      "index": 22,
      "start_time": 97600.0,
      "end_time": 102366.0,
      "text": "So, representations is a central concept in deep learning, and, of course,"
    },
    {
      "index": 23,
      "start_time": 102366.0,
      "end_time": 104836.0,
      "text": "the idea of learning representations is not new."
    },
    {
      "index": 24,
      "start_time": 105960.0,
      "end_time": 107776.0,
      "text": "It was part of the deal of the original neural nets,"
    },
    {
      "index": 25,
      "start_time": 107866.0,
      "end_time": 111160.0,
      "text": "like the Boltzmann machine and the back prop from the &#39;80s."
    },
    {
      "index": 26,
      "start_time": 111226.0,
      "end_time": 116946.0,
      "text": "But what&#39;s new here and what happened about ten years ago is a breakthrough that allowed us"
    },
    {
      "index": 27,
      "start_time": 116946.0,
      "end_time": 122646.0,
      "text": "to train deeper neural networks, meaning that have multiple levels of representation."
    },
    {
      "index": 28,
      "start_time": 122896.0,
      "end_time": 124316.0,
      "text": "And why is that interesting?"
    },
    {
      "index": 29,
      "start_time": 124316.0,
      "end_time": 129156.0,
      "text": "So already I mentioned that there are some theoretical results showing"
    },
    {
      "index": 30,
      "start_time": 129156.0,
      "end_time": 135160.0,
      "text": "that you can represent some complicated functions that are the result of the many levels"
    },
    {
      "index": 31,
      "start_time": 135160.0,
      "end_time": 139536.0,
      "text": "of compositions efficiently with these deep networks, whereas you might --"
    },
    {
      "index": 32,
      "start_time": 139846.0,
      "end_time": 143566.0,
      "text": "or in general, you won&#39;t be able to represent these kinds of functions"
    },
    {
      "index": 33,
      "start_time": 143616.0,
      "end_time": 146600.0,
      "text": "with a shallow network that doesn&#39;t have enough levels."
    },
    {
      "index": 34,
      "start_time": 147516.0,
      "end_time": 150886.0,
      "text": "What does it mean to have more depth?"
    },
    {
      "index": 35,
      "start_time": 151360.0,
      "end_time": 154196.0,
      "text": "It means that you&#39;re able to represent more abstracts concepts,"
    },
    {
      "index": 36,
      "start_time": 154776.0,
      "end_time": 158896.0,
      "text": "and these more abstract concepts allow these machines to generalize better."
    },
    {
      "index": 37,
      "start_time": 159176.0,
      "end_time": 161760.0,
      "text": "So, that&#39;s the essence of what&#39;s going on here."
    },
    {
      "index": 38,
      "start_time": 164236.0,
      "end_time": 164826.0,
      "text": "All right."
    },
    {
      "index": 39,
      "start_time": 164966.0,
      "end_time": 171786.0,
      "text": "So, the breakthrough happened in 2006 where, for the first time,"
    },
    {
      "index": 40,
      "start_time": 171786.0,
      "end_time": 176216.0,
      "text": "we were able to train these deeper networks and we used unsupervised learning for that,"
    },
    {
      "index": 41,
      "start_time": 176216.0,
      "end_time": 182206.0,
      "text": "but it took a few years before these advances made their way"
    },
    {
      "index": 42,
      "start_time": 182206.0,
      "end_time": 184786.0,
      "text": "to industry and to large scale applications."
    },
    {
      "index": 43,
      "start_time": 184786.0,
      "end_time": 187656.0,
      "text": "So, it started around 2010 with speech recognition."
    },
    {
      "index": 44,
      "start_time": 188960.0,
      "end_time": 193786.0,
      "text": "By 2012, if you had an Android phone, like this one, well,"
    },
    {
      "index": 45,
      "start_time": 193786.0,
      "end_time": 196726.0,
      "text": "you had neural nets doing speech recognition in them."
    },
    {
      "index": 46,
      "start_time": 197760.0,
      "end_time": 199626.0,
      "text": "And now, of course, it&#39;s everywhere."
    },
    {
      "index": 47,
      "start_time": 199946.0,
      "end_time": 203646.0,
      "text": "For speech, it&#39;s changed the field of speech recognition."
    },
    {
      "index": 48,
      "start_time": 203896.0,
      "end_time": 205766.0,
      "text": "Everything uses it, essentially."
    },
    {
      "index": 49,
      "start_time": 206460.0,
      "end_time": 210606.0,
      "text": "Then about two years later, 2012, there was another breakthrough using convolution networks,"
    },
    {
      "index": 50,
      "start_time": 210606.0,
      "end_time": 215196.0,
      "text": "which are a particular kind of deep networks that had been around for a long time"
    },
    {
      "index": 51,
      "start_time": 215616.0,
      "end_time": 218860.0,
      "text": "but that have been improved using some"
    },
    {
      "index": 52,
      "start_time": 218860.0,
      "end_time": 222606.0,
      "text": "of the techniques we discovered along these -- in recent years."
    },
    {
      "index": 53,
      "start_time": 223726.0,
      "end_time": 229166.0,
      "text": "Really allowed us to make big impact in the field of computer vision"
    },
    {
      "index": 54,
      "start_time": 229396.0,
      "end_time": 231756.0,
      "text": "and object recognition, in particular."
    },
    {
      "index": 55,
      "start_time": 233596.0,
      "end_time": 240766.0,
      "text": "So, I&#39;m sure [Faye Faye] will say a few words later about that event and then the role"
    },
    {
      "index": 56,
      "start_time": 240766.0,
      "end_time": 244376.0,
      "text": "of the image net dataset in this."
    },
    {
      "index": 57,
      "start_time": 244746.0,
      "end_time": 252226.0,
      "text": "But what&#39;s going on now is that neural nets are going beyond their traditional realm"
    },
    {
      "index": 58,
      "start_time": 252226.0,
      "end_time": 258755.0,
      "text": "of perception and people are exploring how to use them for understanding language."
    },
    {
      "index": 59,
      "start_time": 258755.0,
      "end_time": 261635.0,
      "text": "Of course, we haven&#39;t yet solved that problem."
    },
    {
      "index": 60,
      "start_time": 261976.0,
      "end_time": 264776.0,
      "text": "This is where a lot of the action is now and, of course,"
    },
    {
      "index": 61,
      "start_time": 264776.0,
      "end_time": 269296.0,
      "text": "continues a lot of research and R&D and computer vision."
    },
    {
      "index": 62,
      "start_time": 269296.0,
      "end_time": 274445.0,
      "text": "Now, for example, expanding to video and many other areas."
    },
    {
      "index": 63,
      "start_time": 274826.0,
      "end_time": 281336.0,
      "text": "But I&#39;m particularly interested in the extension of this field in natural language."
    },
    {
      "index": 64,
      "start_time": 281336.0,
      "end_time": 283316.0,
      "text": "There are other areas."
    },
    {
      "index": 65,
      "start_time": 283316.0,
      "end_time": 285416.0,
      "text": "You&#39;ve heard about reinforcement learning."
    },
    {
      "index": 66,
      "start_time": 285416.0,
      "end_time": 288206.0,
      "text": "There is a lot of action there, robotics, control."
    },
    {
      "index": 67,
      "start_time": 288486.0,
      "end_time": 295286.0,
      "text": "So, many areas of AI are now more and more seeing the potential gain coming"
    },
    {
      "index": 68,
      "start_time": 295286.0,
      "end_time": 298556.0,
      "text": "from using these more abstract systems."
    },
    {
      "index": 69,
      "start_time": 299516.0,
      "end_time": 307196.0,
      "text": "So, today, I&#39;m going to go through three of the main challenges that I see"
    },
    {
      "index": 70,
      "start_time": 307196.0,
      "end_time": 311946.0,
      "text": "for bringing deep learning, as we know it today, closer to AI."
    },
    {
      "index": 71,
      "start_time": 312566.0,
      "end_time": 314236.0,
      "text": "One of them is computational."
    },
    {
      "index": 72,
      "start_time": 314406.0,
      "end_time": 320336.0,
      "text": "Of course, for a company like IBM and other companies"
    },
    {
      "index": 73,
      "start_time": 320336.0,
      "end_time": 322886.0,
      "text": "that build machines, this is an important challenge."
    },
    {
      "index": 74,
      "start_time": 323186.0,
      "end_time": 327445.0,
      "text": "It&#39;s an important challenge because what we&#39;ve observed is"
    },
    {
      "index": 75,
      "start_time": 327446.0,
      "end_time": 330260.0,
      "text": "that the bigger the models we are able to train,"
    },
    {
      "index": 76,
      "start_time": 330260.0,
      "end_time": 333956.0,
      "text": "given the amount of data we currently have, the better they are."
    },
    {
      "index": 77,
      "start_time": 334616.0,
      "end_time": 339226.0,
      "text": "So, you know, we just keep building bigger models"
    },
    {
      "index": 78,
      "start_time": 339226.0,
      "end_time": 341766.0,
      "text": "and hopefully we&#39;re going to continue improving."
    },
    {
      "index": 79,
      "start_time": 341956.0,
      "end_time": 346560.0,
      "text": "Now, that being said, I think it&#39;s not going to be enough so there are other challenges."
    },
    {
      "index": 80,
      "start_time": 346560.0,
      "end_time": 350416.0,
      "text": "One of them I mentioned has to do with understanding language."
    },
    {
      "index": 81,
      "start_time": 350716.0,
      "end_time": 353166.0,
      "text": "But understanding language actually requires something more."
    },
    {
      "index": 82,
      "start_time": 353166.0,
      "end_time": 354656.0,
      "text": "It requires a form of reasoning."
    },
    {
      "index": 83,
      "start_time": 355160.0,
      "end_time": 359860.0,
      "text": "So, people are starting to use these recurrent nets you heard about, recurrent networks"
    },
    {
      "index": 84,
      "start_time": 359266.0,
      "end_time": 363536.0,
      "text": "that can be very deep, in some sense, when you consider time in order"
    },
    {
      "index": 85,
      "start_time": 363536.0,
      "end_time": 369916.0,
      "text": "to combine different pieces of evidence, in order to provide answers to questions."
    },
    {
      "index": 86,
      "start_time": 370516.0,
      "end_time": 375466.0,
      "text": "And essentially, displayed in different forms of reasoning."
    },
    {
      "index": 87,
      "start_time": 376316.0,
      "end_time": 379176.0,
      "text": "So, I&#39;ll say a few words about that challenge."
    },
    {
      "index": 88,
      "start_time": 379616.0,
      "end_time": 386486.0,
      "text": "And finally, maybe one of the most important challenges that&#39;s maybe more fundamental even is"
    },
    {
      "index": 89,
      "start_time": 386486.0,
      "end_time": 388460.0,
      "text": "the unsupervised learning challenge."
    },
    {
      "index": 90,
      "start_time": 388426.0,
      "end_time": 394600.0,
      "text": "Up to now, all of the industrial applications of deep learning have exploited supervised learning"
    },
    {
      "index": 91,
      "start_time": 394600.0,
      "end_time": 398850.0,
      "text": "where we have labeled the data we&#39;ve said in that image, it&#39;s a cat."
    },
    {
      "index": 92,
      "start_time": 398860.0,
      "end_time": 400746.0,
      "text": "In that image, there&#39;s a desk, and so on."
    },
    {
      "index": 93,
      "start_time": 400746.0,
      "end_time": 405116.0,
      "text": "But there&#39;s a lot more data we could take advantage of that&#39;s unlabeled,"
    },
    {
      "index": 94,
      "start_time": 405216.0,
      "end_time": 412736.0,
      "text": "and that&#39;s going to be important because all of na information we need to build these AIs has"
    },
    {
      "index": 95,
      "start_time": 412736.0,
      "end_time": 416846.0,
      "text": "to come from somewhere, and we need enough data, and most of it is not going to be labeled."
    },
    {
      "index": 96,
      "start_time": 418606.0,
      "end_time": 423106.0,
      "text": "Right. So, as I mentioned, and I guess as my colleague,"
    },
    {
      "index": 97,
      "start_time": 423146.0,
      "end_time": 426366.0,
      "text": "Ilya Sutskever from Google keeps saying, bigger is better."
    },
    {
      "index": 98,
      "start_time": 426706.0,
      "end_time": 429816.0,
      "text": "At least up to now, we haven&#39;t seen the limitations."
    },
    {
      "index": 99,
      "start_time": 429936.0,
      "end_time": 434765.0,
      "text": "I do believe that there are obstacles, and bigger is not going to be enough."
    },
    {
      "index": 100,
      "start_time": 435166.0,
      "end_time": 439536.0,
      "text": "But clearly, there&#39;s an easy path forward with the current algorithms just"
    },
    {
      "index": 101,
      "start_time": 439536.0,
      "end_time": 445886.0,
      "text": "by making our neural nets a hundred times faster and bigger."
    },
    {
      "index": 102,
      "start_time": 446506.0,
      "end_time": 450895.0,
      "text": "So, why is that?"
    },
    {
      "index": 103,
      "start_time": 452760.0,
      "end_time": 458360.0,
      "text": "Basically, what I see in many experiments with neural nets right now is that they --"
    },
    {
      "index": 104,
      "start_time": 458360.0,
      "end_time": 461636.0,
      "text": "I&#39;m going to use some jargon here."
    },
    {
      "index": 105,
      "start_time": 461636.0,
      "end_time": 467266.0,
      "text": "They under fit, meaning that they&#39;re not big enough or we don&#39;t train them long enough"
    },
    {
      "index": 106,
      "start_time": 467666.0,
      "end_time": 471226.0,
      "text": "for them to exploit all of the information that there is in the data."
    },
    {
      "index": 107,
      "start_time": 471226.0,
      "end_time": 474806.0,
      "text": "And so they&#39;re not even able to learn the data by heart, right,"
    },
    {
      "index": 108,
      "start_time": 474866.0,
      "end_time": 477366.0,
      "text": "which is the thing we usually want to avoid in machine learning."
    },
    {
      "index": 109,
      "start_time": 477696.0,
      "end_time": 484386.0,
      "text": "But that comes almost for free with these networks, and so we just have to press"
    },
    {
      "index": 110,
      "start_time": 484386.0,
      "end_time": 489386.0,
      "text": "on the pedal of more capacity and we&#39;re almost sure to get an improvement here."
    },
    {
      "index": 111,
      "start_time": 489626.0,
      "end_time": 490226.0,
      "text": "All right."
    },
    {
      "index": 112,
      "start_time": 490226.0,
      "end_time": 496106.0,
      "text": "To just illustrate graphically that we have some room to approach the size of human brains,"
    },
    {
      "index": 113,
      "start_time": 496856.0,
      "end_time": 504560.0,
      "text": "this picture was made up by my former student, Ian Goodfellow, where we see the sizes"
    },
    {
      "index": 114,
      "start_time": 504560.0,
      "end_time": 510750.0,
      "text": "of different organisms and neural nets over the years so the DBN here was from 2006."
    },
    {
      "index": 115,
      "start_time": 510516.0,
      "end_time": 514686.0,
      "text": "Of the AlexNet is the breakthrough network of 2012 for computer vision,"
    },
    {
      "index": 116,
      "start_time": 515275.0,
      "end_time": 519315.0,
      "text": "and the AdamNet is maybe a couple of years old."
    },
    {
      "index": 117,
      "start_time": 519885.0,
      "end_time": 528656.0,
      "text": "So, we see that the current technology is maybe between a bee and a frog in terms of size"
    },
    {
      "index": 118,
      "start_time": 528956.0,
      "end_time": 533136.0,
      "text": "of the networks for about the same number of synapses."
    },
    {
      "index": 119,
      "start_time": 533136.0,
      "end_time": 537550.0,
      "text": "So, we&#39;ve almost reached the kind of average number of synapses you see in natural brains,"
    },
    {
      "index": 120,
      "start_time": 537616.0,
      "end_time": 539860.0,
      "text": "between a thousand and ten thousand."
    },
    {
      "index": 121,
      "start_time": 539356.0,
      "end_time": 542926.0,
      "text": "In terms of number of neurons, we&#39;re several orders of ranking away."
    },
    {
      "index": 122,
      "start_time": 542926.0,
      "end_time": 549796.0,
      "text": "So, I&#39;m going to tell you a little bit about a stream of research we&#39;ve been pushing in my lab,"
    },
    {
      "index": 123,
      "start_time": 550226.0,
      "end_time": 556476.0,
      "text": "which is more connected to the computing challenge and potentially part"
    },
    {
      "index": 124,
      "start_time": 556606.0,
      "end_time": 565636.0,
      "text": "of our implementation, which is can we train neural nets that have very low precision."
    },
    {
      "index": 125,
      "start_time": 566336.0,
      "end_time": 571376.0,
      "text": "So, we had a first paper at ICLR."
    },
    {
      "index": 126,
      "start_time": 571376.0,
      "end_time": 577126.0,
      "text": "By the way, ICLR is the deep learning conference, and it happens every year now."
    },
    {
      "index": 127,
      "start_time": 577226.0,
      "end_time": 580796.0,
      "text": "Yann Lecun and I started it in 2013 and it&#39;s been an amazing success"
    },
    {
      "index": 128,
      "start_time": 580796.0,
      "end_time": 582826.0,
      "text": "that year and every year since then."
    },
    {
      "index": 129,
      "start_time": 582826.0,
      "end_time": 587196.0,
      "text": "We&#39;re going to have a third version next May."
    },
    {
      "index": 130,
      "start_time": 588386.0,
      "end_time": 592106.0,
      "text": "And so we wanted to know how many bits do you actually require."
    },
    {
      "index": 131,
      "start_time": 592106.0,
      "end_time": 595516.0,
      "text": "Of course, people have been asking these kinds of questions for decades."
    },
    {
      "index": 132,
      "start_time": 596516.0,
      "end_time": 603565.0,
      "text": "But using sort of the current state of the art neural nets and we found 12,"
    },
    {
      "index": 133,
      "start_time": 604600.0,
      "end_time": 610446.0,
      "text": "and I can show you some pictures how we got these numbers on different data sets"
    },
    {
      "index": 134,
      "start_time": 610446.0,
      "end_time": 615896.0,
      "text": "and comparing different ways of representing numbers with fixed point or dynamic fixed point."
    },
    {
      "index": 135,
      "start_time": 616946.0,
      "end_time": 621286.0,
      "text": "And also, depending on where I use those bits, you actually need less bits"
    },
    {
      "index": 136,
      "start_time": 621286.0,
      "end_time": 623396.0,
      "text": "in the activations than in the weights."
    },
    {
      "index": 137,
      "start_time": 623396.0,
      "end_time": 625266.0,
      "text": "So, you need more rescission in the weights."
    },
    {
      "index": 138,
      "start_time": 625616.0,
      "end_time": 628746.0,
      "text": "So, that was the first investigation."
    },
    {
      "index": 139,
      "start_time": 628746.0,
      "end_time": 632960.0,
      "text": "But then we thought -- so that&#39;s the --"
    },
    {
      "index": 140,
      "start_time": 632576.0,
      "end_time": 636206.0,
      "text": "for the weights, that&#39;s the number of bits you actually need to keep the information"
    },
    {
      "index": 141,
      "start_time": 636206.0,
      "end_time": 639976.0,
      "text": "that you are accumulating from many examples."
    },
    {
      "index": 142,
      "start_time": 640446.0,
      "end_time": 645706.0,
      "text": "But when you actually run your system during training, especially,"
    },
    {
      "index": 143,
      "start_time": 646526.0,
      "end_time": 647976.0,
      "text": "maybe you don&#39;t need all those bits."
    },
    {
      "index": 144,
      "start_time": 648506.0,
      "end_time": 651805.0,
      "text": "Maybe you can get the same effect by introducing noise"
    },
    {
      "index": 145,
      "start_time": 652716.0,
      "end_time": 657636.0,
      "text": "and discretizing randomly those weights to plus one or minus one."
    },
    {
      "index": 146,
      "start_time": 658176.0,
      "end_time": 659326.0,
      "text": "So, that&#39;s exactly what we did."
    },
    {
      "index": 147,
      "start_time": 659326.0,
      "end_time": 667166.0,
      "text": "The idea is -- the cute idea here is that we can replace a real number by a binary number"
    },
    {
      "index": 148,
      "start_time": 667166.0,
      "end_time": 673126.0,
      "text": "that has the same expected value by, you know, sampling those two values with a probability"
    },
    {
      "index": 149,
      "start_time": 673126.0,
      "end_time": 675545.0,
      "text": "such as that the expected value is the correct one."
    },
    {
      "index": 150,
      "start_time": 676960.0,
      "end_time": 678566.0,
      "text": "And now, instead of having a real number to multiply,"
    },
    {
      "index": 151,
      "start_time": 678646.0,
      "end_time": 681685.0,
      "text": "we have a bit to multiply, which is easy."
    },
    {
      "index": 152,
      "start_time": 681686.0,
      "end_time": 684760.0,
      "text": "It&#39;s just an addition."
    },
    {
      "index": 153,
      "start_time": 684760.0,
      "end_time": 684856.0,
      "text": "And why would we do that?"
    },
    {
      "index": 154,
      "start_time": 684976.0,
      "end_time": 686596.0,
      "text": "Because we want to get rid of multiplications."
    },
    {
      "index": 155,
      "start_time": 686596.0,
      "end_time": 691406.0,
      "text": "Multiplications is what takes up most of the surface area on chips for doing neural nets."
    },
    {
      "index": 156,
      "start_time": 692256.0,
      "end_time": 698106.0,
      "text": "So, we had a first try at this, and this is going to be presented at the next NIPS"
    },
    {
      "index": 157,
      "start_time": 698106.0,
      "end_time": 699686.0,
      "text": "in the next few weeks in Montreal."
    },
    {
      "index": 158,
      "start_time": 699686.0,
      "end_time": 705346.0,
      "text": "And it allows us to get rid of the multiplications in the feed forward computation"
    },
    {
      "index": 159,
      "start_time": 705816.0,
      "end_time": 708666.0,
      "text": "and in the backward computation where we compute gradients."
    },
    {
      "index": 160,
      "start_time": 709136.0,
      "end_time": 713795.0,
      "text": "But we remained with the multiplication -- even if you discretize the weights,"
    },
    {
      "index": 161,
      "start_time": 713796.0,
      "end_time": 716736.0,
      "text": "there is another multiplication at the end of the back prop"
    },
    {
      "index": 162,
      "start_time": 717136.0,
      "end_time": 720366.0,
      "text": "where you multiply -- you don&#39;t multiply weights."
    },
    {
      "index": 163,
      "start_time": 720366.0,
      "end_time": 721966.0,
      "text": "You multiply activations and gradients."
    },
    {
      "index": 164,
      "start_time": 721966.0,
      "end_time": 726126.0,
      "text": "So, if those two things are real valued, you still need regular multiplication."
    },
    {
      "index": 165,
      "start_time": 726666.0,
      "end_time": 730386.0,
      "text": "So, we -- yes, so that&#39;s going to be in the NIPS paper."
    },
    {
      "index": 166,
      "start_time": 730706.0,
      "end_time": 738696.0,
      "text": "But the new thing we did is to get rid of that last multiplication that we need for the update"
    },
    {
      "index": 167,
      "start_time": 738696.0,
      "end_time": 741156.0,
      "text": "of the weight, so the delta W is a change in the weights,"
    },
    {
      "index": 168,
      "start_time": 741266.0,
      "end_time": 745496.0,
      "text": "DC DA is the gradient that&#39;s propagated back, and H is the activations."
    },
    {
      "index": 169,
      "start_time": 745766.0,
      "end_time": 746435.0,
      "text": "It&#39;s some jargon."
    },
    {
      "index": 170,
      "start_time": 746436.0,
      "end_time": 752836.0,
      "text": "But anyway, we have to do this multiplication, and so, well, the only thing we need"
    },
    {
      "index": 171,
      "start_time": 752836.0,
      "end_time": 756496.0,
      "text": "to do is take one of these two numbers and replace it again by a stochastic quantity"
    },
    {
      "index": 172,
      "start_time": 756976.0,
      "end_time": 760560.0,
      "text": "that is not going to require multiplication."
    },
    {
      "index": 173,
      "start_time": 760346.0,
      "end_time": 766326.0,
      "text": "So, instead of binarizing it, we quantize it stochastically to its mantissa."
    },
    {
      "index": 174,
      "start_time": 766326.0,
      "end_time": 768486.0,
      "text": "In other words, we get rid of -- to its exponent."
    },
    {
      "index": 175,
      "start_time": 768486.0,
      "end_time": 769396.0,
      "text": "We get rid of the mantissa."
    },
    {
      "index": 176,
      "start_time": 769736.0,
      "end_time": 777760.0,
      "text": "In other words, we represent it, we -- we represent it in a log scale."
    },
    {
      "index": 177,
      "start_time": 777760.0,
      "end_time": 781796.0,
      "text": "So, if you do that, again, you can map the activations"
    },
    {
      "index": 178,
      "start_time": 781796.0,
      "end_time": 785616.0,
      "text": "to some values that are just powers of two."
    },
    {
      "index": 179,
      "start_time": 786760.0,
      "end_time": 787856.0,
      "text": "And now multiplication is just addition."
    },
    {
      "index": 180,
      "start_time": 787856.0,
      "end_time": 788796.0,
      "text": "This is an old trick."
    },
    {
      "index": 181,
      "start_time": 788796.0,
      "end_time": 792676.0,
      "text": "I mean, the trick of using powers of two is an old trick."
    },
    {
      "index": 182,
      "start_time": 792676.0,
      "end_time": 795856.0,
      "text": "The new trick is to do this stochastically so that you actually get the right things"
    },
    {
      "index": 183,
      "start_time": 795856.0,
      "end_time": 800116.0,
      "text": "in average and stochastic gradient works perfectly fine."
    },
    {
      "index": 184,
      "start_time": 800246.0,
      "end_time": 807656.0,
      "text": "And so we&#39;re running some experiments on a few data sets showing that you get a bit"
    },
    {
      "index": 185,
      "start_time": 807656.0,
      "end_time": 811636.0,
      "text": "of a slowdown because of the extra noise."
    },
    {
      "index": 186,
      "start_time": 811676.0,
      "end_time": 817656.0,
      "text": "But so the green and yellow curve here are where this strict with binarized weights"
    },
    {
      "index": 187,
      "start_time": 817656.0,
      "end_time": 822465.0,
      "text": "and quantized, stochastically quantize the calculations."
    },
    {
      "index": 188,
      "start_time": 823260.0,
      "end_time": 828216.0,
      "text": "And the good news is, well, it learns even better, actually,"
    },
    {
      "index": 189,
      "start_time": 828216.0,
      "end_time": 830356.0,
      "text": "because this noise acts as a regularizer."
    },
    {
      "index": 190,
      "start_time": 830356.0,
      "end_time": 833346.0,
      "text": "Now, this -- yes, this is pretty good news."
    },
    {
      "index": 191,
      "start_time": 833416.0,
      "end_time": 837806.0,
      "text": "Now, why is this interesting?"
    },
    {
      "index": 192,
      "start_time": 837806.0,
      "end_time": 841826.0,
      "text": "It&#39;s interesting because we can probably -- for two reasons."
    },
    {
      "index": 193,
      "start_time": 841826.0,
      "end_time": 844816.0,
      "text": "One is for hardware implementations, this could be useful."
    },
    {
      "index": 194,
      "start_time": 845860.0,
      "end_time": 848760.0,
      "text": "The other reasons is that it connects with what the brain -- with spikes, right."
    },
    {
      "index": 195,
      "start_time": 848760.0,
      "end_time": 858776.0,
      "text": "So the idea with -- you can think of, if I go back here, when you replace activations"
    },
    {
      "index": 196,
      "start_time": 858856.0,
      "end_time": 865626.0,
      "text": "by some stoke tick binary values that have the right expected value, you&#39;re introducing noise."
    },
    {
      "index": 197,
      "start_time": 866166.0,
      "end_time": 870626.0,
      "text": "But you&#39;re actually not changing that much the computation of the gradient."
    },
    {
      "index": 198,
      "start_time": 871256.0,
      "end_time": 875760.0,
      "text": "And so it would be reasonable for brains to use the same trick"
    },
    {
      "index": 199,
      "start_time": 875760.0,
      "end_time": 878560.0,
      "text": "if they could save on the hardware side."
    },
    {
      "index": 200,
      "start_time": 879276.0,
      "end_time": 886260.0,
      "text": "Okay. So now let me move on to my second challenge, which has to do with language and,"
    },
    {
      "index": 201,
      "start_time": 886260.0,
      "end_time": 889726.0,
      "text": "in particular, language understanding."
    },
    {
      "index": 202,
      "start_time": 889726.0,
      "end_time": 893160.0,
      "text": "There&#39;s a lot of work to do in this direction,"
    },
    {
      "index": 203,
      "start_time": 893160.0,
      "end_time": 896246.0,
      "text": "but the progress in the last few years is pretty impressive."
    },
    {
      "index": 204,
      "start_time": 898406.0,
      "end_time": 906925.0,
      "text": "Actually, I was part of the beginning of that process of extending the realm"
    },
    {
      "index": 205,
      "start_time": 906926.0,
      "end_time": 909136.0,
      "text": "of application of neural networks to language."
    },
    {
      "index": 206,
      "start_time": 909136.0,
      "end_time": 914536.0,
      "text": "So, in 2000, we had a NIPS paper where we introduced the idea of learning"
    },
    {
      "index": 207,
      "start_time": 914536.0,
      "end_time": 919185.0,
      "text": "to represent probability distributions over sequences of words."
    },
    {
      "index": 208,
      "start_time": 919186.0,
      "end_time": 924216.0,
      "text": "In other words, being able to generate sequences of words that look like English"
    },
    {
      "index": 209,
      "start_time": 924926.0,
      "end_time": 929106.0,
      "text": "by decomposing the problem in two parts."
    },
    {
      "index": 210,
      "start_time": 929106.0,
      "end_time": 935866.0,
      "text": "That&#39;s a kind of a central element that you find in neural nets and especially in deep learning,"
    },
    {
      "index": 211,
      "start_time": 936306.0,
      "end_time": 940360.0,
      "text": "which is think of the problem not as going directly from inputs to outputs,"
    },
    {
      "index": 212,
      "start_time": 940360.0,
      "end_time": 941766.0,
      "text": "but breaking the problem into two parts."
    },
    {
      "index": 213,
      "start_time": 941766.0,
      "end_time": 943945.0,
      "text": "One is the representation part."
    },
    {
      "index": 214,
      "start_time": 943986.0,
      "end_time": 950526.0,
      "text": "So, learning to represent words here by mapping each word to a fixed size, real valued vector."
    },
    {
      "index": 215,
      "start_time": 951286.0,
      "end_time": 955815.0,
      "text": "And then taking those representations and mapping them to the answers you care about."
    },
    {
      "index": 216,
      "start_time": 955816.0,
      "end_time": 957386.0,
      "text": "And here, that&#39;s predicting the next word."
    },
    {
      "index": 217,
      "start_time": 958236.0,
      "end_time": 961160.0,
      "text": "It turned out that those representations of words"
    },
    {
      "index": 218,
      "start_time": 961160.0,
      "end_time": 965795.0,
      "text": "that we learned have incredibly nice properties and they capture a lot"
    },
    {
      "index": 219,
      "start_time": 965796.0,
      "end_time": 968996.0,
      "text": "of the semantic aspects of words."
    },
    {
      "index": 220,
      "start_time": 968996.0,
      "end_time": 971136.0,
      "text": "And there&#39;s been tons and tons of papers"
    },
    {
      "index": 221,
      "start_time": 971446.0,
      "end_time": 973986.0,
      "text": "to analyze these things, to use them in applications."
    },
    {
      "index": 222,
      "start_time": 973986.0,
      "end_time": 977806.0,
      "text": "So, these are called word vectors, word embeddings, and they&#39;re used all over the place"
    },
    {
      "index": 223,
      "start_time": 977806.0,
      "end_time": 981616.0,
      "text": "and becoming like commonplace in natural language processing."
    },
    {
      "index": 224,
      "start_time": 981616.0,
      "end_time": 985936.0,
      "text": "In the last couple of years, there&#39;s been a kind of an exciting observation"
    },
    {
      "index": 225,
      "start_time": 985936.0,
      "end_time": 989286.0,
      "text": "about these word embeddings, which is that they capture analogies,"
    },
    {
      "index": 226,
      "start_time": 989576.0,
      "end_time": 991460.0,
      "text": "even though they were not programmed for that."
    },
    {
      "index": 227,
      "start_time": 991460.0,
      "end_time": 991746.0,
      "text": "So, what do I mean?"
    },
    {
      "index": 228,
      "start_time": 992166.0,
      "end_time": 1001176.0,
      "text": "What I mean is that if you take the vector which is for each word and you do operations on them,"
    },
    {
      "index": 229,
      "start_time": 1001180.0,
      "end_time": 1005830.0,
      "text": "like subtract and add them, you can get interesting things coming up."
    },
    {
      "index": 230,
      "start_time": 1005830.0,
      "end_time": 1010150.0,
      "text": "So, for example, if you take the vector for queen and you subtract the vector for king,"
    },
    {
      "index": 231,
      "start_time": 1010500.0,
      "end_time": 1017299.0,
      "text": "you get a new vector, and that vector is pretty much aligned with the vector that you get"
    },
    {
      "index": 232,
      "start_time": 1017300.0,
      "end_time": 1022380.0,
      "text": "from subtracting the representation for woman from the representation for man."
    },
    {
      "index": 233,
      "start_time": 1022380.0,
      "end_time": 1033530.0,
      "text": "So, that means that you could do something like woman minus man, plus king and get queen, right."
    },
    {
      "index": 234,
      "start_time": 1033530.0,
      "end_time": 1034920.0,
      "text": "So, it can answer the question, you know,"
    },
    {
      "index": 235,
      "start_time": 1034920.0000000001,
      "end_time": 1040480.0000000001,
      "text": "what is to king what woman is to man, and it would find queen."
    },
    {
      "index": 236,
      "start_time": 1040940.0,
      "end_time": 1046530.0,
      "text": "So, that&#39;s interesting, and there is some nice explanations that we&#39;re starting"
    },
    {
      "index": 237,
      "start_time": 1046530.0,
      "end_time": 1048364.0,
      "text": "to understand why this is happening."
    },
    {
      "index": 238,
      "start_time": 1048359.9999999999,
      "end_time": 1053496.0,
      "text": "Basically, directions in that space of representations correspond to attributes"
    },
    {
      "index": 239,
      "start_time": 1053500.0,
      "end_time": 1054990.0,
      "text": "that have been discovered by the machine."
    },
    {
      "index": 240,
      "start_time": 1054990.0,
      "end_time": 1060890.0,
      "text": "So, here, the difference between man and woman, they have all the same attributes somehow,"
    },
    {
      "index": 241,
      "start_time": 1060890.0,
      "end_time": 1063830.0,
      "text": "in some semantic space, except for gender."
    },
    {
      "index": 242,
      "start_time": 1064860.0,
      "end_time": 1066206.0,
      "text": "The same is true for queen and king."
    },
    {
      "index": 243,
      "start_time": 1066210.0,
      "end_time": 1069920.0,
      "text": "They have lots of different attributes, but they essentially have all the same except for gender."
    },
    {
      "index": 244,
      "start_time": 1070230.0,
      "end_time": 1074730.0,
      "text": "So, when you subtract them, the only thing you get in your hand is the direction for gender."
    },
    {
      "index": 245,
      "start_time": 1076360.0,
      "end_time": 1082400.0,
      "text": "Okay. So the progress with representing the meaning of words has been really amazing."
    },
    {
      "index": 246,
      "start_time": 1082650.0,
      "end_time": 1086330.0,
      "text": "But, of course, this is by no means sufficient to understand language."
    },
    {
      "index": 247,
      "start_time": 1086910.0,
      "end_time": 1094330.0,
      "text": "So, the next stage has been, well, can we represent the meaning of sentences or phrases."
    },
    {
      "index": 248,
      "start_time": 1094900.0,
      "end_time": 1100249.0,
      "text": "And in my group, we worked on machine translation as a case study to see"
    },
    {
      "index": 249,
      "start_time": 1100250.0,
      "end_time": 1105700.0,
      "text": "if we could bring up that power of representation that we&#39;ve seen"
    },
    {
      "index": 250,
      "start_time": 1105700.0,
      "end_time": 1107960.0,
      "text": "in those language models to a task"
    },
    {
      "index": 251,
      "start_time": 1108220.0,
      "end_time": 1112660.0,
      "text": "that was a bit more challenging from a semantic point of view."
    },
    {
      "index": 252,
      "start_time": 1112660.0,
      "end_time": 1117400.0,
      "text": "And I guess the thing we&#39;re doing now, and many other groups are also doing,"
    },
    {
      "index": 253,
      "start_time": 1117520.0,
      "end_time": 1122670.0,
      "text": "is pushing that to an even harder semantic task, which is question answering."
    },
    {
      "index": 254,
      "start_time": 1122670.0,
      "end_time": 1128249.0,
      "text": "In other words, read a sentence or read a paragraph or a document and then read a question"
    },
    {
      "index": 255,
      "start_time": 1128460.0,
      "end_time": 1130590.0,
      "text": "and then generate a natural language in answer."
    },
    {
      "index": 256,
      "start_time": 1130590.0,
      "end_time": 1133970.0,
      "text": "So, it&#39;s a bit more challenging, but you can see that it&#39;s a kind of translation as well."
    },
    {
      "index": 257,
      "start_time": 1133970.0,
      "end_time": 1137200.0,
      "text": "You have a sequence in input and you produce a sequence in output."
    },
    {
      "index": 258,
      "start_time": 1137200.0,
      "end_time": 1139499.0,
      "text": "In fact, we used very similar techniques."
    },
    {
      "index": 259,
      "start_time": 1140650.0,
      "end_time": 1144710.0,
      "text": "So, now let me tell you about that machine translation approach"
    },
    {
      "index": 260,
      "start_time": 1144710.0,
      "end_time": 1150454.0,
      "text": "that we created about a year and a half ago."
    },
    {
      "index": 261,
      "start_time": 1150480.0,
      "end_time": 1155460.0,
      "text": "And it uses these recurrent networks that you&#39;ve heard about,"
    },
    {
      "index": 262,
      "start_time": 1155460.0,
      "end_time": 1159829.0,
      "text": "because as soon as you start dealing with sequences, it&#39;s kind of the natural thing to do."
    },
    {
      "index": 263,
      "start_time": 1160180.0,
      "end_time": 1164450.0,
      "text": "It uses something fairly new that has been incredibly successful in the field"
    },
    {
      "index": 264,
      "start_time": 1164450.0,
      "end_time": 1166930.0,
      "text": "in the last year, which is the idea"
    },
    {
      "index": 265,
      "start_time": 1166930.0,
      "end_time": 1172970.0,
      "text": "of introducing attention mechanisms within the computation."
    },
    {
      "index": 266,
      "start_time": 1173510.0,
      "end_time": 1178950.0,
      "text": "So, sometimes we think of attention as, like, visual attention, so deciding where to look."
    },
    {
      "index": 267,
      "start_time": 1179370.0,
      "end_time": 1181400.0,
      "text": "But here we&#39;re talking about a different kind of attention."
    },
    {
      "index": 268,
      "start_time": 1181400.0,
      "end_time": 1184300.0,
      "text": "It&#39;s a kind of internal attention."
    },
    {
      "index": 269,
      "start_time": 1184300.0,
      "end_time": 1189490.0,
      "text": "So, choosing which parts of your neural network are you going to be paying attention to."
    },
    {
      "index": 270,
      "start_time": 1189820.0,
      "end_time": 1193690.0,
      "text": "And here, let me go through this architecture a little bit."
    },
    {
      "index": 271,
      "start_time": 1193690.0,
      "end_time": 1196400.0,
      "text": "What&#39;s going on is -- do I have a pointer?"
    },
    {
      "index": 272,
      "start_time": 1198510.0,
      "end_time": 1199780.0,
      "text": "All right."
    },
    {
      "index": 273,
      "start_time": 1201690.0,
      "end_time": 1207769.0,
      "text": "You have an input sentence in English, say, and there&#39;s a recurrent net that reads it,"
    },
    {
      "index": 274,
      "start_time": 1207770.0,
      "end_time": 1209790.0,
      "text": "meaning that it sees one word at a time."
    },
    {
      "index": 275,
      "start_time": 1210600.0,
      "end_time": 1215566.0,
      "text": "As it goes through it, it builds a representation of the words that it has seen."
    },
    {
      "index": 276,
      "start_time": 1215570.0,
      "end_time": 1217810.0,
      "text": "Actually, there are two recurrent nets, one reading from left to right"
    },
    {
      "index": 277,
      "start_time": 1217810.0,
      "end_time": 1219470.0,
      "text": "and the other from right to left."
    },
    {
      "index": 278,
      "start_time": 1219670.0,
      "end_time": 1224289.0,
      "text": "Then at each position, you have a representation of what&#39;s going on around that word."
    },
    {
      "index": 279,
      "start_time": 1224940.0,
      "end_time": 1227799.0,
      "text": "So, that&#39;s the reading network."
    },
    {
      "index": 280,
      "start_time": 1227800.0,
      "end_time": 1233530.0,
      "text": "Then there is a writing -- an output network, which is going to produce a sequence of words."
    },
    {
      "index": 281,
      "start_time": 1233660.0,
      "end_time": 1238279.0,
      "text": "More precisely, it&#39;s going to produce a probability distribution for each word"
    },
    {
      "index": 282,
      "start_time": 1238280.0,
      "end_time": 1243190.0,
      "text": "in the vocabulary at each stage and then we&#39;re going to pick, according to the distribution,"
    },
    {
      "index": 283,
      "start_time": 1243190.0,
      "end_time": 1244410.0,
      "text": "we&#39;re going to pick the next word."
    },
    {
      "index": 284,
      "start_time": 1244410.0,
      "end_time": 1249739.0,
      "text": "The choice of that word is going to condition the computation for the next stage."
    },
    {
      "index": 285,
      "start_time": 1249740.0,
      "end_time": 1252360.0,
      "text": "The state of the network is going to be different,"
    },
    {
      "index": 286,
      "start_time": 1252360.0,
      "end_time": 1254250.0,
      "text": "depending on what words you&#39;ve said before."
    },
    {
      "index": 287,
      "start_time": 1255310.0,
      "end_time": 1260470.0,
      "text": "And that whole output sequence is going to be influenced by what we have read, of course,"
    },
    {
      "index": 288,
      "start_time": 1260470.0,
      "end_time": 1262279.0,
      "text": "because we want to translate the input sequence."
    },
    {
      "index": 289,
      "start_time": 1263180.0,
      "end_time": 1267840.0,
      "text": "Now, the way that that input sequence and that output sequence are related is important."
    },
    {
      "index": 290,
      "start_time": 1267840.0,
      "end_time": 1269520.0,
      "text": "That&#39;s where the attention mechanism comes in."
    },
    {
      "index": 291,
      "start_time": 1269520.0,
      "end_time": 1271560.0,
      "text": "Because when you&#39;re doing translation, for example,"
    },
    {
      "index": 292,
      "start_time": 1271560.0,
      "end_time": 1273870.0,
      "text": "the input sequence has a different length from the output sequence."
    },
    {
      "index": 293,
      "start_time": 1273870.0,
      "end_time": 1278950.0,
      "text": "So, which word or which part of the sequence here corresponds to which part"
    },
    {
      "index": 294,
      "start_time": 1278950.0,
      "end_time": 1280289.0,
      "text": "in the output sequence, that&#39;s the question"
    },
    {
      "index": 295,
      "start_time": 1280290.0,
      "end_time": 1283760.0,
      "text": "that the attention mechanism is helping us figure out."
    },
    {
      "index": 296,
      "start_time": 1284170.0,
      "end_time": 1288370.0,
      "text": "And we found a way to do that doing a mechanism that allows"
    },
    {
      "index": 297,
      "start_time": 1288370.0,
      "end_time": 1290760.0,
      "text": "to us train using normal techniques with back prop."
    },
    {
      "index": 298,
      "start_time": 1290760.0,
      "end_time": 1292780.0,
      "text": "We can compute exact gradients to this process."
    },
    {
      "index": 299,
      "start_time": 1292900.0,
      "end_time": 1296509.0,
      "text": "And the idea that is for each position in the output sequence,"
    },
    {
      "index": 300,
      "start_time": 1296930.0,
      "end_time": 1302400.0,
      "text": "our network looks in the input sequence at all possible positions and computes a weight."
    },
    {
      "index": 301,
      "start_time": 1302860.0,
      "end_time": 1307820.0,
      "text": "And it&#39;s going to multiply the representation it&#39;s getting at each position by that weight"
    },
    {
      "index": 302,
      "start_time": 1308210.0,
      "end_time": 1311880.0,
      "text": "to form a linear combination which is going to be a context that&#39;s going"
    },
    {
      "index": 303,
      "start_time": 1311880.0,
      "end_time": 1313810.0,
      "text": "to drive the update at the next stage."
    },
    {
      "index": 304,
      "start_time": 1313810.0,
      "end_time": 1318740.0,
      "text": "So, in a sense, you&#39;re choosing where to look at each stage"
    },
    {
      "index": 305,
      "start_time": 1318740.0,
      "end_time": 1322190.0,
      "text": "to decide what the next word is going to be."
    },
    {
      "index": 306,
      "start_time": 1322440.0,
      "end_time": 1324980.0,
      "text": "So, this has actually worked incredibly well."
    },
    {
      "index": 307,
      "start_time": 1325760.0,
      "end_time": 1326896.0,
      "text": "And in the space of one year, we went"
    },
    {
      "index": 308,
      "start_time": 1326900.0,
      "end_time": 1330590.0,
      "text": "from dismal performance to state of the art performance."
    },
    {
      "index": 309,
      "start_time": 1330590.0,
      "end_time": 1338710.0,
      "text": "And at the last WMT, 2015, we got the first place on two of the language pairs,"
    },
    {
      "index": 310,
      "start_time": 1338710.0,
      "end_time": 1342230.0,
      "text": "English to German and English to Czech."
    },
    {
      "index": 311,
      "start_time": 1342340.0,
      "end_time": 1345640.0,
      "text": "And now there&#39;s like a bunch of groups around the world"
    },
    {
      "index": 312,
      "start_time": 1345640.0,
      "end_time": 1347780.0,
      "text": "that are pushing these kinds of systems."
    },
    {
      "index": 313,
      "start_time": 1347780.0,
      "end_time": 1351460.0,
      "text": "So, this is kind of a new way of doing machine translation, which is very,"
    },
    {
      "index": 314,
      "start_time": 1351460.0,
      "end_time": 1355799.0,
      "text": "very different in nature from the state of the art that&#39;s been around for 20 years."
    },
    {
      "index": 315,
      "start_time": 1357260.0,
      "end_time": 1363666.0,
      "text": "So, the next thing we did is use the same, almost the same code for translating not"
    },
    {
      "index": 316,
      "start_time": 1363670.0,
      "end_time": 1372354.0,
      "text": "from English to French but from -- or from French to English, but from image to English."
    },
    {
      "index": 317,
      "start_time": 1372950.0,
      "end_time": 1377864.0,
      "text": "So, the idea is, it&#39;s almost the same architecture, except that instead"
    },
    {
      "index": 318,
      "start_time": 1377860.0,
      "end_time": 1380756.0,
      "text": "of having a recurrent network that reads the French sentence,"
    },
    {
      "index": 319,
      "start_time": 1381230.0,
      "end_time": 1388860.0,
      "text": "we have what&#39;s called a convolutional net that we&#39;ve heard about that looks at the image"
    },
    {
      "index": 320,
      "start_time": 1389190.0,
      "end_time": 1392739.0,
      "text": "and computes for each location or for each block"
    },
    {
      "index": 321,
      "start_time": 1392740.0,
      "end_time": 1396000.0,
      "text": "of pixels a feature vector, a gain or representation."
    },
    {
      "index": 322,
      "start_time": 1396000.0,
      "end_time": 1398630.0,
      "text": "Similarly that we had representations for words,"
    },
    {
      "index": 323,
      "start_time": 1398630.0,
      "end_time": 1400510.0,
      "text": "now we have representations for parts of the image."
    },
    {
      "index": 324,
      "start_time": 1401390.0,
      "end_time": 1407564.0,
      "text": "And then the attention mechanism, as it generates the words in the sentence"
    },
    {
      "index": 325,
      "start_time": 1407560.0,
      "end_time": 1411836.0,
      "text": "that it&#39;s producing, at each stage chooses where to look in the image."
    },
    {
      "index": 326,
      "start_time": 1412800.0,
      "end_time": 1418500.0,
      "text": "So, Terry showed you some pictures from my lab."
    },
    {
      "index": 327,
      "start_time": 1419700.0,
      "end_time": 1420249.0,
      "text": "You&#39;ve seen this."
    },
    {
      "index": 328,
      "start_time": 1420850.0,
      "end_time": 1427610.0,
      "text": "And what we see with each pair of images is on the left,"
    },
    {
      "index": 329,
      "start_time": 1427610.0,
      "end_time": 1430400.0,
      "text": "the image that the system sees an input."
    },
    {
      "index": 330,
      "start_time": 1430560.0,
      "end_time": 1435830.0,
      "text": "On the right, we see where it&#39;s putting its attention for a particular word."
    },
    {
      "index": 331,
      "start_time": 1435830.0,
      "end_time": 1437864.0,
      "text": "That&#39;s the word that&#39;s underlined."
    },
    {
      "index": 332,
      "start_time": 1437860.0,
      "end_time": 1441376.0,
      "text": "So, when it says little girl, when it says girl,"
    },
    {
      "index": 333,
      "start_time": 1441380.0,
      "end_time": 1444670.0,
      "text": "we see that it&#39;s putting attention around the face of the girl."
    },
    {
      "index": 334,
      "start_time": 1444880.0,
      "end_time": 1448650.0,
      "text": "The other one, on top, for example, a woman is throwing a frisbee in the park."
    },
    {
      "index": 335,
      "start_time": 1448650.0,
      "end_time": 1453489.0,
      "text": "So, the underlined word is frisbee, and we show the second image in the pair"
    },
    {
      "index": 336,
      "start_time": 1453700.0,
      "end_time": 1458150.0,
      "text": "where it&#39;s putting its attention in the image."
    },
    {
      "index": 337,
      "start_time": 1458150.0,
      "end_time": 1461290.0,
      "text": "So, these are cases where it works quite well."
    },
    {
      "index": 338,
      "start_time": 1461290.0,
      "end_time": 1464620.0,
      "text": "But it wouldn&#39;t be fair if I only showed you those cases."
    },
    {
      "index": 339,
      "start_time": 1464620.0,
      "end_time": 1466370.0,
      "text": "I need to show you those where it fails."
    },
    {
      "index": 340,
      "start_time": 1466370.0,
      "end_time": 1469500.0,
      "text": "So, here are examples where it fails."
    },
    {
      "index": 341,
      "start_time": 1469500.0,
      "end_time": 1470770.0,
      "text": "That&#39;s where we learn the most."
    },
    {
      "index": 342,
      "start_time": 1470820.0,
      "end_time": 1473910.0,
      "text": "First of all, you realize immediately that we haven&#39;t solved the eye,"
    },
    {
      "index": 343,
      "start_time": 1474650.0,
      "end_time": 1480259.0,
      "text": "and that it&#39;s making mistakes both on the visual side and on the language side."
    },
    {
      "index": 344,
      "start_time": 1480260.0,
      "end_time": 1485264.0,
      "text": "So, on the visual side, you see things like on the top left, it thinks that it&#39;s a bird."
    },
    {
      "index": 345,
      "start_time": 1485640.0,
      "end_time": 1486950.0,
      "text": "It&#39;s two giraffes."
    },
    {
      "index": 346,
      "start_time": 1487000.0,
      "end_time": 1489190.0,
      "text": "Maybe if you squint you can think it&#39;s a bird."
    },
    {
      "index": 347,
      "start_time": 1489460.0,
      "end_time": 1497829.0,
      "text": "On the second one, it thinks that the round shape on the shirt is a clock, which, you know,"
    },
    {
      "index": 348,
      "start_time": 1497830.0,
      "end_time": 1499920.0,
      "text": "again, if you squint, you might think it&#39;s a clock."
    },
    {
      "index": 349,
      "start_time": 1500740.0,
      "end_time": 1503660.0,
      "text": "Now, the third one is totally crazy."
    },
    {
      "index": 350,
      "start_time": 1504310.0,
      "end_time": 1507340.0,
      "text": "A man wearing a hat and a hat on a skateboard."
    },
    {
      "index": 351,
      "start_time": 1507370.0,
      "end_time": 1509170.0,
      "text": "So, it&#39;s wrong visually."
    },
    {
      "index": 352,
      "start_time": 1509170.0,
      "end_time": 1510610.0,
      "text": "It&#39;s wrong, you know, linguistically."
    },
    {
      "index": 353,
      "start_time": 1510610.0,
      "end_time": 1514140.0,
      "text": "You wouldn&#39;t do a hat on a hat, and so on."
    },
    {
      "index": 354,
      "start_time": 1514850.0,
      "end_time": 1518880.0,
      "text": "So, it&#39;s fun and instructive to use these attention mechanisms"
    },
    {
      "index": 355,
      "start_time": 1518910.0,
      "end_time": 1520870.0,
      "text": "to understand what&#39;s going on inside the machine."
    },
    {
      "index": 356,
      "start_time": 1521370.0,
      "end_time": 1525720.0,
      "text": "To see, you know, at each step of the computation, what was it paying attention to."
    },
    {
      "index": 357,
      "start_time": 1526510.0,
      "end_time": 1530970.0,
      "text": "So, it&#39;s pretty interesting."
    },
    {
      "index": 358,
      "start_time": 1530970.0,
      "end_time": 1535710.0,
      "text": "Now, it turns out that this attention mechanism is at the part of another revolution that going"
    },
    {
      "index": 359,
      "start_time": 1535710.0,
      "end_time": 1540989.0,
      "text": "on right now in deep learning that has to do with the notion of memory"
    },
    {
      "index": 360,
      "start_time": 1540990.0,
      "end_time": 1544940.0,
      "text": "that Terry also mentioned during the panel."
    },
    {
      "index": 361,
      "start_time": 1544940.0,
      "end_time": 1551680.0,
      "text": "And neural nets up to recently have been considered as purely sort"
    },
    {
      "index": 362,
      "start_time": 1551680.0,
      "end_time": 1554864.0,
      "text": "of pattern recognition devices that go from input to output."
    },
    {
      "index": 363,
      "start_time": 1554290.0,
      "end_time": 1558240.0,
      "text": "As soon as you start thinking about dealing with reasoning and sequential processing,"
    },
    {
      "index": 364,
      "start_time": 1558680.0,
      "end_time": 1564180.0,
      "text": "comes the idea that it would be nice to have a short-term memory or even a long-term memory"
    },
    {
      "index": 365,
      "start_time": 1564550.0,
      "end_time": 1571410.0,
      "text": "that is different from the straight sort of kind of representation building computation"
    },
    {
      "index": 366,
      "start_time": 1571410.0,
      "end_time": 1574420.0,
      "text": "that we have in those feed forward neural nets."
    },
    {
      "index": 367,
      "start_time": 1574870.0,
      "end_time": 1577760.0,
      "text": "So, the idea is that in addition to the recurrent net"
    },
    {
      "index": 368,
      "start_time": 1577900.0,
      "end_time": 1581190.0,
      "text": "that does the usual computation, we have a memory."
    },
    {
      "index": 369,
      "start_time": 1581190.0,
      "end_time": 1586769.0,
      "text": "So, here, each of the cells, think of it as a memory cell."
    },
    {
      "index": 370,
      "start_time": 1586770.0,
      "end_time": 1591120.0,
      "text": "A memory needs simple concepts like where are you going to be reading and writing"
    },
    {
      "index": 371,
      "start_time": 1591120.0,
      "end_time": 1595260.0,
      "text": "and what are you going to be reading and writing."
    },
    {
      "index": 372,
      "start_time": 1595260.0,
      "end_time": 1599120.0,
      "text": "So, we can generalize these concepts to neural nets that you can join by back prop by saying"
    },
    {
      "index": 373,
      "start_time": 1599120.0,
      "end_time": 1605110.0,
      "text": "that at each time stamp, you basically have a different probability of choosing where to read"
    },
    {
      "index": 374,
      "start_time": 1605110.0,
      "end_time": 1608770.0,
      "text": "and where to write and then you&#39;re going to put something there"
    },
    {
      "index": 375,
      "start_time": 1608770.0,
      "end_time": 1610990.0,
      "text": "with some weight that&#39;s proportional for that probability."
    },
    {
      "index": 376,
      "start_time": 1611680.0,
      "end_time": 1617860.0,
      "text": "So, these kinds of systems, they started less than a year ago at about the same time"
    },
    {
      "index": 377,
      "start_time": 1617860.0,
      "end_time": 1625550.0,
      "text": "from a group in Facebook and a group at DeepMind using the same kind of attention mechanism"
    },
    {
      "index": 378,
      "start_time": 1625550.0,
      "end_time": 1627270.0,
      "text": "that we had proposed just a few months earlier."
    },
    {
      "index": 379,
      "start_time": 1628960.0,
      "end_time": 1635799.0,
      "text": "And so they&#39;re able to do things like this, like read sentences like this and answer questions."
    },
    {
      "index": 380,
      "start_time": 1635800.0,
      "end_time": 1638220.0,
      "text": "So, Joe went to the garden and Fred picked up the milk."
    },
    {
      "index": 381,
      "start_time": 1638220.0,
      "end_time": 1641930.0,
      "text": "Joe moved to the bathroom and Fred dropped the milk and then Dan moved to the living room."
    },
    {
      "index": 382,
      "start_time": 1642460.0,
      "end_time": 1642586.0,
      "text": "Where is Dan?"
    },
    {
      "index": 383,
      "start_time": 1643830.0,
      "end_time": 1645250.0,
      "text": "You&#39;re not supposed to read the answer."
    },
    {
      "index": 384,
      "start_time": 1646370.0,
      "end_time": 1656400.0,
      "text": "Or other things like -- I have other examples down there, like Sam walks into the kitchen."
    },
    {
      "index": 385,
      "start_time": 1656400.0,
      "end_time": 1657460.0,
      "text": "Sam picks up an apple."
    },
    {
      "index": 386,
      "start_time": 1657460.0,
      "end_time": 1658620.0,
      "text": "Sam walks to the bedroom."
    },
    {
      "index": 387,
      "start_time": 1658620.0,
      "end_time": 1659420.0,
      "text": "Sam drops the apple."
    },
    {
      "index": 388,
      "start_time": 1659420.0,
      "end_time": 1660289.0,
      "text": "Where is the apple."
    },
    {
      "index": 389,
      "start_time": 1660830.0,
      "end_time": 1663710.0,
      "text": "So, these are the kinds of things we&#39;re able to do now."
    },
    {
      "index": 390,
      "start_time": 1663710.0,
      "end_time": 1665554.0,
      "text": "Of course, these are toy problems."
    },
    {
      "index": 391,
      "start_time": 1665780.0,
      "end_time": 1672180.0,
      "text": "But it&#39;s not something we would imagine just a few years ago"
    },
    {
      "index": 392,
      "start_time": 1672180.0,
      "end_time": 1673360.0,
      "text": "that neural nets would be able to do."
    },
    {
      "index": 393,
      "start_time": 1673360.0,
      "end_time": 1679730.0,
      "text": "So, by using recurrence and by using new architectures that allow these recurrent nets"
    },
    {
      "index": 394,
      "start_time": 1679790.0,
      "end_time": 1682420.0,
      "text": "to keep information for a longer time,"
    },
    {
      "index": 395,
      "start_time": 1682930.0,
      "end_time": 1686570.0,
      "text": "so dealing with this challenge that&#39;s called long-term dependencies,"
    },
    {
      "index": 396,
      "start_time": 1687410.0,
      "end_time": 1692390.0,
      "text": "we&#39;re able to push the scope of applications"
    },
    {
      "index": 397,
      "start_time": 1692390.0,
      "end_time": 1699130.0,
      "text": "of deep learning well beyond what was thought possible just a few years ago."
    },
    {
      "index": 398,
      "start_time": 1699700.0,
      "end_time": 1705700.0,
      "text": "So, in my lab, we&#39;re working on using these ideas for knowledge extraction."
    },
    {
      "index": 399,
      "start_time": 1705700.0,
      "end_time": 1710769.0,
      "text": "So, the idea is to be able to read pages in Wikipedia and fill that memory"
    },
    {
      "index": 400,
      "start_time": 1710770.0,
      "end_time": 1715540.0,
      "text": "with representations, semantic representations for nuggets"
    },
    {
      "index": 401,
      "start_time": 1715540.0,
      "end_time": 1718960.0,
      "text": "of fact can be then used to answer questions."
    },
    {
      "index": 402,
      "start_time": 1718960.0,
      "end_time": 1722870.0,
      "text": "Of course, if we can do that, that would be extremely useful."
    },
    {
      "index": 403,
      "start_time": 1725270.0,
      "end_time": 1731464.0,
      "text": "Yes. I&#39;m going to skip that and just use a little bit of time for the last challenge,"
    },
    {
      "index": 404,
      "start_time": 1731430.0,
      "end_time": 1735259.0,
      "text": "which is maybe the most difficult one and has to do"
    },
    {
      "index": 405,
      "start_time": 1735260.0,
      "end_time": 1741390.0,
      "text": "with how computers could form these abstractions without being told ahead of time a lot"
    },
    {
      "index": 406,
      "start_time": 1741390.0,
      "end_time": 1743840.0,
      "text": "of the details of what they should be in the first place."
    },
    {
      "index": 407,
      "start_time": 1743840.0,
      "end_time": 1747680.0,
      "text": "So, that&#39;s what unsupervised learning is about."
    },
    {
      "index": 408,
      "start_time": 1749210.0,
      "end_time": 1754539.0,
      "text": "And I mentioned that unsupervised learning is important because we can take advantage of all"
    },
    {
      "index": 409,
      "start_time": 1754540.0,
      "end_time": 1757380.0,
      "text": "of the knowledge implicitly stored in lots and lots"
    },
    {
      "index": 410,
      "start_time": 1757380.0,
      "end_time": 1761400.0,
      "text": "of data hasn&#39;t been tagged and labeled by humans."
    },
    {
      "index": 411,
      "start_time": 1761850.0,
      "end_time": 1764840.0,
      "text": "But there are also reasons why it could be interesting"
    },
    {
      "index": 412,
      "start_time": 1764840.0,
      "end_time": 1769990.0,
      "text": "for other applications in machine learning."
    },
    {
      "index": 413,
      "start_time": 1769990.0,
      "end_time": 1774564.0,
      "text": "For example, in the case of structured outputs where you want the machine to produce something"
    },
    {
      "index": 414,
      "start_time": 1774560.0,
      "end_time": 1776696.0,
      "text": "that is not a yes or a no, or it&#39;s not a category,"
    },
    {
      "index": 415,
      "start_time": 1776980.0,
      "end_time": 1779290.0,
      "text": "but it&#39;s something more complicated, like an image."
    },
    {
      "index": 416,
      "start_time": 1779290.0,
      "end_time": 1783730.0,
      "text": "Maybe you want to transform an image or you want to produce a sentence like you&#39;ve seen before."
    },
    {
      "index": 417,
      "start_time": 1786320.0,
      "end_time": 1789480.0,
      "text": "It&#39;s also interesting because if you start thinking"
    },
    {
      "index": 418,
      "start_time": 1789480.0,
      "end_time": 1795264.0,
      "text": "about how machines could eventually reach the kind of level of performance of humans,"
    },
    {
      "index": 419,
      "start_time": 1795260.0,
      "end_time": 1801386.0,
      "text": "we have to admit that in terms of learning ability, we&#39;re very, very far from humans."
    },
    {
      "index": 420,
      "start_time": 1801850.0,
      "end_time": 1806664.0,
      "text": "Humans are able to learn from very few examples, new tasks."
    },
    {
      "index": 421,
      "start_time": 1806660.0,
      "end_time": 1810269.0,
      "text": "Right now, if you take a machine learning system out of the box, it&#39;s going to take --"
    },
    {
      "index": 422,
      "start_time": 1810270.0,
      "end_time": 1815560.0,
      "text": "it&#39;s going to need, depending on the task, maybe tens of thousands or hundreds of thousands"
    },
    {
      "index": 423,
      "start_time": 1815560.0,
      "end_time": 1817830.0,
      "text": "or millions of examples before you get a decent performance."
    },
    {
      "index": 424,
      "start_time": 1818240.0,
      "end_time": 1820200.0,
      "text": "Humans can learn a new task with just a handful"
    },
    {
      "index": 425,
      "start_time": 1820200.0,
      "end_time": 1822840.0,
      "text": "for sometimes even a single example or even zero examples."
    },
    {
      "index": 426,
      "start_time": 1823440.0,
      "end_time": 1824710.0,
      "text": "You don&#39;t even give them an example."
    },
    {
      "index": 427,
      "start_time": 1824710.0,
      "end_time": 1826829.0,
      "text": "You give them the linguistic description of the task, right."
    },
    {
      "index": 428,
      "start_time": 1827250.0,
      "end_time": 1833664.0,
      "text": "So, we&#39;re thinking, you know, what are plausible ways that we could address this,"
    },
    {
      "index": 429,
      "start_time": 1833480.0,
      "end_time": 1836730.0,
      "text": "and it all has to do with the notion of representation that&#39;s been central"
    },
    {
      "index": 430,
      "start_time": 1836730.0,
      "end_time": 1837880.0,
      "text": "to what I&#39;ve been telling you about."
    },
    {
      "index": 431,
      "start_time": 1838300.0,
      "end_time": 1842850.0,
      "text": "And now, we&#39;re thinking about how those representations become meaningful"
    },
    {
      "index": 432,
      "start_time": 1842850.0,
      "end_time": 1847440.0,
      "text": "as explanations for the data."
    },
    {
      "index": 433,
      "start_time": 1847670.0,
      "end_time": 1853254.0,
      "text": "In other words, what are the explanatory factors that explain the variations we see in the data."
    },
    {
      "index": 434,
      "start_time": 1853260.0,
      "end_time": 1855396.0,
      "text": "And that&#39;s what unsupervised learning is after."
    },
    {
      "index": 435,
      "start_time": 1855400.0,
      "end_time": 1860200.0,
      "text": "It&#39;s trying to discover representations where each element of the representation you can think"
    },
    {
      "index": 436,
      "start_time": 1860200.0,
      "end_time": 1864140.0,
      "text": "of as a factor or a cause that could explain the things we&#39;re seeing."
    },
    {
      "index": 437,
      "start_time": 1864500.0,
      "end_time": 1875230.0,
      "text": "So, in 2011, we participated in a couple of scientific challenges on transfer learning,"
    },
    {
      "index": 438,
      "start_time": 1875230.0,
      "end_time": 1881380.0,
      "text": "where the idea is you&#39;re seeing examples from some tasks."
    },
    {
      "index": 439,
      "start_time": 1881380.0,
      "end_time": 1882190.0,
      "text": "Maybe they&#39;re labeled."
    },
    {
      "index": 440,
      "start_time": 1882520.0,
      "end_time": 1889370.0,
      "text": "But the end goal is to actually use the representation that you&#39;ve learned"
    },
    {
      "index": 441,
      "start_time": 1890160.0,
      "end_time": 1893896.0,
      "text": "to do a good job on new tasks for which you have very few labeled examples."
    },
    {
      "index": 442,
      "start_time": 1894540.0,
      "end_time": 1898580.0,
      "text": "And basically, what we found is that when you use these unsupervised learning methods,"
    },
    {
      "index": 443,
      "start_time": 1899420.0,
      "end_time": 1903450.0,
      "text": "you&#39;re able to generalize much faster with very few labeled examples."
    },
    {
      "index": 444,
      "start_time": 1903450.0,
      "end_time": 1908779.0,
      "text": "So, all these curves have on the X axis the log of the number of labeled examples."
    },
    {
      "index": 445,
      "start_time": 1909240.0,
      "end_time": 1910880.0,
      "text": "And on the Y axis, accuracy."
    },
    {
      "index": 446,
      "start_time": 1911500.0,
      "end_time": 1919280.0,
      "text": "As you build deeper systems that learn actually in an unsupervised way from all the other tasks,"
    },
    {
      "index": 447,
      "start_time": 1919830.0,
      "end_time": 1925330.0,
      "text": "but just looking at the input distribution, you&#39;re able on the new tasks"
    },
    {
      "index": 448,
      "start_time": 1925550.0,
      "end_time": 1929710.0,
      "text": "to extract information from the very few examples you have much faster."
    },
    {
      "index": 449,
      "start_time": 1929710.0,
      "end_time": 1932440.0,
      "text": "Faster meaning you need less examples to get high accuracy."
    },
    {
      "index": 450,
      "start_time": 1932530.0,
      "end_time": 1934410.0,
      "text": "That&#39;s what these curves tell us."
    },
    {
      "index": 451,
      "start_time": 1936600.0,
      "end_time": 1942596.0,
      "text": "Now, there are really big challenges to why is it that unsupervised learning hasn&#39;t been"
    },
    {
      "index": 452,
      "start_time": 1942600.0,
      "end_time": 1944390.0,
      "text": "as successful as supervised learning."
    },
    {
      "index": 453,
      "start_time": 1944810.0,
      "end_time": 1950270.0,
      "text": "At least as we look at the current industrial applications of deep learning."
    },
    {
      "index": 454,
      "start_time": 1950270.0,
      "end_time": 1956650.0,
      "text": "I think it&#39;s because there are really hard fundamental challenges because you&#39;re trying"
    },
    {
      "index": 455,
      "start_time": 1956650.0,
      "end_time": 1958390.0,
      "text": "to model something that&#39;s much higher dimensional."
    },
    {
      "index": 456,
      "start_time": 1958740.0,
      "end_time": 1963664.0,
      "text": "When you&#39;re doing supervised learning, usually the output is a small object."
    },
    {
      "index": 457,
      "start_time": 1963660.0,
      "end_time": 1965960.0,
      "text": "It&#39;s in one category or something like that."
    },
    {
      "index": 458,
      "start_time": 1965960.0,
      "end_time": 1968646.0,
      "text": "In unsupervised learning, you&#39;re trying to characterize a number of configurations"
    },
    {
      "index": 459,
      "start_time": 1968650.0,
      "end_time": 1972200.0,
      "text": "of these variables that&#39;s exponentially large."
    },
    {
      "index": 460,
      "start_time": 1972540.0,
      "end_time": 1980664.0,
      "text": "And for a number of mathematical reasons, that makes the sort of more natural approaches based"
    },
    {
      "index": 461,
      "start_time": 1980660.0,
      "end_time": 1984360.0,
      "text": "on probabilities automatically intractable for reasons"
    },
    {
      "index": 462,
      "start_time": 1984360.0,
      "end_time": 1985916.0,
      "text": "that I won&#39;t have time to explain in detail."
    },
    {
      "index": 463,
      "start_time": 1986440.0,
      "end_time": 1991499.0,
      "text": "But there has been a lot of research recently to try"
    },
    {
      "index": 464,
      "start_time": 1991500.0,
      "end_time": 1994120.0,
      "text": "to bypass these limitations, these intractabilities."
    },
    {
      "index": 465,
      "start_time": 1994510.0,
      "end_time": 1999650.0,
      "text": "And what&#39;s amazing about the research currently in unsupervised learning is there&#39;s"
    },
    {
      "index": 466,
      "start_time": 1999650.0,
      "end_time": 2003739.0,
      "text": "like ten different ways of doing unsupervised learning."
    },
    {
      "index": 467,
      "start_time": 2003740.0,
      "end_time": 2004550.0,
      "text": "There&#39;s not one way."
    },
    {
      "index": 468,
      "start_time": 2004550.0,
      "end_time": 2009330.0,
      "text": "It&#39;s not like the supervised learning where we have basically back prop with small variations."
    },
    {
      "index": 469,
      "start_time": 2009330.0,
      "end_time": 2014780.0,
      "text": "Here we have totally different learning principles that go and try to bypass"
    },
    {
      "index": 470,
      "start_time": 2014780.0,
      "end_time": 2018730.0,
      "text": "in different ways the problems with [maximum light hue] and probabilistic modeling."
    },
    {
      "index": 471,
      "start_time": 2019310.0,
      "end_time": 2021320.0,
      "text": "So, it&#39;s moving pretty fast."
    },
    {
      "index": 472,
      "start_time": 2021320.0,
      "end_time": 2027240.0,
      "text": "Just a few years ago, we were not able to generate, for example, images of anything"
    },
    {
      "index": 473,
      "start_time": 2027240.0,
      "end_time": 2033500.0,
      "text": "but digits, images of digits, black and white."
    },
    {
      "index": 474,
      "start_time": 2033500.0,
      "end_time": 2037604.0,
      "text": "So, just last year we were able to move to sort of more realistic digits."
    },
    {
      "index": 475,
      "start_time": 2037600.0,
      "end_time": 2040176.0,
      "text": "These are images of street view house numbers that were generated"
    },
    {
      "index": 476,
      "start_time": 2040180.0,
      "end_time": 2041549.0,
      "text": "by some of these recent algorithms."
    },
    {
      "index": 477,
      "start_time": 2041890.0,
      "end_time": 2046380.0,
      "text": "And these are more natural images that were generated"
    },
    {
      "index": 478,
      "start_time": 2046380.0,
      "end_time": 2056109.0,
      "text": "by paper presented just a few months ago where the scientists who did this at Facebook"
    },
    {
      "index": 479,
      "start_time": 2056110.0000000002,
      "end_time": 2062510.0000000002,
      "text": "and NYU asked humans whether the images were natural or not."
    },
    {
      "index": 480,
      "start_time": 2062580.0,
      "end_time": 2066400.0,
      "text": "So, is this coming from the machine or is this coming from real world?"
    },
    {
      "index": 481,
      "start_time": 2066969.9999999998,
      "end_time": 2071949.9999999998,
      "text": "And it turned out that 40 percent of the images generated"
    },
    {
      "index": 482,
      "start_time": 2071949.9999999998,
      "end_time": 2074119.9999999998,
      "text": "by the computer were fooling the humans."
    },
    {
      "index": 483,
      "start_time": 2074120.0,
      "end_time": 2076400.0,
      "text": "So, you&#39;re kind of almost passing the train test here."
    },
    {
      "index": 484,
      "start_time": 2076830.0,
      "end_time": 2079509.0,
      "text": "Now, these are, you know, particular class of images."
    },
    {
      "index": 485,
      "start_time": 2079830.0,
      "end_time": 2084300.0,
      "text": "But still, that&#39;s, you know, there&#39;s a lot of progress and so it&#39;s very encouraging."
    },
    {
      "index": 486,
      "start_time": 2084900.0,
      "end_time": 2087690.0,
      "text": "One thing I&#39;m interested in, as a last bit here,"
    },
    {
      "index": 487,
      "start_time": 2087690.0,
      "end_time": 2090920.0,
      "text": "as we&#39;re exploring all these different approaches to unsupervised learning,"
    },
    {
      "index": 488,
      "start_time": 2091219.9999999998,
      "end_time": 2095938.9999999998,
      "text": "some of these look like they might also explain how brains do it and the thing"
    },
    {
      "index": 489,
      "start_time": 2095940.0,
      "end_time": 2102864.0,
      "text": "that is a very interesting source of inspiration for this research."
    },
    {
      "index": 490,
      "start_time": 2102620.0,
      "end_time": 2105680.0,
      "text": "All right."
    },
    {
      "index": 491,
      "start_time": 2106600.0,
      "end_time": 2110660.0,
      "text": "So, why is it interesting to do unsupervised learning?"
    },
    {
      "index": 492,
      "start_time": 2110660.0,
      "end_time": 2113515.0,
      "text": "As I mentioned, because it goes at the heart of what deep learning is about,"
    },
    {
      "index": 493,
      "start_time": 2113520.0,
      "end_time": 2120930.0,
      "text": "which is to allow the computer to discover good representations, more abstract representations."
    },
    {
      "index": 494,
      "start_time": 2121860.0,
      "end_time": 2124265.0,
      "text": "So, what it does mean to be more abstract?"
    },
    {
      "index": 495,
      "start_time": 2124270.0,
      "end_time": 2128690.0,
      "text": "It means that we essentially go to the heart of the explanations"
    },
    {
      "index": 496,
      "start_time": 2128690.0,
      "end_time": 2130320.0,
      "text": "of what&#39;s going on behind the data."
    },
    {
      "index": 497,
      "start_time": 2130720.0,
      "end_time": 2131950.0,
      "text": "Of course, that&#39;s the dream, right?"
    },
    {
      "index": 498,
      "start_time": 2132320.0,
      "end_time": 2133760.0,
      "text": "And we can measure that."
    },
    {
      "index": 499,
      "start_time": 2133760.0,
      "end_time": 2137790.0,
      "text": "We can do experiments where we can see that the computer automatically discovers"
    },
    {
      "index": 500,
      "start_time": 2138000.0,
      "end_time": 2144110.0,
      "text": "through in its [healing] units features that we haven&#39;t programmed explicitly in"
    },
    {
      "index": 501,
      "start_time": 2144380.0,
      "end_time": 2152860.0,
      "text": "but that are perfectly capturing some of the factors that are present as we know them."
    },
    {
      "index": 502,
      "start_time": 2153830.0,
      "end_time": 2159430.0,
      "text": "So, yes, I&#39;m going to close there and show you pictures of the current state"
    },
    {
      "index": 503,
      "start_time": 2159540.0,
      "end_time": 2163660.0,
      "text": "of my lab, which is growing too fast."
    },
    {
      "index": 504,
      "start_time": 2163660.0,
      "end_time": 2164604.0,
      "text": "Thank you."
    },
    {
      "index": 505,
      "start_time": 2165520.0,
      "end_time": 2168504.0,
      "text": "[ APPLAUSE ]"
    }
  ]
}