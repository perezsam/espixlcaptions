{
  "video_id": "tb-WdVA4_bo",
  "title": "What moral decisions should driverless cars make? | Iyad Rahwan",
  "es": 0,
  "json": [
    {
      "index": 1,
      "start_time": 12820.0,
      "end_time": 16900.0,
      "text": "Today I&#39;m going to talk about technology and society."
    },
    {
      "index": 2,
      "start_time": 18860.0,
      "end_time": 22556.0,
      "text": "The Department of Transport estimated that last year"
    },
    {
      "index": 3,
      "start_time": 22580.0,
      "end_time": 26659.0,
      "text": "35,000 people died from traffic crashes in the US alone."
    },
    {
      "index": 4,
      "start_time": 27860.0,
      "end_time": 32659.0,
      "text": "Worldwide, 1.2 million people die every year in traffic accidents."
    },
    {
      "index": 5,
      "start_time": 33580.0,
      "end_time": 37676.0,
      "text": "If there was a way we could eliminate 90 percent of those accidents,"
    },
    {
      "index": 6,
      "start_time": 37700.0,
      "end_time": 38900.0,
      "text": "would you support it?"
    },
    {
      "index": 7,
      "start_time": 39540.0,
      "end_time": 40836.0,
      "text": "Of course you would."
    },
    {
      "index": 8,
      "start_time": 40860.0,
      "end_time": 44515.0,
      "text": "This is what driverless car technology promises to achieve"
    },
    {
      "index": 9,
      "start_time": 44540.0,
      "end_time": 47356.0,
      "text": "by eliminating the main source of accidents --"
    },
    {
      "index": 10,
      "start_time": 47380.0,
      "end_time": 48580.0,
      "text": "human error."
    },
    {
      "index": 11,
      "start_time": 49740.0,
      "end_time": 55156.0,
      "text": "Now picture yourself in a driverless car in the year 2030,"
    },
    {
      "index": 12,
      "start_time": 55180.0,
      "end_time": 58636.0,
      "text": "sitting back and watching this vintage TEDxCambridge video."
    },
    {
      "index": 13,
      "start_time": 58660.0,
      "end_time": 60660.0,
      "text": "(Laughter)"
    },
    {
      "index": 14,
      "start_time": 61340.0,
      "end_time": 62556.0,
      "text": "All of a sudden,"
    },
    {
      "index": 15,
      "start_time": 62580.0,
      "end_time": 65860.0,
      "text": "the car experiences mechanical failure and is unable to stop."
    },
    {
      "index": 16,
      "start_time": 67180.0,
      "end_time": 68700.0,
      "text": "If the car continues,"
    },
    {
      "index": 17,
      "start_time": 69540.0,
      "end_time": 73660.0,
      "text": "it will crash into a bunch of pedestrians crossing the street,"
    },
    {
      "index": 18,
      "start_time": 74900.0,
      "end_time": 77350.0,
      "text": "but the car may swerve,"
    },
    {
      "index": 19,
      "start_time": 77590.0,
      "end_time": 78916.0,
      "text": "hitting one bystander,"
    },
    {
      "index": 20,
      "start_time": 78940.0,
      "end_time": 81200.0,
      "text": "killing them to save the pedestrians."
    },
    {
      "index": 21,
      "start_time": 81860.0,
      "end_time": 84460.0,
      "text": "What should the car do, and who should decide?"
    },
    {
      "index": 22,
      "start_time": 85340.0,
      "end_time": 88876.0,
      "text": "What if instead the car could swerve into a wall,"
    },
    {
      "index": 23,
      "start_time": 88900.0,
      "end_time": 92196.0,
      "text": "crashing and killing you, the passenger,"
    },
    {
      "index": 24,
      "start_time": 92220.0,
      "end_time": 94539.0,
      "text": "in order to save those pedestrians?"
    },
    {
      "index": 25,
      "start_time": 95600.0,
      "end_time": 98140.0,
      "text": "This scenario is inspired by the trolley problem,"
    },
    {
      "index": 26,
      "start_time": 98780.0,
      "end_time": 102556.0,
      "text": "which was invented by philosophers a few decades ago"
    },
    {
      "index": 27,
      "start_time": 102580.0,
      "end_time": 103820.0,
      "text": "to think about ethics."
    },
    {
      "index": 28,
      "start_time": 105940.0,
      "end_time": 108436.0,
      "text": "Now, the way we think about this problem matters."
    },
    {
      "index": 29,
      "start_time": 108460.0,
      "end_time": 111760.0,
      "text": "We may for example not think about it at all."
    },
    {
      "index": 30,
      "start_time": 111100.0,
      "end_time": 114476.0,
      "text": "We may say this scenario is unrealistic,"
    },
    {
      "index": 31,
      "start_time": 114500.0,
      "end_time": 116820.0,
      "text": "incredibly unlikely, or just silly."
    },
    {
      "index": 32,
      "start_time": 117580.0,
      "end_time": 120316.0,
      "text": "But I think this criticism misses the point"
    },
    {
      "index": 33,
      "start_time": 120340.0,
      "end_time": 122500.0,
      "text": "because it takes the scenario too literally."
    },
    {
      "index": 34,
      "start_time": 123740.0,
      "end_time": 126476.0,
      "text": "Of course no accident is going to look like this;"
    },
    {
      "index": 35,
      "start_time": 126500.0,
      "end_time": 129836.0,
      "text": "no accident has two or three options"
    },
    {
      "index": 36,
      "start_time": 129860.00000000001,
      "end_time": 131860.0,
      "text": "where everybody dies somehow."
    },
    {
      "index": 37,
      "start_time": 133300.0,
      "end_time": 135876.0,
      "text": "Instead, the car is going to calculate something"
    },
    {
      "index": 38,
      "start_time": 135900.0,
      "end_time": 140796.0,
      "text": "like the probability of hitting a certain group of people,"
    },
    {
      "index": 39,
      "start_time": 140820.0,
      "end_time": 144156.0,
      "text": "if you swerve one direction versus another direction,"
    },
    {
      "index": 40,
      "start_time": 144180.0,
      "end_time": 147636.0,
      "text": "you might slightly increase the risk to passengers or other drivers"
    },
    {
      "index": 41,
      "start_time": 147660.0,
      "end_time": 149196.0,
      "text": "versus pedestrians."
    },
    {
      "index": 42,
      "start_time": 149220.0,
      "end_time": 151380.0,
      "text": "It&#39;s going to be a more complex calculation,"
    },
    {
      "index": 43,
      "start_time": 152300.0,
      "end_time": 154820.0,
      "text": "but it&#39;s still going to involve trade-offs,"
    },
    {
      "index": 44,
      "start_time": 155660.0,
      "end_time": 158540.0,
      "text": "and trade-offs often require ethics."
    },
    {
      "index": 45,
      "start_time": 159660.0,
      "end_time": 162396.0,
      "text": "We might say then, \"Well, let&#39;s not worry about this."
    },
    {
      "index": 46,
      "start_time": 162420.0,
      "end_time": 167590.0,
      "text": "Let&#39;s wait until technology is fully ready and 100 percent safe.\""
    },
    {
      "index": 47,
      "start_time": 168340.0,
      "end_time": 172200.0,
      "text": "Suppose that we can indeed eliminate 90 percent of those accidents,"
    },
    {
      "index": 48,
      "start_time": 172900.0,
      "end_time": 175740.0,
      "text": "or even 99 percent in the next 10 years."
    },
    {
      "index": 49,
      "start_time": 176740.0,
      "end_time": 179916.0,
      "text": "What if eliminating the last one percent of accidents"
    },
    {
      "index": 50,
      "start_time": 179940.0,
      "end_time": 183600.0,
      "text": "requires 50 more years of research?"
    },
    {
      "index": 51,
      "start_time": 184220.0,
      "end_time": 186200.0,
      "text": "Should we not adopt the technology?"
    },
    {
      "index": 52,
      "start_time": 186540.0,
      "end_time": 191316.0,
      "text": "That&#39;s 60 million people dead in car accidents"
    },
    {
      "index": 53,
      "start_time": 191340.0,
      "end_time": 193100.0,
      "text": "if we maintain the current rate."
    },
    {
      "index": 54,
      "start_time": 194580.0,
      "end_time": 195796.0,
      "text": "So the point is,"
    },
    {
      "index": 55,
      "start_time": 195820.0,
      "end_time": 199436.0,
      "text": "waiting for full safety is also a choice,"
    },
    {
      "index": 56,
      "start_time": 199460.0,
      "end_time": 201620.0,
      "text": "and it also involves trade-offs."
    },
    {
      "index": 57,
      "start_time": 203380.0,
      "end_time": 207716.0,
      "text": "People online on social media have been coming up with all sorts of ways"
    },
    {
      "index": 58,
      "start_time": 207740.0,
      "end_time": 209756.0,
      "text": "to not think about this problem."
    },
    {
      "index": 59,
      "start_time": 209780.0,
      "end_time": 212996.0,
      "text": "One person suggested the car should just swerve somehow"
    },
    {
      "index": 60,
      "start_time": 213200.0,
      "end_time": 215156.0,
      "text": "in between the passengers --"
    },
    {
      "index": 61,
      "start_time": 215180.0,
      "end_time": 216196.0,
      "text": "(Laughter)"
    },
    {
      "index": 62,
      "start_time": 216220.0,
      "end_time": 217476.0,
      "text": "and the bystander."
    },
    {
      "index": 63,
      "start_time": 217500.0,
      "end_time": 220860.0,
      "text": "Of course if that&#39;s what the car can do, that&#39;s what the car should do."
    },
    {
      "index": 64,
      "start_time": 221740.0,
      "end_time": 224580.0,
      "text": "We&#39;re interested in scenarios in which this is not possible."
    },
    {
      "index": 65,
      "start_time": 225100.0,
      "end_time": 230516.0,
      "text": "And my personal favorite was a suggestion by a blogger"
    },
    {
      "index": 66,
      "start_time": 230540.0,
      "end_time": 233555.0,
      "text": "to have an eject button in the car that you press --"
    },
    {
      "index": 67,
      "start_time": 233580.0,
      "end_time": 234796.0,
      "text": "(Laughter)"
    },
    {
      "index": 68,
      "start_time": 234820.0,
      "end_time": 236487.0,
      "text": "just before the car self-destructs."
    },
    {
      "index": 69,
      "start_time": 236511.0,
      "end_time": 238191.0,
      "text": "(Laughter)"
    },
    {
      "index": 70,
      "start_time": 239660.0,
      "end_time": 244859.0,
      "text": "So if we acknowledge that cars will have to make trade-offs on the road,"
    },
    {
      "index": 71,
      "start_time": 246200.0,
      "end_time": 247900.0,
      "text": "how do we think about those trade-offs,"
    },
    {
      "index": 72,
      "start_time": 249140.0,
      "end_time": 250715.0,
      "text": "and how do we decide?"
    },
    {
      "index": 73,
      "start_time": 250740.0,
      "end_time": 253876.0,
      "text": "Well, maybe we should run a survey to find out what society wants,"
    },
    {
      "index": 74,
      "start_time": 253900.0,
      "end_time": 255356.0,
      "text": "because ultimately,"
    },
    {
      "index": 75,
      "start_time": 255380.0,
      "end_time": 259339.0,
      "text": "regulations and the law are a reflection of societal values."
    },
    {
      "index": 76,
      "start_time": 259860.0,
      "end_time": 261100.0,
      "text": "So this is what we did."
    },
    {
      "index": 77,
      "start_time": 261700.0,
      "end_time": 263316.0,
      "text": "With my collaborators,"
    },
    {
      "index": 78,
      "start_time": 263340.0,
      "end_time": 265676.0,
      "text": "Jean-François Bonnefon and Azim Shariff,"
    },
    {
      "index": 79,
      "start_time": 265700.0,
      "end_time": 267316.0,
      "text": "we ran a survey"
    },
    {
      "index": 80,
      "start_time": 267340.0,
      "end_time": 270195.0,
      "text": "in which we presented people with these types of scenarios."
    },
    {
      "index": 81,
      "start_time": 270219.0,
      "end_time": 273996.0,
      "text": "We gave them two options inspired by two philosophers:"
    },
    {
      "index": 82,
      "start_time": 274200.0,
      "end_time": 276659.0,
      "text": "Jeremy Bentham and Immanuel Kant."
    },
    {
      "index": 83,
      "start_time": 277420.0,
      "end_time": 280516.0,
      "text": "Bentham says the car should follow utilitarian ethics:"
    },
    {
      "index": 84,
      "start_time": 280540.0,
      "end_time": 283956.0,
      "text": "it should take the action that will minimize total harm --"
    },
    {
      "index": 85,
      "start_time": 283980.0,
      "end_time": 286796.0,
      "text": "even if that action will kill a bystander"
    },
    {
      "index": 86,
      "start_time": 286820.0,
      "end_time": 289260.0,
      "text": "and even if that action will kill the passenger."
    },
    {
      "index": 87,
      "start_time": 289940.0,
      "end_time": 294916.0,
      "text": "Immanuel Kant says the car should follow duty-bound principles,"
    },
    {
      "index": 88,
      "start_time": 294940.0,
      "end_time": 296500.0,
      "text": "like \"Thou shalt not kill.\""
    },
    {
      "index": 89,
      "start_time": 297300.0,
      "end_time": 301756.0,
      "text": "So you should not take an action that explicitly harms a human being,"
    },
    {
      "index": 90,
      "start_time": 301780.0,
      "end_time": 304236.0,
      "text": "and you should let the car take its course"
    },
    {
      "index": 91,
      "start_time": 304260.0,
      "end_time": 306219.0,
      "text": "even if that&#39;s going to harm more people."
    },
    {
      "index": 92,
      "start_time": 307460.0,
      "end_time": 308659.0,
      "text": "What do you think?"
    },
    {
      "index": 93,
      "start_time": 309180.0,
      "end_time": 310700.0,
      "text": "Bentham or Kant?"
    },
    {
      "index": 94,
      "start_time": 311580.0,
      "end_time": 312835.0,
      "text": "Here&#39;s what we found."
    },
    {
      "index": 95,
      "start_time": 312860.0,
      "end_time": 314660.0,
      "text": "Most people sided with Bentham."
    },
    {
      "index": 96,
      "start_time": 315980.0,
      "end_time": 319756.0,
      "text": "So it seems that people want cars to be utilitarian,"
    },
    {
      "index": 97,
      "start_time": 319780.0,
      "end_time": 321195.0,
      "text": "minimize total harm,"
    },
    {
      "index": 98,
      "start_time": 321220.0,
      "end_time": 322796.0,
      "text": "and that&#39;s what we should all do."
    },
    {
      "index": 99,
      "start_time": 322820.0,
      "end_time": 324200.0,
      "text": "Problem solved."
    },
    {
      "index": 100,
      "start_time": 325600.0,
      "end_time": 326540.0,
      "text": "But there is a little catch."
    },
    {
      "index": 101,
      "start_time": 327740.0,
      "end_time": 331476.0,
      "text": "When we asked people whether they would purchase such cars,"
    },
    {
      "index": 102,
      "start_time": 331500.0,
      "end_time": 333116.0,
      "text": "they said, \"Absolutely not.\""
    },
    {
      "index": 103,
      "start_time": 333140.0,
      "end_time": 335436.0,
      "text": "(Laughter)"
    },
    {
      "index": 104,
      "start_time": 335460.0,
      "end_time": 339356.0,
      "text": "They would like to buy cars that protect them at all costs,"
    },
    {
      "index": 105,
      "start_time": 339380.0,
      "end_time": 342996.0,
      "text": "but they want everybody else to buy cars that minimize harm."
    },
    {
      "index": 106,
      "start_time": 343200.0,
      "end_time": 345539.0,
      "text": "(Laughter)"
    },
    {
      "index": 107,
      "start_time": 346540.0,
      "end_time": 348396.0,
      "text": "We&#39;ve seen this problem before."
    },
    {
      "index": 108,
      "start_time": 348420.0,
      "end_time": 349980.0,
      "text": "It&#39;s called a social dilemma."
    },
    {
      "index": 109,
      "start_time": 350980.0,
      "end_time": 352796.0,
      "text": "And to understand the social dilemma,"
    },
    {
      "index": 110,
      "start_time": 352820.0,
      "end_time": 354860.0,
      "text": "we have to go a little bit back in history."
    },
    {
      "index": 111,
      "start_time": 355820.0,
      "end_time": 358396.0,
      "text": "In the 1800s,"
    },
    {
      "index": 112,
      "start_time": 358420.0,
      "end_time": 362156.0,
      "text": "English economist William Forster Lloyd published a pamphlet"
    },
    {
      "index": 113,
      "start_time": 362180.0,
      "end_time": 364396.0,
      "text": "which describes the following scenario."
    },
    {
      "index": 114,
      "start_time": 364420.0,
      "end_time": 366760.0,
      "text": "You have a group of farmers --"
    },
    {
      "index": 115,
      "start_time": 366100.0,
      "end_time": 367436.0,
      "text": "English farmers --"
    },
    {
      "index": 116,
      "start_time": 367460.0,
      "end_time": 370140.0,
      "text": "who are sharing a common land for their sheep to graze."
    },
    {
      "index": 117,
      "start_time": 371340.0,
      "end_time": 373916.0,
      "text": "Now, if each farmer brings a certain number of sheep --"
    },
    {
      "index": 118,
      "start_time": 373940.0,
      "end_time": 375436.0,
      "text": "let&#39;s say three sheep --"
    },
    {
      "index": 119,
      "start_time": 375460.0,
      "end_time": 377556.0,
      "text": "the land will be rejuvenated,"
    },
    {
      "index": 120,
      "start_time": 377580.0,
      "end_time": 378796.0,
      "text": "the farmers are happy,"
    },
    {
      "index": 121,
      "start_time": 378820.0,
      "end_time": 380436.0,
      "text": "the sheep are happy,"
    },
    {
      "index": 122,
      "start_time": 380460.0,
      "end_time": 381659.0,
      "text": "everything is good."
    },
    {
      "index": 123,
      "start_time": 382260.0,
      "end_time": 384780.0,
      "text": "Now, if one farmer brings one extra sheep,"
    },
    {
      "index": 124,
      "start_time": 385620.0,
      "end_time": 390340.0,
      "text": "that farmer will do slightly better, and no one else will be harmed."
    },
    {
      "index": 125,
      "start_time": 390980.0,
      "end_time": 394620.0,
      "text": "But if every farmer made that individually rational decision,"
    },
    {
      "index": 126,
      "start_time": 395660.0,
      "end_time": 398380.0,
      "text": "the land will be overrun, and it will be depleted"
    },
    {
      "index": 127,
      "start_time": 399180.0,
      "end_time": 401356.0,
      "text": "to the detriment of all the farmers,"
    },
    {
      "index": 128,
      "start_time": 401380.0,
      "end_time": 403500.0,
      "text": "and of course, to the detriment of the sheep."
    },
    {
      "index": 129,
      "start_time": 404540.0,
      "end_time": 408220.0,
      "text": "We see this problem in many places:"
    },
    {
      "index": 130,
      "start_time": 408900.0,
      "end_time": 412750.0,
      "text": "in the difficulty of managing overfishing,"
    },
    {
      "index": 131,
      "start_time": 412100.0,
      "end_time": 416660.0,
      "text": "or in reducing carbon emissions to mitigate climate change."
    },
    {
      "index": 132,
      "start_time": 418980.0,
      "end_time": 421900.0,
      "text": "When it comes to the regulation of driverless cars,"
    },
    {
      "index": 133,
      "start_time": 422900.0,
      "end_time": 427236.0,
      "text": "the common land now is basically public safety --"
    },
    {
      "index": 134,
      "start_time": 427260.0,
      "end_time": 428500.0,
      "text": "that&#39;s the common good --"
    },
    {
      "index": 135,
      "start_time": 429220.0,
      "end_time": 431196.0,
      "text": "and the farmers are the passengers"
    },
    {
      "index": 136,
      "start_time": 431220.0,
      "end_time": 434820.0,
      "text": "or the car owners who are choosing to ride in those cars."
    },
    {
      "index": 137,
      "start_time": 436780.0,
      "end_time": 439395.0,
      "text": "And by making the individually rational choice"
    },
    {
      "index": 138,
      "start_time": 439420.0,
      "end_time": 442236.0,
      "text": "of prioritizing their own safety,"
    },
    {
      "index": 139,
      "start_time": 442260.0,
      "end_time": 445396.0,
      "text": "they may collectively be diminishing the common good,"
    },
    {
      "index": 140,
      "start_time": 445420.0,
      "end_time": 447620.0,
      "text": "which is minimizing total harm."
    },
    {
      "index": 141,
      "start_time": 450140.0,
      "end_time": 452276.0,
      "text": "It&#39;s called the tragedy of the commons,"
    },
    {
      "index": 142,
      "start_time": 452300.0,
      "end_time": 453596.0,
      "text": "traditionally,"
    },
    {
      "index": 143,
      "start_time": 453620.0,
      "end_time": 456716.0,
      "text": "but I think in the case of driverless cars,"
    },
    {
      "index": 144,
      "start_time": 456740.0,
      "end_time": 459596.0,
      "text": "the problem may be a little bit more insidious"
    },
    {
      "index": 145,
      "start_time": 459620.0,
      "end_time": 463116.0,
      "text": "because there is not necessarily an individual human being"
    },
    {
      "index": 146,
      "start_time": 463140.0,
      "end_time": 464836.0,
      "text": "making those decisions."
    },
    {
      "index": 147,
      "start_time": 464860.0,
      "end_time": 468156.0,
      "text": "So car manufacturers may simply program cars"
    },
    {
      "index": 148,
      "start_time": 468180.0,
      "end_time": 470700.0,
      "text": "that will maximize safety for their clients,"
    },
    {
      "index": 149,
      "start_time": 471900.0,
      "end_time": 474876.0,
      "text": "and those cars may learn automatically on their own"
    },
    {
      "index": 150,
      "start_time": 474900.0,
      "end_time": 478419.0,
      "text": "that doing so requires slightly increasing risk for pedestrians."
    },
    {
      "index": 151,
      "start_time": 479340.0,
      "end_time": 480756.0,
      "text": "So to use the sheep metaphor,"
    },
    {
      "index": 152,
      "start_time": 480780.0,
      "end_time": 484395.0,
      "text": "it&#39;s like we now have electric sheep that have a mind of their own."
    },
    {
      "index": 153,
      "start_time": 484420.0,
      "end_time": 485876.0,
      "text": "(Laughter)"
    },
    {
      "index": 154,
      "start_time": 485900.0,
      "end_time": 488979.0,
      "text": "And they may go and graze even if the farmer doesn&#39;t know it."
    },
    {
      "index": 155,
      "start_time": 490460.0,
      "end_time": 494436.0,
      "text": "So this is what we may call the tragedy of the algorithmic commons,"
    },
    {
      "index": 156,
      "start_time": 494460.0,
      "end_time": 496820.0,
      "text": "and if offers new types of challenges."
    },
    {
      "index": 157,
      "start_time": 502340.0,
      "end_time": 504236.0,
      "text": "Typically, traditionally,"
    },
    {
      "index": 158,
      "start_time": 504260.0,
      "end_time": 507596.0,
      "text": "we solve these types of social dilemmas using regulation,"
    },
    {
      "index": 159,
      "start_time": 507620.0,
      "end_time": 510356.0,
      "text": "so either governments or communities get together,"
    },
    {
      "index": 160,
      "start_time": 510380.0,
      "end_time": 514116.0,
      "text": "and they decide collectively what kind of outcome they want"
    },
    {
      "index": 161,
      "start_time": 514140.0,
      "end_time": 516795.0,
      "text": "and what sort of constraints on individual behavior"
    },
    {
      "index": 162,
      "start_time": 516820.00000000006,
      "end_time": 518200.00000000006,
      "text": "they need to implement."
    },
    {
      "index": 163,
      "start_time": 519419.0,
      "end_time": 522350.0,
      "text": "And then using monitoring and enforcement,"
    },
    {
      "index": 164,
      "start_time": 522590.00000000006,
      "end_time": 524618.0,
      "text": "they can make sure that the public good is preserved."
    },
    {
      "index": 165,
      "start_time": 525260.0,
      "end_time": 526835.0,
      "text": "So why don&#39;t we just,"
    },
    {
      "index": 166,
      "start_time": 526859.0,
      "end_time": 528355.0,
      "text": "as regulators,"
    },
    {
      "index": 167,
      "start_time": 528379.0,
      "end_time": 531276.0,
      "text": "require that all cars minimize harm?"
    },
    {
      "index": 168,
      "start_time": 531300.0,
      "end_time": 533540.0,
      "text": "After all, this is what people say they want."
    },
    {
      "index": 169,
      "start_time": 535200.0,
      "end_time": 536436.0,
      "text": "And more importantly,"
    },
    {
      "index": 170,
      "start_time": 536460.0,
      "end_time": 539556.0,
      "text": "I can be sure that as an individual,"
    },
    {
      "index": 171,
      "start_time": 539580.0,
      "end_time": 543436.0,
      "text": "if I buy a car that may sacrifice me in a very rare case,"
    },
    {
      "index": 172,
      "start_time": 543460.0,
      "end_time": 545116.0,
      "text": "I&#39;m not the only sucker doing that"
    },
    {
      "index": 173,
      "start_time": 545140.0,
      "end_time": 547819.0,
      "text": "while everybody else enjoys unconditional protection."
    },
    {
      "index": 174,
      "start_time": 548940.0,
      "end_time": 552276.0,
      "text": "In our survey, we did ask people whether they would support regulation"
    },
    {
      "index": 175,
      "start_time": 552300.0,
      "end_time": 553500.0,
      "text": "and here&#39;s what we found."
    },
    {
      "index": 176,
      "start_time": 554180.0,
      "end_time": 557939.0,
      "text": "First of all, people said no to regulation;"
    },
    {
      "index": 177,
      "start_time": 559100.0,
      "end_time": 560356.0,
      "text": "and second, they said,"
    },
    {
      "index": 178,
      "start_time": 560380.0,
      "end_time": 564316.0,
      "text": "\"Well if you regulate cars to do this and to minimize total harm,"
    },
    {
      "index": 179,
      "start_time": 564340.0,
      "end_time": 565820.0,
      "text": "I will not buy those cars.\""
    },
    {
      "index": 180,
      "start_time": 567220.0,
      "end_time": 568596.0,
      "text": "So ironically,"
    },
    {
      "index": 181,
      "start_time": 568620.0,
      "end_time": 572116.0,
      "text": "by regulating cars to minimize harm,"
    },
    {
      "index": 182,
      "start_time": 572140.0,
      "end_time": 573980.0,
      "text": "we may actually end up with more harm"
    },
    {
      "index": 183,
      "start_time": 574860.0,
      "end_time": 578516.0,
      "text": "because people may not opt into the safer technology"
    },
    {
      "index": 184,
      "start_time": 578540.0,
      "end_time": 580620.0,
      "text": "even if it&#39;s much safer than human drivers."
    },
    {
      "index": 185,
      "start_time": 582180.0,
      "end_time": 585596.0,
      "text": "I don&#39;t have the final answer to this riddle,"
    },
    {
      "index": 186,
      "start_time": 585620.0,
      "end_time": 587196.0,
      "text": "but I think as a starting point,"
    },
    {
      "index": 187,
      "start_time": 587220.0,
      "end_time": 590516.0,
      "text": "we need society to come together"
    },
    {
      "index": 188,
      "start_time": 590540.0,
      "end_time": 593300.0,
      "text": "to decide what trade-offs we are comfortable with"
    },
    {
      "index": 189,
      "start_time": 594180.0,
      "end_time": 597660.0,
      "text": "and to come up with ways in which we can enforce those trade-offs."
    },
    {
      "index": 190,
      "start_time": 598340.0,
      "end_time": 600876.0,
      "text": "As a starting point, my brilliant students,"
    },
    {
      "index": 191,
      "start_time": 600900.0,
      "end_time": 603356.0,
      "text": "Edmond Awad and Sohan Dsouza,"
    },
    {
      "index": 192,
      "start_time": 603380.0,
      "end_time": 605180.0,
      "text": "built the Moral Machine website,"
    },
    {
      "index": 193,
      "start_time": 606200.0,
      "end_time": 608699.0,
      "text": "which generates random scenarios at you --"
    },
    {
      "index": 194,
      "start_time": 609900.0,
      "end_time": 612356.0,
      "text": "basically a bunch of random dilemmas in a sequence"
    },
    {
      "index": 195,
      "start_time": 612380.0,
      "end_time": 616300.0,
      "text": "where you have to choose what the car should do in a given scenario."
    },
    {
      "index": 196,
      "start_time": 616860.0,
      "end_time": 621460.0,
      "text": "And we vary the ages and even the species of the different victims."
    },
    {
      "index": 197,
      "start_time": 622860.0,
      "end_time": 626556.0,
      "text": "So far we&#39;ve collected over five million decisions"
    },
    {
      "index": 198,
      "start_time": 626580.0,
      "end_time": 628780.0,
      "text": "by over one million people worldwide"
    },
    {
      "index": 199,
      "start_time": 630220.0,
      "end_time": 631420.0,
      "text": "from the website."
    },
    {
      "index": 200,
      "start_time": 632180.0,
      "end_time": 634596.0,
      "text": "And this is helping us form an early picture"
    },
    {
      "index": 201,
      "start_time": 634620.0,
      "end_time": 637236.0,
      "text": "of what trade-offs people are comfortable with"
    },
    {
      "index": 202,
      "start_time": 637260.0,
      "end_time": 639156.0,
      "text": "and what matters to them --"
    },
    {
      "index": 203,
      "start_time": 639180.0,
      "end_time": 640620.0,
      "text": "even across cultures."
    },
    {
      "index": 204,
      "start_time": 642600.0,
      "end_time": 643555.0,
      "text": "But more importantly,"
    },
    {
      "index": 205,
      "start_time": 643580.0,
      "end_time": 646956.0,
      "text": "doing this exercise is helping people recognize"
    },
    {
      "index": 206,
      "start_time": 646980.0,
      "end_time": 649796.0,
      "text": "the difficulty of making those choices"
    },
    {
      "index": 207,
      "start_time": 649820.0,
      "end_time": 653620.0,
      "text": "and that the regulators are tasked with impossible choices."
    },
    {
      "index": 208,
      "start_time": 655180.0,
      "end_time": 658756.0,
      "text": "And maybe this will help us as a society understand the kinds of trade-offs"
    },
    {
      "index": 209,
      "start_time": 658780.0,
      "end_time": 661836.0,
      "text": "that will be implemented ultimately in regulation."
    },
    {
      "index": 210,
      "start_time": 661860.0,
      "end_time": 663596.0,
      "text": "And indeed, I was very happy to hear"
    },
    {
      "index": 211,
      "start_time": 663620.0,
      "end_time": 665636.0,
      "text": "that the first set of regulations"
    },
    {
      "index": 212,
      "start_time": 665660.0,
      "end_time": 667795.0,
      "text": "that came from the Department of Transport --"
    },
    {
      "index": 213,
      "start_time": 667820.0,
      "end_time": 669196.0,
      "text": "announced last week --"
    },
    {
      "index": 214,
      "start_time": 669220.0,
      "end_time": 675796.0,
      "text": "included a 15-point checklist for all carmakers to provide,"
    },
    {
      "index": 215,
      "start_time": 675820.0,
      "end_time": 679760.0,
      "text": "and number 14 was ethical consideration --"
    },
    {
      "index": 216,
      "start_time": 679100.0,
      "end_time": 680820.0,
      "text": "how are you going to deal with that."
    },
    {
      "index": 217,
      "start_time": 683620.0,
      "end_time": 686276.0,
      "text": "We also have people reflect on their own decisions"
    },
    {
      "index": 218,
      "start_time": 686300.0,
      "end_time": 689300.0,
      "text": "by giving them summaries of what they chose."
    },
    {
      "index": 219,
      "start_time": 690260.0,
      "end_time": 691915.0,
      "text": "I&#39;ll give you one example --"
    },
    {
      "index": 220,
      "start_time": 691940.0,
      "end_time": 695476.0,
      "text": "I&#39;m just going to warn you that this is not your typical example,"
    },
    {
      "index": 221,
      "start_time": 695500.0,
      "end_time": 696876.0,
      "text": "your typical user."
    },
    {
      "index": 222,
      "start_time": 696900.0,
      "end_time": 700516.0,
      "text": "This is the most sacrificed and the most saved character for this person."
    },
    {
      "index": 223,
      "start_time": 700540.0,
      "end_time": 705740.0,
      "text": "(Laughter)"
    },
    {
      "index": 224,
      "start_time": 706500.0,
      "end_time": 708396.0,
      "text": "Some of you may agree with him,"
    },
    {
      "index": 225,
      "start_time": 708420.0,
      "end_time": 710600.0,
      "text": "or her, we don&#39;t know."
    },
    {
      "index": 226,
      "start_time": 712300.0,
      "end_time": 718435.0,
      "text": "But this person also seems to slightly prefer passengers over pedestrians"
    },
    {
      "index": 227,
      "start_time": 718460.0,
      "end_time": 720556.0,
      "text": "in their choices"
    },
    {
      "index": 228,
      "start_time": 720580.0,
      "end_time": 723396.0,
      "text": "and is very happy to punish jaywalking."
    },
    {
      "index": 229,
      "start_time": 723420.0,
      "end_time": 726459.0,
      "text": "(Laughter)"
    },
    {
      "index": 230,
      "start_time": 729140.0,
      "end_time": 730356.0,
      "text": "So let&#39;s wrap up."
    },
    {
      "index": 231,
      "start_time": 730379.0,
      "end_time": 733795.0,
      "text": "We started with the question -- let&#39;s call it the ethical dilemma --"
    },
    {
      "index": 232,
      "start_time": 733820.0,
      "end_time": 736876.0,
      "text": "of what the car should do in a specific scenario:"
    },
    {
      "index": 233,
      "start_time": 736900.0,
      "end_time": 738100.0,
      "text": "swerve or stay?"
    },
    {
      "index": 234,
      "start_time": 739600.0,
      "end_time": 741795.0,
      "text": "But then we realized that the problem was a different one."
    },
    {
      "index": 235,
      "start_time": 741820.0,
      "end_time": 746356.0,
      "text": "It was the problem of how to get society to agree on and enforce"
    },
    {
      "index": 236,
      "start_time": 746380.0,
      "end_time": 748316.0,
      "text": "the trade-offs they&#39;re comfortable with."
    },
    {
      "index": 237,
      "start_time": 748340.0,
      "end_time": 749596.0,
      "text": "It&#39;s a social dilemma."
    },
    {
      "index": 238,
      "start_time": 749620.0,
      "end_time": 754636.0,
      "text": "In the 1940s, Isaac Asimov wrote his famous laws of robotics --"
    },
    {
      "index": 239,
      "start_time": 754660.0,
      "end_time": 755980.0,
      "text": "the three laws of robotics."
    },
    {
      "index": 240,
      "start_time": 757600.0,
      "end_time": 759516.0,
      "text": "A robot may not harm a human being,"
    },
    {
      "index": 241,
      "start_time": 759540.0,
      "end_time": 762750.0,
      "text": "a robot may not disobey a human being,"
    },
    {
      "index": 242,
      "start_time": 762100.0,
      "end_time": 765356.0,
      "text": "and a robot may not allow itself to come to harm --"
    },
    {
      "index": 243,
      "start_time": 765380.0,
      "end_time": 767340.0,
      "text": "in this order of importance."
    },
    {
      "index": 244,
      "start_time": 768180.0,
      "end_time": 770315.0,
      "text": "But after 40 years or so"
    },
    {
      "index": 245,
      "start_time": 770340.0,
      "end_time": 774760.0,
      "text": "and after so many stories pushing these laws to the limit,"
    },
    {
      "index": 246,
      "start_time": 774100.0,
      "end_time": 777796.0,
      "text": "Asimov introduced the zeroth law"
    },
    {
      "index": 247,
      "start_time": 777820.0,
      "end_time": 780760.0,
      "text": "which takes precedence above all,"
    },
    {
      "index": 248,
      "start_time": 780100.0,
      "end_time": 783380.0,
      "text": "and it&#39;s that a robot may not harm humanity as a whole."
    },
    {
      "index": 249,
      "start_time": 784300.0,
      "end_time": 788675.0,
      "text": "I don&#39;t know what this means in the context of driverless cars"
    },
    {
      "index": 250,
      "start_time": 788700.0,
      "end_time": 791436.0,
      "text": "or any specific situation,"
    },
    {
      "index": 251,
      "start_time": 791460.0,
      "end_time": 793676.0,
      "text": "and I don&#39;t know how we can implement it,"
    },
    {
      "index": 252,
      "start_time": 793700.0,
      "end_time": 795236.0,
      "text": "but I think that by recognizing"
    },
    {
      "index": 253,
      "start_time": 795260.0,
      "end_time": 801396.0,
      "text": "that the regulation of driverless cars is not only a technological problem"
    },
    {
      "index": 254,
      "start_time": 801420.0,
      "end_time": 804699.0,
      "text": "but also a societal cooperation problem,"
    },
    {
      "index": 255,
      "start_time": 805620.0,
      "end_time": 808500.0,
      "text": "I hope that we can at least begin to ask the right questions."
    },
    {
      "index": 256,
      "start_time": 809200.0,
      "end_time": 810236.0,
      "text": "Thank you."
    },
    {
      "index": 257,
      "start_time": 810260.0,
      "end_time": 813180.0,
      "text": "(Applause)"
    }
  ]
}